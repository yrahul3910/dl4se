{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from raise_utils.learners import MulticlassDL, FeedforwardDL\n",
    "from raise_utils.data import Data\n",
    "from raise_utils.hyperparams import DODGE\n",
    "from raise_utils.interpret import DODGEInterpreter\n",
    "from keras.utils import to_categorical\n",
    "from raise_utils.hooks import Hook\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Bug-Related-Activity-Logs/eclipse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bugID</th>\n",
       "      <th>user_comments</th>\n",
       "      <th>system_records</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>300005</td>\n",
       "      <td>['backport', 'jar', 'files', 'directory', 'can...</td>\n",
       "      <td>['depends', 'assignee', 'dsdp.tm.rse-inbox', '...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>300005</td>\n",
       "      <td>['samuelwu', 'comment2', 'installed', 'patch',...</td>\n",
       "      <td>['cc', 'samuelwu', 'attachment', 'attachment',...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>300005</td>\n",
       "      <td>['samuelwu', 'comment5', 'thank', 'dave', 'ca'...</td>\n",
       "      <td>['flags', 'review', 'kjdoyle', 'attachment', '...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>300017</td>\n",
       "      <td>['fix', 'warnings', 'cmatheson.can', 'descript...</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>300017</td>\n",
       "      <td>['wayne.beaton', 'wayne.beaton', 'wayne.beaton...</td>\n",
       "      <td>['depends', 'attachment', 'flags', 'iplog', 'd...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   bugID                                      user_comments  \\\n",
       "0           0  300005  ['backport', 'jar', 'files', 'directory', 'can...   \n",
       "1           1  300005  ['samuelwu', 'comment2', 'installed', 'patch',...   \n",
       "2           2  300005  ['samuelwu', 'comment5', 'thank', 'dave', 'ca'...   \n",
       "3           3  300017  ['fix', 'warnings', 'cmatheson.can', 'descript...   \n",
       "4           4  300017  ['wayne.beaton', 'wayne.beaton', 'wayne.beaton...   \n",
       "\n",
       "                                      system_records  s1  s2  s3   s4  s5  s6  \\\n",
       "0  ['depends', 'assignee', 'dsdp.tm.rse-inbox', '...   3   2   1   34   1   0   \n",
       "1  ['cc', 'samuelwu', 'attachment', 'attachment',...   5   3   2   50   2   1   \n",
       "2  ['flags', 'review', 'kjdoyle', 'attachment', '...   6   3   3   37   3   2   \n",
       "3                                                 []   4   4   0  127   1   0   \n",
       "4  ['depends', 'attachment', 'flags', 'iplog', 'd...   4   1   3   84   2   2   \n",
       "\n",
       "          s7  s8      s9  y  \n",
       "0  [0, 0, 0]   1  [1, 1]  2  \n",
       "1  [0, 0, 1]   2  [1, 1]  1  \n",
       "2  [0, 1, 1]   3  [1, 1]  0  \n",
       "3  [0, 0, 0]   1  [1, 1]  9  \n",
       "4  [0, 1, 0]   1  [0, 1]  7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'bugID'], axis=1, inplace=True)\n",
    "_df = df[['s1', 's2', 's3', 's4', 's5', 's6', 's8', 'y']]\n",
    "_df['s70'] = df['s7'].apply(lambda x: eval(x)[0])\n",
    "_df['s71'] = df['s7'].apply(lambda x: eval(x)[1])\n",
    "_df['s72'] = df['s7'].apply(lambda x: eval(x)[2])\n",
    "_df['s90'] = df['s9'].apply(lambda x: eval(x)[0])\n",
    "_df['s91'] = df['s9'].apply(lambda x: eval(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = _df.drop('y', axis=1)\n",
    "y = _df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2 = []\n",
    "\n",
    "def top_2(model, x_test, y_test):\n",
    "    probs = model.model.predict(x_test)\n",
    "    best_n = np.argsort(probs, axis=-1)[:, -2:]\n",
    "    correct = 0\n",
    "    total = len(y_test)\n",
    "    \n",
    "    for i, pred in enumerate(best_n):\n",
    "        if np.argmax(y_test[i], axis=-1) in pred:\n",
    "            correct += 1\n",
    "    print('Top-2 accuracy =', round(correct / total, 3))\n",
    "    top2.append(correct / total)\n",
    "\n",
    "top2_hook = Hook(name='top2', function=top_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = np.where(data.y_train < 6, 0, 1)\n",
    "data.y_test = np.where(data.y_test < 6, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d217610>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 4, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d217670>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d23e820>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d23eb80>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 4, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d23ee20>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 5, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d252100>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d23e8b0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d252610>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d2528b0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 4, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d252b50>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d252df0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 4, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d2560d0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d256370>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d256610>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 5, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d2568b0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d256b50>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d256df0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 2, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d25e0d0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d25e370>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d25e610>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 2, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d25e8b0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 5, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d25eb50>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d25edf0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d2660d0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d266370>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 2, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d266610>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 5, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d2668b0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d266b50>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d266df0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 5, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d26c0d0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 4, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d26c370>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 4, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d26c610>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d26c8b0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d26cb50>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d26cdf0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d2730d0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 4, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d273370>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d273610>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 2, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d2738b0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d273b50>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d273df0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 4, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d27a0d0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 2, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d27a370>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d27a610>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d27a8b0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d27ab50>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 5, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d27adf0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 5, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d27f0d0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d27f370>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d27f610>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d27f8b0>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 6, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': False, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardizeZ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6646 - val_loss: 0.6418\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6297 - val_loss: 0.6245\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.6153\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6112\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6078 - val_loss: 0.6091\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6063 - val_loss: 0.6080\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6052 - val_loss: 0.6079\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6043 - val_loss: 0.6060\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6038 - val_loss: 0.6058\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6031 - val_loss: 0.6061\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6028 - val_loss: 0.6050\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6021 - val_loss: 0.6043\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.6041\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6040\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6012 - val_loss: 0.6035\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6006 - val_loss: 0.6030\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6032\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6029\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5999 - val_loss: 0.6030\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5997 - val_loss: 0.6026\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/raise_utils/learners/feedforward.py:100: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "1\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6683 - val_loss: 0.6365\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6278 - val_loss: 0.6219\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6183 - val_loss: 0.6181\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6148 - val_loss: 0.6162\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6133 - val_loss: 0.6145\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.6131\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6109 - val_loss: 0.6126\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6101 - val_loss: 0.6120\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6094 - val_loss: 0.6113\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6123\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6107\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6078 - val_loss: 0.6099\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6069 - val_loss: 0.6089\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6064 - val_loss: 0.6086\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6059 - val_loss: 0.6081\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.6090\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6066\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6057\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6033 - val_loss: 0.6058\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6030 - val_loss: 0.6060\n",
      "2\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6817 - val_loss: 0.6555\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6384 - val_loss: 0.6259\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6181 - val_loss: 0.6198\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.6131\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6108\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6082 - val_loss: 0.6113\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6079\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6061 - val_loss: 0.6065\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6058 - val_loss: 0.6064\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6052 - val_loss: 0.6062\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6050 - val_loss: 0.6056\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6057\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6053\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6051\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6050\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6052\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6040 - val_loss: 0.6049\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6037 - val_loss: 0.6075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6061\n",
      "3\n",
      "normalizeb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_15 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6778 - val_loss: 0.6537\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6325 - val_loss: 0.6279\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6200 - val_loss: 0.6220\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6160 - val_loss: 0.6195\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6145 - val_loss: 0.6193\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.6175\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 0.6167\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6161\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.6164\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6190\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6156\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6114 - val_loss: 0.6162\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6147\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6102 - val_loss: 0.6152\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6100 - val_loss: 0.6143\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6097 - val_loss: 0.6141\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6094 - val_loss: 0.6137\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6090 - val_loss: 0.6132\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.6128\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6082 - val_loss: 0.6150\n",
      "4\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_20 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6996 - val_loss: 0.6783\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6690 - val_loss: 0.6589\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6466 - val_loss: 0.6383\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6328 - val_loss: 0.6315\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6270 - val_loss: 0.6271\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6233 - val_loss: 0.6248\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6208 - val_loss: 0.6229\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6185 - val_loss: 0.6211\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6169 - val_loss: 0.6198\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6156 - val_loss: 0.6194\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.6181\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 0.6175\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6133 - val_loss: 0.6170\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.6167\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.6170\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6162\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.6159\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6110 - val_loss: 0.6159\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6153\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6103 - val_loss: 0.6152\n",
      "5\n",
      "normalizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6862 - val_loss: 0.6694\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6480 - val_loss: 0.6275\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6226 - val_loss: 0.6227\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6183 - val_loss: 0.6202\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6181\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 0.6155\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6168\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6143\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 0.6137\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6093 - val_loss: 0.6140\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.6152\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6110\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6073 - val_loss: 0.6140\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6065 - val_loss: 0.6091\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6093\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6044 - val_loss: 0.6085\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6041 - val_loss: 0.6081\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6092\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 0.6078\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6073\n",
      "6\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6686 - val_loss: 0.6359\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6241 - val_loss: 0.6250\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6182 - val_loss: 0.6212\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.6177\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6144\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6148\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6118\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6112\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6106\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6108\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 0.6101\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6101\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6099\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6102\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6102\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6095\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6090\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6118\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 0.6089\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6089\n",
      "7\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_31 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6582 - val_loss: 0.6302\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6221 - val_loss: 0.6212\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6163 - val_loss: 0.6189\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6137 - val_loss: 0.6186\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.6155\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6109 - val_loss: 0.6146\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6103 - val_loss: 0.6131\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.6123\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6083 - val_loss: 0.6115\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6077 - val_loss: 0.6112\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6076 - val_loss: 0.6105\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.6103\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6059 - val_loss: 0.6103\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6053 - val_loss: 0.6086\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6050 - val_loss: 0.6091\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6049 - val_loss: 0.6091\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6038 - val_loss: 0.6073\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6039 - val_loss: 0.6071\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6032 - val_loss: 0.6078\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6032 - val_loss: 0.6070\n",
      "8\n",
      "maxabsv|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_35 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6586 - val_loss: 0.6442\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6342 - val_loss: 0.6306\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6235 - val_loss: 0.6250\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6189 - val_loss: 0.6209\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6161 - val_loss: 0.6192\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6149 - val_loss: 0.6178\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6137 - val_loss: 0.6171\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.6156\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.6147\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6111 - val_loss: 0.6144\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6138\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6099 - val_loss: 0.6131\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6098 - val_loss: 0.6124\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6093 - val_loss: 0.6121\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6088 - val_loss: 0.6124\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6083 - val_loss: 0.6114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6081 - val_loss: 0.6106\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6079 - val_loss: 0.6104\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6075 - val_loss: 0.6101\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.6097\n",
      "9\n",
      "minmaxh|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_38 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6640 - val_loss: 0.6313\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6253 - val_loss: 0.6303\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6207 - val_loss: 0.6204\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.6222\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6187\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6142 - val_loss: 0.6163\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6133 - val_loss: 0.6187\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 0.6151\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.6145\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.6127\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6171\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6193\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6119\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6136\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6107\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6106\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6247\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6182\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 0.6151\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6091\n",
      "10\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6903 - val_loss: 0.6885\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6893 - val_loss: 0.6875\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6884 - val_loss: 0.6863\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6864 - val_loss: 0.6831\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6807 - val_loss: 0.6736\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6684 - val_loss: 0.6621\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6580 - val_loss: 0.6546\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6520 - val_loss: 0.6500\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6473 - val_loss: 0.6452\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6398 - val_loss: 0.6398\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6347 - val_loss: 0.6375\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6319 - val_loss: 0.6354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6301 - val_loss: 0.6342\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6287 - val_loss: 0.6333\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6275 - val_loss: 0.6337\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6267 - val_loss: 0.6319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6261 - val_loss: 0.6314\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6255 - val_loss: 0.6311\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6250 - val_loss: 0.6306\n",
      "11\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_48 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6653 - val_loss: 0.6388\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6301 - val_loss: 0.6302\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6247 - val_loss: 0.6281\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6228 - val_loss: 0.6262\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6215 - val_loss: 0.6248\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6201 - val_loss: 0.6243\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6188 - val_loss: 0.6215\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6173 - val_loss: 0.6211\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6159 - val_loss: 0.6196\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.6186\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6141 - val_loss: 0.6172\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.6188\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6134 - val_loss: 0.6161\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.6156\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.6148\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6108 - val_loss: 0.6146\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6147\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6098 - val_loss: 0.6171\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6096 - val_loss: 0.6133\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6096 - val_loss: 0.6132\n",
      "12\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_52 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6741 - val_loss: 0.6568\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6441 - val_loss: 0.6422\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6375 - val_loss: 0.6385\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6340 - val_loss: 0.6367\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6327 - val_loss: 0.6372\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6317 - val_loss: 0.6353\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6307 - val_loss: 0.6373\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6303 - val_loss: 0.6352\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6286 - val_loss: 0.6323\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.6304\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6233 - val_loss: 0.6295\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6229 - val_loss: 0.6279\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6221 - val_loss: 0.6279\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6213 - val_loss: 0.6264\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6211 - val_loss: 0.6266\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6208 - val_loss: 0.6275\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6204 - val_loss: 0.6263\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6202 - val_loss: 0.6269\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6196 - val_loss: 0.6252\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6196 - val_loss: 0.6256\n",
      "13\n",
      "robustd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6593 - val_loss: 0.6274\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6142 - val_loss: 0.6111\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6085\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6075\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6074\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6063\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6061\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6062\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6069\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 0.6060\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6007 - val_loss: 0.6061\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 0.6056\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6001 - val_loss: 0.6065\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 0.6049\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6050\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 0.6050\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5993 - val_loss: 0.6048\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6000 - val_loss: 0.6053\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 0.6049\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5989 - val_loss: 0.6074\n",
      "14\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_62 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6727 - val_loss: 0.6581\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6456 - val_loss: 0.6443\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6348 - val_loss: 0.6382\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6288 - val_loss: 0.6332\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6239 - val_loss: 0.6279\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6192 - val_loss: 0.6233\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6161 - val_loss: 0.6198\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6184\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.6179\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.6171\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.6164\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6108 - val_loss: 0.6160\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6104 - val_loss: 0.6154\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6096 - val_loss: 0.6147\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6093 - val_loss: 0.6140\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.6134\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6085 - val_loss: 0.6133\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6077 - val_loss: 0.6129\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6075 - val_loss: 0.6124\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.6121\n",
      "15\n",
      "normalizeQ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_68 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6580 - val_loss: 0.6356\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6233 - val_loss: 0.6184\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 0.6141\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6085 - val_loss: 0.6110\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6095\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6057 - val_loss: 0.6089\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6048 - val_loss: 0.6092\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6044 - val_loss: 0.6081\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6080\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6029 - val_loss: 0.6076\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6078\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6024 - val_loss: 0.6077\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6018 - val_loss: 0.6072\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6013 - val_loss: 0.6071\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.6070\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6009 - val_loss: 0.6081\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6010 - val_loss: 0.6065\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6001 - val_loss: 0.6070\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 0.6078\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.6061\n",
      "16\n",
      "robustp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_73 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6709 - val_loss: 0.6440\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6235 - val_loss: 0.6199\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6128 - val_loss: 0.6173\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.6156\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6101 - val_loss: 0.6130\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6121\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6073 - val_loss: 0.6118\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.6108\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6110\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.6113\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6037 - val_loss: 0.6098\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6106\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6108\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6094\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6100\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6025 - val_loss: 0.6092\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6027 - val_loss: 0.6080\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6083\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6012 - val_loss: 0.6079\n",
      "17\n",
      "robusth|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_80 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6519 - val_loss: 0.6289\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6176 - val_loss: 0.6201\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6151\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6126\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6136\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6123\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.6109\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6108\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6044 - val_loss: 0.6101\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6083\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6078\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6078\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6070\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6073\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6070\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6011 - val_loss: 0.6065\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6057\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 0.6065\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5999 - val_loss: 0.6054\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5997 - val_loss: 0.6053\n",
      "18\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_87 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6760 - val_loss: 0.6569\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6390 - val_loss: 0.6360\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6262 - val_loss: 0.6290\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6209 - val_loss: 0.6238\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6178 - val_loss: 0.6212\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6157 - val_loss: 0.6205\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6177\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6130 - val_loss: 0.6167\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6160\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6112 - val_loss: 0.6151\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6103 - val_loss: 0.6143\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6097 - val_loss: 0.6146\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.6134\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.6133\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6082 - val_loss: 0.6127\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6074 - val_loss: 0.6113\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.6110\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.6107\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6102\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6058 - val_loss: 0.6100\n",
      "19\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_91 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6659 - val_loss: 0.6333\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6234 - val_loss: 0.6217\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.6171\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6143\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6094 - val_loss: 0.6173\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6085 - val_loss: 0.6122\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6075 - val_loss: 0.6125\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6124\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 0.6112\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 0.6124\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6042 - val_loss: 0.6102\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6039 - val_loss: 0.6102\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6106\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6028 - val_loss: 0.6109\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6099\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 0.6105\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6017 - val_loss: 0.6101\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.6099\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6009 - val_loss: 0.6093\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6006 - val_loss: 0.6107\n",
      "20\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_98 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7461 - val_loss: 0.6793\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6638 - val_loss: 0.6575\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6470 - val_loss: 0.6457\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6373 - val_loss: 0.6393\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6324 - val_loss: 0.6351\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6293 - val_loss: 0.6326\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6271 - val_loss: 0.6306\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6251 - val_loss: 0.6285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6232 - val_loss: 0.6269\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6218 - val_loss: 0.6252\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6205 - val_loss: 0.6239\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6194 - val_loss: 0.6229\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6186 - val_loss: 0.6220\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6178 - val_loss: 0.6212\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6171 - val_loss: 0.6205\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6164 - val_loss: 0.6197\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6160 - val_loss: 0.6194\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6152 - val_loss: 0.6188\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6151 - val_loss: 0.6189\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6145 - val_loss: 0.6179\n",
      "21\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_103 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6903 - val_loss: 0.6835\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6733 - val_loss: 0.6578\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6475 - val_loss: 0.6402\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6297 - val_loss: 0.6287\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6214 - val_loss: 0.6243\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6180 - val_loss: 0.6225\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6163 - val_loss: 0.6216\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.6221\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6148 - val_loss: 0.6199\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6194\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6191\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6137 - val_loss: 0.6189\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6137 - val_loss: 0.6191\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6133 - val_loss: 0.6183\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6130 - val_loss: 0.6185\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.6179\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.6177\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.6173\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.6175\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6179\n",
      "22\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6639 - val_loss: 0.6344\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6215 - val_loss: 0.6205\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6173 - val_loss: 0.6192\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6123 - val_loss: 0.6142\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 0.6100\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6095\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6080\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6085\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6092\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6077\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6103\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6079\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6067\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 0.6067\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6088\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6010 - val_loss: 0.6065\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.6071\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5996 - val_loss: 0.6088\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5999 - val_loss: 0.6074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5999 - val_loss: 0.6086\n",
      "23\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_111 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6517 - val_loss: 0.6353\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6242 - val_loss: 0.6259\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.6205\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 0.6170\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6155\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6144\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6148\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6133\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6107\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6149\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6097\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 0.6086\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6097\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6110\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.6080\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6006 - val_loss: 0.6086\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6084\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 0.6081\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6079\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6000 - val_loss: 0.6076\n",
      "24\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_118 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6771 - val_loss: 0.6565\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6367 - val_loss: 0.6313\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6252 - val_loss: 0.6276\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6215 - val_loss: 0.6245\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6184 - val_loss: 0.6220\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6159 - val_loss: 0.6200\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6141 - val_loss: 0.6182\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.6176\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.6166\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6111 - val_loss: 0.6155\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 0.6150\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6100 - val_loss: 0.6143\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.6136\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.6127\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6121\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6077 - val_loss: 0.6114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.6113\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6069 - val_loss: 0.6106\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6064 - val_loss: 0.6104\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6063 - val_loss: 0.6096\n",
      "25\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_122 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6819 - val_loss: 0.6688\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6543 - val_loss: 0.6412\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6276 - val_loss: 0.6265\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6181 - val_loss: 0.6209\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6150 - val_loss: 0.6185\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.6160\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6157\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6142\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6105 - val_loss: 0.6135\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6099 - val_loss: 0.6132\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6098 - val_loss: 0.6126\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.6121\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6086 - val_loss: 0.6117\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6084 - val_loss: 0.6117\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6080 - val_loss: 0.6113\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6081 - val_loss: 0.6112\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6076 - val_loss: 0.6105\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6071 - val_loss: 0.6101\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 0.6098\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6065 - val_loss: 0.6097\n",
      "26\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_127 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6575 - val_loss: 0.6303\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6210 - val_loss: 0.6234\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6155 - val_loss: 0.6178\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6123 - val_loss: 0.6150\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.6131\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6081 - val_loss: 0.6121\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.6109\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6061 - val_loss: 0.6102\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6098\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 0.6108\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6044 - val_loss: 0.6092\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6031 - val_loss: 0.6091\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6084\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6020 - val_loss: 0.6086\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6091\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6087\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6022 - val_loss: 0.6079\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 0.6078\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6003 - val_loss: 0.6075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6078\n",
      "27\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_134 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6864 - val_loss: 0.6721\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6604 - val_loss: 0.6485\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6400 - val_loss: 0.6357\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6302 - val_loss: 0.6300\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6256 - val_loss: 0.6273\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6230 - val_loss: 0.6255\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6211 - val_loss: 0.6241\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6197 - val_loss: 0.6228\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6186 - val_loss: 0.6218\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6176 - val_loss: 0.6209\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 0.6203\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6162 - val_loss: 0.6195\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6156 - val_loss: 0.6193\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6152 - val_loss: 0.6185\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.6182\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6178\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6176\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6136 - val_loss: 0.6173\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6133 - val_loss: 0.6169\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6131 - val_loss: 0.6167\n",
      "28\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6811 - val_loss: 0.6631\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6407 - val_loss: 0.6258\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6179 - val_loss: 0.6166\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6134 - val_loss: 0.6143\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.6138\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6100 - val_loss: 0.6131\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6096 - val_loss: 0.6122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6086 - val_loss: 0.6116\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6078 - val_loss: 0.6112\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6103\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6102\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6061 - val_loss: 0.6103\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6056 - val_loss: 0.6100\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6056 - val_loss: 0.6095\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6088\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6046 - val_loss: 0.6089\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6043 - val_loss: 0.6091\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6043 - val_loss: 0.6096\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6039 - val_loss: 0.6081\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6076\n",
      "29\n",
      "normalized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6910 - val_loss: 0.6886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6881 - val_loss: 0.6825\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6733 - val_loss: 0.6593\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6511 - val_loss: 0.6401\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6374 - val_loss: 0.6323\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.6287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6275 - val_loss: 0.6259\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6248 - val_loss: 0.6241\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6227 - val_loss: 0.6228\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6214 - val_loss: 0.6215\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6201 - val_loss: 0.6208\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6188 - val_loss: 0.6197\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6178 - val_loss: 0.6191\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 0.6184\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6158 - val_loss: 0.6177\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6150 - val_loss: 0.6170\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6140 - val_loss: 0.6163\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.6157\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.6150\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6144\n",
      "0\n",
      "minmaxo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6780 - val_loss: 0.6484\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6348 - val_loss: 0.6261\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6185\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6141 - val_loss: 0.6162\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6152\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6331\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6141 - val_loss: 0.6134\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6104 - val_loss: 0.6139\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.6155\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 0.6114\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.6157\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6127\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6114\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6125\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6128\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6070 - val_loss: 0.6116\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6066 - val_loss: 0.6095\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6097\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6059 - val_loss: 0.6147\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6082 - val_loss: 0.6084\n",
      "1\n",
      "normalizeT|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_149 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6827 - val_loss: 0.6695\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6576 - val_loss: 0.6503\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6425 - val_loss: 0.6396\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6331 - val_loss: 0.6322\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6269 - val_loss: 0.6285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6228 - val_loss: 0.6249\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6201 - val_loss: 0.6242\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6190 - val_loss: 0.6225\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6182 - val_loss: 0.6218\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6174 - val_loss: 0.6215\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6169 - val_loss: 0.6218\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6166 - val_loss: 0.6227\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6165 - val_loss: 0.6205\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6202\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.6207\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.6204\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.6202\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.6208\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.6203\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.6197\n",
      "2\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6827 - val_loss: 0.6681\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6516 - val_loss: 0.6395\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6289 - val_loss: 0.6271\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6198 - val_loss: 0.6230\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 0.6214\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6157 - val_loss: 0.6207\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6154 - val_loss: 0.6195\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6151 - val_loss: 0.6190\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6151 - val_loss: 0.6190\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.6188\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6145 - val_loss: 0.6185\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6188\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6141 - val_loss: 0.6189\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6151 - val_loss: 0.6199\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6182\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6193\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6140 - val_loss: 0.6190\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6182\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6137 - val_loss: 0.6178\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.6180\n",
      "3\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_155 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 0.6660\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6496 - val_loss: 0.6442\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6346 - val_loss: 0.6356\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6280 - val_loss: 0.6308\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6240 - val_loss: 0.6278\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6214 - val_loss: 0.6248\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6196 - val_loss: 0.6232\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6181 - val_loss: 0.6214\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6171 - val_loss: 0.6207\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6161 - val_loss: 0.6202\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6156 - val_loss: 0.6190\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6148 - val_loss: 0.6185\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6142 - val_loss: 0.6174\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6174\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6134 - val_loss: 0.6165\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6130 - val_loss: 0.6164\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6127 - val_loss: 0.6164\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.6158\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.6157\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6155\n",
      "4\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6578 - val_loss: 0.6279\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6174 - val_loss: 0.6200\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6148\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6254\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6145\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6122\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6073 - val_loss: 0.6155\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6110\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6120\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6192\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6109\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6166\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6111\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6097\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6097\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6044 - val_loss: 0.6090\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6112\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6099\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6102\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6104\n",
      "5\n",
      "minmaxp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_165 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6886 - val_loss: 0.6763\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6548 - val_loss: 0.6367\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6280 - val_loss: 0.6254\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6193 - val_loss: 0.6236\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.6197\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.6187\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6192\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6192\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6202\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6187\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6178\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6131 - val_loss: 0.6175\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.6174\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6170\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6127 - val_loss: 0.6166\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.6171\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.6167\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6170\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6161\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6197\n",
      "6\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_170 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6788 - val_loss: 0.6557\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6431 - val_loss: 0.6350\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6243 - val_loss: 0.6242\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6189 - val_loss: 0.6218\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.6212\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.6200\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6151 - val_loss: 0.6189\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.6198\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6150 - val_loss: 0.6182\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6159 - val_loss: 0.6178\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 0.6177\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 0.6178\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.6174\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6136 - val_loss: 0.6166\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6176\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.6175\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6127 - val_loss: 0.6165\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6128 - val_loss: 0.6160\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6161\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6127 - val_loss: 0.6192\n",
      "7\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6973 - val_loss: 0.6892\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6869 - val_loss: 0.6814\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6725 - val_loss: 0.6581\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6461 - val_loss: 0.6350\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6270 - val_loss: 0.6230\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6189 - val_loss: 0.6192\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6165 - val_loss: 0.6176\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6153 - val_loss: 0.6164\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6158\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6155\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6134 - val_loss: 0.6152\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6131 - val_loss: 0.6149\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.6143\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.6141\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6138\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6138\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.6138\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6137\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6137\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.6137\n",
      "8\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6537 - val_loss: 0.6222\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.6130\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6100 - val_loss: 0.6162\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6095\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6076 - val_loss: 0.6097\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6064 - val_loss: 0.6084\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6288\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6067\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6064\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6033 - val_loss: 0.6067\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6067\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6052\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6051\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6019 - val_loss: 0.6056\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6045\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6040 - val_loss: 0.6044\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6120\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.6049\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6010 - val_loss: 0.6061\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6073\n",
      "9\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6787 - val_loss: 0.6548\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6434 - val_loss: 0.6320\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6230 - val_loss: 0.6224\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6146 - val_loss: 0.6155\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 0.6172\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6114 - val_loss: 0.6148\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6282\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6114 - val_loss: 0.6169\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6129\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6178\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.6122\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6107\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6133\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6073 - val_loss: 0.6114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.6105\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6059 - val_loss: 0.6106\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.6098\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6093\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6070 - val_loss: 0.6096\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6103\n",
      "10\n",
      "minmaxT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6837 - val_loss: 0.6676\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6424 - val_loss: 0.6255\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.6169\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 0.6162\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.6133\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6105 - val_loss: 0.6133\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.6150\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6103 - val_loss: 0.6144\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6104 - val_loss: 0.6126\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6096 - val_loss: 0.6122\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.6118\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6098 - val_loss: 0.6115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.6122\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.6123\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6085 - val_loss: 0.6113\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6079 - val_loss: 0.6103\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6075 - val_loss: 0.6101\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.6107\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6078 - val_loss: 0.6109\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6069 - val_loss: 0.6109\n",
      "11\n",
      "normalizek|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_196 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6911 - val_loss: 0.6886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6895 - val_loss: 0.6876\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6881 - val_loss: 0.6854\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6848 - val_loss: 0.6807\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6797 - val_loss: 0.6748\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6738 - val_loss: 0.6689\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6679 - val_loss: 0.6632\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6618 - val_loss: 0.6580\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6560 - val_loss: 0.6520\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6501 - val_loss: 0.6468\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6442 - val_loss: 0.6410\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6385 - val_loss: 0.6363\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6340 - val_loss: 0.6331\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6304 - val_loss: 0.6319\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6269 - val_loss: 0.6275\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6242 - val_loss: 0.6253\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6226 - val_loss: 0.6238\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6207 - val_loss: 0.6233\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6199 - val_loss: 0.6223\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6186 - val_loss: 0.6213\n",
      "12\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6655 - val_loss: 0.6454\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.6226\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6148 - val_loss: 0.6140\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.6124\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6103\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6091\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6089\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6080\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6083\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6077\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 0.6079\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 0.6082\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6064\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6059\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6062\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6058\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6063\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6057\n",
      "13\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_205 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6920 - val_loss: 0.6906\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6906 - val_loss: 0.6893\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6900 - val_loss: 0.6887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "14\n",
      "maxabsC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6692 - val_loss: 0.6421\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6279 - val_loss: 0.6230\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6185 - val_loss: 0.6192\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.6150\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6122\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6110\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6118\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6108\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6059 - val_loss: 0.6103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6054 - val_loss: 0.6099\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6064 - val_loss: 0.6129\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6039 - val_loss: 0.6076\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6088\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6103\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.6102\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6089\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6032 - val_loss: 0.6067\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6097\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6081\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.6073\n",
      "15\n",
      "standardizeq|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_215 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6654 - val_loss: 0.6371\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6235 - val_loss: 0.6232\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6154 - val_loss: 0.6182\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6163\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6109 - val_loss: 0.6150\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6094 - val_loss: 0.6135\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6083 - val_loss: 0.6137\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6074 - val_loss: 0.6127\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.6118\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6062 - val_loss: 0.6122\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6056 - val_loss: 0.6112\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6053 - val_loss: 0.6114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 0.6104\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6042 - val_loss: 0.6099\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6043 - val_loss: 0.6102\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6035 - val_loss: 0.6099\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6033 - val_loss: 0.6111\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6032 - val_loss: 0.6096\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6027 - val_loss: 0.6095\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6025 - val_loss: 0.6091\n",
      "16\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_219 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6874 - val_loss: 0.6701\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6532 - val_loss: 0.6390\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6316 - val_loss: 0.6274\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6221 - val_loss: 0.6227\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6179 - val_loss: 0.6201\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6156 - val_loss: 0.6185\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6170\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 0.6193\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6155\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.6145\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6107 - val_loss: 0.6148\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6103 - val_loss: 0.6147\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6101 - val_loss: 0.6145\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6091 - val_loss: 0.6124\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.6136\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6143\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6115\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6074 - val_loss: 0.6124\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6074 - val_loss: 0.6111\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6071 - val_loss: 0.6111\n",
      "17\n",
      "maxabsH|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_223 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6875 - val_loss: 0.6815\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6738 - val_loss: 0.6628\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6596 - val_loss: 0.6538\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6495 - val_loss: 0.6440\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6400 - val_loss: 0.6371\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6327 - val_loss: 0.6315\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6275 - val_loss: 0.6280\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6232 - val_loss: 0.6253\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6217 - val_loss: 0.6241\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6191 - val_loss: 0.6230\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6176 - val_loss: 0.6210\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 0.6200\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6161 - val_loss: 0.6197\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6153 - val_loss: 0.6195\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6155 - val_loss: 0.6184\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6149 - val_loss: 0.6185\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6142 - val_loss: 0.6201\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6142 - val_loss: 0.6181\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6141 - val_loss: 0.6183\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6190\n",
      "18\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6681 - val_loss: 0.6482\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6273 - val_loss: 0.6211\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 0.6135\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6115\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6107\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.6180\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6065 - val_loss: 0.6105\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6056 - val_loss: 0.6100\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6100\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6088\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6094\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.6082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.6104\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6044 - val_loss: 0.6117\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6081\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6104\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6104\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6081\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6085\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6035 - val_loss: 0.6081\n",
      "19\n",
      "standardizef|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_234 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6730 - val_loss: 0.6427\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6356 - val_loss: 0.6286\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.6225\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.6161\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 0.6148\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.6134\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6124\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6108 - val_loss: 0.6124\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6082 - val_loss: 0.6121\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6111\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6106\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6109\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 0.6111\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6061 - val_loss: 0.6095\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6062 - val_loss: 0.6095\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6056 - val_loss: 0.6100\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6091\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6052 - val_loss: 0.6091\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6049 - val_loss: 0.6085\n",
      "20\n",
      "robustp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6900 - val_loss: 0.6891\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6899 - val_loss: 0.6888\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6888\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6887\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "21\n",
      "robusth|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6789 - val_loss: 0.6475\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.6208\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6136\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6115\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6154\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.6116\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6094\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6094\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6101\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6087\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6089\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.6086\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6121\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6103\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6084\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6077\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6099\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.6077\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6011 - val_loss: 0.6078\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6103\n",
      "22\n",
      "normalizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6566 - val_loss: 0.6254\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6091 - val_loss: 0.6085\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.6075\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6007 - val_loss: 0.6129\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 0.6080\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5995 - val_loss: 0.6109\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6005 - val_loss: 0.6076\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5997 - val_loss: 0.6105\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6016 - val_loss: 0.6068\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5993 - val_loss: 0.6082\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5989 - val_loss: 0.6079\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5994 - val_loss: 0.6069\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5985 - val_loss: 0.6073\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 0.6065\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5984 - val_loss: 0.6068\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5989 - val_loss: 0.6064\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5978 - val_loss: 0.6056\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5977 - val_loss: 0.6058\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5971 - val_loss: 0.6072\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5984 - val_loss: 0.6063\n",
      "23\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6880 - val_loss: 0.6790\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6595 - val_loss: 0.6395\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6235 - val_loss: 0.6205\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6140 - val_loss: 0.6171\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6162\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.6154\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6111 - val_loss: 0.6162\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6145\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6105 - val_loss: 0.6155\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6139\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.6138\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6098 - val_loss: 0.6141\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6096 - val_loss: 0.6134\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.6125\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6090 - val_loss: 0.6125\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6091 - val_loss: 0.6131\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6125\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 0.6147\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.6120\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6120\n",
      "24\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6763 - val_loss: 0.6560\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6365 - val_loss: 0.6314\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.6240\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6182 - val_loss: 0.6216\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6158 - val_loss: 0.6188\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 0.6208\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.6178\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 0.6172\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 0.6170\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6127 - val_loss: 0.6169\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.6163\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6167\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6156\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.6160\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6149\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6097 - val_loss: 0.6144\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6096 - val_loss: 0.6160\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6137\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6090 - val_loss: 0.6140\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6135\n",
      "25\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6910 - val_loss: 0.6880\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6814 - val_loss: 0.6686\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6512 - val_loss: 0.6387\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6284 - val_loss: 0.6273\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6216 - val_loss: 0.6246\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6197 - val_loss: 0.6225\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6185 - val_loss: 0.6213\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6180 - val_loss: 0.6205\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 0.6196\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6159 - val_loss: 0.6187\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6152 - val_loss: 0.6181\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6146 - val_loss: 0.6185\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6142 - val_loss: 0.6175\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6139 - val_loss: 0.6174\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6172\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6134 - val_loss: 0.6176\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6134 - val_loss: 0.6174\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 0.6180\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6129 - val_loss: 0.6171\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.6171\n",
      "26\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6907 - val_loss: 0.6887\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6897 - val_loss: 0.6860\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6712 - val_loss: 0.6495\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6471 - val_loss: 0.6378\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6386 - val_loss: 0.6295\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.6252\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6259 - val_loss: 0.6231\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6225 - val_loss: 0.6208\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.6197\n",
      "27\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_278 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6662 - val_loss: 0.6427\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6288 - val_loss: 0.6236\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6183 - val_loss: 0.6223\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6164 - val_loss: 0.6206\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6150 - val_loss: 0.6206\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6189\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6140 - val_loss: 0.6183\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6134 - val_loss: 0.6174\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 0.6198\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6172\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.6169\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.6179\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6167\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.6175\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.6159\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6109 - val_loss: 0.6177\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6112 - val_loss: 0.6160\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6103 - val_loss: 0.6151\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6101 - val_loss: 0.6148\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6100 - val_loss: 0.6149\n",
      "28\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_282 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6647 - val_loss: 0.6455\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6319 - val_loss: 0.6296\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6217 - val_loss: 0.6255\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6175 - val_loss: 0.6209\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.6203\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6134 - val_loss: 0.6186\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6174\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6111 - val_loss: 0.6166\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6105 - val_loss: 0.6168\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6098 - val_loss: 0.6158\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6093 - val_loss: 0.6150\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6086 - val_loss: 0.6152\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6081 - val_loss: 0.6144\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6080 - val_loss: 0.6138\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6073 - val_loss: 0.6139\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 0.6132\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.6129\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6127\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6060 - val_loss: 0.6128\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6058 - val_loss: 0.6122\n",
      "29\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_286 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6615 - val_loss: 0.6344\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6214 - val_loss: 0.6199\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6158 - val_loss: 0.6182\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6138 - val_loss: 0.6169\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6163\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6148\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6143\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6142\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6134\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6141\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6124\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.6126\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6119\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.6129\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.6121\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6108\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6115\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6111\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6101\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6114\n",
      "0\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6546 - val_loss: 0.6159\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.6116\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6095\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6139\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6061\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 0.6059\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5996 - val_loss: 0.6067\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 0.6064\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5982 - val_loss: 0.6041\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5984 - val_loss: 0.6045\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5978 - val_loss: 0.6045\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5974 - val_loss: 0.6043\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5980 - val_loss: 0.6061\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5972 - val_loss: 0.6061\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5970 - val_loss: 0.6049\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5973 - val_loss: 0.6057\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5968 - val_loss: 0.6041\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5974 - val_loss: 0.6044\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5959 - val_loss: 0.6060\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5960 - val_loss: 0.6040\n",
      "1\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6809 - val_loss: 0.6650\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6465 - val_loss: 0.6355\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.6216\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.6156\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6133\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.6124\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6118\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6099\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 0.6100\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6111\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6083\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6086\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6033 - val_loss: 0.6068\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6072\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 0.6068\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6057\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.6070\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6060\n",
      "2\n",
      "normalizeq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6741 - val_loss: 0.6395\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6241 - val_loss: 0.6148\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6101 - val_loss: 0.6094\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6081 - val_loss: 0.6089\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6061 - val_loss: 0.6083\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6092\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.6070\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6040 - val_loss: 0.6064\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6020 - val_loss: 0.6056\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 0.6060\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6028 - val_loss: 0.6046\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6053\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6009 - val_loss: 0.6045\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6051\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6047\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6016 - val_loss: 0.6048\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 0.6047\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 0.6049\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 0.6055\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5998 - val_loss: 0.6043\n",
      "3\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6791 - val_loss: 0.6655\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6570 - val_loss: 0.6563\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6477 - val_loss: 0.6490\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6407 - val_loss: 0.6430\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6353 - val_loss: 0.6382\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.6343\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6272 - val_loss: 0.6307\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6241 - val_loss: 0.6276\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6215 - val_loss: 0.6254\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6194 - val_loss: 0.6232\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6177 - val_loss: 0.6224\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6163 - val_loss: 0.6199\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6151 - val_loss: 0.6190\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6141 - val_loss: 0.6179\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6134 - val_loss: 0.6169\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6127 - val_loss: 0.6163\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.6157\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6154\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6150\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6111 - val_loss: 0.6146\n",
      "4\n",
      "maxabsj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6667 - val_loss: 0.6268\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6126\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6111\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6118\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6113\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 0.6130\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6044 - val_loss: 0.6126\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6116\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6033 - val_loss: 0.6096\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6106\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6108\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6100\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6103\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6092\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6088\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6085\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6089\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6096\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6088\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6080\n",
      "5\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6879 - val_loss: 0.6654\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6388 - val_loss: 0.6279\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6171 - val_loss: 0.6158\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6094 - val_loss: 0.6142\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6058 - val_loss: 0.6204\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6083 - val_loss: 0.6077\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6080\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6026 - val_loss: 0.6081\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6026 - val_loss: 0.6105\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 0.6070\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6015 - val_loss: 0.6069\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6020 - val_loss: 0.6071\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6010 - val_loss: 0.6148\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6020 - val_loss: 0.6061\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6008 - val_loss: 0.6073\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6003 - val_loss: 0.6053\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6008 - val_loss: 0.6053\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5996 - val_loss: 0.6055\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6002 - val_loss: 0.6059\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5997 - val_loss: 0.6068\n",
      "6\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6864 - val_loss: 0.6785\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6624 - val_loss: 0.6497\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6367 - val_loss: 0.6335\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6246 - val_loss: 0.6263\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6199 - val_loss: 0.6225\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6172 - val_loss: 0.6214\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6163 - val_loss: 0.6195\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6154 - val_loss: 0.6190\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6151 - val_loss: 0.6186\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6148 - val_loss: 0.6187\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6145 - val_loss: 0.6184\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6184\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6182\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6183\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6140 - val_loss: 0.6186\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6185\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 0.6183\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6140 - val_loss: 0.6180\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6138 - val_loss: 0.6189\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6138 - val_loss: 0.6181\n",
      "7\n",
      "maxabse|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6904 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6895 - val_loss: 0.6859\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6617 - val_loss: 0.6343\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6263 - val_loss: 0.6239\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6187 - val_loss: 0.6197\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6107 - val_loss: 0.6082\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6057 - val_loss: 0.6064\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.6052\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6023 - val_loss: 0.6049\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.6037\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6014 - val_loss: 0.6037\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6001 - val_loss: 0.6042\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6001 - val_loss: 0.6038\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5999 - val_loss: 0.6028\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6003 - val_loss: 0.6030\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5998 - val_loss: 0.6048\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6002 - val_loss: 0.6045\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5988 - val_loss: 0.6025\n",
      "8\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6765 - val_loss: 0.6579\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6392 - val_loss: 0.6271\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.6171\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 0.6134\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6113\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6109\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6103\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6092\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6089\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6073 - val_loss: 0.6087\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6078\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6095\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6120\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6087\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6068\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6080\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6095\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6064\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6066\n",
      "9\n",
      "minmaxQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6658 - val_loss: 0.6455\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6278 - val_loss: 0.6206\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 0.6142\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6111 - val_loss: 0.6203\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.6127\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6096 - val_loss: 0.6121\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6140\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.6113\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.6109\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6085 - val_loss: 0.6106\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6076 - val_loss: 0.6115\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6101\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6073 - val_loss: 0.6100\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.6096\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.6100\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6067 - val_loss: 0.6109\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6070 - val_loss: 0.6116\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.6087\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6060 - val_loss: 0.6087\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6053 - val_loss: 0.6115\n",
      "10\n",
      "normalizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6863 - val_loss: 0.6697\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6432 - val_loss: 0.6315\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6203 - val_loss: 0.6209\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6145 - val_loss: 0.6180\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 0.6184\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6130 - val_loss: 0.6169\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6128 - val_loss: 0.6166\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6169\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6149\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6110 - val_loss: 0.6160\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6146\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6107 - val_loss: 0.6167\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6141\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 0.6126\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6091 - val_loss: 0.6146\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.6128\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6163\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.6111\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.6118\n",
      "11\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6886 - val_loss: 0.6818\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6716 - val_loss: 0.6586\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6422 - val_loss: 0.6306\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6214 - val_loss: 0.6213\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6186\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 0.6170\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 0.6159\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.6152\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6160\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6111 - val_loss: 0.6147\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6108 - val_loss: 0.6142\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 0.6142\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6096 - val_loss: 0.6129\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6090 - val_loss: 0.6123\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.6118\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6112\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.6110\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.6105\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6105\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6056 - val_loss: 0.6100\n",
      "12\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6888 - val_loss: 0.6807\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6583 - val_loss: 0.6331\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6226 - val_loss: 0.6206\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6172\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 0.6165\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.6149\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6113 - val_loss: 0.6139\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6109 - val_loss: 0.6135\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 0.6129\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6130\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 0.6113\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6073 - val_loss: 0.6104\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.6103\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6058 - val_loss: 0.6092\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6053 - val_loss: 0.6085\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6084\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6081\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6042 - val_loss: 0.6075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6039 - val_loss: 0.6074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6077\n",
      "13\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_356 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6663 - val_loss: 0.6412\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.6212\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.6155\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6131 - val_loss: 0.6135\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6121\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6099 - val_loss: 0.6117\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6089 - val_loss: 0.6108\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6081 - val_loss: 0.6099\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6079 - val_loss: 0.6105\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6067 - val_loss: 0.6121\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6061 - val_loss: 0.6094\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6063 - val_loss: 0.6094\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6058 - val_loss: 0.6088\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6048 - val_loss: 0.6087\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6094\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6046 - val_loss: 0.6090\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6044 - val_loss: 0.6082\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6042 - val_loss: 0.6083\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6039 - val_loss: 0.6077\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6036 - val_loss: 0.6077\n",
      "14\n",
      "normalizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6609 - val_loss: 0.6380\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 0.6131\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6088 - val_loss: 0.6103\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6073 - val_loss: 0.6085\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6054 - val_loss: 0.6076\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6094\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6033 - val_loss: 0.6070\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.6068\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 0.6103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6023 - val_loss: 0.6051\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 0.6069\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6010 - val_loss: 0.6067\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6048\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6007 - val_loss: 0.6046\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 0.6123\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 0.6047\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6010 - val_loss: 0.6070\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6007 - val_loss: 0.6055\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 0.6045\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 0.6042\n",
      "15\n",
      "normalizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6755 - val_loss: 0.6503\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6268 - val_loss: 0.6161\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6122\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6111\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6098\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.6088\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.6106\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6114\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6081\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6041 - val_loss: 0.6074\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6110\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6077\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6062\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6068\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6074\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6059\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6069\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6059\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 0.6060\n",
      "16\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6913 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6895 - val_loss: 0.6874\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6737 - val_loss: 0.6449\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6253 - val_loss: 0.6227\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6178 - val_loss: 0.6204\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.6199\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.6191\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.6188\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6141 - val_loss: 0.6210\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.6184\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6141 - val_loss: 0.6180\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 0.6175\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6176\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6174\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6128 - val_loss: 0.6182\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.6171\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6123 - val_loss: 0.6175\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6172\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6164\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.6168\n",
      "17\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_377 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6674 - val_loss: 0.6488\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6330 - val_loss: 0.6264\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.6208\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6145 - val_loss: 0.6185\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6158\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6147\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6143\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 0.6138\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6140\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.6133\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6122\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6113\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6110\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6044 - val_loss: 0.6102\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6112\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6102\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6102\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6125\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6100\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6094\n",
      "18\n",
      "standardizeH|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_382 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6459 - val_loss: 0.6258\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6194\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.6171\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 0.6150\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.6140\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6095 - val_loss: 0.6127\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.6126\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6121\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6070 - val_loss: 0.6123\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.6105\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6055 - val_loss: 0.6105\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6101\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6099\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6044 - val_loss: 0.6096\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6088\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6086\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6077\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 0.6079\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6087\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.6079\n",
      "19\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6587 - val_loss: 0.6267\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6144 - val_loss: 0.6148\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6093 - val_loss: 0.6153\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6068 - val_loss: 0.6089\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6056 - val_loss: 0.6156\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 0.6153\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 0.6126\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.6073\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 0.6082\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6051 - val_loss: 0.6093\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.6057\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6022 - val_loss: 0.6057\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6046 - val_loss: 0.6083\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 0.6055\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6033 - val_loss: 0.6065\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6027 - val_loss: 0.6066\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6022 - val_loss: 0.6132\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.6071\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.6090\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6026 - val_loss: 0.6054\n",
      "20\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6694 - val_loss: 0.6296\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.6118\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6094\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 0.6083\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6094\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6064\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6060\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6064\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6063\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5999 - val_loss: 0.6052\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 0.6046\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6046\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5992 - val_loss: 0.6050\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5992 - val_loss: 0.6046\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5983 - val_loss: 0.6048\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5983 - val_loss: 0.6046\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5984 - val_loss: 0.6057\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5977 - val_loss: 0.6061\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5982 - val_loss: 0.6064\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5982 - val_loss: 0.6041\n",
      "21\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6795 - val_loss: 0.6712\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6626 - val_loss: 0.6587\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6511 - val_loss: 0.6504\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6437 - val_loss: 0.6452\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6390 - val_loss: 0.6414\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6358 - val_loss: 0.6384\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6332 - val_loss: 0.6359\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.6341\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.6327\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6289 - val_loss: 0.6322\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6282 - val_loss: 0.6316\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6276 - val_loss: 0.6310\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6271 - val_loss: 0.6306\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.6297\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6261 - val_loss: 0.6299\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6256 - val_loss: 0.6297\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6255 - val_loss: 0.6289\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.6283\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6244 - val_loss: 0.6278\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.6267\n",
      "22\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6836 - val_loss: 0.6585\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6321 - val_loss: 0.6153\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6123\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6099\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.6093\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6118\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6080\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6094\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.6082\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6088\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6090\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6085\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6080\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6113\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6044 - val_loss: 0.6122\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6155\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6085\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6082\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6078\n",
      "23\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6920 - val_loss: 0.6904\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6905 - val_loss: 0.6892\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6900 - val_loss: 0.6887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "24\n",
      "normalizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6732 - val_loss: 0.6389\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6245 - val_loss: 0.6190\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.6161\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 0.6163\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 0.6137\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6120\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6136\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.6121\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6129\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6075 - val_loss: 0.6109\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.6108\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6114\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6135\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6121\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6136\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6100\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6110\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6153\n",
      "25\n",
      "normalizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6896 - val_loss: 0.6784\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6486 - val_loss: 0.6251\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6146 - val_loss: 0.6216\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 0.6169\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6197\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 0.6156\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6143\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6114 - val_loss: 0.6236\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6114 - val_loss: 0.6140\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6114 - val_loss: 0.6158\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.6186\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6110 - val_loss: 0.6125\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.6122\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.6124\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6113 - val_loss: 0.6125\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.6127\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6119\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6111\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6113\n",
      "26\n",
      "minmaxG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6905 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "27\n",
      "standardizeq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6724 - val_loss: 0.6438\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6245 - val_loss: 0.6220\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.6194\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 0.6188\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6176\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6172\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6113 - val_loss: 0.6163\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 0.6189\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6164\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6168\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6144\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 0.6140\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.6131\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.6128\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.6148\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6120\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6119\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6118\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6118\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6110\n",
      "28\n",
      "maxabsY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6897 - val_loss: 0.6813\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6555 - val_loss: 0.6333\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6229 - val_loss: 0.6205\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.6170\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6139 - val_loss: 0.6156\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6163\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6141\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.6136\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6127\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6143\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 0.6117\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6131\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6075 - val_loss: 0.6105\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6073 - val_loss: 0.6094\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6123\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6118\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 0.6085\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6083\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6083\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6159\n",
      "29\n",
      "minmaxP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6890 - val_loss: 0.6813\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6624 - val_loss: 0.6426\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6273 - val_loss: 0.6240\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6181 - val_loss: 0.6213\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.6207\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.6196\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6146 - val_loss: 0.6185\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6185\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6142 - val_loss: 0.6176\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 0.6181\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6171\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6130 - val_loss: 0.6172\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6129 - val_loss: 0.6169\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6172\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6166\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6165\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.6159\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6160\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6220\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6155\n",
      "0\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_447 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.8210 - val_loss: 0.6489\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6363 - val_loss: 0.6361\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6257 - val_loss: 0.6289\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6202 - val_loss: 0.6256\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 0.6225\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6142 - val_loss: 0.6198\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6188\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.6183\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6104 - val_loss: 0.6172\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6102 - val_loss: 0.6172\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6090 - val_loss: 0.6171\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.6162\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6081 - val_loss: 0.6156\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6082 - val_loss: 0.6155\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.6148\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6147\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 0.6170\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6062 - val_loss: 0.6143\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6146\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6141\n",
      "1\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6904 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6864 - val_loss: 0.6535\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.6091\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6095\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6071\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.6057\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6076\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5992 - val_loss: 0.6053\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6050\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5984 - val_loss: 0.6061\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5978 - val_loss: 0.6072\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5986 - val_loss: 0.6054\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5976 - val_loss: 0.6060\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5974 - val_loss: 0.6041\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5970 - val_loss: 0.6036\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5981 - val_loss: 0.6046\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5966 - val_loss: 0.6041\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5964 - val_loss: 0.6047\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5971 - val_loss: 0.6055\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5958 - val_loss: 0.6058\n",
      "2\n",
      "normalizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6614 - val_loss: 0.6431\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6257 - val_loss: 0.6206\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6097 - val_loss: 0.6092\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6122\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.6054\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6016 - val_loss: 0.6051\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6009 - val_loss: 0.6047\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 0.6043\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 0.6050\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6010 - val_loss: 0.6055\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 0.6107\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6015 - val_loss: 0.6092\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6007 - val_loss: 0.6046\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5996 - val_loss: 0.6096\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 0.6063\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5996 - val_loss: 0.6108\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6020 - val_loss: 0.6039\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 0.6038\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 0.6332\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6043 - val_loss: 0.6072\n",
      "3\n",
      "robustR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6792 - val_loss: 0.6646\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6518 - val_loss: 0.6415\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6310 - val_loss: 0.6269\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6210 - val_loss: 0.6224\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6183 - val_loss: 0.6209\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6160 - val_loss: 0.6180\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6169\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.6166\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6127 - val_loss: 0.6163\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6166\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6168\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6164\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.6162\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6110 - val_loss: 0.6156\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6108 - val_loss: 0.6156\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6105 - val_loss: 0.6155\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6107 - val_loss: 0.6154\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6105 - val_loss: 0.6149\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6101 - val_loss: 0.6157\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6101 - val_loss: 0.6150\n",
      "4\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6701 - val_loss: 0.6493\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6314 - val_loss: 0.6227\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.6134\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6100\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6088\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6082\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6066\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6125\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6125\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6051\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 0.6053\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6056\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6063\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6046\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 0.6047\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6044\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6047\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5999 - val_loss: 0.6043\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 0.6065\n",
      "5\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6906 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6888 - val_loss: 0.6799\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6459 - val_loss: 0.6323\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6238 - val_loss: 0.6316\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6122 - val_loss: 0.6127\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6066 - val_loss: 0.6125\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6047 - val_loss: 0.6144\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6045 - val_loss: 0.6088\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6022 - val_loss: 0.6094\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6017 - val_loss: 0.6075\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6007 - val_loss: 0.6203\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6030 - val_loss: 0.6101\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6002 - val_loss: 0.6063\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6005 - val_loss: 0.6076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5992 - val_loss: 0.6081\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5990 - val_loss: 0.6121\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5996 - val_loss: 0.6058\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5978 - val_loss: 0.6116\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5984 - val_loss: 0.6081\n",
      "6\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_477 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6951 - val_loss: 0.6483\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6365 - val_loss: 0.6360\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6273 - val_loss: 0.6296\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6210 - val_loss: 0.6244\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 0.6214\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6146 - val_loss: 0.6197\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.6178\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.6167\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6103 - val_loss: 0.6160\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6093 - val_loss: 0.6152\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6088 - val_loss: 0.6146\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6077 - val_loss: 0.6134\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6073 - val_loss: 0.6130\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 0.6126\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6067 - val_loss: 0.6117\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6060 - val_loss: 0.6119\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6055 - val_loss: 0.6114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 0.6109\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6114\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6106\n",
      "7\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6817 - val_loss: 0.6635\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6427 - val_loss: 0.6308\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.6177\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 0.6154\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6133\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 0.6123\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6121\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6108\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6078 - val_loss: 0.6103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6135\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6109\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6105\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.6101\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6059 - val_loss: 0.6098\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.6099\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6096\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6091\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6085\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6091\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6116\n",
      "8\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6847 - val_loss: 0.6593\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6285 - val_loss: 0.6197\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6159\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 0.6150\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.6140\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6142\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6117\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6143\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6099\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6095\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 0.6097\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6096\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6102\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6084\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6011 - val_loss: 0.6077\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6088\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6136\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 0.6079\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6077\n",
      "9\n",
      "minmaxO|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_492 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6856 - val_loss: 0.6746\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6660 - val_loss: 0.6609\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6576 - val_loss: 0.6563\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6526 - val_loss: 0.6531\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6485 - val_loss: 0.6488\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6441 - val_loss: 0.6435\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6364 - val_loss: 0.6353\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6286 - val_loss: 0.6320\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6250 - val_loss: 0.6265\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6224 - val_loss: 0.6247\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6213 - val_loss: 0.6237\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6196 - val_loss: 0.6230\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6197 - val_loss: 0.6227\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6190 - val_loss: 0.6215\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6179 - val_loss: 0.6216\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6175 - val_loss: 0.6210\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6178 - val_loss: 0.6231\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6170 - val_loss: 0.6217\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6171 - val_loss: 0.6217\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6165 - val_loss: 0.6200\n",
      "10\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6598 - val_loss: 0.6306\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6173 - val_loss: 0.6176\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6129 - val_loss: 0.6182\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6162 - val_loss: 0.6136\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.6123\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.6090\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6135\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6067 - val_loss: 0.6085\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6048 - val_loss: 0.6090\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6070 - val_loss: 0.6084\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6039 - val_loss: 0.6099\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6049 - val_loss: 0.6084\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6034 - val_loss: 0.6087\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6033 - val_loss: 0.6073\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6035 - val_loss: 0.6075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6042 - val_loss: 0.6063\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6027 - val_loss: 0.6068\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6020 - val_loss: 0.6087\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6029 - val_loss: 0.6182\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.6067\n",
      "11\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6887 - val_loss: 0.6746\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6434 - val_loss: 0.6279\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6205 - val_loss: 0.6200\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6130\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.6165\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6138 - val_loss: 0.6131\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6130\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6108 - val_loss: 0.6132\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6128\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6120\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6120\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6116\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6109\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6123\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6113\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 0.6109\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6116\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6146\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6132\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6106\n",
      "12\n",
      "maxabsY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6604 - val_loss: 0.6284\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.6282\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6181 - val_loss: 0.6193\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 0.6159\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 0.6173\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6173\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 0.6159\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.6233\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6133\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6137\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6119\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6073 - val_loss: 0.6145\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 0.6185\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.6125\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6115\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6075 - val_loss: 0.6147\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6106\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6218\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 0.6115\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6044 - val_loss: 0.6108\n",
      "13\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6902 - val_loss: 0.6887\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6901 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6894 - val_loss: 0.6822\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6555 - val_loss: 0.6367\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6342 - val_loss: 0.6290\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6240 - val_loss: 0.6156\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6119 - val_loss: 0.6166\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6087 - val_loss: 0.6130\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6073 - val_loss: 0.6137\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6084\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.6069\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6035 - val_loss: 0.6077\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6037 - val_loss: 0.6083\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6032 - val_loss: 0.6126\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.6059\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6020 - val_loss: 0.6059\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 0.6064\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6024 - val_loss: 0.6061\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 0.6066\n",
      "14\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6479 - val_loss: 0.6213\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6131\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6075 - val_loss: 0.6110\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6114\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6089\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6082\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6077\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 0.6083\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6076\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6085\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 0.6070\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6006 - val_loss: 0.6064\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 0.6065\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6000 - val_loss: 0.6085\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6006 - val_loss: 0.6086\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6065\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5994 - val_loss: 0.6063\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5999 - val_loss: 0.6062\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5992 - val_loss: 0.6063\n",
      "15\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6778 - val_loss: 0.6607\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6443 - val_loss: 0.6394\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.6273\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6197 - val_loss: 0.6202\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.6163\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.6146\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6161\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 0.6135\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6136\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6134\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6148\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6129\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6131\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6123\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6120\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6116\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6118\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6122\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6109\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6108\n",
      "16\n",
      "normalizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6902 - val_loss: 0.6874\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6721 - val_loss: 0.6389\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6253 - val_loss: 0.6193\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 0.6160\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 0.6157\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6095 - val_loss: 0.6128\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6121\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6120\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.6101\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 0.6094\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6090\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6091\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6044 - val_loss: 0.6082\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6081\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6077\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6032 - val_loss: 0.6079\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6037 - val_loss: 0.6074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6073\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6070\n",
      "17\n",
      "maxabsd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6664 - val_loss: 0.6404\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6215 - val_loss: 0.6140\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6091\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6067\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6033 - val_loss: 0.6073\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6033 - val_loss: 0.6066\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6060\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6066\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6104\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6060\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6056\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 0.6059\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6073\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6086\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.6058\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6010 - val_loss: 0.6056\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.6053\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.6052\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6048\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6049\n",
      "18\n",
      "minmaxp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6908 - val_loss: 0.6886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6897 - val_loss: 0.6882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6872 - val_loss: 0.6716\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6504 - val_loss: 0.6390\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6370 - val_loss: 0.6318\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6308 - val_loss: 0.6287\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6266 - val_loss: 0.6256\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6241 - val_loss: 0.6241\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6225 - val_loss: 0.6219\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.6223\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6186 - val_loss: 0.6195\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6174 - val_loss: 0.6189\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.6201\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.6182\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.6184\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.6168\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6171\n",
      "19\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_548 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6816 - val_loss: 0.6669\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6484 - val_loss: 0.6368\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6321 - val_loss: 0.6305\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6274 - val_loss: 0.6269\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6233 - val_loss: 0.6252\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6214 - val_loss: 0.6242\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6204 - val_loss: 0.6225\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6181 - val_loss: 0.6215\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6179 - val_loss: 0.6222\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6172 - val_loss: 0.6208\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6162 - val_loss: 0.6203\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6160 - val_loss: 0.6226\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6162 - val_loss: 0.6201\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6155 - val_loss: 0.6200\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6152 - val_loss: 0.6206\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6146 - val_loss: 0.6203\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6149 - val_loss: 0.6202\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6204\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6150 - val_loss: 0.6197\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6145 - val_loss: 0.6196\n",
      "20\n",
      "standardizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6909 - val_loss: 0.6840\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6684 - val_loss: 0.6410\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6251 - val_loss: 0.6177\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6142 - val_loss: 0.6146\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6111 - val_loss: 0.6131\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6095 - val_loss: 0.6124\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6118\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6112\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6107\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.6106\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6101\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6094\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 0.6096\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6098\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6098\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6089\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.6089\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6085\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6082\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.6078\n",
      "21\n",
      "normalizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6689 - val_loss: 0.6379\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6197 - val_loss: 0.6134\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6069 - val_loss: 0.6110\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6126\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 0.6089\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.6116\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6020 - val_loss: 0.6087\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.6095\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6019 - val_loss: 0.6083\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6087\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.6114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 0.6073\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6005 - val_loss: 0.6070\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6009 - val_loss: 0.6078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6073\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6007 - val_loss: 0.6114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6007 - val_loss: 0.6155\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6016 - val_loss: 0.6093\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6005 - val_loss: 0.6073\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6114\n",
      "22\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6908 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6881\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6728 - val_loss: 0.6363\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6189 - val_loss: 0.6106\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6066 - val_loss: 0.6095\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.6089\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6028 - val_loss: 0.6063\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.6103\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 0.6113\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 0.6059\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6008 - val_loss: 0.6067\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6005 - val_loss: 0.6132\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6016 - val_loss: 0.6197\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6028 - val_loss: 0.6068\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5997 - val_loss: 0.6085\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6000 - val_loss: 0.6112\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5996 - val_loss: 0.6057\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5991 - val_loss: 0.6080\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6007 - val_loss: 0.6067\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 0.6074\n",
      "23\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6557 - val_loss: 0.6321\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6244 - val_loss: 0.6157\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6124 - val_loss: 0.6167\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6061 - val_loss: 0.6076\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6067 - val_loss: 0.6052\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6028 - val_loss: 0.6066\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6063 - val_loss: 0.6208\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6032 - val_loss: 0.6043\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6021 - val_loss: 0.6046\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6021 - val_loss: 0.6043\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6022 - val_loss: 0.6095\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.6117\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6018 - val_loss: 0.6095\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6039 - val_loss: 0.6089\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6011 - val_loss: 0.6040\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6009 - val_loss: 0.6033\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6024 - val_loss: 0.6126\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6040 - val_loss: 0.6136\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6008 - val_loss: 0.6039\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5998 - val_loss: 0.6064\n",
      "24\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6916 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6888\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6900 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6889\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "25\n",
      "maxabso|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6896 - val_loss: 0.6808\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6417 - val_loss: 0.6131\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6104\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6101\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.6090\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6147\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6087\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6081\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6081\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6072\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6072\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6093\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6065\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6081\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 0.6062\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6006 - val_loss: 0.6067\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 0.6060\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 0.6056\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 0.6064\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 0.6052\n",
      "26\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_585 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6606 - val_loss: 0.6404\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 0.6234\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.6156\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6105 - val_loss: 0.6128\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6084 - val_loss: 0.6120\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6071 - val_loss: 0.6105\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6063 - val_loss: 0.6102\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6054 - val_loss: 0.6102\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6091\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6052 - val_loss: 0.6090\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6039 - val_loss: 0.6100\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6037 - val_loss: 0.6085\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6032 - val_loss: 0.6085\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6030 - val_loss: 0.6076\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6025 - val_loss: 0.6073\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6024 - val_loss: 0.6074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6020 - val_loss: 0.6071\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 0.6063\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6017 - val_loss: 0.6073\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6017 - val_loss: 0.6075\n",
      "27\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6539 - val_loss: 0.6196\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6058 - val_loss: 0.6086\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6005 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5993 - val_loss: 0.6069\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5992 - val_loss: 0.6079\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5986 - val_loss: 0.6070\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5981 - val_loss: 0.6239\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5979 - val_loss: 0.6092\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5968 - val_loss: 0.6154\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 0.6061\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5973 - val_loss: 0.6118\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5994 - val_loss: 0.6090\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5966 - val_loss: 0.6242\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6005 - val_loss: 0.6060\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5961 - val_loss: 0.6085\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5961 - val_loss: 0.6067\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5964 - val_loss: 0.6140\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5957 - val_loss: 0.6075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5949 - val_loss: 0.6069\n",
      "28\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6706 - val_loss: 0.6429\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6287 - val_loss: 0.6172\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6136 - val_loss: 0.6121\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6122 - val_loss: 0.6213\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6106\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6099 - val_loss: 0.6098\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6056 - val_loss: 0.6201\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6072 - val_loss: 0.6089\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6046 - val_loss: 0.6096\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6041 - val_loss: 0.6135\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6053 - val_loss: 0.6101\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6059 - val_loss: 0.6069\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6023 - val_loss: 0.6074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6019 - val_loss: 0.6058\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6021 - val_loss: 0.6053\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6028 - val_loss: 0.6068\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6027 - val_loss: 0.6052\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6028 - val_loss: 0.6056\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6025 - val_loss: 0.6073\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6017 - val_loss: 0.6058\n",
      "29\n",
      "maxabsG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6922 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6888\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6900 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6900 - val_loss: 0.6886\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "0\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6692 - val_loss: 0.6490\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.6188\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6102\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6090\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6041 - val_loss: 0.6093\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6079\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6077\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6066\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 0.6068\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6068\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 0.6062\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6006 - val_loss: 0.6062\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 0.6071\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 0.6059\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.6065\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5996 - val_loss: 0.6067\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5994 - val_loss: 0.6056\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6056\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5992 - val_loss: 0.6057\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6063\n",
      "1\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6818 - val_loss: 0.6639\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6413 - val_loss: 0.6318\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6221 - val_loss: 0.6228\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.6226\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.6189\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6138 - val_loss: 0.6188\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6139 - val_loss: 0.6184\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.6191\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.6187\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6123 - val_loss: 0.6171\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6134 - val_loss: 0.6180\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.6156\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6114 - val_loss: 0.6180\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6191\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.6153\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6156\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 0.6164\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 0.6183\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6110 - val_loss: 0.6167\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6150\n",
      "2\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6559 - val_loss: 0.6248\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6156 - val_loss: 0.6119\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6061 - val_loss: 0.6197\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6055 - val_loss: 0.6149\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6040 - val_loss: 0.6062\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6026 - val_loss: 0.6094\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6020 - val_loss: 0.6180\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6047 - val_loss: 0.6074\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6018 - val_loss: 0.6084\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6011 - val_loss: 0.6043\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6010 - val_loss: 0.6053\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6016 - val_loss: 0.6204\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6043 - val_loss: 0.6047\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6019 - val_loss: 0.6052\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6018 - val_loss: 0.6046\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6006 - val_loss: 0.6094\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6005 - val_loss: 0.6084\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6009 - val_loss: 0.6044\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6011 - val_loss: 0.6074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6014 - val_loss: 0.6041\n",
      "3\n",
      "robustI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6736 - val_loss: 0.6604\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6500 - val_loss: 0.6500\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6412 - val_loss: 0.6421\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6345 - val_loss: 0.6369\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.6306\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6251 - val_loss: 0.6273\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6223 - val_loss: 0.6239\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.6215\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6174 - val_loss: 0.6185\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.6174\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6133 - val_loss: 0.6149\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6135\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6136\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 0.6124\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6115\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6111\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6101\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6104\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6096\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6085\n",
      "4\n",
      "robustp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_630 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6888 - val_loss: 0.6793\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6657 - val_loss: 0.6398\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6291 - val_loss: 0.6277\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6232 - val_loss: 0.6247\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6209 - val_loss: 0.6233\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6191 - val_loss: 0.6215\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6179 - val_loss: 0.6205\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6170 - val_loss: 0.6200\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6162 - val_loss: 0.6195\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6156 - val_loss: 0.6187\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6149 - val_loss: 0.6177\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6171\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6136 - val_loss: 0.6167\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6133 - val_loss: 0.6162\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.6161\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6155\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.6151\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6152\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.6158\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 0.6145\n",
      "5\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6902 - val_loss: 0.6887\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6887\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6890\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6770 - val_loss: 0.6525\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6904 - val_loss: 0.6885\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "6\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6908 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "7\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6911 - val_loss: 0.6877\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 0.6538\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6389 - val_loss: 0.6373\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6328 - val_loss: 0.6335\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.6311\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6281 - val_loss: 0.6298\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6272 - val_loss: 0.6287\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6270 - val_loss: 0.6273\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6260 - val_loss: 0.6265\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6262 - val_loss: 0.6266\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6253 - val_loss: 0.6261\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.6268\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6244 - val_loss: 0.6279\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6244 - val_loss: 0.6265\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6248 - val_loss: 0.6263\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6242 - val_loss: 0.6256\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6241 - val_loss: 0.6261\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6236 - val_loss: 0.6272\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6241 - val_loss: 0.6256\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6234 - val_loss: 0.6259\n",
      "8\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6787 - val_loss: 0.6552\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.6176\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6123 - val_loss: 0.6131\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 0.6118\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6105\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.6095\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6087\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6080\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 0.6084\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6096\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6083\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6073\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6106\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6038 - val_loss: 0.6068\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6068\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6076\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6077\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6157\n",
      "9\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6668 - val_loss: 0.6185\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6099 - val_loss: 0.6125\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6091\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 0.6073\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 0.6086\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6059\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 0.6043\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6041\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5987 - val_loss: 0.6042\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5984 - val_loss: 0.6040\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5976 - val_loss: 0.6061\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5985 - val_loss: 0.6035\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5984 - val_loss: 0.6048\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5983 - val_loss: 0.6032\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5978 - val_loss: 0.6073\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 0.6037\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5964 - val_loss: 0.6025\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5967 - val_loss: 0.6091\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5966 - val_loss: 0.6038\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5967 - val_loss: 0.6022\n",
      "10\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_664 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6719 - val_loss: 0.6519\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6384 - val_loss: 0.6330\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6238 - val_loss: 0.6266\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6179 - val_loss: 0.6232\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6154 - val_loss: 0.6202\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6129 - val_loss: 0.6184\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.6163\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6101 - val_loss: 0.6149\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.6144\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6084 - val_loss: 0.6133\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6075 - val_loss: 0.6126\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 0.6125\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6071 - val_loss: 0.6120\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6061 - val_loss: 0.6126\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6055 - val_loss: 0.6118\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6057 - val_loss: 0.6113\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6050 - val_loss: 0.6113\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6048 - val_loss: 0.6114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6048 - val_loss: 0.6110\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6046 - val_loss: 0.6107\n",
      "11\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6838\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6688 - val_loss: 0.6464\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6266 - val_loss: 0.6199\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.6170\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6145\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6137\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6128\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6124\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 0.6121\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6098 - val_loss: 0.6114\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6095 - val_loss: 0.6114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.6115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6106\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.6111\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.6108\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6106\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6105\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6105\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6107\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6107\n",
      "12\n",
      "standardizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6641 - val_loss: 0.6283\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6124 - val_loss: 0.6166\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.6036\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 0.6044\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5981 - val_loss: 0.6033\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5975 - val_loss: 0.6090\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 0.6022\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5972 - val_loss: 0.6110\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5976 - val_loss: 0.6027\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 0.6044\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5975 - val_loss: 0.6018\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5955 - val_loss: 0.6035\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5954 - val_loss: 0.6011\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5951 - val_loss: 0.6036\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5955 - val_loss: 0.6029\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5944 - val_loss: 0.6025\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5944 - val_loss: 0.6027\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5959 - val_loss: 0.6022\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5943 - val_loss: 0.6027\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5949 - val_loss: 0.6049\n",
      "13\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6902 - val_loss: 0.6891\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6891\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6887\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6897 - val_loss: 0.6882\n",
      "14\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6667 - val_loss: 0.6374\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6199 - val_loss: 0.6127\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6235\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6127\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6077\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6071\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6070\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6093\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6101\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6057\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6033 - val_loss: 0.6052\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6047\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6049\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.6090\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6154\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6061\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6077\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6129\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6050\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 0.6050\n",
      "15\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6904 - val_loss: 0.6886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6881\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6733 - val_loss: 0.6332\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6211 - val_loss: 0.6190\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6133 - val_loss: 0.6088\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6049 - val_loss: 0.6055\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6041 - val_loss: 0.6058\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6006 - val_loss: 0.6039\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6004 - val_loss: 0.6155\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6028 - val_loss: 0.6034\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5998 - val_loss: 0.6022\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 0.6044\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5989 - val_loss: 0.6028\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5986 - val_loss: 0.6048\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5986 - val_loss: 0.6026\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5981 - val_loss: 0.6053\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5981 - val_loss: 0.6023\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5961 - val_loss: 0.6057\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5970 - val_loss: 0.6027\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5960 - val_loss: 0.6050\n",
      "16\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6900 - val_loss: 0.6839\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6707 - val_loss: 0.6545\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6427 - val_loss: 0.6320\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6243 - val_loss: 0.6218\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6171 - val_loss: 0.6184\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.6169\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 0.6161\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6133 - val_loss: 0.6155\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.6154\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6150\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6142\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6133\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6131\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6100 - val_loss: 0.6126\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6126\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6124\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6088 - val_loss: 0.6116\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6084 - val_loss: 0.6116\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6117\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6112\n",
      "17\n",
      "standardizeq|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_701 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6618 - val_loss: 0.6412\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6284 - val_loss: 0.6259\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6178 - val_loss: 0.6194\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6126 - val_loss: 0.6165\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6105 - val_loss: 0.6152\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6089 - val_loss: 0.6142\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6078 - val_loss: 0.6132\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.6123\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6060 - val_loss: 0.6118\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.6114\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6048 - val_loss: 0.6109\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6044 - val_loss: 0.6113\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6037 - val_loss: 0.6101\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6029 - val_loss: 0.6094\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6027 - val_loss: 0.6099\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6023 - val_loss: 0.6094\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6020 - val_loss: 0.6090\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.6086\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6014 - val_loss: 0.6081\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6014 - val_loss: 0.6086\n",
      "18\n",
      "standardizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6642 - val_loss: 0.6329\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6184 - val_loss: 0.6147\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 0.6136\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.6114\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.6100\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6086\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6093\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6107\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6078\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6085\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6069\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6069\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.6100\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6076\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6063\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 0.6068\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.6088\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 0.6056\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 0.6058\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6001 - val_loss: 0.6080\n",
      "19\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6684 - val_loss: 0.6371\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6225 - val_loss: 0.6169\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6136 - val_loss: 0.6223\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.6155\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6111 - val_loss: 0.6125\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6136\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 0.6115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6138\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6066 - val_loss: 0.6116\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6058 - val_loss: 0.6115\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6052 - val_loss: 0.6145\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6050 - val_loss: 0.6104\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6108\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6086\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.6102\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6082\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6079 - val_loss: 0.6076\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6037 - val_loss: 0.6088\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.6084\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.6105\n",
      "20\n",
      "standardizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6903 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6858 - val_loss: 0.6657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6376 - val_loss: 0.6311\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6192 - val_loss: 0.6176\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6084 - val_loss: 0.6302\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6075 - val_loss: 0.6083\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6030 - val_loss: 0.6071\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6012 - val_loss: 0.6091\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6004 - val_loss: 0.6088\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5993 - val_loss: 0.6086\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6008 - val_loss: 0.6065\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6006 - val_loss: 0.6061\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5994 - val_loss: 0.6062\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6016 - val_loss: 0.6087\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5989 - val_loss: 0.6064\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5991 - val_loss: 0.6126\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5996 - val_loss: 0.6106\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6007 - val_loss: 0.6083\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6003 - val_loss: 0.6062\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5985 - val_loss: 0.6083\n",
      "21\n",
      "minmaxf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6568 - val_loss: 0.6280\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6103\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6049 - val_loss: 0.6076\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6026 - val_loss: 0.6082\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5999 - val_loss: 0.6036\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6016 - val_loss: 0.6040\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6022 - val_loss: 0.6052\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6006 - val_loss: 0.6210\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6017 - val_loss: 0.6031\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5987 - val_loss: 0.6104\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6010 - val_loss: 0.6031\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5990 - val_loss: 0.6081\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5992 - val_loss: 0.6030\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5988 - val_loss: 0.6117\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5993 - val_loss: 0.6054\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5998 - val_loss: 0.6042\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5995 - val_loss: 0.6048\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5979 - val_loss: 0.6027\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5991 - val_loss: 0.6058\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5980 - val_loss: 0.6014\n",
      "22\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6903 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6862 - val_loss: 0.6823\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6518 - val_loss: 0.6397\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6405 - val_loss: 0.6419\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6412 - val_loss: 0.6443\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6399 - val_loss: 0.6390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6404 - val_loss: 0.6413\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6406 - val_loss: 0.6425\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6447 - val_loss: 0.6457\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 0.6882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6889\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6901 - val_loss: 0.6885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "23\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6890 - val_loss: 0.6822\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6684 - val_loss: 0.6550\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6413 - val_loss: 0.6402\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6300 - val_loss: 0.6326\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6236 - val_loss: 0.6269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6193 - val_loss: 0.6230\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 0.6216\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6156 - val_loss: 0.6197\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.6186\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6141 - val_loss: 0.6186\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6137 - val_loss: 0.6186\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.6169\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6129 - val_loss: 0.6171\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6170\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.6163\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.6158\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.6156\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6155\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.6153\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6109 - val_loss: 0.6159\n",
      "24\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6729 - val_loss: 0.6528\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6375 - val_loss: 0.6377\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.6380\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6300 - val_loss: 0.6362\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.6353\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6275 - val_loss: 0.6316\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6234 - val_loss: 0.6283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6205 - val_loss: 0.6234\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6175 - val_loss: 0.6230\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.6229\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6145 - val_loss: 0.6217\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.6199\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6133 - val_loss: 0.6200\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 0.6196\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6178\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6160\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.6164\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6167\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6151\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6135\n",
      "25\n",
      "normalizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6903 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6897 - val_loss: 0.6873\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6690 - val_loss: 0.6446\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6391 - val_loss: 0.6330\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6315 - val_loss: 0.6299\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6278 - val_loss: 0.6259\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6235 - val_loss: 0.6235\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6210 - val_loss: 0.6235\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.6236\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6187 - val_loss: 0.6188\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6207\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.6176\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6146 - val_loss: 0.6164\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 0.6156\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 0.6155\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6121 - val_loss: 0.6161\n",
      "26\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6923 - val_loss: 0.6869\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6652 - val_loss: 0.6260\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 0.6138\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6147\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.6113\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6106\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6113\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6106\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6041 - val_loss: 0.6102\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6095\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6107\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6098\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6096\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6092\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6112\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6090\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6090\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6080\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6086\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 0.6072\n",
      "27\n",
      "minmaxo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6764 - val_loss: 0.6649\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6487 - val_loss: 0.6464\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6323 - val_loss: 0.6392\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6220 - val_loss: 0.6160\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6136 - val_loss: 0.6146\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.6137\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6101 - val_loss: 0.6122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6213\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 0.6118\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6123\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6117\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6163\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.6139\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6113\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6181\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6112\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6126\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6125\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6141\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6124\n",
      "28\n",
      "normalizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6902 - val_loss: 0.6888\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "29\n",
      "normalizeG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6907 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6890 - val_loss: 0.6868\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6871 - val_loss: 0.6840\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6830 - val_loss: 0.6779\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6747 - val_loss: 0.6689\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6666 - val_loss: 0.6619\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6597 - val_loss: 0.6558\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6533 - val_loss: 0.6498\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6468 - val_loss: 0.6436\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6410 - val_loss: 0.6386\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6359 - val_loss: 0.6344\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6320 - val_loss: 0.6317\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6295 - val_loss: 0.6296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6279 - val_loss: 0.6283\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6263 - val_loss: 0.6277\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6251 - val_loss: 0.6268\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6243 - val_loss: 0.6262\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6244 - val_loss: 0.6258\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6230 - val_loss: 0.6254\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6223 - val_loss: 0.6253\n",
      "0\n",
      "robustp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_767 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6693 - val_loss: 0.6431\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6316 - val_loss: 0.6288\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6208 - val_loss: 0.6237\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6155 - val_loss: 0.6199\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6183\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.6160\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6099 - val_loss: 0.6146\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6088 - val_loss: 0.6139\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.6142\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6076 - val_loss: 0.6149\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6071 - val_loss: 0.6128\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6069 - val_loss: 0.6127\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6062 - val_loss: 0.6131\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6058 - val_loss: 0.6129\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6064 - val_loss: 0.6132\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6057 - val_loss: 0.6123\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6120\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6116\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6122\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6119\n",
      "1\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6697 - val_loss: 0.6348\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.6169\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6134 - val_loss: 0.6153\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6149\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6168\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 0.6142\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.6121\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6122\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6113\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6059 - val_loss: 0.6118\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6109\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6140\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.6094\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6097\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6093\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6119\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6089\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6091\n",
      "2\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_778 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.8553 - val_loss: 0.6556\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6440 - val_loss: 0.6412\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6336 - val_loss: 0.6359\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6277 - val_loss: 0.6324\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6231 - val_loss: 0.6280\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6196 - val_loss: 0.6232\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6167 - val_loss: 0.6214\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6152 - val_loss: 0.6220\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6192\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 0.6178\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6133 - val_loss: 0.6173\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6103 - val_loss: 0.6166\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6097 - val_loss: 0.6171\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6088 - val_loss: 0.6163\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6081 - val_loss: 0.6146\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6075 - val_loss: 0.6153\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6071 - val_loss: 0.6136\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.6134\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6055 - val_loss: 0.6133\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6052 - val_loss: 0.6127\n",
      "3\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6908 - val_loss: 0.6885\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6887\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6878 - val_loss: 0.6793\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6531 - val_loss: 0.6318\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.6326\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.6278\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6232 - val_loss: 0.6262\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 0.6282\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6222 - val_loss: 0.6250\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6215 - val_loss: 0.6245\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.6262\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6194 - val_loss: 0.6232\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6186 - val_loss: 0.6223\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6179 - val_loss: 0.6219\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.6251\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.6205\n",
      "4\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6902 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6900 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6897 - val_loss: 0.6887\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6889\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6900 - val_loss: 0.6885\n",
      "5\n",
      "robustX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6888 - val_loss: 0.6792\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6573 - val_loss: 0.6358\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6239 - val_loss: 0.6221\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.6168\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 0.6172\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6113 - val_loss: 0.6148\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6135\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 0.6129\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6130\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6216\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6123\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.6120\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6120\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6136\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.6155\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 0.6138\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6129\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6069 - val_loss: 0.6110\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6104\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6099\n",
      "6\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6697 - val_loss: 0.6495\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6339 - val_loss: 0.6271\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 0.6195\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6136 - val_loss: 0.6163\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.6115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6145\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6091\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6126\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6058 - val_loss: 0.6085\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6088\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 0.6081\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 0.6111\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6080\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6085\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 0.6075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.6093\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6081\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6070\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6069\n",
      "7\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6626 - val_loss: 0.6387\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6232 - val_loss: 0.6169\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6108 - val_loss: 0.6411\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6132 - val_loss: 0.6155\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6072 - val_loss: 0.6098\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6054 - val_loss: 0.6106\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6053 - val_loss: 0.6100\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6055 - val_loss: 0.6147\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6041 - val_loss: 0.6162\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6069 - val_loss: 0.6109\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6042 - val_loss: 0.6099\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6041 - val_loss: 0.6075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6030 - val_loss: 0.6204\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6037 - val_loss: 0.6091\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6026 - val_loss: 0.6081\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6028 - val_loss: 0.6170\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6037 - val_loss: 0.6076\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6027 - val_loss: 0.6194\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6028 - val_loss: 0.6098\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6022 - val_loss: 0.6082\n",
      "8\n",
      "robustN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6901 - val_loss: 0.6852\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6725 - val_loss: 0.6507\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6447 - val_loss: 0.6400\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6366 - val_loss: 0.6351\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6327 - val_loss: 0.6324\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6292 - val_loss: 0.6308\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6265 - val_loss: 0.6281\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6242 - val_loss: 0.6263\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6236 - val_loss: 0.6263\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6223 - val_loss: 0.6254\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6208 - val_loss: 0.6231\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.6226\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6186 - val_loss: 0.6231\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6178 - val_loss: 0.6203\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.6188\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6138 - val_loss: 0.6168\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6162\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.6160\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6149\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6110 - val_loss: 0.6143\n",
      "9\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6855 - val_loss: 0.6638\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6351 - val_loss: 0.6220\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6163 - val_loss: 0.6175\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 0.6105\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6103\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6110\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6097\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6041 - val_loss: 0.6085\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6084\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.6082\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6097\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6020 - val_loss: 0.6077\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6081\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6069\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 0.6066\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6083\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6106\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6066\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6014 - val_loss: 0.6071\n",
      "10\n",
      "maxabsd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6909 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6854 - val_loss: 0.6680\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6465 - val_loss: 0.6284\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6206 - val_loss: 0.6167\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6159\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6121\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6106\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6109\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6102\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6105\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.6096\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6120\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6098\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.6086\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6089\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6059 - val_loss: 0.6092\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6083\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6085\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 0.6109\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6083\n",
      "11\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6906 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6889 - val_loss: 0.6857\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6827 - val_loss: 0.6730\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6600 - val_loss: 0.6486\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6404 - val_loss: 0.6354\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6286 - val_loss: 0.6282\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6232 - val_loss: 0.6303\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6225 - val_loss: 0.6248\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 0.6267\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6209 - val_loss: 0.6250\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6203 - val_loss: 0.6244\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6196 - val_loss: 0.6265\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6207 - val_loss: 0.6247\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6195 - val_loss: 0.6253\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6195 - val_loss: 0.6242\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6195 - val_loss: 0.6249\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6197 - val_loss: 0.6241\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6194 - val_loss: 0.6259\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6202 - val_loss: 0.6251\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6193 - val_loss: 0.6241\n",
      "12\n",
      "normalizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6584 - val_loss: 0.6301\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6206 - val_loss: 0.6267\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.6173\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.6165\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 0.6120\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6085 - val_loss: 0.6148\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6084 - val_loss: 0.6106\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6089 - val_loss: 0.6119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6075 - val_loss: 0.6108\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6078 - val_loss: 0.6144\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6067 - val_loss: 0.6120\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 0.6113\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6059 - val_loss: 0.6128\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6078 - val_loss: 0.6132\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6059 - val_loss: 0.6119\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6102\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6071 - val_loss: 0.6116\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6051 - val_loss: 0.6121\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6063 - val_loss: 0.6117\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.6092\n",
      "13\n",
      "standardizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6640 - val_loss: 0.6386\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 0.6170\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6155\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6137\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6140\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6075 - val_loss: 0.6128\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6141\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6070 - val_loss: 0.6119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.6122\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6059 - val_loss: 0.6114\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6124\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6113\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6101\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6118\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6106\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6112\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.6093\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6099\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6033 - val_loss: 0.6098\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6098\n",
      "14\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6662 - val_loss: 0.6386\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6260 - val_loss: 0.6174\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 0.6159\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6145 - val_loss: 0.6134\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6128\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6108 - val_loss: 0.6128\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6095 - val_loss: 0.6113\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6139\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6169\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6070 - val_loss: 0.6101\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6050 - val_loss: 0.6092\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6088\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6040 - val_loss: 0.6110\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6086\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6078\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.6076\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6091\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6099\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6070\n",
      "15\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6920 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6895 - val_loss: 0.6868\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6687 - val_loss: 0.6385\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6304 - val_loss: 0.6202\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6187 - val_loss: 0.6160\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6167 - val_loss: 0.6173\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.6166\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6149 - val_loss: 0.6160\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6118 - val_loss: 0.6156\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6117 - val_loss: 0.6140\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6105 - val_loss: 0.6161\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6111 - val_loss: 0.6168\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6117 - val_loss: 0.6153\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6087 - val_loss: 0.6167\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6075 - val_loss: 0.6104\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6067 - val_loss: 0.6100\n",
      "16\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6868 - val_loss: 0.6680\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6413 - val_loss: 0.6259\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6197 - val_loss: 0.6193\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.6179\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6156\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6159\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.6142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 0.6146\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6123\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6128\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.6119\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 0.6101\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6107\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6094\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6085\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6033 - val_loss: 0.6075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6088\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6076\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6083\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6071\n",
      "17\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6573 - val_loss: 0.6288\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6132 - val_loss: 0.6156\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6066 - val_loss: 0.6073\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6005 - val_loss: 0.6035\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6022 - val_loss: 0.6104\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6009 - val_loss: 0.6049\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6003 - val_loss: 0.6037\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5989 - val_loss: 0.6058\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5983 - val_loss: 0.6023\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5983 - val_loss: 0.6024\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5975 - val_loss: 0.6045\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5967 - val_loss: 0.6023\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5960 - val_loss: 0.6031\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5963 - val_loss: 0.6063\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5965 - val_loss: 0.6114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5984 - val_loss: 0.6061\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5978 - val_loss: 0.6080\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5968 - val_loss: 0.6032\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5947 - val_loss: 0.6081\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5959 - val_loss: 0.6025\n",
      "18\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6753 - val_loss: 0.6380\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.6127\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6105\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6099\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 0.6085\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6073\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6076\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6071\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6091\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6064\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6009 - val_loss: 0.6065\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6001 - val_loss: 0.6060\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6065\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 0.6060\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6061\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5989 - val_loss: 0.6061\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5988 - val_loss: 0.6057\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6056\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5984 - val_loss: 0.6056\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5989 - val_loss: 0.6055\n",
      "19\n",
      "maxabsm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6791 - val_loss: 0.6604\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6442 - val_loss: 0.6398\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6351 - val_loss: 0.6362\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6252 - val_loss: 0.6215\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.6235\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6137 - val_loss: 0.6306\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.6163\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6116 - val_loss: 0.6159\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.6175\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6170\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6099 - val_loss: 0.6141\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6106 - val_loss: 0.6159\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6093 - val_loss: 0.6134\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6097 - val_loss: 0.6162\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 0.6141\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6089 - val_loss: 0.6174\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6089 - val_loss: 0.6131\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6083 - val_loss: 0.6128\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6088 - val_loss: 0.6150\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 0.6130\n",
      "20\n",
      "standardizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6545 - val_loss: 0.6252\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6122\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6059 - val_loss: 0.6131\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.6095\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6099\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6081\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6032 - val_loss: 0.6078\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6079\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6087\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6016 - val_loss: 0.6065\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6059\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 0.6058\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6007 - val_loss: 0.6051\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.6061\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.6058\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6008 - val_loss: 0.6048\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6044\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6002 - val_loss: 0.6048\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5993 - val_loss: 0.6043\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6001 - val_loss: 0.6046\n",
      "21\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6821 - val_loss: 0.6533\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6258 - val_loss: 0.6179\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 0.6139\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.6123\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6114\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6110\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6113\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6105\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6107\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6053 - val_loss: 0.6096\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6046 - val_loss: 0.6085\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6084\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6041 - val_loss: 0.6082\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6034 - val_loss: 0.6076\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6069\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6067\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6063\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6020 - val_loss: 0.6055\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6059\n",
      "22\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6732 - val_loss: 0.6444\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6210 - val_loss: 0.6160\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6125\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6120\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6110\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6095\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6033 - val_loss: 0.6085\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.6075\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6112\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6091\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6011 - val_loss: 0.6081\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 0.6071\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6010 - val_loss: 0.6077\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 0.6063\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.6080\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5997 - val_loss: 0.6068\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5997 - val_loss: 0.6069\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 0.6073\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 0.6132\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6066\n",
      "23\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_887 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6855 - val_loss: 0.6789\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6714 - val_loss: 0.6640\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6573 - val_loss: 0.6530\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6456 - val_loss: 0.6428\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6354 - val_loss: 0.6348\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6276 - val_loss: 0.6287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6232 - val_loss: 0.6255\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6205 - val_loss: 0.6238\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6191 - val_loss: 0.6230\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6177 - val_loss: 0.6215\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6167 - val_loss: 0.6207\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6160 - val_loss: 0.6206\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6156 - val_loss: 0.6197\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6149 - val_loss: 0.6192\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6144 - val_loss: 0.6188\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6142 - val_loss: 0.6184\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6134 - val_loss: 0.6185\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.6181\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6127 - val_loss: 0.6174\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.6172\n",
      "24\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6888 - val_loss: 0.6810\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6623 - val_loss: 0.6460\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6410 - val_loss: 0.6347\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.6313\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6258 - val_loss: 0.6256\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6225 - val_loss: 0.6236\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 0.6257\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6211 - val_loss: 0.6220\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.6221\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.6213\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6171 - val_loss: 0.6208\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.6209\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.6215\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.6262\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6194\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.6205\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.6193\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.6200\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.6198\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.6180\n",
      "25\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6914 - val_loss: 0.6886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6894 - val_loss: 0.6867\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6669 - val_loss: 0.6335\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6277 - val_loss: 0.6198\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 0.6148\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6097\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6095\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6039 - val_loss: 0.6058\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6112\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6078\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6062\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6067\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.6062\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.6053\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.6066\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6116\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6007 - val_loss: 0.6050\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 0.6056\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6071\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.6048\n",
      "26\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6901 - val_loss: 0.6877\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6863 - val_loss: 0.6779\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6658 - val_loss: 0.6486\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6372 - val_loss: 0.6343\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6271 - val_loss: 0.6278\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6226 - val_loss: 0.6259\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.6226\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6175 - val_loss: 0.6204\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6162 - val_loss: 0.6197\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.6188\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6148 - val_loss: 0.6197\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6177\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6133 - val_loss: 0.6168\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6129 - val_loss: 0.6169\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.6172\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6163\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.6159\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6108 - val_loss: 0.6192\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6155\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6103 - val_loss: 0.6156\n",
      "27\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6707 - val_loss: 0.6556\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6322 - val_loss: 0.6231\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6109 - val_loss: 0.6141\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6095\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6061 - val_loss: 0.6072\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6048 - val_loss: 0.6091\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6057 - val_loss: 0.6091\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6025 - val_loss: 0.6073\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6024 - val_loss: 0.6127\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6040 - val_loss: 0.6219\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6038 - val_loss: 0.6064\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6030 - val_loss: 0.6069\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6010 - val_loss: 0.6063\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6017 - val_loss: 0.6282\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6021 - val_loss: 0.6171\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6011 - val_loss: 0.6062\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5991 - val_loss: 0.6055\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6003 - val_loss: 0.6080\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5995 - val_loss: 0.6131\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6036 - val_loss: 0.6052\n",
      "28\n",
      "maxabsO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6837 - val_loss: 0.6679\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6483 - val_loss: 0.6401\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6279 - val_loss: 0.6288\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6213 - val_loss: 0.6260\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.6236\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6182 - val_loss: 0.6231\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6178 - val_loss: 0.6226\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.6224\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.6216\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.6217\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.6218\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.6205\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.6216\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.6180\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.6171\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6166\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 0.6167\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6128 - val_loss: 0.6164\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6150\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6123 - val_loss: 0.6150\n",
      "29\n",
      "robustK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6910 - val_loss: 0.6873\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6763 - val_loss: 0.6482\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6313 - val_loss: 0.6296\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6211 - val_loss: 0.6246\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.6214\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.6197\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6190\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6133 - val_loss: 0.6182\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.6174\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.6173\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6169\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6161\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6166\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6162\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6156\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 0.6154\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6159\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6095 - val_loss: 0.6156\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6146\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 0.6147\n",
      "0\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6903 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6669 - val_loss: 0.6326\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6234 - val_loss: 0.6148\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6114 - val_loss: 0.6114\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6118 - val_loss: 0.6123\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 0.6097\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6066 - val_loss: 0.6102\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 0.6083\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 0.6074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6055 - val_loss: 0.6075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6147\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6043 - val_loss: 0.6088\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.6066\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.6058\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.6083\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6015 - val_loss: 0.6091\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6017 - val_loss: 0.6056\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6011 - val_loss: 0.6080\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6091\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6016 - val_loss: 0.6050\n",
      "1\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6901 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "2\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6841 - val_loss: 0.6630\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6389 - val_loss: 0.6235\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.6254\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.6155\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.6187\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6127 - val_loss: 0.6196\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.6133\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6155\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 0.6119\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 0.6115\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6144\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6124\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6141\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6163\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6135\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6106\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.6112\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6099\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6186\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 0.6144\n",
      "3\n",
      "minmaxY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6825 - val_loss: 0.6688\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6554 - val_loss: 0.6517\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6439 - val_loss: 0.6429\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6357 - val_loss: 0.6370\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.6319\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.6288\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6234 - val_loss: 0.6257\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6211 - val_loss: 0.6228\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6185 - val_loss: 0.6213\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.6200\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.6193\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.6191\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6139 - val_loss: 0.6165\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6134 - val_loss: 0.6157\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6152\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 0.6157\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.6144\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 0.6134\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6114 - val_loss: 0.6152\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6133\n",
      "4\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6872 - val_loss: 0.6791\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6690 - val_loss: 0.6617\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6520 - val_loss: 0.6509\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6451 - val_loss: 0.6468\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6411 - val_loss: 0.6425\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6372 - val_loss: 0.6388\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6306 - val_loss: 0.6305\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6251 - val_loss: 0.6264\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6214 - val_loss: 0.6247\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 0.6257\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6182 - val_loss: 0.6215\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6165 - val_loss: 0.6197\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6175\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 0.6165\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 0.6158\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 0.6153\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6128 - val_loss: 0.6217\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.6146\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6144\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6197\n",
      "5\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6901 - val_loss: 0.6873\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6662 - val_loss: 0.6474\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6387 - val_loss: 0.6324\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6318 - val_loss: 0.6285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6268 - val_loss: 0.6230\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6258 - val_loss: 0.6218\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 0.6187\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6190 - val_loss: 0.6207\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6173 - val_loss: 0.6161\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6162 - val_loss: 0.6159\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6147 - val_loss: 0.6153\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6141 - val_loss: 0.6163\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6171 - val_loss: 0.6139\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6116 - val_loss: 0.6133\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6111 - val_loss: 0.6128\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 0.6245\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6115 - val_loss: 0.6110\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6096 - val_loss: 0.6106\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6076 - val_loss: 0.6103\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6079 - val_loss: 0.6109\n",
      "6\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6891 - val_loss: 0.6805\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6595 - val_loss: 0.6390\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6272 - val_loss: 0.6229\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6173 - val_loss: 0.6189\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.6166\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6127 - val_loss: 0.6158\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 0.6158\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 0.6151\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6146\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6118 - val_loss: 0.6144\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.6140\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 0.6137\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 0.6138\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6136\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.6137\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6140\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6131\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6127\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6129\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 0.6124\n",
      "7\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6903 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6889\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "8\n",
      "normalizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6675 - val_loss: 0.6573\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6400 - val_loss: 0.6363\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6257 - val_loss: 0.6186\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6117 - val_loss: 0.6320\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6086 - val_loss: 0.6079\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6045 - val_loss: 0.6059\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6072 - val_loss: 0.6060\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6033 - val_loss: 0.6061\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6036 - val_loss: 0.6074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6028 - val_loss: 0.6088\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6053 - val_loss: 0.6074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6005 - val_loss: 0.6127\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6026 - val_loss: 0.6093\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6030 - val_loss: 0.6113\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6016 - val_loss: 0.6218\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6020 - val_loss: 0.6249\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6080 - val_loss: 0.6078\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6027 - val_loss: 0.6078\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6010 - val_loss: 0.6044\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6024 - val_loss: 0.6047\n",
      "9\n",
      "minmaxs|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6889 - val_loss: 0.6825\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6577 - val_loss: 0.6314\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.6182\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6150 - val_loss: 0.6146\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6142 - val_loss: 0.6136\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6127 - val_loss: 0.6138\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6128\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6149\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6110 - val_loss: 0.6116\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6110\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.6115\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6109\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6106\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 0.6103\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6135\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6093\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.6089\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6096\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6119\n",
      "10\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6799 - val_loss: 0.6603\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6403 - val_loss: 0.6324\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6224 - val_loss: 0.6210\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6146 - val_loss: 0.6155\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6128 - val_loss: 0.6126\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6093 - val_loss: 0.6110\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6076 - val_loss: 0.6115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 0.6126\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6067 - val_loss: 0.6090\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6055 - val_loss: 0.6188\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6057 - val_loss: 0.6087\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6044 - val_loss: 0.6093\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 0.6097\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6044 - val_loss: 0.6103\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 0.6076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 0.6077\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6072\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.6070\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.6067\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6027 - val_loss: 0.6067\n",
      "11\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6919 - val_loss: 0.6891\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6806 - val_loss: 0.6459\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6410 - val_loss: 0.6331\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6273 - val_loss: 0.6268\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6243 - val_loss: 0.6201\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6207 - val_loss: 0.6188\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6187 - val_loss: 0.6158\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.6185\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.6133\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.6099\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6096 - val_loss: 0.6098\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6095 - val_loss: 0.6101\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6084 - val_loss: 0.6113\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6090 - val_loss: 0.6098\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6071 - val_loss: 0.6080\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 0.6076\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 0.6090\n",
      "12\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6842 - val_loss: 0.6612\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6380 - val_loss: 0.6290\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6225 - val_loss: 0.6209\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.6186\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.6171\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 0.6166\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 0.6154\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 0.6157\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6111 - val_loss: 0.6142\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6154\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6191\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.6149\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.6204\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6135\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6127\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6124\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6129\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6133\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6130\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6117\n",
      "13\n",
      "standardizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6904 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "14\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6646 - val_loss: 0.6551\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6366 - val_loss: 0.6279\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.6126\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6080 - val_loss: 0.6117\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 0.6088\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6043 - val_loss: 0.6102\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 0.6058\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6023 - val_loss: 0.6083\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6035 - val_loss: 0.6076\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6009 - val_loss: 0.6127\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.6055\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5999 - val_loss: 0.6038\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5998 - val_loss: 0.6084\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6010 - val_loss: 0.6046\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5999 - val_loss: 0.6070\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6006 - val_loss: 0.6122\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.6048\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5990 - val_loss: 0.6045\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6002 - val_loss: 0.6037\n",
      "15\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6668 - val_loss: 0.6608\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6515 - val_loss: 0.6533\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6440 - val_loss: 0.6453\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6375 - val_loss: 0.6388\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6321 - val_loss: 0.6339\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6278 - val_loss: 0.6297\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 0.6282\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6215 - val_loss: 0.6237\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6185 - val_loss: 0.6228\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.6205\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6154 - val_loss: 0.6181\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6134 - val_loss: 0.6222\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6123 - val_loss: 0.6158\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6111 - val_loss: 0.6172\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6104 - val_loss: 0.6145\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6091 - val_loss: 0.6137\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6084 - val_loss: 0.6140\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6077 - val_loss: 0.6123\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6067 - val_loss: 0.6118\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 0.6146\n",
      "16\n",
      "standardizeq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6904 - val_loss: 0.6885\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "17\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6913 - val_loss: 0.6891\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "18\n",
      "minmaxW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6908 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "19\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6900 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6781 - val_loss: 0.6496\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.6204\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6199 - val_loss: 0.6179\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.6161\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6151 - val_loss: 0.6147\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6135\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6121 - val_loss: 0.6136\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 0.6193\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6109\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6083 - val_loss: 0.6107\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6108\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6099\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6136\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6073 - val_loss: 0.6094\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6169\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6098\n",
      "20\n",
      "minmaxZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6868 - val_loss: 0.6737\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6528 - val_loss: 0.6406\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.6267\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 0.6186\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.6208\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6141 - val_loss: 0.6153\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6124 - val_loss: 0.6155\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.6145\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6121 - val_loss: 0.6137\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6127\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6129\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6124\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6124\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6136\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6129\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6129\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6133\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6133\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6122\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6154\n",
      "21\n",
      "minmaxn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6903 - val_loss: 0.6877\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6805 - val_loss: 0.6649\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6616 - val_loss: 0.6508\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6414 - val_loss: 0.6333\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6335 - val_loss: 0.6399\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.6287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6274 - val_loss: 0.6287\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6272 - val_loss: 0.6253\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6245 - val_loss: 0.6261\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6238 - val_loss: 0.6248\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6231 - val_loss: 0.6230\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6216 - val_loss: 0.6227\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6209 - val_loss: 0.6231\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6199 - val_loss: 0.6213\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.6217\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.6207\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6182 - val_loss: 0.6218\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6186 - val_loss: 0.6210\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6179 - val_loss: 0.6195\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6173 - val_loss: 0.6245\n",
      "22\n",
      "maxabsq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6933 - val_loss: 0.6897\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6901 - val_loss: 0.6886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "23\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6713 - val_loss: 0.6494\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6297 - val_loss: 0.6182\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6130 - val_loss: 0.6140\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6100 - val_loss: 0.6118\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6091 - val_loss: 0.6126\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6080 - val_loss: 0.6123\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6073 - val_loss: 0.6150\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6075 - val_loss: 0.6106\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6068 - val_loss: 0.6144\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6098\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6117\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6057 - val_loss: 0.6128\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 0.6096\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6043 - val_loss: 0.6099\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6103\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6051 - val_loss: 0.6151\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 0.6110\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.6091\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 0.6093\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.6092\n",
      "24\n",
      "maxabsj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6905 - val_loss: 0.6860\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6774 - val_loss: 0.6660\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6538 - val_loss: 0.6474\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6398 - val_loss: 0.6380\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6320 - val_loss: 0.6325\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6272 - val_loss: 0.6278\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6232 - val_loss: 0.6244\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6206 - val_loss: 0.6223\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.6197\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.6177\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6150 - val_loss: 0.6162\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 0.6174\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6147\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6143\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6138\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.6134\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6128\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6136\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6121\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6120\n",
      "25\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6902 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "26\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6872 - val_loss: 0.6788\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6667 - val_loss: 0.6499\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6364 - val_loss: 0.6276\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6241 - val_loss: 0.6247\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6210 - val_loss: 0.6229\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6204 - val_loss: 0.6267\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6206 - val_loss: 0.6208\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.6218\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6186 - val_loss: 0.6234\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6183 - val_loss: 0.6199\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6181 - val_loss: 0.6206\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6181 - val_loss: 0.6216\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6181 - val_loss: 0.6206\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6175 - val_loss: 0.6196\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6175 - val_loss: 0.6196\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6173 - val_loss: 0.6200\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6171 - val_loss: 0.6191\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6171 - val_loss: 0.6193\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6171 - val_loss: 0.6204\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6175 - val_loss: 0.6194\n",
      "27\n",
      "standardizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6905 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "28\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6932 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "29\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6928 - val_loss: 0.6894\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6896 - val_loss: 0.6871\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6804 - val_loss: 0.6664\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6562 - val_loss: 0.6368\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6260 - val_loss: 0.6195\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6211 - val_loss: 0.6198\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6196 - val_loss: 0.6191\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6189\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6184 - val_loss: 0.6187\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.6184\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6177 - val_loss: 0.6187\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.6185\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6171 - val_loss: 0.6199\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6175 - val_loss: 0.6184\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.6183\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6165 - val_loss: 0.6180\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.6173\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.6169\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.6164\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6145 - val_loss: 0.6163\n",
      "0\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6923 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6881\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6881\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6897 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6894 - val_loss: 0.6875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6876 - val_loss: 0.6814\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6560 - val_loss: 0.6345\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.6236\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6213 - val_loss: 0.6206\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6177 - val_loss: 0.6183\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.6182\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.6168\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.6158\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6139 - val_loss: 0.6169\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6146 - val_loss: 0.6156\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6147\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6123 - val_loss: 0.6146\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.6136\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.6131\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6129\n",
      "1\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6910 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "2\n",
      "standardizei|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6702 - val_loss: 0.6292\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6183 - val_loss: 0.6116\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6101 - val_loss: 0.6101\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6088 - val_loss: 0.6195\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6091 - val_loss: 0.6115\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6077 - val_loss: 0.6104\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6064 - val_loss: 0.6085\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6063 - val_loss: 0.6163\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6054 - val_loss: 0.6089\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.6085\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 0.6095\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6038 - val_loss: 0.6086\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6043 - val_loss: 0.6118\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.6105\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 0.6121\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 0.6090\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6026 - val_loss: 0.6086\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6033 - val_loss: 0.6090\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.6095\n",
      "3\n",
      "maxabsv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6935 - val_loss: 0.6886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6878 - val_loss: 0.6757\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6425 - val_loss: 0.6332\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6280 - val_loss: 0.6216\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 0.6209\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6242 - val_loss: 0.6260\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6229 - val_loss: 0.6213\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6221 - val_loss: 0.6206\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6204 - val_loss: 0.6200\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6212 - val_loss: 0.6210\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 0.6197\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6204 - val_loss: 0.6216\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6203 - val_loss: 0.6177\n",
      "4\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6919 - val_loss: 0.6904\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6905 - val_loss: 0.6892\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6900 - val_loss: 0.6887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "5\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6907 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "6\n",
      "normalizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6919 - val_loss: 0.6904\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6905 - val_loss: 0.6891\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6900 - val_loss: 0.6886\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "7\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6906 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "8\n",
      "standardizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6704 - val_loss: 0.6499\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6321 - val_loss: 0.6232\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6209 - val_loss: 0.6212\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6212 - val_loss: 0.6220\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6199 - val_loss: 0.6235\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6200 - val_loss: 0.6206\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6194 - val_loss: 0.6193\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6190 - val_loss: 0.6196\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6185 - val_loss: 0.6193\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6183 - val_loss: 0.6202\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6191 - val_loss: 0.6197\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6184 - val_loss: 0.6205\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6182 - val_loss: 0.6186\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6160 - val_loss: 0.6177\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6160 - val_loss: 0.6165\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6132 - val_loss: 0.6145\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6127 - val_loss: 0.6155\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6111 - val_loss: 0.6138\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6098 - val_loss: 0.6118\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6105 - val_loss: 0.6115\n",
      "9\n",
      "robustq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6907 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "10\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6941 - val_loss: 0.6890\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "11\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "12\n",
      "minmaxb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6592 - val_loss: 0.6231\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6159 - val_loss: 0.6122\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6074 - val_loss: 0.6195\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6054 - val_loss: 0.6077\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6047 - val_loss: 0.6176\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 0.6138\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6054 - val_loss: 0.6085\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6033 - val_loss: 0.6372\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 0.6117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6024 - val_loss: 0.6064\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6027 - val_loss: 0.6077\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.6062\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 0.6067\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6033 - val_loss: 0.6081\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.6142\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6028 - val_loss: 0.6121\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6022 - val_loss: 0.6063\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6025 - val_loss: 0.6067\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6026 - val_loss: 0.6072\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 0.6071\n",
      "13\n",
      "robustF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.6903 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "14\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.6904 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6889\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "15\n",
      "minmaxQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6903 - val_loss: 0.6885\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "16\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6920 - val_loss: 0.6904\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6905 - val_loss: 0.6893\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6900 - val_loss: 0.6887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "17\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6829 - val_loss: 0.6688\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6496 - val_loss: 0.6357\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6238 - val_loss: 0.6190\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 0.6158\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.6138\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6121 - val_loss: 0.6122\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6105 - val_loss: 0.6118\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6102 - val_loss: 0.6123\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.6114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.6117\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 0.6104\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6084 - val_loss: 0.6129\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.6114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6096\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6097\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6091\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6092\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6070 - val_loss: 0.6093\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6117\n",
      "18\n",
      "normalizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6819 - val_loss: 0.6662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6470 - val_loss: 0.6325\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6230 - val_loss: 0.6169\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6139 - val_loss: 0.6126\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6107 - val_loss: 0.6107\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6094\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6087\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.6096\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6083\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6089\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6084\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6061 - val_loss: 0.6084\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6111\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.6071\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6104\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6059 - val_loss: 0.6087\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6047 - val_loss: 0.6083\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6071\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6093\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6072\n",
      "19\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6903 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6900 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6889 - val_loss: 0.6792\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6462 - val_loss: 0.6255\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6230 - val_loss: 0.6225\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6204 - val_loss: 0.6188\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6188 - val_loss: 0.6175\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6172 - val_loss: 0.6192\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 0.6160\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 0.6157\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6147 - val_loss: 0.6171\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6133 - val_loss: 0.6148\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6121 - val_loss: 0.6186\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6145 - val_loss: 0.6121\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6100 - val_loss: 0.6188\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6104 - val_loss: 0.6121\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6095 - val_loss: 0.6120\n",
      "20\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6927 - val_loss: 0.6892\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "21\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6655 - val_loss: 0.6446\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6354 - val_loss: 0.6376\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6299 - val_loss: 0.6299\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6179 - val_loss: 0.6172\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6099 - val_loss: 0.6150\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6076 - val_loss: 0.6161\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6056 - val_loss: 0.6191\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6066 - val_loss: 0.6176\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6060 - val_loss: 0.6117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6049 - val_loss: 0.6163\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6039 - val_loss: 0.6138\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6038 - val_loss: 0.6125\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6032 - val_loss: 0.6136\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6047 - val_loss: 0.6110\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6050 - val_loss: 0.6115\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6018 - val_loss: 0.6114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6027 - val_loss: 0.6117\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6014 - val_loss: 0.6204\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6046 - val_loss: 0.6097\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6012 - val_loss: 0.6133\n",
      "22\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6908 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "23\n",
      "robustz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6914 - val_loss: 0.6889\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "24\n",
      "maxabsw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6920 - val_loss: 0.6905\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6905 - val_loss: 0.6893\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6901 - val_loss: 0.6888\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "25\n",
      "robusty|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6646 - val_loss: 0.6399\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6246 - val_loss: 0.6192\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6106 - val_loss: 0.6104\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6053 - val_loss: 0.6082\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6032 - val_loss: 0.6145\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.6071\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6015 - val_loss: 0.6061\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6068\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6006 - val_loss: 0.6268\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6057\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5995 - val_loss: 0.6069\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 0.6059\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5997 - val_loss: 0.6061\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5982 - val_loss: 0.6056\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5979 - val_loss: 0.6057\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5983 - val_loss: 0.6065\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5981 - val_loss: 0.6076\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5975 - val_loss: 0.6074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5973 - val_loss: 0.6090\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5975 - val_loss: 0.6076\n",
      "26\n",
      "standardizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6961 - val_loss: 0.6888\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "27\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6901 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6858 - val_loss: 0.6624\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6474 - val_loss: 0.6437\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6612 - val_loss: 0.6726\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6643 - val_loss: 0.6535\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6543 - val_loss: 0.6495\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6391 - val_loss: 0.6396\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6390 - val_loss: 0.6390\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6306 - val_loss: 0.6341\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6269 - val_loss: 0.6322\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6332 - val_loss: 0.6336\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6351 - val_loss: 0.6356\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6326 - val_loss: 0.6346\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6351 - val_loss: 0.6380\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6316 - val_loss: 0.6335\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6279 - val_loss: 0.6306\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6263 - val_loss: 0.6284\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6289 - val_loss: 0.6343\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6359 - val_loss: 0.6527\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6645 - val_loss: 0.6730\n",
      "28\n",
      "minmaxg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6887\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6900 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "29\n",
      "normalizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6764 - val_loss: 0.6549\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6359 - val_loss: 0.6356\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6206 - val_loss: 0.6333\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6171 - val_loss: 0.6231\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6177 - val_loss: 0.6188\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6160 - val_loss: 0.6152\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 0.6171\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6134 - val_loss: 0.6216\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6145 - val_loss: 0.6129\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6127 - val_loss: 0.6275\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6137 - val_loss: 0.6123\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6116 - val_loss: 0.6129\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6128 - val_loss: 0.6262\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6123 - val_loss: 0.6139\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.6129\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6109 - val_loss: 0.6175\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6097 - val_loss: 0.6285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6135 - val_loss: 0.6228\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 0.6123\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 0.6110\n",
      "0\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6931 - val_loss: 0.6897\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6901 - val_loss: 0.6886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "1\n",
      "maxabsT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6935 - val_loss: 0.6903\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6903 - val_loss: 0.6887\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "2\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6771 - val_loss: 0.6626\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6440 - val_loss: 0.6321\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6244 - val_loss: 0.6178\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6141 - val_loss: 0.6130\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6130\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6106 - val_loss: 0.6111\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6107\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6083 - val_loss: 0.6115\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6071 - val_loss: 0.6136\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 0.6148\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6069 - val_loss: 0.6094\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6064 - val_loss: 0.6120\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.6100\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.6126\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6117\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6070 - val_loss: 0.6091\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6081\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6089\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6093\n",
      "3\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6908 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "4\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6921 - val_loss: 0.6906\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6906 - val_loss: 0.6893\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6901 - val_loss: 0.6888\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "5\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6637 - val_loss: 0.6393\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6209 - val_loss: 0.6134\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6064 - val_loss: 0.6086\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6051 - val_loss: 0.6083\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6029 - val_loss: 0.6073\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6015 - val_loss: 0.6057\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6009 - val_loss: 0.6056\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6008 - val_loss: 0.6055\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6001 - val_loss: 0.6053\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6007 - val_loss: 0.6058\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5997 - val_loss: 0.6081\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5995 - val_loss: 0.6092\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6001 - val_loss: 0.6113\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6002 - val_loss: 0.6071\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5984 - val_loss: 0.6078\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5978 - val_loss: 0.6054\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5981 - val_loss: 0.6083\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5988 - val_loss: 0.6055\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5988 - val_loss: 0.6163\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5974 - val_loss: 0.6048\n",
      "6\n",
      "standardizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6902 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "7\n",
      "minmaxW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6912 - val_loss: 0.6886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "8\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6828 - val_loss: 0.6745\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6645 - val_loss: 0.6559\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6474 - val_loss: 0.6432\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6363 - val_loss: 0.6371\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6317 - val_loss: 0.6348\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.6333\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6282 - val_loss: 0.6324\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6276 - val_loss: 0.6318\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6271 - val_loss: 0.6318\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6270 - val_loss: 0.6321\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6269 - val_loss: 0.6319\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6266 - val_loss: 0.6322\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6263 - val_loss: 0.6308\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.6305\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.6310\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6267 - val_loss: 0.6312\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6262 - val_loss: 0.6297\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6258 - val_loss: 0.6310\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6258 - val_loss: 0.6306\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6257 - val_loss: 0.6302\n",
      "9\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6901 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6839 - val_loss: 0.6659\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6550 - val_loss: 0.6444\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6348 - val_loss: 0.6362\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6264 - val_loss: 0.6444\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6196 - val_loss: 0.6201\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6157 - val_loss: 0.6173\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6150 - val_loss: 0.6157\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6137 - val_loss: 0.6151\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6140 - val_loss: 0.6187\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6128 - val_loss: 0.6147\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6125 - val_loss: 0.6163\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6124 - val_loss: 0.6162\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6129 - val_loss: 0.6234\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.6203\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6118 - val_loss: 0.6139\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6113 - val_loss: 0.6127\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6116 - val_loss: 0.6215\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6120 - val_loss: 0.6161\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6106 - val_loss: 0.6350\n",
      "10\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6906 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "11\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6717 - val_loss: 0.6480\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6263 - val_loss: 0.6150\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6112\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6103\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.6107\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6097\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6075 - val_loss: 0.6117\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6087\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.6076\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.6080\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6046 - val_loss: 0.6084\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 0.6107\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 0.6083\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.6064\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6068\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6061\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6018 - val_loss: 0.6062\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6055\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6056\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6010 - val_loss: 0.6055\n",
      "12\n",
      "minmaxX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.6900 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6890\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "13\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 0.6902 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6888\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "14\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6908 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "15\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 0.6907 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6900 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "16\n",
      "normalizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.695 - 0s 4ms/step - loss: 0.6948 - val_loss: 0.6898\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6901 - val_loss: 0.6886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "17\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6919 - val_loss: 0.6903\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6904 - val_loss: 0.6891\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6900 - val_loss: 0.6886\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "18\n",
      "robustf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6900 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6900 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6900 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "19\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6598 - val_loss: 0.6293\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.6144\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6112 - val_loss: 0.6311\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6096 - val_loss: 0.6106\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6107 - val_loss: 0.6130\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6215\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.6119\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6053 - val_loss: 0.6085\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6072 - val_loss: 0.6086\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6054 - val_loss: 0.6075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6054 - val_loss: 0.6073\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6054 - val_loss: 0.6131\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6037 - val_loss: 0.6118\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6046 - val_loss: 0.6097\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6037 - val_loss: 0.6080\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6035 - val_loss: 0.6062\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6032 - val_loss: 0.6315\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6070 - val_loss: 0.6061\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6037 - val_loss: 0.6096\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6049 - val_loss: 0.6051\n",
      "20\n",
      "minmaxz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6761 - val_loss: 0.6455\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6292 - val_loss: 0.6191\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6161 - val_loss: 0.6149\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6111 - val_loss: 0.6125\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6122 - val_loss: 0.6156\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6111 - val_loss: 0.6142\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6084 - val_loss: 0.6282\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6123 - val_loss: 0.6132\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6145\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6073 - val_loss: 0.6148\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6112\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6061 - val_loss: 0.6173\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6068 - val_loss: 0.6109\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6092 - val_loss: 0.6202\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6072 - val_loss: 0.6087\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.6115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6095 - val_loss: 0.6103\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 0.6095\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6089\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6057 - val_loss: 0.6099\n",
      "21\n",
      "robustA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6810 - val_loss: 0.6604\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6412 - val_loss: 0.6251\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6216 - val_loss: 0.6195\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6175 - val_loss: 0.6168\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6152 - val_loss: 0.6165\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6140 - val_loss: 0.6153\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6134 - val_loss: 0.6158\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6125 - val_loss: 0.6182\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 0.6133\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 0.6168\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6110 - val_loss: 0.6169\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6102 - val_loss: 0.6118\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6104 - val_loss: 0.6115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6105 - val_loss: 0.6161\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6081 - val_loss: 0.6143\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6090 - val_loss: 0.6104\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6077 - val_loss: 0.6101\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6074 - val_loss: 0.6108\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 0.6123\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6075 - val_loss: 0.6091\n",
      "22\n",
      "normalizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6908 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6881\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6880 - val_loss: 0.6809\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6574 - val_loss: 0.6317\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6260 - val_loss: 0.6271\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6228 - val_loss: 0.6262\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6220 - val_loss: 0.6245\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6207 - val_loss: 0.6238\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.6230\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.6224\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6182 - val_loss: 0.6226\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6182 - val_loss: 0.6211\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.6203\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.6196\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.6211\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.6186\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 0.6176\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6171\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6168\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6180\n",
      "23\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6940 - val_loss: 0.6888\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "24\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6643 - val_loss: 0.6367\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.6240\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.6144\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6174\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6075 - val_loss: 0.6096\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6097\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6129\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6088\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6031 - val_loss: 0.6066\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6030 - val_loss: 0.6061\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6057\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6065\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6019 - val_loss: 0.6062\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6066\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.6066\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6010 - val_loss: 0.6095\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6012 - val_loss: 0.6124\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6076\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6004 - val_loss: 0.6083\n",
      "25\n",
      "standardizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6684 - val_loss: 0.6312\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 0.6124\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6069 - val_loss: 0.6096\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6041 - val_loss: 0.6089\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.6118\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6080\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6010 - val_loss: 0.6077\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6007 - val_loss: 0.6096\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6010 - val_loss: 0.6078\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6000 - val_loss: 0.6113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5997 - val_loss: 0.6071\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6003 - val_loss: 0.6060\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 0.6059\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5996 - val_loss: 0.6077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5994 - val_loss: 0.6070\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6056\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5981 - val_loss: 0.6065\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5985 - val_loss: 0.6107\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6000 - val_loss: 0.6059\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5985 - val_loss: 0.6054\n",
      "26\n",
      "standardizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6902 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "27\n",
      "minmaxb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6903 - val_loss: 0.6854\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6662 - val_loss: 0.6493\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6314 - val_loss: 0.6252\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6212 - val_loss: 0.6216\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6185 - val_loss: 0.6201\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6170 - val_loss: 0.6185\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.6178\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.6172\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6142 - val_loss: 0.6192\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 0.6188\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6161\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6129 - val_loss: 0.6156\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6128 - val_loss: 0.6158\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6153\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6153\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6150\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6115 - val_loss: 0.6142\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6113 - val_loss: 0.6172\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6127 - val_loss: 0.6138\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6149\n",
      "28\n",
      "normalizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6887\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "29\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6635 - val_loss: 0.6345\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6247 - val_loss: 0.6293\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6172 - val_loss: 0.6196\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6163\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6132\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6059 - val_loss: 0.6170\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6045 - val_loss: 0.6144\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6046 - val_loss: 0.6106\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6040 - val_loss: 0.6103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6025 - val_loss: 0.6103\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6031 - val_loss: 0.6099\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6020 - val_loss: 0.6128\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6035 - val_loss: 0.6121\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6017 - val_loss: 0.6089\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6018 - val_loss: 0.6112\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6013 - val_loss: 0.6143\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6045 - val_loss: 0.6094\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6010 - val_loss: 0.6181\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6030 - val_loss: 0.6095\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6005 - val_loss: 0.6111\n",
      "0\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6901 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6889\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "1\n",
      "standardizej|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6800 - val_loss: 0.6564\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6368 - val_loss: 0.6273\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6190 - val_loss: 0.6229\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6135 - val_loss: 0.6149\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6108 - val_loss: 0.6148\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6085 - val_loss: 0.6116\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6066 - val_loss: 0.6115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6052 - val_loss: 0.6108\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.6128\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.6142\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6039 - val_loss: 0.6098\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6033 - val_loss: 0.6093\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.6093\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 0.6089\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6026 - val_loss: 0.6100\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6040 - val_loss: 0.6089\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6117\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 0.6153\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6019 - val_loss: 0.6080\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6003 - val_loss: 0.6096\n",
      "2\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6912 - val_loss: 0.6886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "3\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6920 - val_loss: 0.6905\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6906 - val_loss: 0.6893\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6900 - val_loss: 0.6887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "4\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6901 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6851 - val_loss: 0.6651\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6533 - val_loss: 0.6416\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6346 - val_loss: 0.6329\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6226 - val_loss: 0.6204\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6178 - val_loss: 0.6221\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6177 - val_loss: 0.6250\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6171 - val_loss: 0.6281\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 0.6237\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6160 - val_loss: 0.6174\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6142 - val_loss: 0.6160\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6132 - val_loss: 0.6170\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6139 - val_loss: 0.6164\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6135 - val_loss: 0.6179\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6126 - val_loss: 0.6174\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6135 - val_loss: 0.6147\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6127 - val_loss: 0.6152\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6143 - val_loss: 0.6199\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 0.6139\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6115 - val_loss: 0.6164\n",
      "5\n",
      "standardizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6904 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "6\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.6577 - val_loss: 0.6437\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6383 - val_loss: 0.6452\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6412 - val_loss: 0.6415\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6423 - val_loss: 0.6462\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6384 - val_loss: 0.6397\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6353 - val_loss: 0.6375\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6421 - val_loss: 0.6389\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6389 - val_loss: 0.6405\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6380 - val_loss: 0.6356\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6349 - val_loss: 0.6341\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6377 - val_loss: 0.6494\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6420 - val_loss: 0.6413\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6379 - val_loss: 0.6474\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6612 - val_loss: 0.6597\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6591 - val_loss: 0.6596\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6576 - val_loss: 0.6610\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6553 - val_loss: 0.6563\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6525 - val_loss: 0.6441\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6426 - val_loss: 0.6463\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6457 - val_loss: 0.6460\n",
      "7\n",
      "robustq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6706 - val_loss: 0.6479\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6289 - val_loss: 0.6204\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6159 - val_loss: 0.6141\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6123 - val_loss: 0.6137\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6102 - val_loss: 0.6124\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6093 - val_loss: 0.6149\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6098 - val_loss: 0.6125\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6074 - val_loss: 0.6138\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6068 - val_loss: 0.6134\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6058 - val_loss: 0.6108\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6055 - val_loss: 0.6106\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 0.6110\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6043 - val_loss: 0.6182\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6061 - val_loss: 0.6104\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6045 - val_loss: 0.6245\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6111\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6039 - val_loss: 0.6134\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6043 - val_loss: 0.6115\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6035 - val_loss: 0.6089\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6032 - val_loss: 0.6089\n",
      "8\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6708 - val_loss: 0.6372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6301 - val_loss: 0.6300\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6248 - val_loss: 0.6227\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6146 - val_loss: 0.6193\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6140 - val_loss: 0.6160\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6105 - val_loss: 0.6160\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6092 - val_loss: 0.6158\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6091 - val_loss: 0.6160\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6064 - val_loss: 0.6127\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 0.6138\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6053 - val_loss: 0.6107\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.6207\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6049 - val_loss: 0.6122\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.6101\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6034 - val_loss: 0.6155\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.6128\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6028 - val_loss: 0.6098\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6024 - val_loss: 0.6106\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6028 - val_loss: 0.6100\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6032 - val_loss: 0.6088\n",
      "9\n",
      "maxabsF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6907 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "10\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6910 - val_loss: 0.6885\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "11\n",
      "minmaxU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6786 - val_loss: 0.6451\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6269 - val_loss: 0.6171\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.6155\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.6154\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.6124\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 0.6119\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.6129\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6098\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6096\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.6141\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6207\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6224\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6070 - val_loss: 0.6095\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6105\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6266\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6142\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 0.6104\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6172\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.6081\n",
      "12\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6755 - val_loss: 0.6599\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6468 - val_loss: 0.6409\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6332 - val_loss: 0.6269\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6221 - val_loss: 0.6174\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6157 - val_loss: 0.6132\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6124 - val_loss: 0.6114\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6116 - val_loss: 0.6107\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6104 - val_loss: 0.6181\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.6154\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6121 - val_loss: 0.6113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.6101\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6097 - val_loss: 0.6135\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6093 - val_loss: 0.6099\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6091 - val_loss: 0.6131\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6172\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6102\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.6115\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6122\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.6108\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6092 - val_loss: 0.6106\n",
      "13\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6927 - val_loss: 0.6902\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6904 - val_loss: 0.6889\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "14\n",
      "standardizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6904 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6846 - val_loss: 0.6652\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6455 - val_loss: 0.6288\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6246 - val_loss: 0.6219\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.6189\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6179 - val_loss: 0.6182\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.6161\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.6143\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 0.6139\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.6157\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6113 - val_loss: 0.6118\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6120\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6097 - val_loss: 0.6101\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6098\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6075 - val_loss: 0.6096\n",
      "15\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6917 - val_loss: 0.6890\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6882 - val_loss: 0.6828\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6708 - val_loss: 0.6549\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6397 - val_loss: 0.6295\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6229 - val_loss: 0.6224\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.6209\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6180 - val_loss: 0.6198\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6173 - val_loss: 0.6194\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.6189\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6162 - val_loss: 0.6183\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6158 - val_loss: 0.6179\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.6184\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.6176\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6150 - val_loss: 0.6175\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6150 - val_loss: 0.6171\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.6172\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.6169\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6144 - val_loss: 0.6170\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 0.6165\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6162\n",
      "16\n",
      "normalizei|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6902 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "17\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6920 - val_loss: 0.6905\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6906 - val_loss: 0.6892\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6900 - val_loss: 0.6887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "18\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 0.6902 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6899 - val_loss: 0.6891\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6900 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6901 - val_loss: 0.6886\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "19\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6624 - val_loss: 0.6385\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6236 - val_loss: 0.6183\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6120 - val_loss: 0.6195\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6068 - val_loss: 0.6111\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6056 - val_loss: 0.6097\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6037 - val_loss: 0.6096\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6035 - val_loss: 0.6104\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6020 - val_loss: 0.6093\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6022 - val_loss: 0.6110\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6040 - val_loss: 0.6075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6014 - val_loss: 0.6127\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6012 - val_loss: 0.6059\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5998 - val_loss: 0.6069\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6017 - val_loss: 0.6210\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6039 - val_loss: 0.6071\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5999 - val_loss: 0.6063\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5999 - val_loss: 0.6112\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6010 - val_loss: 0.6112\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.5996 - val_loss: 0.6083\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.5995 - val_loss: 0.6243\n",
      "20\n",
      "normalizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6900 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6886\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "21\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6908 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "22\n",
      "normalizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6906 - val_loss: 0.6883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6887\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "23\n",
      "normalizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6796 - val_loss: 0.6571\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6379 - val_loss: 0.6306\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6221 - val_loss: 0.6228\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6190 - val_loss: 0.6202\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6187 - val_loss: 0.6199\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6173 - val_loss: 0.6210\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6175 - val_loss: 0.6205\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.6195\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6166 - val_loss: 0.6202\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.6194\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.6211\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.6191\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.6193\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.6210\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.6188\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.6185\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6152 - val_loss: 0.6189\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6159 - val_loss: 0.6197\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6156 - val_loss: 0.6185\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.6199\n",
      "24\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6901 - val_loss: 0.6882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6882\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "25\n",
      "minmaxG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6917 - val_loss: 0.6894\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "26\n",
      "normalizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.6918 - val_loss: 0.6886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6899 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "27\n",
      "robustV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.6990 - val_loss: 0.6899\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6902 - val_loss: 0.6886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "28\n",
      "standardizeq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 0.6907 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 0.6899 - val_loss: 0.6882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6899 - val_loss: 0.6885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.6898 - val_loss: 0.6884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6898 - val_loss: 0.6883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.6899 - val_loss: 0.6884\n",
      "29\n",
      "standardizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.6626 - val_loss: 0.6336\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6159 - val_loss: 0.6122\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6059 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6036 - val_loss: 0.6086\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6028 - val_loss: 0.6070\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6018 - val_loss: 0.6173\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6024 - val_loss: 0.6057\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6001 - val_loss: 0.6090\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5995 - val_loss: 0.6073\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5995 - val_loss: 0.6056\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6004 - val_loss: 0.6058\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5987 - val_loss: 0.6055\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5984 - val_loss: 0.6175\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6008 - val_loss: 0.6106\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.6015 - val_loss: 0.6078\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5986 - val_loss: 0.6059\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5987 - val_loss: 0.6049\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5984 - val_loss: 0.6066\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5981 - val_loss: 0.6060\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.5972 - val_loss: 0.6106\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"accuracy\", \"pd\", \"pf\", \"prec\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [FeedforwardDL(random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20)],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"eclipse\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        FeedforwardDL(random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': array([0.68916062, 0.68607508, 0.68973202, 0.68881778, 0.68961774,\n",
      "       0.68761785, 0.68830353, 0.68767499, 0.68716073, 0.68458945]), 'pd': array([0.6061131 , 0.5495607 , 0.61626036, 0.5892835 , 0.61155798,\n",
      "       0.63432743, 0.63828734, 0.60858805, 0.60982552, 0.5955946 ]), 'pf': array([0.2395966 , 0.19681529, 0.24723992, 0.22579618, 0.24341826,\n",
      "       0.26666667, 0.26878981, 0.24447983, 0.24649682, 0.23906582]), 'prec': array([0.68455625, 0.70548054, 0.68135176, 0.69124692, 0.68306842,\n",
      "       0.67111809, 0.67074122, 0.6810691 , 0.67972414, 0.68124558])}\n",
      "acc: 0.6879892577566996\n",
      "pd: 0.6092067813389432\n",
      "pf: 0.24394904458598726\n",
      "prec: 0.6812986674467111\n"
     ]
    }
   ],
   "source": [
    "interp = DODGEInterpreter(files=['./eclipse.txt'], max_by=0, \n",
    "                          metrics=['accuracy', 'pd', 'pf', 'prec'])\n",
    "results = interp.interpret()['eclipse.txt']\n",
    "print(results)\n",
    "print('acc:', np.median(results['accuracy']))\n",
    "print('pd:', np.median(results['pd']))\n",
    "print('pf:', np.median(results['pf']))\n",
    "print('prec:', np.median(results['prec']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = np.where(data.y_train < 2, 0, np.where(data.y_train < 6, 1, 2))\n",
    "data.y_test = np.where(data.y_test < 2, 0, np.where(data.y_test < 6, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y_train = to_categorical(data.y_train, num_classes=3)\n",
    "data.y_test = to_categorical(data.y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152eba970>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152ebaeb0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152eba130>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d206190>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2062e0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d206f40>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152ebab20>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d206100>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1501dd340>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14fe686d0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14dea2fa0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1501f9400>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x10e46cb20>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x10e46c370>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2ae190>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2ae1c0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152fc7490>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152fc7ca0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152fc7e20>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a02e0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a03a0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a0a30>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a0d60>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a0c40>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a09a0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a01f0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f9eb80>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f9e970>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f9e0d0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f9e100>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f9eee0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d26ca90>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a7be0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a7b80>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a7430>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a7760>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a7370>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a7f40>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a7160>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d296250>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d296760>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d296e20>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2964c0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d296a60>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2965b0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d296670>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15012b4f0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d206370>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a9a60>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a9af0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a96d0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robustx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1552 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0486 - val_loss: 0.9804\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9460 - val_loss: 0.9287\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9218 - val_loss: 0.9199\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9158 - val_loss: 0.9160\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9117 - val_loss: 0.9133\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9101 - val_loss: 0.9126\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9090 - val_loss: 0.9122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9077 - val_loss: 0.9114\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9081 - val_loss: 0.9115\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9074 - val_loss: 0.9111\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9064 - val_loss: 0.9106\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9060 - val_loss: 0.9091\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9053 - val_loss: 0.9095\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9050 - val_loss: 0.9111\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9054 - val_loss: 0.9109\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9051 - val_loss: 0.9112\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9050 - val_loss: 0.9110\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9046 - val_loss: 0.9087\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.9093\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.9091\n",
      "Top-2 accuracy = 0.845\n",
      "1\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1559 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0446 - val_loss: 1.0050\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9736 - val_loss: 0.9538\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9435 - val_loss: 0.9397\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9347 - val_loss: 0.9348\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9310 - val_loss: 0.9319\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9286 - val_loss: 0.9304\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9269 - val_loss: 0.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9252 - val_loss: 0.9264\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9232 - val_loss: 0.9249\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9216 - val_loss: 0.9236\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9206 - val_loss: 0.9225\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9193 - val_loss: 0.9216\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9186 - val_loss: 0.9211\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9178 - val_loss: 0.9215\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9174 - val_loss: 0.9203\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9168 - val_loss: 0.9196\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9163 - val_loss: 0.9193\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9159 - val_loss: 0.9196\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9155 - val_loss: 0.9186\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9153 - val_loss: 0.9182\n",
      "Top-2 accuracy = 0.842\n",
      "2\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1562 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0097 - val_loss: 0.9618\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9342\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 0.9260\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 0.9222\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9211 - val_loss: 0.9204\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9202\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9177\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.9177\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9158 - val_loss: 0.9175\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9154 - val_loss: 0.9177\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9146 - val_loss: 0.9173\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9141 - val_loss: 0.9156\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9132 - val_loss: 0.9158\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9131 - val_loss: 0.9203\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9148 - val_loss: 0.9152\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9126 - val_loss: 0.9162\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9119 - val_loss: 0.9151\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9116 - val_loss: 0.9155\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9117 - val_loss: 0.9148\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9112 - val_loss: 0.9157\n",
      "Top-2 accuracy = 0.838\n",
      "3\n",
      "standardizep|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1569 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0685 - val_loss: 1.0429\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0213 - val_loss: 0.9996\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9871 - val_loss: 0.9760\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9691 - val_loss: 0.9637\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9592 - val_loss: 0.9570\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9522 - val_loss: 0.9505\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9463 - val_loss: 0.9452\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9414 - val_loss: 0.9406\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9376 - val_loss: 0.9372\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9344 - val_loss: 0.9348\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9321 - val_loss: 0.9329\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9303 - val_loss: 0.9315\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9291 - val_loss: 0.9304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9274 - val_loss: 0.9286\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9264 - val_loss: 0.9277\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9256 - val_loss: 0.9268\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9249 - val_loss: 0.9266\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9244 - val_loss: 0.9267\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9240 - val_loss: 0.9255\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9249\n",
      "Top-2 accuracy = 0.836\n",
      "4\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1576 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0500 - val_loss: 1.0039\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9674 - val_loss: 0.9472\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9368 - val_loss: 0.9354\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 0.9319\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9279 - val_loss: 0.9307\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9261 - val_loss: 0.9283\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9247 - val_loss: 0.9272\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9264\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9222 - val_loss: 0.9255\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9249\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9242\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9256\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9186 - val_loss: 0.9239\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9232\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9173 - val_loss: 0.9226\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 0.9224\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 0.9221\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9152 - val_loss: 0.9214\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9150 - val_loss: 0.9216\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9151 - val_loss: 0.9212\n",
      "Top-2 accuracy = 0.837\n",
      "5\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1582 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0815 - val_loss: 1.0693\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0650 - val_loss: 1.0646\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0615 - val_loss: 1.0615\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0560 - val_loss: 1.0528\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0404 - val_loss: 1.0282\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0065 - val_loss: 0.9907\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9737 - val_loss: 0.9648\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9556 - val_loss: 0.9518\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9462 - val_loss: 0.9455\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9420 - val_loss: 0.9423\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9396 - val_loss: 0.9393\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9378 - val_loss: 0.9378\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9367 - val_loss: 0.9368\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9360 - val_loss: 0.9361\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9357 - val_loss: 0.9355\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9351 - val_loss: 0.9352\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9351 - val_loss: 0.9347\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9345 - val_loss: 0.9346\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9344 - val_loss: 0.9341\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9339 - val_loss: 0.9342\n",
      "Top-2 accuracy = 0.829\n",
      "6\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1587 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0897 - val_loss: 1.0825\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0768 - val_loss: 1.0735\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0698 - val_loss: 1.0689\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0662 - val_loss: 1.0668\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0646 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0638 - val_loss: 1.0637\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0511 - val_loss: 1.0353\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0191 - val_loss: 1.0060\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9975 - val_loss: 0.9909\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9849 - val_loss: 0.9802\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9758 - val_loss: 0.9736\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9702 - val_loss: 0.9690\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9660 - val_loss: 0.9654\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9631 - val_loss: 0.9634\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9609 - val_loss: 0.9609\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9600 - val_loss: 0.9595\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9573 - val_loss: 0.9583\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9559 - val_loss: 0.9568\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9547 - val_loss: 0.9557\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9539 - val_loss: 0.9577\n",
      "Top-2 accuracy = 0.827\n",
      "7\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1592 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0399 - val_loss: 0.9652\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9448 - val_loss: 0.9345\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9315 - val_loss: 0.9291\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9274 - val_loss: 0.9267\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9249 - val_loss: 0.9251\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9231 - val_loss: 0.9239\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9220 - val_loss: 0.9230\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9207 - val_loss: 0.9225\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9198 - val_loss: 0.9225\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9212\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9189 - val_loss: 0.9204\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9180 - val_loss: 0.9200\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9173 - val_loss: 0.9195\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9169 - val_loss: 0.9196\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9168 - val_loss: 0.9195\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9160 - val_loss: 0.9195\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9163 - val_loss: 0.9189\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9155 - val_loss: 0.9196\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9154 - val_loss: 0.9186\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9150 - val_loss: 0.9184\n",
      "Top-2 accuracy = 0.84\n",
      "8\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1597 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0660 - val_loss: 1.0399\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0132 - val_loss: 0.9844\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9624 - val_loss: 0.9469\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9394\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9375 - val_loss: 0.9366\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9355 - val_loss: 0.9351\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9343 - val_loss: 0.9344\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9335 - val_loss: 0.9339\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9330 - val_loss: 0.9337\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9328 - val_loss: 0.9330\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9328\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9317 - val_loss: 0.9324\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9312 - val_loss: 0.9319\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9310 - val_loss: 0.9318\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9306 - val_loss: 0.9312\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9302 - val_loss: 0.9308\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9300 - val_loss: 0.9306\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9296 - val_loss: 0.9303\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9294 - val_loss: 0.9301\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9292 - val_loss: 0.9298\n",
      "Top-2 accuracy = 0.837\n",
      "9\n",
      "maxabsY|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1602 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0856 - val_loss: 1.0693\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0467 - val_loss: 1.0242\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9979 - val_loss: 0.9750\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9595 - val_loss: 0.9519\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 0.9437\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9397 - val_loss: 0.9389\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9367 - val_loss: 0.9369\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9350 - val_loss: 0.9353\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9340 - val_loss: 0.9349\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 0.9341\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9333 - val_loss: 0.9335\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9327 - val_loss: 0.9333\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9326 - val_loss: 0.9333\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9329 - val_loss: 0.9326\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9326 - val_loss: 0.9336\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9323 - val_loss: 0.9326\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9320 - val_loss: 0.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9319 - val_loss: 0.9329\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9319 - val_loss: 0.9328\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9319 - val_loss: 0.9323\n",
      "Top-2 accuracy = 0.838\n",
      "10\n",
      "standardizeU|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1609 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0305 - val_loss: 0.9551\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9328\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9290 - val_loss: 0.9281\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9256 - val_loss: 0.9265\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.9262\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9234\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.9226\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9221\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9210\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9169 - val_loss: 0.9204\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 0.9211\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9158 - val_loss: 0.9191\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9143 - val_loss: 0.9188\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9142 - val_loss: 0.9183\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9128 - val_loss: 0.9172\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9123 - val_loss: 0.9179\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9119 - val_loss: 0.9168\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9127 - val_loss: 0.9155\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9112 - val_loss: 0.9163\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9110 - val_loss: 0.9156\n",
      "Top-2 accuracy = 0.841\n",
      "11\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.1166 - val_loss: 1.0598\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0492 - val_loss: 1.0373\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0262 - val_loss: 1.0145\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0025 - val_loss: 0.9918\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9809 - val_loss: 0.9722\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9631 - val_loss: 0.9578\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.9477\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 0.9413\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9378 - val_loss: 0.9371\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9340 - val_loss: 0.9338\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9320\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9311\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9292 - val_loss: 0.9302\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9285 - val_loss: 0.9295\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9280 - val_loss: 0.9287\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9276 - val_loss: 0.9292\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9276 - val_loss: 0.9279\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9274 - val_loss: 0.9281\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9274 - val_loss: 0.9280\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 0.9277\n",
      "Top-2 accuracy = 0.837\n",
      "12\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1621 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0414 - val_loss: 0.9556\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9353 - val_loss: 0.9322\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9290 - val_loss: 0.9284\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9264 - val_loss: 0.9273\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9240 - val_loss: 0.9250\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9230 - val_loss: 0.9245\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9226\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.9228\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 0.9216\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9205\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.9197\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9169 - val_loss: 0.9197\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 0.9189\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9155 - val_loss: 0.9206\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9153 - val_loss: 0.9192\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9143 - val_loss: 0.9183\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9146 - val_loss: 0.9180\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9141 - val_loss: 0.9176\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9141 - val_loss: 0.9173\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9134 - val_loss: 0.9171\n",
      "Top-2 accuracy = 0.841\n",
      "13\n",
      "normalizeM|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1627 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0685 - val_loss: 1.0347\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0009 - val_loss: 0.9771\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9605 - val_loss: 0.9524\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9438 - val_loss: 0.9421\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9364 - val_loss: 0.9364\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9318 - val_loss: 0.9326\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9287 - val_loss: 0.9297\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9263 - val_loss: 0.9282\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9248 - val_loss: 0.9269\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9261\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9224 - val_loss: 0.9251\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9240\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9205 - val_loss: 0.9241\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9200 - val_loss: 0.9231\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9194 - val_loss: 0.9227\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9188 - val_loss: 0.9229\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9184 - val_loss: 0.9220\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9179 - val_loss: 0.9215\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9176 - val_loss: 0.9213\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9172 - val_loss: 0.9212\n",
      "Top-2 accuracy = 0.841\n",
      "14\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1631 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0242 - val_loss: 0.9628\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 0.9397\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.9316\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9268 - val_loss: 0.9275\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9239 - val_loss: 0.9263\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9222 - val_loss: 0.9244\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9237\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9202 - val_loss: 0.9231\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9193 - val_loss: 0.9228\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9218\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9181 - val_loss: 0.9216\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9212\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9171 - val_loss: 0.9205\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9167 - val_loss: 0.9200\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9163 - val_loss: 0.9198\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 0.9193\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9154 - val_loss: 0.9190\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9151 - val_loss: 0.9185\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9151 - val_loss: 0.9188\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9147 - val_loss: 0.9190\n",
      "Top-2 accuracy = 0.841\n",
      "15\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0505 - val_loss: 1.0090\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9800 - val_loss: 0.9644\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9455\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9393\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9352\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9329\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9298 - val_loss: 0.9313\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9272 - val_loss: 0.9287\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 0.9269\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9271\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9235 - val_loss: 0.9261\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9225 - val_loss: 0.9258\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9264\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9250\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9249\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9274\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.9264\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9237\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.9237\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 0.9235\n",
      "Top-2 accuracy = 0.841\n",
      "16\n",
      "standardizej|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1639 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0396 - val_loss: 0.9711\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9490 - val_loss: 0.9396\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9329 - val_loss: 0.9327\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9275 - val_loss: 0.9303\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9248 - val_loss: 0.9269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9227 - val_loss: 0.9254\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9209 - val_loss: 0.9247\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9200 - val_loss: 0.9226\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9188 - val_loss: 0.9222\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9179 - val_loss: 0.9212\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9175 - val_loss: 0.9206\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9167 - val_loss: 0.9200\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9164 - val_loss: 0.9199\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9158 - val_loss: 0.9192\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9157 - val_loss: 0.9189\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9150 - val_loss: 0.9194\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9142 - val_loss: 0.9185\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9144 - val_loss: 0.9184\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9142 - val_loss: 0.9181\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9136 - val_loss: 0.9176\n",
      "Top-2 accuracy = 0.841\n",
      "17\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1643 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0258 - val_loss: 0.9754\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9475\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9398 - val_loss: 0.9392\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9358 - val_loss: 0.9366\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9334 - val_loss: 0.9342\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9323 - val_loss: 0.9328\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9308 - val_loss: 0.9319\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9296 - val_loss: 0.9299\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9272 - val_loss: 0.9276\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9258 - val_loss: 0.9273\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9237 - val_loss: 0.9252\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9227 - val_loss: 0.9237\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9218 - val_loss: 0.9296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9213 - val_loss: 0.9234\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9204 - val_loss: 0.9225\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9199 - val_loss: 0.9222\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9195 - val_loss: 0.9233\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9190 - val_loss: 0.9228\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9192 - val_loss: 0.9209\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9187 - val_loss: 0.9206\n",
      "Top-2 accuracy = 0.837\n",
      "18\n",
      "maxabsB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0383 - val_loss: 0.9716\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9353\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 0.9309\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.9266\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9236 - val_loss: 0.9244\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9225 - val_loss: 0.9242\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9221 - val_loss: 0.9246\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9215 - val_loss: 0.9247\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9247\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9241\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9231\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9225\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9273\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9222 - val_loss: 0.9221\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9198 - val_loss: 0.9224\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9226\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 0.9271\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9222\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.9220\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9214\n",
      "Top-2 accuracy = 0.837\n",
      "19\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1655 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0585 - val_loss: 1.0152\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9741 - val_loss: 0.9462\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 0.9387\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9365 - val_loss: 0.9366\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9357\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9335 - val_loss: 0.9347\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9331 - val_loss: 0.9354\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9322\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9317\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 0.9305\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9293\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9283\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9275\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9258 - val_loss: 0.9268\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9261\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9252 - val_loss: 0.9265\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9248 - val_loss: 0.9258\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9244 - val_loss: 0.9255\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9240 - val_loss: 0.9250\n",
      "Top-2 accuracy = 0.837\n",
      "20\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1660 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0535 - val_loss: 1.0055\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9816 - val_loss: 0.9624\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 0.9492\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9423 - val_loss: 0.9425\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 0.9372\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 0.9355\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9307 - val_loss: 0.9316\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9278 - val_loss: 0.9302\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 0.9274\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9249 - val_loss: 0.9283\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9255\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9219 - val_loss: 0.9248\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9242\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9233\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9226\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9221\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.9214\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9208\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9179 - val_loss: 0.9203\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9178 - val_loss: 0.9206\n",
      "Top-2 accuracy = 0.838\n",
      "21\n",
      "robustp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1666 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.1422 - val_loss: 0.9703\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9610 - val_loss: 0.9517\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9435\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9373\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9344\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9340 - val_loss: 0.9311\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9317\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 0.9304\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9280 - val_loss: 0.9301\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9279 - val_loss: 0.9278\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.9262\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9235 - val_loss: 0.9255\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9283\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9239 - val_loss: 0.9246\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9221 - val_loss: 0.9242\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9221 - val_loss: 0.9290\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9209 - val_loss: 0.9233\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.9239\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 0.9257\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9207 - val_loss: 0.9223\n",
      "Top-2 accuracy = 0.84\n",
      "22\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0174 - val_loss: 0.9759\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9359\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9301 - val_loss: 0.9313\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9262 - val_loss: 0.9288\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9232 - val_loss: 0.9266\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9212 - val_loss: 0.9254\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9203 - val_loss: 0.9248\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9196 - val_loss: 0.9238\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9234\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9221\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9179 - val_loss: 0.9223\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9175 - val_loss: 0.9212\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9172 - val_loss: 0.9212\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9167 - val_loss: 0.9210\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9162 - val_loss: 0.9199\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9159 - val_loss: 0.9193\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9162 - val_loss: 0.9198\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9153 - val_loss: 0.9187\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9152 - val_loss: 0.9186\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9149 - val_loss: 0.9193\n",
      "Top-2 accuracy = 0.841\n",
      "23\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1674 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0302 - val_loss: 0.9615\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9405 - val_loss: 0.9323\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9283 - val_loss: 0.9280\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.9265\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9242\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9205\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9172 - val_loss: 0.9189\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.9183\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9152 - val_loss: 0.9180\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9150 - val_loss: 0.9203\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9149 - val_loss: 0.9188\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9135 - val_loss: 0.9171\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9126 - val_loss: 0.9172\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9126 - val_loss: 0.9175\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9128 - val_loss: 0.9161\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9114 - val_loss: 0.9153\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9114 - val_loss: 0.9165\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9113 - val_loss: 0.9182\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9129 - val_loss: 0.9146\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9103 - val_loss: 0.9166\n",
      "Top-2 accuracy = 0.841\n",
      "24\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0314 - val_loss: 0.9579\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9333\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9308\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9288 - val_loss: 0.9301\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9272 - val_loss: 0.9286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9267\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 0.9259\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9235 - val_loss: 0.9244\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9215 - val_loss: 0.9242\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9197 - val_loss: 0.9213\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9211\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9176 - val_loss: 0.9198\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 0.9194\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9152 - val_loss: 0.9175\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9153 - val_loss: 0.9189\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9147 - val_loss: 0.9170\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9132 - val_loss: 0.9179\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9128 - val_loss: 0.9160\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9125 - val_loss: 0.9159\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9127 - val_loss: 0.9165\n",
      "Top-2 accuracy = 0.84\n",
      "25\n",
      "maxabsq|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1686 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0561 - val_loss: 1.0224\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9738 - val_loss: 0.9482\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9351\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 0.9310\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9267 - val_loss: 0.9299\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9244 - val_loss: 0.9267\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9234 - val_loss: 0.9250\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9240\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9246\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.9226\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9222\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9186 - val_loss: 0.9214\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9218\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9214\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 0.9210\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9169 - val_loss: 0.9213\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9168 - val_loss: 0.9198\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.9200\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 0.9194\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9151 - val_loss: 0.9188\n",
      "Top-2 accuracy = 0.841\n",
      "26\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0307 - val_loss: 0.9656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.9305\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 0.9263\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.9250\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.9228\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9220\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9203\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9199\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 0.9203\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 0.9187\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9150 - val_loss: 0.9179\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9154 - val_loss: 0.9175\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9147 - val_loss: 0.9187\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9141 - val_loss: 0.9169\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9135 - val_loss: 0.9164\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9136 - val_loss: 0.9171\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9131 - val_loss: 0.9171\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9126 - val_loss: 0.9170\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9121 - val_loss: 0.9171\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9124 - val_loss: 0.9162\n",
      "Top-2 accuracy = 0.84\n",
      "27\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0526 - val_loss: 1.0040\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9616 - val_loss: 0.9428\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9310 - val_loss: 0.9293\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9235 - val_loss: 0.9241\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9194 - val_loss: 0.9212\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9202\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9167 - val_loss: 0.9213\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9159 - val_loss: 0.9208\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9148 - val_loss: 0.9232\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9140 - val_loss: 0.9207\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9137 - val_loss: 0.9212\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9137 - val_loss: 0.9174\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9117 - val_loss: 0.9173\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9111 - val_loss: 0.9182\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9114 - val_loss: 0.9174\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9105 - val_loss: 0.9176\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9110 - val_loss: 0.9166\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9101 - val_loss: 0.9162\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9096 - val_loss: 0.9201\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9106 - val_loss: 0.9158\n",
      "Top-2 accuracy = 0.841\n",
      "28\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1704 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0779 - val_loss: 1.0562\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0323 - val_loss: 1.0049\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9807 - val_loss: 0.9622\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9533 - val_loss: 0.9475\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9439 - val_loss: 0.9404\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9364\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9355 - val_loss: 0.9340\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9329 - val_loss: 0.9326\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9319 - val_loss: 0.9317\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9311 - val_loss: 0.9308\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9306 - val_loss: 0.9304\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9299 - val_loss: 0.9298\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9295 - val_loss: 0.9294\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9290 - val_loss: 0.9292\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9286 - val_loss: 0.9288\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9282 - val_loss: 0.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9279 - val_loss: 0.9281\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9275 - val_loss: 0.9279\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9272 - val_loss: 0.9275\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9270 - val_loss: 0.9274\n",
      "Top-2 accuracy = 0.838\n",
      "29\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0376 - val_loss: 0.9987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9695 - val_loss: 0.9500\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9381\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9360\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 0.9380\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9273\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9241 - val_loss: 0.9295\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9231\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9272\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.9237\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9249\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9268\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9227\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9221\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9211\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9210\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9207\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 0.9209\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9208 - val_loss: 0.9246\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9218\n",
      "Top-2 accuracy = 0.833\n",
      "0\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1713 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0923 - val_loss: 1.0831\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0774 - val_loss: 1.0740\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0703 - val_loss: 1.0693\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0665 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0644 - val_loss: 1.0645\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0424\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0246 - val_loss: 1.0132\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0019 - val_loss: 0.9961\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9877 - val_loss: 0.9845\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9792 - val_loss: 0.9774\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9734 - val_loss: 0.9728\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9696 - val_loss: 0.9696\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9668 - val_loss: 0.9683\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9646 - val_loss: 0.9655\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9625 - val_loss: 0.9631\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9606 - val_loss: 0.9617\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9593 - val_loss: 0.9605\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9580 - val_loss: 0.9594\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9570 - val_loss: 0.9585\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9562 - val_loss: 0.9576\n",
      "Top-2 accuracy = 0.819\n",
      "1\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1719 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.0886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0380 - val_loss: 1.0119\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9944 - val_loss: 0.9928\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9796 - val_loss: 0.9790\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9700 - val_loss: 0.9727\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9623 - val_loss: 0.9649\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9571 - val_loss: 0.9597\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9525 - val_loss: 0.9552\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9480 - val_loss: 0.9543\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9460 - val_loss: 0.9508\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9434 - val_loss: 0.9492\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9426 - val_loss: 0.9443\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9403 - val_loss: 0.9419\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9384 - val_loss: 0.9415\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9368 - val_loss: 0.9404\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9358 - val_loss: 0.9400\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9347 - val_loss: 0.9384\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9331 - val_loss: 0.9391\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9340 - val_loss: 0.9374\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9323 - val_loss: 0.9370\n",
      "Top-2 accuracy = 0.833\n",
      "2\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1723 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0582 - val_loss: 1.0242\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9853 - val_loss: 0.9562\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9356\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9314 - val_loss: 0.9319\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9301\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9282\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9255 - val_loss: 0.9270\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9240 - val_loss: 0.9258\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9228 - val_loss: 0.9250\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9239\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9209 - val_loss: 0.9231\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9201 - val_loss: 0.9228\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9197 - val_loss: 0.9223\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9189 - val_loss: 0.9217\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9184 - val_loss: 0.9210\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9178 - val_loss: 0.9207\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9175 - val_loss: 0.9200\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9170 - val_loss: 0.9195\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9167 - val_loss: 0.9196\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9163 - val_loss: 0.9191\n",
      "Top-2 accuracy = 0.839\n",
      "3\n",
      "normalizeq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9987 - val_loss: 0.9492\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9299\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 0.9254\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9235\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.9228\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9198 - val_loss: 0.9212\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9206\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.9204\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.9200\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9201\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9171 - val_loss: 0.9201\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9166 - val_loss: 0.9197\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9167 - val_loss: 0.9204\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9163 - val_loss: 0.9193\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 0.9194\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 0.9188\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9155 - val_loss: 0.9185\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9154 - val_loss: 0.9186\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9151 - val_loss: 0.9179\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9146 - val_loss: 0.9177\n",
      "Top-2 accuracy = 0.837\n",
      "4\n",
      "maxabse|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1731 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0842 - val_loss: 1.0554\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0134 - val_loss: 0.9762\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9501 - val_loss: 0.9385\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9339 - val_loss: 0.9331\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9311 - val_loss: 0.9315\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9299 - val_loss: 0.9305\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9292 - val_loss: 0.9301\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9286 - val_loss: 0.9291\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9279 - val_loss: 0.9288\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9275 - val_loss: 0.9283\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9271 - val_loss: 0.9280\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9267 - val_loss: 0.9273\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9259 - val_loss: 0.9267\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9250 - val_loss: 0.9259\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9238 - val_loss: 0.9245\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9227 - val_loss: 0.9239\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9218 - val_loss: 0.9232\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9208 - val_loss: 0.9229\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9201 - val_loss: 0.9222\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9199 - val_loss: 0.9220\n",
      "Top-2 accuracy = 0.837\n",
      "5\n",
      "standardizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9904 - val_loss: 0.9372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9231 - val_loss: 0.9215\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9150 - val_loss: 0.9177\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9143 - val_loss: 0.9195\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9165 - val_loss: 0.9176\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9129 - val_loss: 0.9172\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9124 - val_loss: 0.9161\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9130 - val_loss: 0.9220\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9132 - val_loss: 0.9220\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9137 - val_loss: 0.9152\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9118 - val_loss: 0.9173\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9121 - val_loss: 0.9156\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9109 - val_loss: 0.9171\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9127 - val_loss: 0.9176\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9110 - val_loss: 0.9207\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9151 - val_loss: 0.9147\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9102 - val_loss: 0.9180\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9106 - val_loss: 0.9174\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9126 - val_loss: 0.9167\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9101 - val_loss: 0.9173\n",
      "Top-2 accuracy = 0.836\n",
      "6\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0234 - val_loss: 0.9482\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9335 - val_loss: 0.9298\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9259 - val_loss: 0.9303\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9239 - val_loss: 0.9263\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9229 - val_loss: 0.9241\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9217 - val_loss: 0.9239\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9211 - val_loss: 0.9245\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9206 - val_loss: 0.9239\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9202 - val_loss: 0.9233\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9192 - val_loss: 0.9224\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9199 - val_loss: 0.9215\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9175 - val_loss: 0.9201\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9178 - val_loss: 0.9191\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9162 - val_loss: 0.9192\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9158 - val_loss: 0.9191\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9157 - val_loss: 0.9185\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9154 - val_loss: 0.9199\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9150 - val_loss: 0.9226\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9154 - val_loss: 0.9183\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9154 - val_loss: 0.9177\n",
      "Top-2 accuracy = 0.837\n",
      "7\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0354 - val_loss: 0.9556\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 0.9362\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 0.9283\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9253 - val_loss: 0.9251\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9266\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9228 - val_loss: 0.9230\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9209 - val_loss: 0.9244\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9231\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.9224\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9241\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.9217\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 0.9224\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 0.9214\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9212\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9209\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 0.9210\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9238\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9204\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9171 - val_loss: 0.9209\n",
      "Top-2 accuracy = 0.838\n",
      "8\n",
      "standardizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0221 - val_loss: 0.9475\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9256 - val_loss: 0.9307\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9208 - val_loss: 0.9217\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9178 - val_loss: 0.9211\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9170 - val_loss: 0.9195\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9150 - val_loss: 0.9211\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9149 - val_loss: 0.9189\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9142 - val_loss: 0.9191\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9137 - val_loss: 0.9183\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9129 - val_loss: 0.9179\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9127 - val_loss: 0.9172\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9127 - val_loss: 0.9222\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9125 - val_loss: 0.9198\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9126 - val_loss: 0.9181\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9114 - val_loss: 0.9174\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9112 - val_loss: 0.9168\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9116 - val_loss: 0.9188\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9115 - val_loss: 0.9166\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9109 - val_loss: 0.9168\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9111 - val_loss: 0.9183\n",
      "Top-2 accuracy = 0.834\n",
      "9\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0451 - val_loss: 0.9898\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9589 - val_loss: 0.9455\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 0.9352\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 0.9322\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9318\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 0.9315\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 0.9287\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9280\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9247 - val_loss: 0.9269\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9240 - val_loss: 0.9256\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9239 - val_loss: 0.9254\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9225 - val_loss: 0.9245\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9265\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9244\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9231\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9224\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9207 - val_loss: 0.9221\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9227\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9199 - val_loss: 0.9216\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9218\n",
      "Top-2 accuracy = 0.838\n",
      "10\n",
      "maxabsD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0765 - val_loss: 1.0494\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0114 - val_loss: 0.9713\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 0.9369\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 0.9338\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9308 - val_loss: 0.9311\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 0.9294\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9284 - val_loss: 0.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9278 - val_loss: 0.9282\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9272\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.9266\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9260 - val_loss: 0.9264\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9256 - val_loss: 0.9282\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9250 - val_loss: 0.9250\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9247 - val_loss: 0.9276\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9244 - val_loss: 0.9245\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.9240\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9239 - val_loss: 0.9236\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9231\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9225 - val_loss: 0.9230\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9227 - val_loss: 0.9233\n",
      "Top-2 accuracy = 0.839\n",
      "11\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1771 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0666 - val_loss: 1.0543\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0431 - val_loss: 1.0323\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0129 - val_loss: 0.9973\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9804 - val_loss: 0.9720\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9620 - val_loss: 0.9592\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9522 - val_loss: 0.9513\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9467 - val_loss: 0.9469\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9429 - val_loss: 0.9434\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9403 - val_loss: 0.9406\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9384 - val_loss: 0.9391\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9368 - val_loss: 0.9374\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9359 - val_loss: 0.9366\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9351 - val_loss: 0.9358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9343 - val_loss: 0.9348\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9338 - val_loss: 0.9343\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9335 - val_loss: 0.9340\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9330 - val_loss: 0.9335\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9325 - val_loss: 0.9331\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9320 - val_loss: 0.9326\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9316 - val_loss: 0.9321\n",
      "Top-2 accuracy = 0.836\n",
      "12\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1775 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0780 - val_loss: 1.0527\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0219 - val_loss: 0.9897\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9679 - val_loss: 0.9574\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 0.9435\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9374\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9359\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9334 - val_loss: 0.9340\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9341\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9309 - val_loss: 0.9321\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 0.9319\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9295 - val_loss: 0.9315\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9304 - val_loss: 0.9304\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9281 - val_loss: 0.9303\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9286 - val_loss: 0.9296\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9276 - val_loss: 0.9296\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9273 - val_loss: 0.9283\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.9288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 0.9279\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9261 - val_loss: 0.9286\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9258 - val_loss: 0.9273\n",
      "Top-2 accuracy = 0.837\n",
      "13\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0979 - val_loss: 1.0696\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0416 - val_loss: 1.0008\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9668 - val_loss: 0.9486\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9407 - val_loss: 0.9409\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9357 - val_loss: 0.9390\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9340\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 0.9316\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9286 - val_loss: 0.9300\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9273 - val_loss: 0.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9270\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9261\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9235 - val_loss: 0.9257\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9254\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9225 - val_loss: 0.9255\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.9243\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9221 - val_loss: 0.9248\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9240\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9253\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9242\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9237\n",
      "Top-2 accuracy = 0.838\n",
      "14\n",
      "maxabsg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0105 - val_loss: 0.9516\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9352\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9337 - val_loss: 0.9378\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9322 - val_loss: 0.9286\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9272 - val_loss: 0.9361\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9240 - val_loss: 0.9229\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9233\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.9344\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9217 - val_loss: 0.9287\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9220\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9197\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.9222\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9352\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9250\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9212 - val_loss: 0.9196\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9171 - val_loss: 0.9204\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9215\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9200\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9188\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9169 - val_loss: 0.9206\n",
      "Top-2 accuracy = 0.838\n",
      "15\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1791 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0763 - val_loss: 1.0540\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0173 - val_loss: 0.9776\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9602 - val_loss: 0.9519\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9438\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9405 - val_loss: 0.9392\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.9371\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 0.9372\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 0.9330\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9314 - val_loss: 0.9312\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 0.9355\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 0.9313\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9284 - val_loss: 0.9306\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9274 - val_loss: 0.9282\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9264 - val_loss: 0.9295\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9260 - val_loss: 0.9266\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.9312\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9253 - val_loss: 0.9258\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 0.9300\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9243 - val_loss: 0.9254\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9263\n",
      "Top-2 accuracy = 0.836\n",
      "16\n",
      "normalized|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1796 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0706 - val_loss: 1.0554\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0215 - val_loss: 0.9757\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9554 - val_loss: 0.9487\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9430 - val_loss: 0.9423\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9397\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9373 - val_loss: 0.9377\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9359 - val_loss: 0.9359\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9350\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9339 - val_loss: 0.9347\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9355\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9325 - val_loss: 0.9385\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9326\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 0.9317\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9311 - val_loss: 0.9320\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9309\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 0.9311\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9298 - val_loss: 0.9311\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9295 - val_loss: 0.9348\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9295\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.9323\n",
      "Top-2 accuracy = 0.832\n",
      "17\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1801 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0871 - val_loss: 1.0693\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0623 - val_loss: 1.0614\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0567 - val_loss: 1.0558\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0491 - val_loss: 1.0461\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0339 - val_loss: 1.0245\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0094 - val_loss: 0.9988\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9836 - val_loss: 0.9776\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9692 - val_loss: 0.9687\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9632 - val_loss: 0.9640\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9592 - val_loss: 0.9604\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9564 - val_loss: 0.9574\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9537 - val_loss: 0.9545\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9515 - val_loss: 0.9524\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9498 - val_loss: 0.9508\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9485 - val_loss: 0.9499\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9474 - val_loss: 0.9490\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9462 - val_loss: 0.9487\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9455 - val_loss: 0.9465\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9444 - val_loss: 0.9450\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9434 - val_loss: 0.9447\n",
      "Top-2 accuracy = 0.828\n",
      "18\n",
      "robustX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0738 - val_loss: 1.0645\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0350 - val_loss: 0.9920\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9747 - val_loss: 0.9702\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9667 - val_loss: 0.9668\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9640 - val_loss: 0.9624\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9609 - val_loss: 0.9551\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9502 - val_loss: 0.9483\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 0.9396\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9370 - val_loss: 0.9353\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9336\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9335 - val_loss: 0.9353\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9309 - val_loss: 0.9287\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9258 - val_loss: 0.9279\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9255 - val_loss: 0.9265\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 0.9265\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9218 - val_loss: 0.9246\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9224 - val_loss: 0.9240\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9214 - val_loss: 0.9253\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9219 - val_loss: 0.9288\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9297 - val_loss: 0.9250\n",
      "Top-2 accuracy = 0.835\n",
      "19\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0427 - val_loss: 0.9940\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9590 - val_loss: 0.9406\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 0.9339\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9318 - val_loss: 0.9320\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9308 - val_loss: 0.9306\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9325\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 0.9317\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9285 - val_loss: 0.9291\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9294\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.9287\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 0.9280\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9256 - val_loss: 0.9282\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 0.9277\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9288\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9255 - val_loss: 0.9281\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 0.9275\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.9277\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9244 - val_loss: 0.9276\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9270\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.9276\n",
      "Top-2 accuracy = 0.837\n",
      "20\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1814 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0376 - val_loss: 0.9748\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9527 - val_loss: 0.9453\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9359 - val_loss: 0.9342\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9292 - val_loss: 0.9290\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.9279\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9231 - val_loss: 0.9234\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9201 - val_loss: 0.9225\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.9216\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9178 - val_loss: 0.9203\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 0.9192\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9155 - val_loss: 0.9183\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9150 - val_loss: 0.9183\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9140 - val_loss: 0.9177\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9136 - val_loss: 0.9170\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9134 - val_loss: 0.9171\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9128 - val_loss: 0.9176\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9123 - val_loss: 0.9173\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9123 - val_loss: 0.9156\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9121 - val_loss: 0.9187\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9130 - val_loss: 0.9161\n",
      "Top-2 accuracy = 0.842\n",
      "21\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0369 - val_loss: 0.9569\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9437 - val_loss: 0.9494\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9368 - val_loss: 0.9362\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9335 - val_loss: 0.9404\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 0.9319\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9293 - val_loss: 0.9334\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9285 - val_loss: 0.9324\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9294 - val_loss: 0.9324\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9271 - val_loss: 0.9416\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9282 - val_loss: 0.9316\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9256 - val_loss: 0.9254\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9250 - val_loss: 0.9249\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9263 - val_loss: 0.9244\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9256 - val_loss: 0.9247\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9254 - val_loss: 0.9249\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9252 - val_loss: 0.9256\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9240 - val_loss: 0.9275\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9262 - val_loss: 0.9300\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9246 - val_loss: 0.9318\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9254 - val_loss: 0.9307\n",
      "Top-2 accuracy = 0.83\n",
      "22\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1825 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0608 - val_loss: 1.0227\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9969 - val_loss: 0.9761\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9661 - val_loss: 0.9616\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 0.9568\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9537 - val_loss: 0.9557\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9544\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9516 - val_loss: 0.9534\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9513 - val_loss: 0.9525\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9503 - val_loss: 0.9521\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9502 - val_loss: 0.9524\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9503 - val_loss: 0.9530\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9492 - val_loss: 0.9524\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9498 - val_loss: 0.9539\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9486 - val_loss: 0.9504\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9514\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9506\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9482 - val_loss: 0.9497\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9492\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9475 - val_loss: 0.9486\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9470 - val_loss: 0.9498\n",
      "Top-2 accuracy = 0.825\n",
      "23\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1829 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0615 - val_loss: 1.0438\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0039 - val_loss: 0.9749\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9594 - val_loss: 0.9549\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9514 - val_loss: 0.9518\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9490\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9470 - val_loss: 0.9513\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9452 - val_loss: 0.9503\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9434 - val_loss: 0.9448\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9467\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9408 - val_loss: 0.9412\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9396 - val_loss: 0.9411\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9393 - val_loss: 0.9401\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9482\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9385\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9353 - val_loss: 0.9409\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 0.9358\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 0.9344\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9341 - val_loss: 0.9350\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9326\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9318 - val_loss: 0.9341\n",
      "Top-2 accuracy = 0.836\n",
      "24\n",
      "maxabsa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0320 - val_loss: 0.9677\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 0.9392\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 0.9410\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9339 - val_loss: 0.9351\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9317 - val_loss: 0.9411\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9328 - val_loss: 0.9352\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9310 - val_loss: 0.9339\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9319 - val_loss: 0.9336\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9315\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9295 - val_loss: 0.9329\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9301 - val_loss: 0.9332\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 0.9301\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9329\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 0.9307\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.9303\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 0.9296\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9279 - val_loss: 0.9354\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9293 - val_loss: 0.9297\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9278 - val_loss: 0.9353\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9286 - val_loss: 0.9353\n",
      "Top-2 accuracy = 0.836\n",
      "25\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0809 - val_loss: 1.0505\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0106 - val_loss: 0.9712\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9443\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.9392\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9372\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9346\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9295 - val_loss: 0.9337\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9311\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.9298\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9240 - val_loss: 0.9290\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9279\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.9275\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9273\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9243\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9236\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.9236\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9233\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9245\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9252\n",
      "Top-2 accuracy = 0.833\n",
      "26\n",
      "maxabsw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0068 - val_loss: 0.9570\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9439\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 0.9385\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 0.9364\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 0.9373\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9307 - val_loss: 0.9306\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.9295\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9280 - val_loss: 0.9285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9267 - val_loss: 0.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 0.9261\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 0.9283\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.9269\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.9256\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9250\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9225 - val_loss: 0.9258\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9229 - val_loss: 0.9244\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9244\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9209 - val_loss: 0.9245\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9236\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9233\n",
      "Top-2 accuracy = 0.836\n",
      "27\n",
      "maxabsV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0586 - val_loss: 1.0051\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9636 - val_loss: 0.9397\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9330 - val_loss: 0.9316\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9275 - val_loss: 0.9310\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9266 - val_loss: 0.9316\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9258 - val_loss: 0.9309\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9245 - val_loss: 0.9277\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9247 - val_loss: 0.9260\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9238 - val_loss: 0.9254\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9227 - val_loss: 0.9248\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9224 - val_loss: 0.9242\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9220 - val_loss: 0.9273\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9245\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9282\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9210 - val_loss: 0.9235\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.9236\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9229\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9221\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.9222\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.9223\n",
      "Top-2 accuracy = 0.837\n",
      "28\n",
      "standardizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0436 - val_loss: 0.9760\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9522 - val_loss: 0.9357\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9282 - val_loss: 0.9276\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9250 - val_loss: 0.9275\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9215 - val_loss: 0.9253\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9215 - val_loss: 0.9246\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9209 - val_loss: 0.9231\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9195 - val_loss: 0.9222\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9190 - val_loss: 0.9225\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9200 - val_loss: 0.9224\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9183 - val_loss: 0.9229\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9195 - val_loss: 0.9221\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9185 - val_loss: 0.9210\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9177 - val_loss: 0.9215\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9181 - val_loss: 0.9240\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9178 - val_loss: 0.9212\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9179 - val_loss: 0.9210\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9174 - val_loss: 0.9208\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9168 - val_loss: 0.9204\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9175 - val_loss: 0.9205\n",
      "Top-2 accuracy = 0.839\n",
      "29\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0707 - val_loss: 1.0323\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9984 - val_loss: 0.9714\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9549 - val_loss: 0.9481\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9374 - val_loss: 0.9349\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9311 - val_loss: 0.9388\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9308 - val_loss: 0.9307\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9277 - val_loss: 0.9287\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9269 - val_loss: 0.9291\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9273 - val_loss: 0.9313\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9251 - val_loss: 0.9294\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9251 - val_loss: 0.9438\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9250 - val_loss: 0.9336\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9250 - val_loss: 0.9257\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9229 - val_loss: 0.9261\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 0.9239\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 0.9280\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9222 - val_loss: 0.9259\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 0.9273\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9219 - val_loss: 0.9237\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9210 - val_loss: 0.9235\n",
      "Top-2 accuracy = 0.838\n",
      "0\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0709 - val_loss: 1.0509\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0125 - val_loss: 0.9814\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9557 - val_loss: 0.9587\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9374 - val_loss: 0.9431\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9309 - val_loss: 0.9305\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9287 - val_loss: 0.9338\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9287 - val_loss: 0.9313\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 0.9304\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9287 - val_loss: 0.9306\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9277 - val_loss: 0.9293\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9276 - val_loss: 0.9305\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9274 - val_loss: 0.9290\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9280 - val_loss: 0.9292\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9270 - val_loss: 0.9405\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9292 - val_loss: 0.9283\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9268 - val_loss: 0.9347\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9276 - val_loss: 0.9289\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9270 - val_loss: 0.9272\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9260 - val_loss: 0.9283\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9257 - val_loss: 0.9268\n",
      "Top-2 accuracy = 0.839\n",
      "1\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0244 - val_loss: 0.9558\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9387\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9319 - val_loss: 0.9326\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9274 - val_loss: 0.9378\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 0.9294\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9245 - val_loss: 0.9277\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9227 - val_loss: 0.9279\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9282\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9279\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9267\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9255\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9215 - val_loss: 0.9241\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9245\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9245\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9243\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9235\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9222\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.9240\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.9237\n",
      "Top-2 accuracy = 0.834\n",
      "2\n",
      "normalizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0092 - val_loss: 0.9586\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9425\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.9385\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 0.9347\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.9336\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9308 - val_loss: 0.9313\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9273 - val_loss: 0.9310\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.9295\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9258 - val_loss: 0.9289\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9250 - val_loss: 0.9278\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9234 - val_loss: 0.9275\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 0.9273\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.9264\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9253\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9251\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9243\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9242\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9245\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9198 - val_loss: 0.9249\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9199 - val_loss: 0.9240\n",
      "Top-2 accuracy = 0.836\n",
      "3\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1882 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0699 - val_loss: 1.0309\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 0.9773\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9631 - val_loss: 0.9605\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9502 - val_loss: 0.9516\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9475\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9405 - val_loss: 0.9463\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9435\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 0.9414\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9355 - val_loss: 0.9415\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9376\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.9357\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 0.9342\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9301 - val_loss: 0.9331\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 0.9331\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9285 - val_loss: 0.9317\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9281 - val_loss: 0.9314\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9279 - val_loss: 0.9319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9272 - val_loss: 0.9313\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9267 - val_loss: 0.9301\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9264 - val_loss: 0.9302\n",
      "Top-2 accuracy = 0.831\n",
      "4\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1889 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0683 - val_loss: 1.0441\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0211 - val_loss: 0.9968\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9787 - val_loss: 0.9677\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9590 - val_loss: 0.9554\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9493 - val_loss: 0.9484\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9445 - val_loss: 0.9446\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9415\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 0.9388\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9347 - val_loss: 0.9366\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9345\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9310 - val_loss: 0.9328\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9295 - val_loss: 0.9312\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9282 - val_loss: 0.9306\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9294\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9261 - val_loss: 0.9287\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9253 - val_loss: 0.9274\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9249 - val_loss: 0.9267\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.9264\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9263\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9230 - val_loss: 0.9255\n",
      "Top-2 accuracy = 0.836\n",
      "5\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0375 - val_loss: 0.9656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9469 - val_loss: 0.9367\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9337 - val_loss: 0.9315\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9294 - val_loss: 0.9299\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9278 - val_loss: 0.9300\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9273 - val_loss: 0.9291\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9263 - val_loss: 0.9292\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9259 - val_loss: 0.9292\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9264 - val_loss: 0.9282\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9246 - val_loss: 0.9327\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9261 - val_loss: 0.9271\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9238 - val_loss: 0.9268\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9232 - val_loss: 0.9265\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 0.9264\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 0.9283\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9223 - val_loss: 0.9257\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9221 - val_loss: 0.9251\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9212 - val_loss: 0.9246\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9207 - val_loss: 0.9247\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9209 - val_loss: 0.9243\n",
      "Top-2 accuracy = 0.833\n",
      "6\n",
      "maxabsw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0898 - val_loss: 1.0826\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0769 - val_loss: 1.0736\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0697 - val_loss: 1.0689\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0661 - val_loss: 1.0668\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0645 - val_loss: 1.0659\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "7\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0605 - val_loss: 1.0195\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9648 - val_loss: 0.9462\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9443 - val_loss: 0.9402\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9375 - val_loss: 0.9376\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9363 - val_loss: 0.9410\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9346 - val_loss: 0.9371\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9326 - val_loss: 0.9396\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9321 - val_loss: 0.9319\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9314 - val_loss: 0.9349\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9279 - val_loss: 0.9249\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9249 - val_loss: 0.9252\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9212 - val_loss: 0.9222\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.9210\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9194 - val_loss: 0.9201\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9193 - val_loss: 0.9257\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9181 - val_loss: 0.9227\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9194 - val_loss: 0.9195\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9181 - val_loss: 0.9198\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9168 - val_loss: 0.9193\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9175 - val_loss: 0.9234\n",
      "Top-2 accuracy = 0.835\n",
      "8\n",
      "normalizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0826 - val_loss: 1.0702\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0611 - val_loss: 1.0516\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0287 - val_loss: 1.0131\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 0.9882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9756 - val_loss: 0.9724\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9625 - val_loss: 0.9611\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9528\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9460 - val_loss: 0.9458\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9409\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9362 - val_loss: 0.9412\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9347 - val_loss: 0.9352\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9318 - val_loss: 0.9338\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9324\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9293 - val_loss: 0.9315\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9318\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9278 - val_loss: 0.9306\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9317\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9272 - val_loss: 0.9300\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9267 - val_loss: 0.9297\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9314\n",
      "Top-2 accuracy = 0.836\n",
      "9\n",
      "normalized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0564 - val_loss: 1.0127\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9646 - val_loss: 0.9383\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9335 - val_loss: 0.9360\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9314 - val_loss: 0.9312\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9264 - val_loss: 0.9336\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9247 - val_loss: 0.9241\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9219 - val_loss: 0.9225\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9214 - val_loss: 0.9219\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9204 - val_loss: 0.9229\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9196 - val_loss: 0.9238\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9190 - val_loss: 0.9215\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 0.9217\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9176 - val_loss: 0.9200\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9184 - val_loss: 0.9200\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9184 - val_loss: 0.9215\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9178 - val_loss: 0.9226\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9171 - val_loss: 0.9231\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9169 - val_loss: 0.9216\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9172 - val_loss: 0.9200\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9169 - val_loss: 0.9215\n",
      "Top-2 accuracy = 0.834\n",
      "10\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1924 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0897 - val_loss: 1.0825\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0768 - val_loss: 1.0736\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0698 - val_loss: 1.0689\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0662 - val_loss: 1.0668\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0647 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "11\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9961 - val_loss: 0.9450\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9278 - val_loss: 0.9254\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9226 - val_loss: 0.9224\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.9234\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9180 - val_loss: 0.9247\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9163 - val_loss: 0.9207\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9161 - val_loss: 0.9216\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9161 - val_loss: 0.9198\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9150 - val_loss: 0.9202\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9161 - val_loss: 0.9203\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9145 - val_loss: 0.9198\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9143 - val_loss: 0.9208\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9146 - val_loss: 0.9188\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9139 - val_loss: 0.9222\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9133 - val_loss: 0.9226\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9163 - val_loss: 0.9188\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9137 - val_loss: 0.9186\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9133 - val_loss: 0.9206\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9124 - val_loss: 0.9235\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9136 - val_loss: 0.9227\n",
      "Top-2 accuracy = 0.835\n",
      "12\n",
      "normalizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0483 - val_loss: 0.9817\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9383\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9344 - val_loss: 0.9348\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9331 - val_loss: 0.9352\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9322\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9310 - val_loss: 0.9315\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9309\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 0.9300\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.9297\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9287 - val_loss: 0.9297\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9284 - val_loss: 0.9296\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 0.9288\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9278 - val_loss: 0.9286\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9272 - val_loss: 0.9286\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9294\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9268 - val_loss: 0.9293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9276\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9264 - val_loss: 0.9266\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9269 - val_loss: 0.9269\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9264\n",
      "Top-2 accuracy = 0.838\n",
      "13\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.1102 - val_loss: 1.0880\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0771 - val_loss: 1.0704\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0650 - val_loss: 1.0589\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0307 - val_loss: 0.9989\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9708 - val_loss: 0.9627\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9534 - val_loss: 0.9544\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9478 - val_loss: 0.9524\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9451 - val_loss: 0.9488\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9430 - val_loss: 0.9466\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9418 - val_loss: 0.9458\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 0.9451\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9401 - val_loss: 0.9444\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9397 - val_loss: 0.9438\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 0.9431\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9385 - val_loss: 0.9425\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9378 - val_loss: 0.9425\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 0.9410\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9367 - val_loss: 0.9405\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9400\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9347 - val_loss: 0.9363\n",
      "Top-2 accuracy = 0.833\n",
      "14\n",
      "normalizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0654 - val_loss: 1.0218\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 0.9671\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9469\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 0.9328\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9284 - val_loss: 0.9307\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.9281\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.9236\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9233\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9211 - val_loss: 0.9224\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.9221\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9227\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9215\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9208\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.9217\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9214\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9207\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9176 - val_loss: 0.9203\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.9214\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9206\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 0.9209\n",
      "Top-2 accuracy = 0.837\n",
      "15\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0441 - val_loss: 0.9762\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 0.9346\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9256 - val_loss: 0.9338\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9234 - val_loss: 0.9284\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9216 - val_loss: 0.9269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9233 - val_loss: 0.9256\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9199 - val_loss: 0.9279\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9199 - val_loss: 0.9244\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9185 - val_loss: 0.9232\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9176 - val_loss: 0.9218\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9183 - val_loss: 0.9223\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9179 - val_loss: 0.9232\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9185 - val_loss: 0.9225\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9172 - val_loss: 0.9229\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9167 - val_loss: 0.9253\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9165 - val_loss: 0.9259\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9175 - val_loss: 0.9220\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9156 - val_loss: 0.9254\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9157 - val_loss: 0.9236\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9157 - val_loss: 0.9238\n",
      "Top-2 accuracy = 0.833\n",
      "16\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0762 - val_loss: 1.0659\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0636 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0653\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0269 - val_loss: 1.0489\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9857 - val_loss: 0.9694\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9657 - val_loss: 0.9677\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9575 - val_loss: 0.9567\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9492 - val_loss: 0.9500\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9400 - val_loss: 0.9403\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9354 - val_loss: 0.9400\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9383 - val_loss: 0.9394\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9362\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9307 - val_loss: 0.9343\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9292 - val_loss: 0.9321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9303 - val_loss: 0.9303\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9283 - val_loss: 0.9309\n",
      "Top-2 accuracy = 0.839\n",
      "17\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1962 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0627 - val_loss: 1.0564\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0340 - val_loss: 0.9973\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9668 - val_loss: 0.9607\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9494 - val_loss: 0.9506\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9451 - val_loss: 0.9481\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9426 - val_loss: 0.9466\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9437\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9478\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 0.9409\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9417\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9359 - val_loss: 0.9428\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9392\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 0.9391\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9392\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9385\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9378\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9325 - val_loss: 0.9381\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9325 - val_loss: 0.9367\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.9375\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9327 - val_loss: 0.9381\n",
      "Top-2 accuracy = 0.837\n",
      "18\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0825 - val_loss: 1.0350\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9651 - val_loss: 0.9416\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9389\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9352\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.9341\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9339 - val_loss: 0.9346\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9333\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9319 - val_loss: 0.9376\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9328\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9398\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9315 - val_loss: 0.9334\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9306 - val_loss: 0.9348\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9315\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9292 - val_loss: 0.9345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9293 - val_loss: 0.9345\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9308 - val_loss: 0.9307\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9293 - val_loss: 0.9358\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9298\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9285 - val_loss: 0.9300\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9287 - val_loss: 0.9324\n",
      "Top-2 accuracy = 0.835\n",
      "19\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1973 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0256 - val_loss: 0.9911\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9686 - val_loss: 0.9639\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9554 - val_loss: 0.9582\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9517 - val_loss: 0.9556\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9490 - val_loss: 0.9529\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9468 - val_loss: 0.9510\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9455 - val_loss: 0.9492\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9508\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9421 - val_loss: 0.9465\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9412 - val_loss: 0.9456\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9404 - val_loss: 0.9447\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9393 - val_loss: 0.9436\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9383 - val_loss: 0.9428\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9379 - val_loss: 0.9425\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9366 - val_loss: 0.9414\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9360 - val_loss: 0.9405\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9354 - val_loss: 0.9399\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9346 - val_loss: 0.9392\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9343 - val_loss: 0.9383\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9337 - val_loss: 0.9389\n",
      "Top-2 accuracy = 0.835\n",
      "20\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1976 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 0.9960\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9709 - val_loss: 0.9588\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9456 - val_loss: 0.9425\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9360 - val_loss: 0.9374\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9316 - val_loss: 0.9347\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9292 - val_loss: 0.9325\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9278 - val_loss: 0.9317\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9269 - val_loss: 0.9303\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9260 - val_loss: 0.9293\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9249 - val_loss: 0.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9239 - val_loss: 0.9283\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9232 - val_loss: 0.9279\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9226 - val_loss: 0.9265\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9220 - val_loss: 0.9262\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9217 - val_loss: 0.9260\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9209 - val_loss: 0.9254\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9203 - val_loss: 0.9250\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9200 - val_loss: 0.9243\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9195 - val_loss: 0.9243\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9191 - val_loss: 0.9245\n",
      "Top-2 accuracy = 0.84\n",
      "21\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0463 - val_loss: 1.0145\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9770 - val_loss: 0.9541\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9430 - val_loss: 0.9383\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9318\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9276\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9245 - val_loss: 0.9260\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.9251\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.9241\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9241\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9235\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9206 - val_loss: 0.9251\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.9232\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9245\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9232\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9223\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9248\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9223\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9227\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9224\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9230\n",
      "Top-2 accuracy = 0.839\n",
      "22\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0642 - val_loss: 1.0075\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9609 - val_loss: 0.9353\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9338 - val_loss: 0.9336\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9308 - val_loss: 0.9352\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9306 - val_loss: 0.9303\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9308 - val_loss: 0.9297\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9278 - val_loss: 0.9283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9276 - val_loss: 0.9329\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9265 - val_loss: 0.9270\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9234 - val_loss: 0.9226\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9217 - val_loss: 0.9241\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9203 - val_loss: 0.9242\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9202 - val_loss: 0.9247\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9198 - val_loss: 0.9253\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9204 - val_loss: 0.9207\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9184 - val_loss: 0.9247\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9184 - val_loss: 0.9266\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9188 - val_loss: 0.9201\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9178 - val_loss: 0.9309\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9192 - val_loss: 0.9247\n",
      "Top-2 accuracy = 0.833\n",
      "23\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1991 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 31s 378ms/step - loss: 1.1296 - val_loss: 1.0865\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0719 - val_loss: 1.0636\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0502 - val_loss: 1.0396\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0172 - val_loss: 1.0010\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9858 - val_loss: 0.9774\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9688 - val_loss: 0.9671\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9600 - val_loss: 0.9602\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9550 - val_loss: 0.9570\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9522 - val_loss: 0.9541\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9497 - val_loss: 0.9513\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9458 - val_loss: 0.9466\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9426 - val_loss: 0.9435\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9400 - val_loss: 0.9413\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9391\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9357 - val_loss: 0.9368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9340 - val_loss: 0.9361\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9328 - val_loss: 0.9349\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9322 - val_loss: 0.9342\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9313 - val_loss: 0.9336\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9308 - val_loss: 0.9329\n",
      "Top-2 accuracy = 0.833\n",
      "24\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1995 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0586 - val_loss: 1.0160\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9825 - val_loss: 0.9567\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9459 - val_loss: 0.9436\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9395 - val_loss: 0.9400\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9366 - val_loss: 0.9382\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9346 - val_loss: 0.9365\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9326 - val_loss: 0.9349\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9312 - val_loss: 0.9346\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9304 - val_loss: 0.9328\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9291 - val_loss: 0.9320\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9282 - val_loss: 0.9314\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9276 - val_loss: 0.9303\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9267 - val_loss: 0.9295\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9262 - val_loss: 0.9289\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9256 - val_loss: 0.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9251 - val_loss: 0.9278\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9245 - val_loss: 0.9275\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9240 - val_loss: 0.9269\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9235 - val_loss: 0.9268\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9232 - val_loss: 0.9262\n",
      "Top-2 accuracy = 0.839\n",
      "25\n",
      "standardizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0354 - val_loss: 0.9920\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9692 - val_loss: 0.9570\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9437 - val_loss: 0.9348\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.9283\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9228 - val_loss: 0.9234\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9218\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9226\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9221\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9216\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9178 - val_loss: 0.9232\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.9203\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9165 - val_loss: 0.9197\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9173 - val_loss: 0.9208\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9170 - val_loss: 0.9206\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 0.9202\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.9206\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9169 - val_loss: 0.9225\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 0.9199\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 0.9202\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9163 - val_loss: 0.9202\n",
      "Top-2 accuracy = 0.838\n",
      "26\n",
      "normalizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0354 - val_loss: 0.9808\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9490 - val_loss: 0.9384\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9328 - val_loss: 0.9331\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9296 - val_loss: 0.9330\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9282 - val_loss: 0.9301\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9267 - val_loss: 0.9293\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9256 - val_loss: 0.9295\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9253 - val_loss: 0.9288\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9242 - val_loss: 0.9267\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9236 - val_loss: 0.9263\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9237 - val_loss: 0.9259\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9225 - val_loss: 0.9249\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9220 - val_loss: 0.9243\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9214 - val_loss: 0.9238\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9206 - val_loss: 0.9230\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9201 - val_loss: 0.9221\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9198 - val_loss: 0.9215\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9191 - val_loss: 0.9211\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9187 - val_loss: 0.9230\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9191 - val_loss: 0.9209\n",
      "Top-2 accuracy = 0.838\n",
      "27\n",
      "maxabsW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9802 - val_loss: 0.9451\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9367\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 0.9332\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9323\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9313\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 0.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9268\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9227 - val_loss: 0.9241\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9231\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9224\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9261\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9214\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9178 - val_loss: 0.9257\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9217\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9168 - val_loss: 0.9212\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9166 - val_loss: 0.9205\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9172 - val_loss: 0.9208\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 0.9228\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 0.9209\n",
      "Top-2 accuracy = 0.833\n",
      "28\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0213 - val_loss: 0.9706\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9345\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9269 - val_loss: 0.9272\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9229 - val_loss: 0.9323\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9221 - val_loss: 0.9239\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9209 - val_loss: 0.9307\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.9241\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9238\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9248\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9238\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9229\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.9234\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9254\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9246\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9231\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9235\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9251\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.9241\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9242\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9230\n",
      "Top-2 accuracy = 0.837\n",
      "29\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0364 - val_loss: 0.9793\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9359\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9284 - val_loss: 0.9261\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9271\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9208 - val_loss: 0.9237\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9226\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9221\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9204\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9172 - val_loss: 0.9267\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9226\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 0.9200\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 0.9235\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9170 - val_loss: 0.9238\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9167 - val_loss: 0.9201\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 0.9198\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.9217\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 0.9227\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 0.9214\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.9203\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 0.9195\n",
      "Top-2 accuracy = 0.839\n",
      "0\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0372 - val_loss: 0.9697\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9420 - val_loss: 0.9318\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9242 - val_loss: 0.9370\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9238 - val_loss: 0.9243\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9187 - val_loss: 0.9218\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9182 - val_loss: 0.9193\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9182 - val_loss: 0.9319\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9221 - val_loss: 0.9204\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9172 - val_loss: 0.9213\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9166 - val_loss: 0.9196\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9156 - val_loss: 0.9183\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9171 - val_loss: 0.9179\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9159 - val_loss: 0.9188\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9145 - val_loss: 0.9183\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9146 - val_loss: 0.9211\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9154 - val_loss: 0.9205\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9147 - val_loss: 0.9168\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9141 - val_loss: 0.9175\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9140 - val_loss: 0.9204\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9142 - val_loss: 0.9299\n",
      "Top-2 accuracy = 0.823\n",
      "1\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0416 - val_loss: 0.9850\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9555 - val_loss: 0.9493\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 0.9295\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9245 - val_loss: 0.9255\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9226\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9208 - val_loss: 0.9213\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9206\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9260\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9178 - val_loss: 0.9212\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9170 - val_loss: 0.9204\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9173 - val_loss: 0.9202\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9167 - val_loss: 0.9201\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9170 - val_loss: 0.9209\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 0.9226\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9176 - val_loss: 0.9206\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9171 - val_loss: 0.9197\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 0.9195\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9171 - val_loss: 0.9226\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9176 - val_loss: 0.9232\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 0.9198\n",
      "Top-2 accuracy = 0.835\n",
      "2\n",
      "minmaxK|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2030 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0778 - val_loss: 1.0647\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0522 - val_loss: 1.0406\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0244 - val_loss: 1.0106\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0025 - val_loss: 0.9964\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9918 - val_loss: 0.9879\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9843 - val_loss: 0.9821\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9796 - val_loss: 0.9782\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9762 - val_loss: 0.9753\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9739 - val_loss: 0.9733\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9719 - val_loss: 0.9717\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9705 - val_loss: 0.9708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9697 - val_loss: 0.9694\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9682 - val_loss: 0.9686\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9670 - val_loss: 0.9680\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9663 - val_loss: 0.9664\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9649 - val_loss: 0.9660\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9639 - val_loss: 0.9645\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9627 - val_loss: 0.9636\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9604 - val_loss: 0.9611\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9546 - val_loss: 0.9565\n",
      "Top-2 accuracy = 0.826\n",
      "3\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0348 - val_loss: 0.9901\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9615 - val_loss: 0.9442\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9319 - val_loss: 0.9269\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9215 - val_loss: 0.9226\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9189 - val_loss: 0.9215\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9209\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.9274\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9291\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9201\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9163 - val_loss: 0.9188\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9157 - val_loss: 0.9198\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9158 - val_loss: 0.9185\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.9321\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 0.9205\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9166 - val_loss: 0.9180\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9148 - val_loss: 0.9220\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9158 - val_loss: 0.9180\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9153 - val_loss: 0.9184\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 0.9182\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9148 - val_loss: 0.9181\n",
      "Top-2 accuracy = 0.839\n",
      "4\n",
      "maxabsD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0104 - val_loss: 0.9547\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9382\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 0.9361\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9346\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9332 - val_loss: 0.9334\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9327\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9310 - val_loss: 0.9321\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9304 - val_loss: 0.9310\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9301 - val_loss: 0.9305\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 0.9296\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9287 - val_loss: 0.9294\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9284 - val_loss: 0.9289\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9283 - val_loss: 0.9290\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9278 - val_loss: 0.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9276 - val_loss: 0.9287\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9276 - val_loss: 0.9304\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9278 - val_loss: 0.9276\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9268 - val_loss: 0.9287\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9267 - val_loss: 0.9288\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9268 - val_loss: 0.9278\n",
      "Top-2 accuracy = 0.837\n",
      "5\n",
      "maxabsZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0552 - val_loss: 1.0289\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 0.9787\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9612 - val_loss: 0.9546\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9458 - val_loss: 0.9445\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9387 - val_loss: 0.9389\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9351 - val_loss: 0.9361\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9334 - val_loss: 0.9349\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9322 - val_loss: 0.9337\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9316 - val_loss: 0.9343\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9313 - val_loss: 0.9330\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9311 - val_loss: 0.9327\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9308 - val_loss: 0.9323\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9306 - val_loss: 0.9320\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9302 - val_loss: 0.9324\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9303 - val_loss: 0.9324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9301 - val_loss: 0.9317\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9303 - val_loss: 0.9317\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9301 - val_loss: 0.9317\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9298 - val_loss: 0.9320\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9301 - val_loss: 0.9316\n",
      "Top-2 accuracy = 0.837\n",
      "6\n",
      "normalizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0800 - val_loss: 1.0629\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0249 - val_loss: 0.9842\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9617 - val_loss: 0.9455\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9361 - val_loss: 0.9312\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 0.9262\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9236 - val_loss: 0.9249\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9227 - val_loss: 0.9250\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9209 - val_loss: 0.9228\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9231\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9223\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9198 - val_loss: 0.9220\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 0.9215\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9198 - val_loss: 0.9216\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9322\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9217 - val_loss: 0.9239\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9213\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9217\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9186 - val_loss: 0.9204\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9230\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9213\n",
      "Top-2 accuracy = 0.837\n",
      "7\n",
      "normalizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0112 - val_loss: 0.9615\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9361\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 0.9291\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9291\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.9290\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9230 - val_loss: 0.9307\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9221 - val_loss: 0.9216\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9199 - val_loss: 0.9217\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9194\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9263\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9196\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9186 - val_loss: 0.9211\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.9197\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9163 - val_loss: 0.9204\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9166 - val_loss: 0.9184\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9157 - val_loss: 0.9246\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9170 - val_loss: 0.9182\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9151 - val_loss: 0.9188\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.9176\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 0.9169\n",
      "Top-2 accuracy = 0.838\n",
      "8\n",
      "standardizeV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2059 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0708 - val_loss: 1.0634\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0499 - val_loss: 1.0321\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0038 - val_loss: 0.9857\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9733 - val_loss: 0.9666\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9590 - val_loss: 0.9571\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9522 - val_loss: 0.9524\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9482 - val_loss: 0.9486\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9451 - val_loss: 0.9456\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9419 - val_loss: 0.9441\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9407 - val_loss: 0.9427\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9391 - val_loss: 0.9431\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9380 - val_loss: 0.9412\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9369 - val_loss: 0.9396\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9351 - val_loss: 0.9374\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9325 - val_loss: 0.9341\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9312 - val_loss: 0.9333\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9302 - val_loss: 0.9323\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9293 - val_loss: 0.9326\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9283 - val_loss: 0.9313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9278 - val_loss: 0.9309\n",
      "Top-2 accuracy = 0.834\n",
      "9\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0161 - val_loss: 0.9746\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9546 - val_loss: 0.9393\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9297 - val_loss: 0.9262\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9233 - val_loss: 0.9221\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 0.9227\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9198 - val_loss: 0.9219\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9205 - val_loss: 0.9208\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9194 - val_loss: 0.9230\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9192 - val_loss: 0.9198\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9194 - val_loss: 0.9207\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9204\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9221\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9254\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9209\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9194\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9186 - val_loss: 0.9251\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9188 - val_loss: 0.9204\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9230\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9199\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9182 - val_loss: 0.9209\n",
      "Top-2 accuracy = 0.838\n",
      "10\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0144 - val_loss: 0.9480\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9329 - val_loss: 0.9262\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9248 - val_loss: 0.9249\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9231 - val_loss: 0.9238\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9219 - val_loss: 0.9233\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9216 - val_loss: 0.9250\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9216 - val_loss: 0.9233\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9206 - val_loss: 0.9231\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9191 - val_loss: 0.9222\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 0.9210\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9176 - val_loss: 0.9219\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9173 - val_loss: 0.9202\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9175 - val_loss: 0.9210\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9173 - val_loss: 0.9238\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9175 - val_loss: 0.9206\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9177 - val_loss: 0.9243\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9173 - val_loss: 0.9206\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9161 - val_loss: 0.9227\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9163 - val_loss: 0.9204\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9160 - val_loss: 0.9208\n",
      "Top-2 accuracy = 0.837\n",
      "11\n",
      "minmaxn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0569 - val_loss: 1.0102\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9704 - val_loss: 0.9464\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 0.9361\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 0.9301\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9279 - val_loss: 0.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9268 - val_loss: 0.9270\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.9305\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9240 - val_loss: 0.9251\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9223 - val_loss: 0.9243\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9260\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9233\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9217 - val_loss: 0.9231\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9230\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9209 - val_loss: 0.9241\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9228\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9226\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9241\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9229\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.9252\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9244\n",
      "Top-2 accuracy = 0.837\n",
      "12\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0943 - val_loss: 1.0828\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0771 - val_loss: 1.0738\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0700 - val_loss: 1.0691\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0665 - val_loss: 1.0670\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0648 - val_loss: 1.0661\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0641 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0657\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "13\n",
      "robustR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0308 - val_loss: 0.9590\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9337\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 0.9298\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9268 - val_loss: 0.9289\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.9273\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.9254\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9221 - val_loss: 0.9251\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9255\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9239\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9237\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9226\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9244\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9222\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9242\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9231\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9224\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9218\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9170 - val_loss: 0.9206\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9168 - val_loss: 0.9201\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 0.9202\n",
      "Top-2 accuracy = 0.839\n",
      "14\n",
      "minmaxa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0314 - val_loss: 0.9641\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 0.9459\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9359 - val_loss: 0.9353\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9332 - val_loss: 0.9315\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9309 - val_loss: 0.9310\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9301 - val_loss: 0.9302\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 0.9303\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9297\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9292 - val_loss: 0.9294\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9290 - val_loss: 0.9288\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9293 - val_loss: 0.9283\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 0.9302\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.9278\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9290 - val_loss: 0.9288\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9278 - val_loss: 0.9292\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9283 - val_loss: 0.9335\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9273\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9286 - val_loss: 0.9281\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9283 - val_loss: 0.9296\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9273\n",
      "Top-2 accuracy = 0.837\n",
      "15\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0545 - val_loss: 1.0036\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9653 - val_loss: 0.9425\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9369 - val_loss: 0.9385\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9369 - val_loss: 0.9349\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9305 - val_loss: 0.9311\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9275 - val_loss: 0.9288\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9273 - val_loss: 0.9272\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9239 - val_loss: 0.9309\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9233 - val_loss: 0.9254\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9199 - val_loss: 0.9267\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9215 - val_loss: 0.9335\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9201 - val_loss: 0.9307\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9198 - val_loss: 0.9230\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9178 - val_loss: 0.9255\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9179 - val_loss: 0.9247\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9176 - val_loss: 0.9227\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9170 - val_loss: 0.9275\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9175 - val_loss: 0.9253\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9174 - val_loss: 0.9217\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9160 - val_loss: 0.9246\n",
      "Top-2 accuracy = 0.835\n",
      "16\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0721 - val_loss: 1.0536\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0207 - val_loss: 0.9939\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9778 - val_loss: 0.9719\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9595 - val_loss: 0.9576\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9470 - val_loss: 0.9467\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9400 - val_loss: 0.9447\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9383 - val_loss: 0.9391\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 0.9380\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9319 - val_loss: 0.9375\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9304 - val_loss: 0.9356\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 0.9351\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.9331\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9280 - val_loss: 0.9326\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9276 - val_loss: 0.9323\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9272 - val_loss: 0.9311\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.9315\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9273 - val_loss: 0.9300\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 0.9314\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9260 - val_loss: 0.9311\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 0.9332\n",
      "Top-2 accuracy = 0.831\n",
      "17\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0321 - val_loss: 0.9661\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.9367\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 0.9388\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9330 - val_loss: 0.9327\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9327 - val_loss: 0.9324\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9320\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 0.9305\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 0.9311\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9287 - val_loss: 0.9313\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9292\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 0.9299\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 0.9277\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.9254\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.9227\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.9223\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9222\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9214\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9209 - val_loss: 0.9218\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.9326\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9218\n",
      "Top-2 accuracy = 0.838\n",
      "18\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0465 - val_loss: 1.0047\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9751 - val_loss: 0.9647\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9573 - val_loss: 0.9675\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9373 - val_loss: 0.9363\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9322 - val_loss: 0.9325\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9313 - val_loss: 0.9472\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9314 - val_loss: 0.9308\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9279 - val_loss: 0.9324\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9267 - val_loss: 0.9423\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9290 - val_loss: 0.9307\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9267 - val_loss: 0.9267\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9251 - val_loss: 0.9264\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9257 - val_loss: 0.9280\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9250 - val_loss: 0.9273\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9254 - val_loss: 0.9260\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9243 - val_loss: 0.9244\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9237 - val_loss: 0.9261\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9231 - val_loss: 0.9247\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 0.9254\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9240 - val_loss: 0.9378\n",
      "Top-2 accuracy = 0.825\n",
      "19\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.1084 - val_loss: 1.0647\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0414 - val_loss: 1.0179\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9947 - val_loss: 0.9756\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9648 - val_loss: 0.9620\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9553 - val_loss: 0.9557\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9511 - val_loss: 0.9529\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9488 - val_loss: 0.9507\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9472 - val_loss: 0.9484\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9442\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9409 - val_loss: 0.9420\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9396 - val_loss: 0.9414\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9386 - val_loss: 0.9406\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9381 - val_loss: 0.9392\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9368 - val_loss: 0.9394\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9363 - val_loss: 0.9397\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9363 - val_loss: 0.9388\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9354 - val_loss: 0.9369\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9351 - val_loss: 0.9357\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9344 - val_loss: 0.9363\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9344 - val_loss: 0.9351\n",
      "Top-2 accuracy = 0.832\n",
      "20\n",
      "standardizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0380\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0061 - val_loss: 0.9858\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9667 - val_loss: 0.9595\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9478 - val_loss: 0.9466\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9392\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9310 - val_loss: 0.9327\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9274 - val_loss: 0.9317\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9256 - val_loss: 0.9307\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9250 - val_loss: 0.9325\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 0.9307\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9241 - val_loss: 0.9306\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9301\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9241 - val_loss: 0.9312\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9241 - val_loss: 0.9313\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9235 - val_loss: 0.9310\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.9295\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9223 - val_loss: 0.9292\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9309\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9296\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9229 - val_loss: 0.9283\n",
      "Top-2 accuracy = 0.838\n",
      "21\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0873 - val_loss: 1.0713\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0312 - val_loss: 0.9889\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9631 - val_loss: 0.9475\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9412 - val_loss: 0.9418\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9336\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9327\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9334 - val_loss: 0.9316\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 0.9324\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9280 - val_loss: 0.9256\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 0.9317\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.9265\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9245 - val_loss: 0.9279\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9248 - val_loss: 0.9281\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9266 - val_loss: 0.9241\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 0.9235\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9230 - val_loss: 0.9222\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9368\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9274\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9208 - val_loss: 0.9217\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9222\n",
      "Top-2 accuracy = 0.838\n",
      "22\n",
      "normalizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0213 - val_loss: 0.9519\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9331 - val_loss: 0.9333\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9261 - val_loss: 0.9269\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 0.9306\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9246 - val_loss: 0.9249\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9234 - val_loss: 0.9228\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9270\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9243 - val_loss: 0.9348\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9241 - val_loss: 0.9250\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9233 - val_loss: 0.9315\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9239 - val_loss: 0.9352\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9222 - val_loss: 0.9253\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9224 - val_loss: 0.9296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9239 - val_loss: 0.9234\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9223 - val_loss: 0.9227\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9213 - val_loss: 0.9275\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9211 - val_loss: 0.9221\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9204 - val_loss: 0.9263\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9208 - val_loss: 0.9262\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9245\n",
      "Top-2 accuracy = 0.833\n",
      "23\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0898 - val_loss: 1.0826\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0769 - val_loss: 1.0736\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0698 - val_loss: 1.0690\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0663 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0648 - val_loss: 1.0661\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0641 - val_loss: 1.0658\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "24\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0791 - val_loss: 1.0625\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0479 - val_loss: 1.0345\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0261 - val_loss: 1.0186\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0111 - val_loss: 1.0041\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9926\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9886 - val_loss: 0.9841\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9814 - val_loss: 0.9780\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9755 - val_loss: 0.9725\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9709 - val_loss: 0.9686\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9671 - val_loss: 0.9651\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9641 - val_loss: 0.9623\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9615 - val_loss: 0.9608\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9598 - val_loss: 0.9583\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9579 - val_loss: 0.9563\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9559 - val_loss: 0.9543\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 0.9540\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9518 - val_loss: 0.9502\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9494 - val_loss: 0.9488\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 0.9461\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 0.9443\n",
      "Top-2 accuracy = 0.834\n",
      "25\n",
      "maxabsh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0626 - val_loss: 1.0498\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9867 - val_loss: 0.9506\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9417 - val_loss: 0.9496\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9377\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9362 - val_loss: 0.9364\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9395\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9351 - val_loss: 0.9358\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9334 - val_loss: 0.9350\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9342\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9325 - val_loss: 0.9356\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9332 - val_loss: 0.9331\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 0.9340\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9314 - val_loss: 0.9316\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 0.9329\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 0.9299\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9282 - val_loss: 0.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9292 - val_loss: 0.9284\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9269 - val_loss: 0.9283\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9285\n",
      "Top-2 accuracy = 0.837\n",
      "26\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0037 - val_loss: 0.9499\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9318 - val_loss: 0.9249\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9208 - val_loss: 0.9207\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 0.9282\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9188 - val_loss: 0.9193\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9165 - val_loss: 0.9194\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9152 - val_loss: 0.9176\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9157 - val_loss: 0.9188\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9150 - val_loss: 0.9189\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9141 - val_loss: 0.9176\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9135 - val_loss: 0.9169\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9137 - val_loss: 0.9196\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9123 - val_loss: 0.9175\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9143 - val_loss: 0.9185\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9127 - val_loss: 0.9160\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9127 - val_loss: 0.9251\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9132 - val_loss: 0.9177\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9141 - val_loss: 0.9160\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9116 - val_loss: 0.9159\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9128 - val_loss: 0.9181\n",
      "Top-2 accuracy = 0.84\n",
      "27\n",
      "maxabsT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0885 - val_loss: 1.0770\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0607 - val_loss: 1.0282\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9882 - val_loss: 0.9716\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9495 - val_loss: 0.9388\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9308 - val_loss: 0.9288\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9229 - val_loss: 0.9302\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9210 - val_loss: 0.9241\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.9211\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9187 - val_loss: 0.9211\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9194 - val_loss: 0.9242\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9180 - val_loss: 0.9231\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9200 - val_loss: 0.9202\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9187 - val_loss: 0.9200\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9170 - val_loss: 0.9210\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 0.9205\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9175 - val_loss: 0.9212\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9188 - val_loss: 0.9202\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9179 - val_loss: 0.9196\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9166 - val_loss: 0.9188\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9171 - val_loss: 0.9214\n",
      "Top-2 accuracy = 0.839\n",
      "28\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0763 - val_loss: 1.0654\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0356 - val_loss: 0.9708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9437 - val_loss: 0.9283\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9240 - val_loss: 0.9325\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9240 - val_loss: 0.9233\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9210 - val_loss: 0.9240\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.9283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9190 - val_loss: 0.9220\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9199 - val_loss: 0.9258\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9185 - val_loss: 0.9234\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9191 - val_loss: 0.9226\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9181 - val_loss: 0.9214\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9181 - val_loss: 0.9209\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9180 - val_loss: 0.9207\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9181 - val_loss: 0.9222\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9171 - val_loss: 0.9223\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9187 - val_loss: 0.9257\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9184 - val_loss: 0.9264\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9170 - val_loss: 0.9222\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9176 - val_loss: 0.9218\n",
      "Top-2 accuracy = 0.839\n",
      "29\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0902 - val_loss: 1.0830\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0773 - val_loss: 1.0739\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0700 - val_loss: 1.0691\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0664 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0647 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "0\n",
      "standardizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9892 - val_loss: 0.9409\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9221 - val_loss: 0.9239\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9172 - val_loss: 0.9197\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9161 - val_loss: 0.9192\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9170 - val_loss: 0.9200\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9173 - val_loss: 0.9186\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9160 - val_loss: 0.9196\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9146 - val_loss: 0.9202\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9149 - val_loss: 0.9187\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9154 - val_loss: 0.9273\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9154 - val_loss: 0.9187\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9135 - val_loss: 0.9175\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9135 - val_loss: 0.9183\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9133 - val_loss: 0.9182\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9125 - val_loss: 0.9179\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9149 - val_loss: 0.9188\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9126 - val_loss: 0.9170\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9126 - val_loss: 0.9195\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9122 - val_loss: 0.9199\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9126 - val_loss: 0.9179\n",
      "Top-2 accuracy = 0.839\n",
      "1\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0352 - val_loss: 0.9688\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9371\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9346 - val_loss: 0.9337\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.9294\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9244 - val_loss: 0.9350\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9241 - val_loss: 0.9274\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9225 - val_loss: 0.9233\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9253\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.9274\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.9238\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9199 - val_loss: 0.9346\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9222 - val_loss: 0.9219\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9189 - val_loss: 0.9225\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.9219\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9186 - val_loss: 0.9204\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9230\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9224\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9173 - val_loss: 0.9264\n",
      "Top-2 accuracy = 0.831\n",
      "2\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0281 - val_loss: 0.9818\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9541 - val_loss: 0.9350\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9266 - val_loss: 0.9345\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.9222\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.9257\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 0.9234\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.9250\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9168 - val_loss: 0.9204\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 0.9247\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.9207\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9197\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9162 - val_loss: 0.9200\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9158 - val_loss: 0.9203\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 0.9194\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9154 - val_loss: 0.9226\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9150 - val_loss: 0.9228\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9149 - val_loss: 0.9233\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9155 - val_loss: 0.9200\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9152 - val_loss: 0.9193\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9157 - val_loss: 0.9197\n",
      "Top-2 accuracy = 0.839\n",
      "3\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0672 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0659\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0589 - val_loss: 1.0375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0101 - val_loss: 0.9991\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9811 - val_loss: 0.9625\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9591 - val_loss: 0.9645\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0343 - val_loss: 1.0632\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0634 - val_loss: 1.0657\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "4\n",
      "maxabsG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0564 - val_loss: 0.9734\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9503 - val_loss: 0.9474\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9331 - val_loss: 0.9326\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9327 - val_loss: 0.9318\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9262 - val_loss: 0.9284\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9204 - val_loss: 0.9280\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9203 - val_loss: 0.9226\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9189 - val_loss: 0.9234\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 0.9216\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9180 - val_loss: 0.9209\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9172 - val_loss: 0.9205\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9166 - val_loss: 0.9267\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9167 - val_loss: 0.9225\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9174 - val_loss: 0.9211\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9168 - val_loss: 0.9208\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9181 - val_loss: 0.9209\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9166 - val_loss: 0.9218\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9175 - val_loss: 0.9207\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9159 - val_loss: 0.9222\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9169 - val_loss: 0.9215\n",
      "Top-2 accuracy = 0.837\n",
      "5\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2200 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0445 - val_loss: 1.0165\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9840 - val_loss: 0.9635\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9514 - val_loss: 0.9495\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9424 - val_loss: 0.9440\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9380 - val_loss: 0.9417\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9354 - val_loss: 0.9389\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9338 - val_loss: 0.9384\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9325 - val_loss: 0.9360\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9312 - val_loss: 0.9350\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9302 - val_loss: 0.9338\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9290 - val_loss: 0.9331\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 0.9318\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9273 - val_loss: 0.9308\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9264 - val_loss: 0.9302\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9256 - val_loss: 0.9295\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9250 - val_loss: 0.9288\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9245 - val_loss: 0.9283\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9236 - val_loss: 0.9278\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9229 - val_loss: 0.9274\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9223 - val_loss: 0.9266\n",
      "Top-2 accuracy = 0.838\n",
      "6\n",
      "maxabsh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0382 - val_loss: 0.9810\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9568 - val_loss: 0.9446\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9309 - val_loss: 0.9339\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9221 - val_loss: 0.9242\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9207 - val_loss: 0.9222\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.9265\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9187 - val_loss: 0.9222\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9177 - val_loss: 0.9273\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9177 - val_loss: 0.9292\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9204 - val_loss: 0.9206\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9202\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9171 - val_loss: 0.9210\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.9224\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9219\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9173 - val_loss: 0.9204\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.9204\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9171 - val_loss: 0.9225\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9178 - val_loss: 0.9252\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9210\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-2 accuracy = 0.838\n",
      "7\n",
      "standardizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0288 - val_loss: 0.9662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 0.9392\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9343 - val_loss: 0.9332\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9296 - val_loss: 0.9295\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 0.9298\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9256 - val_loss: 0.9243\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9235 - val_loss: 0.9249\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 0.9234\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 0.9224\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9208 - val_loss: 0.9239\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9219 - val_loss: 0.9237\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9206 - val_loss: 0.9233\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9211 - val_loss: 0.9250\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9204 - val_loss: 0.9236\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9199 - val_loss: 0.9223\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9219\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9209\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 0.9225\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.9222\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9184 - val_loss: 0.9212\n",
      "Top-2 accuracy = 0.839\n",
      "8\n",
      "minmaxO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0702 - val_loss: 1.0442\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0154 - val_loss: 0.9940\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9764 - val_loss: 0.9742\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9628 - val_loss: 0.9624\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 0.9552\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 0.9503\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9451 - val_loss: 0.9474\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9454\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9442\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9409 - val_loss: 0.9433\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9401 - val_loss: 0.9425\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9422\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9390 - val_loss: 0.9411\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9421\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9385 - val_loss: 0.9401\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9422\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 0.9399\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9373 - val_loss: 0.9398\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 0.9403\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9367 - val_loss: 0.9389\n",
      "Top-2 accuracy = 0.836\n",
      "9\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2221 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0391 - val_loss: 0.9689\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9390\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9342\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9305\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9262 - val_loss: 0.9283\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9243 - val_loss: 0.9276\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9234 - val_loss: 0.9250\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9220 - val_loss: 0.9242\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.9247\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.9232\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9227\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9214\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9214\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9174 - val_loss: 0.9204\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9173 - val_loss: 0.9215\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9164 - val_loss: 0.9218\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9159 - val_loss: 0.9193\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9154 - val_loss: 0.9226\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9153 - val_loss: 0.9204\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9150 - val_loss: 0.9178\n",
      "Top-2 accuracy = 0.839\n",
      "10\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0410 - val_loss: 0.9882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9575 - val_loss: 0.9510\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9364 - val_loss: 0.9471\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9309 - val_loss: 0.9343\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9275 - val_loss: 0.9288\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9254 - val_loss: 0.9257\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9245 - val_loss: 0.9362\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9239 - val_loss: 0.9296\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9245 - val_loss: 0.9236\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9209 - val_loss: 0.9227\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9219 - val_loss: 0.9221\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9219 - val_loss: 0.9233\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9211 - val_loss: 0.9219\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9208 - val_loss: 0.9211\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.9201\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9187 - val_loss: 0.9223\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9195 - val_loss: 0.9199\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9188 - val_loss: 0.9225\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9217 - val_loss: 0.9288\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9198 - val_loss: 0.9266\n",
      "Top-2 accuracy = 0.836\n",
      "11\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0515 - val_loss: 0.9964\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9617 - val_loss: 0.9403\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9330\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9338\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 0.9291\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9284 - val_loss: 0.9250\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9229\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9298\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9212\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9210\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9260\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.9209\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9206\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9206\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9200\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9202\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9217\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 0.9201\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9199\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.9194\n",
      "Top-2 accuracy = 0.835\n",
      "12\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0900 - val_loss: 1.0828\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0771 - val_loss: 1.0737\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0698 - val_loss: 1.0690\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0663 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0647 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "13\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0675 - val_loss: 0.9943\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9590 - val_loss: 0.9424\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9329 - val_loss: 0.9320\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9270 - val_loss: 0.9304\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9246 - val_loss: 0.9281\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9229 - val_loss: 0.9283\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9217 - val_loss: 0.9257\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9207 - val_loss: 0.9256\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9201 - val_loss: 0.9248\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9198 - val_loss: 0.9242\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9192 - val_loss: 0.9244\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9182 - val_loss: 0.9238\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9179 - val_loss: 0.9230\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9171 - val_loss: 0.9233\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9172 - val_loss: 0.9219\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9167 - val_loss: 0.9219\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9163 - val_loss: 0.9220\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9161 - val_loss: 0.9211\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9163 - val_loss: 0.9204\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9156 - val_loss: 0.9203\n",
      "Top-2 accuracy = 0.836\n",
      "14\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0927 - val_loss: 1.0787\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0665 - val_loss: 1.0515\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0167 - val_loss: 0.9864\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9694 - val_loss: 0.9593\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9502 - val_loss: 0.9467\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9417 - val_loss: 0.9404\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9366\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9344 - val_loss: 0.9355\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9344\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9326 - val_loss: 0.9338\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9320 - val_loss: 0.9335\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9315 - val_loss: 0.9335\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9320 - val_loss: 0.9330\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9309 - val_loss: 0.9325\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9309 - val_loss: 0.9326\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9304 - val_loss: 0.9326\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9306 - val_loss: 0.9319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9299 - val_loss: 0.9321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9297 - val_loss: 0.9316\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9295 - val_loss: 0.9315\n",
      "Top-2 accuracy = 0.837\n",
      "15\n",
      "minmaxn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0347 - val_loss: 0.9619\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9393\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 0.9363\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9339 - val_loss: 0.9349\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9330 - val_loss: 0.9383\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9334\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9305 - val_loss: 0.9348\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9322 - val_loss: 0.9302\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9305 - val_loss: 0.9309\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9342\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9319\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9288 - val_loss: 0.9309\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9338\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9298 - val_loss: 0.9295\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9288 - val_loss: 0.9307\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9327\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 0.9277\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 0.9330\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9260 - val_loss: 0.9263\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9271\n",
      "Top-2 accuracy = 0.835\n",
      "16\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0749 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0655\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0653\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0617 - val_loss: 1.0544\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9942 - val_loss: 0.9584\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9519 - val_loss: 0.9525\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9478 - val_loss: 0.9523\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9449 - val_loss: 0.9451\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9444\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9430 - val_loss: 0.9499\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9416 - val_loss: 0.9429\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9402 - val_loss: 0.9428\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9396 - val_loss: 0.9464\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9405 - val_loss: 0.9426\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9395 - val_loss: 0.9427\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9390 - val_loss: 0.9458\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9420\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9396 - val_loss: 0.9420\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9389 - val_loss: 0.9410\n",
      "Top-2 accuracy = 0.831\n",
      "17\n",
      "minmaxa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0731 - val_loss: 1.0475\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9981 - val_loss: 0.9606\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9479 - val_loss: 0.9585\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9444\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9375 - val_loss: 0.9505\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9351 - val_loss: 0.9370\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9415\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9326 - val_loss: 0.9418\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9341 - val_loss: 0.9399\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9333 - val_loss: 0.9482\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9331 - val_loss: 0.9373\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9320 - val_loss: 0.9426\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9331 - val_loss: 0.9339\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9300 - val_loss: 0.9421\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9302 - val_loss: 0.9443\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9321 - val_loss: 0.9347\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9309 - val_loss: 0.9326\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9294 - val_loss: 0.9313\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9310 - val_loss: 0.9312\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9284 - val_loss: 0.9311\n",
      "Top-2 accuracy = 0.832\n",
      "18\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0379 - val_loss: 0.9889\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9673 - val_loss: 0.9550\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9427\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 0.9352\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9292 - val_loss: 0.9324\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9269 - val_loss: 0.9332\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9261 - val_loss: 0.9296\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9245 - val_loss: 0.9315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9296\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9230 - val_loss: 0.9294\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9222 - val_loss: 0.9277\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9290\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9300\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9257\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.9277\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 0.9251\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 0.9253\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9238\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 0.9254\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9233\n",
      "Top-2 accuracy = 0.833\n",
      "19\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9984 - val_loss: 0.9491\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9435 - val_loss: 0.9427\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9376 - val_loss: 0.9386\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9356 - val_loss: 0.9377\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9331 - val_loss: 0.9331\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9281 - val_loss: 0.9348\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9261 - val_loss: 0.9270\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9241 - val_loss: 0.9293\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9269 - val_loss: 0.9255\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9227 - val_loss: 0.9239\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9208 - val_loss: 0.9242\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9209 - val_loss: 0.9237\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9211 - val_loss: 0.9249\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9202 - val_loss: 0.9226\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9205 - val_loss: 0.9220\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9187 - val_loss: 0.9213\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9188 - val_loss: 0.9204\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 0.9223\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9177 - val_loss: 0.9259\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9185 - val_loss: 0.9207\n",
      "Top-2 accuracy = 0.837\n",
      "20\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0345 - val_loss: 0.9826\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9591 - val_loss: 0.9529\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.9456\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9390 - val_loss: 0.9411\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9328 - val_loss: 0.9359\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 0.9339\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9292 - val_loss: 0.9329\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9269 - val_loss: 0.9350\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9306\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9260 - val_loss: 0.9308\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9243 - val_loss: 0.9312\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9245 - val_loss: 0.9299\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 0.9283\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 0.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9228 - val_loss: 0.9280\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9230 - val_loss: 0.9342\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9275\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9276\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9268\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9297\n",
      "Top-2 accuracy = 0.829\n",
      "21\n",
      "minmaxU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0365 - val_loss: 0.9746\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9541 - val_loss: 0.9493\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9443 - val_loss: 0.9604\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9424 - val_loss: 0.9419\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9383 - val_loss: 0.9452\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9376 - val_loss: 0.9452\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9341 - val_loss: 0.9327\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9333 - val_loss: 0.9352\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9322 - val_loss: 0.9396\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9323 - val_loss: 0.9402\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9313\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 0.9348\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9326\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9298 - val_loss: 0.9320\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9283 - val_loss: 0.9533\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9309 - val_loss: 0.9298\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9281 - val_loss: 0.9302\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9283 - val_loss: 0.9586\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9315 - val_loss: 0.9323\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9279 - val_loss: 0.9300\n",
      "Top-2 accuracy = 0.833\n",
      "22\n",
      "standardizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0892 - val_loss: 1.0803\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0730 - val_loss: 1.0691\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0658 - val_loss: 1.0661\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "23\n",
      "normalizei|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2295 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0667 - val_loss: 1.0301\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9894 - val_loss: 0.9619\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9486 - val_loss: 0.9441\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9386 - val_loss: 0.9380\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9352\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9305 - val_loss: 0.9300\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9286 - val_loss: 0.9289\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9272 - val_loss: 0.9281\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9262 - val_loss: 0.9271\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9252 - val_loss: 0.9266\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9243 - val_loss: 0.9261\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9237 - val_loss: 0.9254\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.9246\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9221 - val_loss: 0.9238\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9210 - val_loss: 0.9279\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9209 - val_loss: 0.9238\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.9229\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9242\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9196 - val_loss: 0.9228\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9193 - val_loss: 0.9232\n",
      "Top-2 accuracy = 0.837\n",
      "24\n",
      "robustF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0557 - val_loss: 1.0042\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9752 - val_loss: 0.9656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9625 - val_loss: 0.9622\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9505\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9443 - val_loss: 0.9410\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9389\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 0.9367\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9349 - val_loss: 0.9367\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9358\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9325 - val_loss: 0.9358\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9365\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.9360\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9322 - val_loss: 0.9358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 0.9343\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9317 - val_loss: 0.9353\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9347\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9393\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9305 - val_loss: 0.9357\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9347\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9342\n",
      "Top-2 accuracy = 0.835\n",
      "25\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0038 - val_loss: 0.9630\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9449\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9332 - val_loss: 0.9328\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9304 - val_loss: 0.9321\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9287 - val_loss: 0.9325\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9288 - val_loss: 0.9385\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9318 - val_loss: 0.9304\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.9326\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9290 - val_loss: 0.9301\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 0.9379\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9272 - val_loss: 0.9297\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9256 - val_loss: 0.9304\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 0.9372\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.9295\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9249 - val_loss: 0.9331\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9260 - val_loss: 0.9314\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9248 - val_loss: 0.9317\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9248 - val_loss: 0.9298\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9247 - val_loss: 0.9309\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9248 - val_loss: 0.9337\n",
      "Top-2 accuracy = 0.823\n",
      "26\n",
      "maxabsF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0657 - val_loss: 1.0433\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0074 - val_loss: 0.9766\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9583 - val_loss: 0.9521\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9446 - val_loss: 0.9454\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9403 - val_loss: 0.9422\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9375 - val_loss: 0.9388\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9359 - val_loss: 0.9455\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9400\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9344 - val_loss: 0.9385\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9339 - val_loss: 0.9356\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9328 - val_loss: 0.9353\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9334\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9314 - val_loss: 0.9329\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9309 - val_loss: 0.9351\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9308 - val_loss: 0.9347\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9306 - val_loss: 0.9343\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9292 - val_loss: 0.9319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 0.9308\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9287 - val_loss: 0.9324\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9287 - val_loss: 0.9316\n",
      "Top-2 accuracy = 0.835\n",
      "27\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0715 - val_loss: 1.0334\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0003 - val_loss: 0.9672\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9459 - val_loss: 0.9404\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9333 - val_loss: 0.9463\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9324 - val_loss: 0.9700\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9343 - val_loss: 0.9404\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9305 - val_loss: 0.9518\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9331 - val_loss: 0.9390\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9306 - val_loss: 0.9405\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9287 - val_loss: 0.9311\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9289 - val_loss: 0.9309\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9285 - val_loss: 0.9366\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9305 - val_loss: 0.9514\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9346 - val_loss: 0.9325\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9278 - val_loss: 0.9298\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9269 - val_loss: 0.9300\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9282 - val_loss: 0.9340\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9276 - val_loss: 0.9301\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9279 - val_loss: 0.9324\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9276 - val_loss: 0.9377\n",
      "Top-2 accuracy = 0.828\n",
      "28\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0469 - val_loss: 0.9842\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9617 - val_loss: 0.9477\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9403 - val_loss: 0.9419\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9350 - val_loss: 0.9293\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9252 - val_loss: 0.9255\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 0.9243\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9216 - val_loss: 0.9230\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9207 - val_loss: 0.9233\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.9231\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9196 - val_loss: 0.9224\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9208 - val_loss: 0.9265\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9187 - val_loss: 0.9213\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9185 - val_loss: 0.9225\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.9212\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9176 - val_loss: 0.9222\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9169 - val_loss: 0.9211\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9162 - val_loss: 0.9195\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 0.9198\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9161 - val_loss: 0.9202\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9164 - val_loss: 0.9235\n",
      "Top-2 accuracy = 0.834\n",
      "29\n",
      "maxabsm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0108 - val_loss: 0.9539\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9431 - val_loss: 0.9359\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 0.9333\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9309 - val_loss: 0.9314\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9298 - val_loss: 0.9300\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9292 - val_loss: 0.9287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9344\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 0.9316\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9269 - val_loss: 0.9280\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9265 - val_loss: 0.9303\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9269 - val_loss: 0.9282\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9281\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9266 - val_loss: 0.9277\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.9274\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9255 - val_loss: 0.9287\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9286\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.9271\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9250 - val_loss: 0.9270\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9247 - val_loss: 0.9279\n",
      "Top-2 accuracy = 0.837\n",
      "0\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0698 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0537 - val_loss: 1.0038\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9689 - val_loss: 0.9511\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9473 - val_loss: 0.9508\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9463 - val_loss: 0.9545\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9442 - val_loss: 0.9488\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9468\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 0.9435\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9451 - val_loss: 0.9454\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9527\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9387 - val_loss: 0.9393\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9355 - val_loss: 0.9379\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9350 - val_loss: 0.9377\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9348 - val_loss: 0.9425\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9351 - val_loss: 0.9377\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9343 - val_loss: 0.9379\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9342 - val_loss: 0.9401\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 0.9379\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9332 - val_loss: 0.9385\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9322 - val_loss: 0.9377\n",
      "Top-2 accuracy = 0.83\n",
      "1\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0385 - val_loss: 0.9915\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9719 - val_loss: 0.9616\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9511 - val_loss: 0.9504\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9449 - val_loss: 0.9483\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9395 - val_loss: 0.9407\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9338 - val_loss: 0.9356\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9322 - val_loss: 0.9327\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9286 - val_loss: 0.9313\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9278 - val_loss: 0.9306\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9273 - val_loss: 0.9309\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9260 - val_loss: 0.9310\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9277 - val_loss: 0.9292\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9270 - val_loss: 0.9279\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9247 - val_loss: 0.9277\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9238 - val_loss: 0.9306\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9240 - val_loss: 0.9263\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9238 - val_loss: 0.9283\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9254 - val_loss: 0.9348\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9230 - val_loss: 0.9306\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9234 - val_loss: 0.9255\n",
      "Top-2 accuracy = 0.836\n",
      "2\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0901 - val_loss: 1.0829\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0772 - val_loss: 1.0738\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0699 - val_loss: 1.0691\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0664 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0647 - val_loss: 1.0661\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0657\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0657\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "3\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0900 - val_loss: 1.0828\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0770 - val_loss: 1.0737\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0698 - val_loss: 1.0690\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0663 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0647 - val_loss: 1.0661\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0641 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "4\n",
      "normalizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0550 - val_loss: 1.0299\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0038 - val_loss: 0.9810\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9589 - val_loss: 0.9552\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9443 - val_loss: 0.9389\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 0.9449\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 0.9328\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9283 - val_loss: 0.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9277 - val_loss: 0.9275\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9260 - val_loss: 0.9261\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9248 - val_loss: 0.9314\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9261 - val_loss: 0.9258\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9244 - val_loss: 0.9260\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9239 - val_loss: 0.9294\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9239 - val_loss: 0.9281\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 0.9408\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9282 - val_loss: 0.9261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9230 - val_loss: 0.9277\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9233 - val_loss: 0.9273\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9235 - val_loss: 0.9241\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9227 - val_loss: 0.9246\n",
      "Top-2 accuracy = 0.833\n",
      "5\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0386 - val_loss: 0.9708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 0.9383\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 0.9355\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9273\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9249 - val_loss: 0.9254\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.9250\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9223 - val_loss: 0.9237\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9230\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9224\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9258\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9270\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9235\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9209\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9225\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9198 - val_loss: 0.9221\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9189 - val_loss: 0.9211\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.9208\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9168 - val_loss: 0.9214\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9165 - val_loss: 0.9275\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9172 - val_loss: 0.9207\n",
      "Top-2 accuracy = 0.835\n",
      "6\n",
      "robustB|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2361 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.3717 - val_loss: 1.0136\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9903 - val_loss: 0.9771\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9676 - val_loss: 0.9626\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9568 - val_loss: 0.9537\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9493 - val_loss: 0.9475\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9443 - val_loss: 0.9436\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9402 - val_loss: 0.9400\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9375 - val_loss: 0.9374\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 0.9354\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9332 - val_loss: 0.9337\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9319 - val_loss: 0.9326\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9305 - val_loss: 0.9315\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9291 - val_loss: 0.9298\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9289 - val_loss: 0.9287\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9274 - val_loss: 0.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9264 - val_loss: 0.9273\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9260 - val_loss: 0.9270\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9254 - val_loss: 0.9268\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9253 - val_loss: 0.9257\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9235 - val_loss: 0.9253\n",
      "Top-2 accuracy = 0.835\n",
      "7\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0644 - val_loss: 1.0577\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9869 - val_loss: 0.9606\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9481 - val_loss: 0.9454\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9409 - val_loss: 0.9456\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9407 - val_loss: 0.9417\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9385 - val_loss: 0.9416\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9378 - val_loss: 0.9422\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9389 - val_loss: 0.9432\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9380 - val_loss: 0.9408\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9368 - val_loss: 0.9360\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9331 - val_loss: 0.9338\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9306 - val_loss: 0.9293\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9280 - val_loss: 0.9295\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9268 - val_loss: 0.9274\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9268 - val_loss: 0.9272\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9273 - val_loss: 0.9307\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9265 - val_loss: 0.9260\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9257 - val_loss: 0.9262\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9255 - val_loss: 0.9337\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9277 - val_loss: 0.9351\n",
      "Top-2 accuracy = 0.827\n",
      "8\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0765 - val_loss: 1.0611\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0393 - val_loss: 1.0106\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9804 - val_loss: 0.9640\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9465\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9402\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 0.9359\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9344\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9333\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 0.9321\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 0.9306\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9309\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9280 - val_loss: 0.9293\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 0.9298\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9267 - val_loss: 0.9271\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9260 - val_loss: 0.9281\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9256 - val_loss: 0.9277\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9271\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.9268\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9243 - val_loss: 0.9265\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9239 - val_loss: 0.9267\n",
      "Top-2 accuracy = 0.836\n",
      "9\n",
      "robustz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0562 - val_loss: 1.0021\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9617 - val_loss: 0.9448\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9348 - val_loss: 0.9329\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9302 - val_loss: 0.9281\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9263 - val_loss: 0.9265\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9267 - val_loss: 0.9457\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9251 - val_loss: 0.9273\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9244 - val_loss: 0.9317\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9259 - val_loss: 0.9277\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9234 - val_loss: 0.9237\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9229 - val_loss: 0.9238\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9230 - val_loss: 0.9249\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9215 - val_loss: 0.9235\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9224 - val_loss: 0.9238\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9213 - val_loss: 0.9322\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9231 - val_loss: 0.9373\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9221 - val_loss: 0.9238\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9226 - val_loss: 0.9351\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9202 - val_loss: 0.9214\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9197 - val_loss: 0.9238\n",
      "Top-2 accuracy = 0.833\n",
      "10\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0298 - val_loss: 0.9805\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9558 - val_loss: 0.9504\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9433 - val_loss: 0.9414\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9438 - val_loss: 0.9415\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9402 - val_loss: 0.9375\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9395 - val_loss: 0.9382\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9375 - val_loss: 0.9338\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9350 - val_loss: 0.9332\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9355 - val_loss: 0.9338\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9333 - val_loss: 0.9307\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9327 - val_loss: 0.9318\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9321 - val_loss: 0.9297\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9314 - val_loss: 0.9297\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9306 - val_loss: 0.9291\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9290 - val_loss: 0.9290\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9299 - val_loss: 0.9356\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9312 - val_loss: 0.9290\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9288 - val_loss: 0.9281\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9282 - val_loss: 0.9299\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9291 - val_loss: 0.9306\n",
      "Top-2 accuracy = 0.834\n",
      "11\n",
      "maxabsN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0460 - val_loss: 0.9730\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.9392\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9314 - val_loss: 0.9395\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9394\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9322\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.9338\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9256 - val_loss: 0.9292\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9248 - val_loss: 0.9272\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9240 - val_loss: 0.9253\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.9314\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9245\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9242\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9211 - val_loss: 0.9263\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9303\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.9242\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9233\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9236\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9186 - val_loss: 0.9227\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9199 - val_loss: 0.9230\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9189 - val_loss: 0.9233\n",
      "Top-2 accuracy = 0.835\n",
      "12\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0670 - val_loss: 1.0656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0454 - val_loss: 0.9902\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9678 - val_loss: 0.9666\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 0.9555\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9503 - val_loss: 0.9530\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9497 - val_loss: 0.9540\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9512\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9467 - val_loss: 0.9701\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9518\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9446 - val_loss: 0.9511\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9463 - val_loss: 0.9549\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9445 - val_loss: 0.9470\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9429 - val_loss: 0.9517\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9474\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9523\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9424 - val_loss: 0.9520\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9396\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9359 - val_loss: 0.9382\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9397\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9405\n",
      "Top-2 accuracy = 0.824\n",
      "13\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0722 - val_loss: 1.0661\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0641 - val_loss: 1.0660\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Top-2 accuracy = 0.752\n",
      "14\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0434 - val_loss: 0.9807\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9705 - val_loss: 0.9684\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9612 - val_loss: 0.9603\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9582 - val_loss: 0.9565\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9493 - val_loss: 0.9500\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9461 - val_loss: 0.9451\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9415 - val_loss: 0.9412\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9371 - val_loss: 0.9377\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9412\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9333 - val_loss: 0.9364\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9307 - val_loss: 0.9302\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9265 - val_loss: 0.9282\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9252 - val_loss: 0.9267\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9223 - val_loss: 0.9268\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9222 - val_loss: 0.9241\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9210 - val_loss: 0.9242\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9203 - val_loss: 0.9275\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9219 - val_loss: 0.9240\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9189 - val_loss: 0.9226\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9185 - val_loss: 0.9221\n",
      "Top-2 accuracy = 0.833\n",
      "15\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0506 - val_loss: 0.9948\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9683 - val_loss: 0.9538\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9432 - val_loss: 0.9376\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9325 - val_loss: 0.9313\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9287 - val_loss: 0.9383\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9269 - val_loss: 0.9285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9266 - val_loss: 0.9337\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9259 - val_loss: 0.9288\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9260 - val_loss: 0.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9259 - val_loss: 0.9327\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9249 - val_loss: 0.9328\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9254 - val_loss: 0.9267\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9239 - val_loss: 0.9252\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9244 - val_loss: 0.9271\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9236 - val_loss: 0.9261\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9234 - val_loss: 0.9276\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9232 - val_loss: 0.9244\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9234 - val_loss: 0.9243\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9221 - val_loss: 0.9283\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9244 - val_loss: 0.9278\n",
      "Top-2 accuracy = 0.833\n",
      "16\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0781 - val_loss: 1.0615\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0419 - val_loss: 1.0240\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9996 - val_loss: 0.9823\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9685 - val_loss: 0.9646\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9569 - val_loss: 0.9571\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9516 - val_loss: 0.9537\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9490 - val_loss: 0.9507\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9475 - val_loss: 0.9510\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9467 - val_loss: 0.9494\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9485\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9479\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 0.9475\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 0.9477\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9451 - val_loss: 0.9472\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9449 - val_loss: 0.9472\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9449 - val_loss: 0.9478\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9449 - val_loss: 0.9471\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9446 - val_loss: 0.9468\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9446 - val_loss: 0.9474\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9445 - val_loss: 0.9470\n",
      "Top-2 accuracy = 0.831\n",
      "17\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0597 - val_loss: 1.0081\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9767 - val_loss: 0.9589\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9543 - val_loss: 0.9529\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9483 - val_loss: 0.9525\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9465 - val_loss: 0.9661\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9523 - val_loss: 0.9545\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9483 - val_loss: 0.9438\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9412 - val_loss: 0.9416\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9380 - val_loss: 0.9426\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9412 - val_loss: 0.9363\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9365 - val_loss: 0.9389\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9355 - val_loss: 0.9392\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9340 - val_loss: 0.9434\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9345 - val_loss: 0.9523\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9356 - val_loss: 0.9370\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9370 - val_loss: 0.9385\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9336 - val_loss: 0.9329\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9328 - val_loss: 0.9440\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9354 - val_loss: 0.9328\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9317 - val_loss: 0.9339\n",
      "Top-2 accuracy = 0.828\n",
      "18\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0237 - val_loss: 0.9613\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9416 - val_loss: 0.9402\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9310 - val_loss: 0.9283\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9270 - val_loss: 0.9298\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 0.9306\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9238 - val_loss: 0.9258\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9226 - val_loss: 0.9239\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9213 - val_loss: 0.9259\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9208 - val_loss: 0.9260\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9216 - val_loss: 0.9225\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.9230\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9199 - val_loss: 0.9228\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9191 - val_loss: 0.9218\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9184 - val_loss: 0.9223\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9186 - val_loss: 0.9219\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9183 - val_loss: 0.9253\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9180 - val_loss: 0.9219\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9178 - val_loss: 0.9218\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9174 - val_loss: 0.9259\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9188 - val_loss: 0.9216\n",
      "Top-2 accuracy = 0.837\n",
      "19\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0712 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0630 - val_loss: 1.0542\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9957 - val_loss: 0.9624\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9504\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 0.9447\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9423 - val_loss: 0.9423\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9367 - val_loss: 0.9370\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9331 - val_loss: 0.9333\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 0.9362\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 0.9277\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9265 - val_loss: 0.9266\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9262 - val_loss: 0.9260\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9250 - val_loss: 0.9256\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9260 - val_loss: 0.9271\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9257 - val_loss: 0.9231\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 0.9237\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9222 - val_loss: 0.9218\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9211 - val_loss: 0.9260\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9215 - val_loss: 0.9234\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9206 - val_loss: 0.9210\n",
      "Top-2 accuracy = 0.835\n",
      "20\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0410 - val_loss: 1.0055\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9725 - val_loss: 0.9499\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 0.9363\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9291 - val_loss: 0.9289\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9255 - val_loss: 0.9262\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9237 - val_loss: 0.9344\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9226 - val_loss: 0.9281\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9204 - val_loss: 0.9235\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9210 - val_loss: 0.9238\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9206 - val_loss: 0.9246\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9194 - val_loss: 0.9247\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9185 - val_loss: 0.9252\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9197 - val_loss: 0.9242\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9177 - val_loss: 0.9273\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9183 - val_loss: 0.9233\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9181 - val_loss: 0.9266\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9175 - val_loss: 0.9260\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9190 - val_loss: 0.9261\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9236 - val_loss: 0.9244\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9177 - val_loss: 0.9263\n",
      "Top-2 accuracy = 0.827\n",
      "21\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0686 - val_loss: 1.0658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0640 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0659\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0658\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0640 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "22\n",
      "robustc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0807 - val_loss: 1.0660\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "23\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0749 - val_loss: 1.0658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0660\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0658\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0640 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "24\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0751 - val_loss: 1.0661\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0665\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "25\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2462 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0631 - val_loss: 1.0229\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9851 - val_loss: 0.9628\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9498 - val_loss: 0.9477\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9397 - val_loss: 0.9403\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9346 - val_loss: 0.9363\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9323 - val_loss: 0.9336\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9290 - val_loss: 0.9313\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9271 - val_loss: 0.9303\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9256 - val_loss: 0.9294\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9245 - val_loss: 0.9276\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9250 - val_loss: 0.9269\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9269\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9224 - val_loss: 0.9253\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9216 - val_loss: 0.9260\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9207 - val_loss: 0.9249\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9196 - val_loss: 0.9252\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9194 - val_loss: 0.9258\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9190 - val_loss: 0.9247\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9186 - val_loss: 0.9237\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9243\n",
      "Top-2 accuracy = 0.831\n",
      "26\n",
      "minmaxt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0285 - val_loss: 0.9809\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.9600\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9407 - val_loss: 0.9417\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9340 - val_loss: 0.9351\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9329 - val_loss: 0.9332\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9295 - val_loss: 0.9346\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9281 - val_loss: 0.9360\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9266 - val_loss: 0.9314\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9262 - val_loss: 0.9297\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9253 - val_loss: 0.9306\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 0.9288\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9247 - val_loss: 0.9283\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9258 - val_loss: 0.9294\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.9276\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9276\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9234 - val_loss: 0.9268\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9233 - val_loss: 0.9277\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9276\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9228 - val_loss: 0.9295\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9248 - val_loss: 0.9260\n",
      "Top-2 accuracy = 0.834\n",
      "27\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0198 - val_loss: 0.9463\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9274 - val_loss: 0.9289\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9216 - val_loss: 0.9230\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9174 - val_loss: 0.9277\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9189 - val_loss: 0.9232\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9170 - val_loss: 0.9225\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9177 - val_loss: 0.9222\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9180 - val_loss: 0.9221\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9154 - val_loss: 0.9223\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9159 - val_loss: 0.9252\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9155 - val_loss: 0.9217\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9162 - val_loss: 0.9234\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9152 - val_loss: 0.9212\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9151 - val_loss: 0.9213\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9148 - val_loss: 0.9216\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9181 - val_loss: 0.9219\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9145 - val_loss: 0.9211\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9148 - val_loss: 0.9321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9155 - val_loss: 0.9217\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9155 - val_loss: 0.9306\n",
      "Top-2 accuracy = 0.831\n",
      "28\n",
      "minmaxz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0414 - val_loss: 0.9924\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9752 - val_loss: 0.9588\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9462 - val_loss: 0.9475\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9414 - val_loss: 0.9434\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 0.9401\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9398 - val_loss: 0.9386\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9356 - val_loss: 0.9420\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9367 - val_loss: 0.9355\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.9343\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9322 - val_loss: 0.9368\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9331 - val_loss: 0.9513\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9329 - val_loss: 0.9338\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9296 - val_loss: 0.9341\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9310 - val_loss: 0.9342\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9288 - val_loss: 0.9346\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9295 - val_loss: 0.9315\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9287 - val_loss: 0.9323\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9287 - val_loss: 0.9306\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9301 - val_loss: 0.9394\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9284 - val_loss: 0.9395\n",
      "Top-2 accuracy = 0.829\n",
      "29\n",
      "maxabsC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.0724 - val_loss: 1.0664\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0666\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0662\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0662\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0660\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "0\n",
      "standardized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0466 - val_loss: 1.0102\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9906 - val_loss: 0.9721\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9571 - val_loss: 0.9481\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9422 - val_loss: 0.9446\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9368 - val_loss: 0.9377\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 0.9400\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9337\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9313 - val_loss: 0.9368\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9312 - val_loss: 0.9331\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9292 - val_loss: 0.9313\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9278 - val_loss: 0.9308\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9271 - val_loss: 0.9309\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9279 - val_loss: 0.9296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9269 - val_loss: 0.9293\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9264 - val_loss: 0.9289\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9259 - val_loss: 0.9299\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9251 - val_loss: 0.9282\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9255 - val_loss: 0.9271\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9241 - val_loss: 0.9282\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9247 - val_loss: 0.9270\n",
      "Top-2 accuracy = 0.827\n",
      "1\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0669 - val_loss: 1.0250\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9795 - val_loss: 0.9522\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 0.9346\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9293 - val_loss: 0.9298\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9320\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 0.9269\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9230 - val_loss: 0.9266\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9253\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9211 - val_loss: 0.9243\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9242\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.9230\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9193 - val_loss: 0.9229\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9187 - val_loss: 0.9224\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9250\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9189 - val_loss: 0.9219\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9213\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9173 - val_loss: 0.9216\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.9227\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.9211\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9167 - val_loss: 0.9210\n",
      "Top-2 accuracy = 0.834\n",
      "2\n",
      "standardizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0888 - val_loss: 1.0785\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0706 - val_loss: 1.0671\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0641 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0658\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "3\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0901 - val_loss: 1.0828\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0770 - val_loss: 1.0736\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0698 - val_loss: 1.0689\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0663 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0647 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "4\n",
      "standardizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.0827 - val_loss: 1.0656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0638 - val_loss: 1.0662\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0640 - val_loss: 1.0661\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "5\n",
      "robustR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0716 - val_loss: 1.0540\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9999 - val_loss: 0.9640\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9464 - val_loss: 0.9441\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9391 - val_loss: 0.9612\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9385 - val_loss: 0.9423\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9352 - val_loss: 0.9397\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9367 - val_loss: 0.9382\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9365 - val_loss: 0.9387\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9352 - val_loss: 0.9357\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9340 - val_loss: 0.9451\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9344 - val_loss: 0.9361\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9335 - val_loss: 0.9459\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9338 - val_loss: 0.9362\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9336 - val_loss: 0.9363\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9322 - val_loss: 0.9379\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9318 - val_loss: 0.9377\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9321 - val_loss: 0.9384\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9334 - val_loss: 0.9358\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9314 - val_loss: 0.9358\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9305 - val_loss: 0.9340\n",
      "Top-2 accuracy = 0.834\n",
      "6\n",
      "maxabsT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0902 - val_loss: 1.0830\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0773 - val_loss: 1.0738\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0700 - val_loss: 1.0690\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0664 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0647 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "7\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0760 - val_loss: 1.0654\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0252 - val_loss: 0.9653\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9500 - val_loss: 0.9539\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9452 - val_loss: 0.9483\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9431 - val_loss: 0.9457\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9413 - val_loss: 0.9447\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9417 - val_loss: 0.9423\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9377 - val_loss: 0.9400\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9378 - val_loss: 0.9378\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9358 - val_loss: 0.9460\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9375 - val_loss: 0.9349\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9345 - val_loss: 0.9393\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9335 - val_loss: 0.9336\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9339 - val_loss: 0.9334\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9337 - val_loss: 0.9381\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9340 - val_loss: 0.9343\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.9325\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9320 - val_loss: 0.9327\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9319 - val_loss: 0.9323\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9323 - val_loss: 0.9320\n",
      "Top-2 accuracy = 0.835\n",
      "8\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0719 - val_loss: 1.0403\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0061 - val_loss: 0.9766\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9546 - val_loss: 0.9426\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9334 - val_loss: 0.9315\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9274 - val_loss: 0.9281\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9249 - val_loss: 0.9273\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9235 - val_loss: 0.9300\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9242 - val_loss: 0.9397\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9242 - val_loss: 0.9277\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9231 - val_loss: 0.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9220 - val_loss: 0.9299\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9235 - val_loss: 0.9323\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9235 - val_loss: 0.9265\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9224 - val_loss: 0.9259\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9220 - val_loss: 0.9271\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9227 - val_loss: 0.9275\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9221 - val_loss: 0.9255\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9215 - val_loss: 0.9267\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9212 - val_loss: 0.9250\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9213 - val_loss: 0.9248\n",
      "Top-2 accuracy = 0.834\n",
      "9\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0728 - val_loss: 1.0654\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0485 - val_loss: 1.0181\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0065 - val_loss: 0.9877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9931 - val_loss: 0.9876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9898 - val_loss: 0.9834\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9908 - val_loss: 0.9835\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9873 - val_loss: 0.9809\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9875 - val_loss: 0.9799\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9870 - val_loss: 0.9865\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9892 - val_loss: 0.9834\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9871 - val_loss: 0.9831\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9869 - val_loss: 0.9830\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9888 - val_loss: 0.9837\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9888 - val_loss: 0.9832\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9883 - val_loss: 0.9825\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9879 - val_loss: 0.9831\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9888 - val_loss: 0.9845\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9935 - val_loss: 0.9879\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9949 - val_loss: 0.9878\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9937 - val_loss: 0.9888\n",
      "Top-2 accuracy = 0.813\n",
      "10\n",
      "minmaxf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0662 - val_loss: 1.0660\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0640 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0640 - val_loss: 1.0665\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 1.0661\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0296 - val_loss: 0.9783\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9543 - val_loss: 0.9695\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9491 - val_loss: 0.9589\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9490 - val_loss: 0.9507\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9441 - val_loss: 0.9470\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9476\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9413 - val_loss: 0.9541\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 0.9384\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9381 - val_loss: 0.9404\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9379 - val_loss: 0.9398\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9377 - val_loss: 0.9457\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9370 - val_loss: 0.9485\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9383\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9375 - val_loss: 0.9365\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9351 - val_loss: 0.9380\n",
      "Top-2 accuracy = 0.835\n",
      "11\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0590 - val_loss: 1.0316\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0079 - val_loss: 1.0126\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9825 - val_loss: 0.9723\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9659 - val_loss: 0.9717\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9614 - val_loss: 0.9827\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.9590\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 0.9557\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 0.9519\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9490 - val_loss: 0.9542\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9484 - val_loss: 0.9512\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9505\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9474 - val_loss: 0.9541\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 0.9501\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9552\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9503\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9500\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9492\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9482\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9495\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9504\n",
      "Top-2 accuracy = 0.824\n",
      "12\n",
      "normalizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0652 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0640 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0660\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0660\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Top-2 accuracy = 0.752\n",
      "13\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0571 - val_loss: 1.0009\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9811 - val_loss: 0.9815\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9757 - val_loss: 0.9744\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9577 - val_loss: 0.9516\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9460 - val_loss: 0.9453\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9418 - val_loss: 0.9418\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9354 - val_loss: 0.9402\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9332 - val_loss: 0.9476\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9307 - val_loss: 0.9335\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9303 - val_loss: 0.9398\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9304 - val_loss: 0.9320\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9287 - val_loss: 0.9302\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9272 - val_loss: 0.9301\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9264 - val_loss: 0.9399\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9269 - val_loss: 0.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9248 - val_loss: 0.9310\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9246 - val_loss: 0.9335\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9259 - val_loss: 0.9280\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9238 - val_loss: 0.9279\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9236 - val_loss: 0.9296\n",
      "Top-2 accuracy = 0.832\n",
      "14\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0736 - val_loss: 1.0660\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0658\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "15\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0860 - val_loss: 1.0731\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0451 - val_loss: 1.0106\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9827 - val_loss: 0.9691\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9590 - val_loss: 0.9579\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 0.9527\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 0.9504\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9471 - val_loss: 0.9495\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 0.9486\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9446 - val_loss: 0.9480\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 0.9474\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9472\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9465\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9434 - val_loss: 0.9462\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9431 - val_loss: 0.9458\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9456\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9457\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 0.9454\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9455\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9422 - val_loss: 0.9450\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9452\n",
      "Top-2 accuracy = 0.832\n",
      "16\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0621 - val_loss: 1.0221\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9824 - val_loss: 0.9555\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9327\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9279\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9262 - val_loss: 0.9274\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.9245\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9227 - val_loss: 0.9252\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9231 - val_loss: 0.9231\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9273\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9256\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9217 - val_loss: 0.9244\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9220 - val_loss: 0.9229\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9207 - val_loss: 0.9235\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.9228\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.9240\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 0.9220\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.9226\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 0.9224\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9197 - val_loss: 0.9225\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9199 - val_loss: 0.9221\n",
      "Top-2 accuracy = 0.836\n",
      "17\n",
      "standardizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0004 - val_loss: 0.9565\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9458 - val_loss: 0.9406\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9331 - val_loss: 0.9306\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9294 - val_loss: 0.9309\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.927 - 0s 4ms/step - loss: 0.9276 - val_loss: 0.9293\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9270 - val_loss: 0.9269\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9241 - val_loss: 0.9289\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9249 - val_loss: 0.9277\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9223 - val_loss: 0.9235\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 0.9219\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9213 - val_loss: 0.9229\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9247 - val_loss: 0.9220\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9211 - val_loss: 0.9314\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9231 - val_loss: 0.9234\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9202 - val_loss: 0.9210\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9195 - val_loss: 0.9213\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9192 - val_loss: 0.9260\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9209 - val_loss: 0.9213\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9182 - val_loss: 0.9236\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9189 - val_loss: 0.9208\n",
      "Top-2 accuracy = 0.833\n",
      "18\n",
      "maxabsq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0218 - val_loss: 0.9766\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9534 - val_loss: 0.9419\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9359 - val_loss: 0.9357\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9323 - val_loss: 0.9339\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9312 - val_loss: 0.9362\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9297 - val_loss: 0.9331\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9290 - val_loss: 0.9328\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9289 - val_loss: 0.9353\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9307 - val_loss: 0.9352\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9290 - val_loss: 0.9302\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9269 - val_loss: 0.9282\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9254 - val_loss: 0.9312\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9278 - val_loss: 0.9263\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9245 - val_loss: 0.9264\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9238 - val_loss: 0.9256\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9234 - val_loss: 0.9250\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9250 - val_loss: 0.9249\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9220 - val_loss: 0.9256\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9240 - val_loss: 0.9254\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9223 - val_loss: 0.9289\n",
      "Top-2 accuracy = 0.827\n",
      "19\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0123 - val_loss: 0.9496\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9400 - val_loss: 0.9330\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9300 - val_loss: 0.9294\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9264 - val_loss: 0.9320\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9230 - val_loss: 0.9316\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9217 - val_loss: 0.9246\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9209 - val_loss: 0.9307\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9214 - val_loss: 0.9234\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9188 - val_loss: 0.9297\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9197 - val_loss: 0.9238\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9214 - val_loss: 0.9256\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9186 - val_loss: 0.9295\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9181 - val_loss: 0.9252\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9185 - val_loss: 0.9228\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.9263\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9168 - val_loss: 0.9221\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9171 - val_loss: 0.9241\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9160 - val_loss: 0.9232\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9161 - val_loss: 0.9241\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9152 - val_loss: 0.9241\n",
      "Top-2 accuracy = 0.83\n",
      "20\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0759 - val_loss: 1.0432\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0088 - val_loss: 0.9772\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9610 - val_loss: 0.9482\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9413 - val_loss: 0.9380\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9356 - val_loss: 0.9342\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9324 - val_loss: 0.9321\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9311 - val_loss: 0.9323\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9304 - val_loss: 0.9321\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9301 - val_loss: 0.9312\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9293 - val_loss: 0.9316\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9288 - val_loss: 0.9314\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9278 - val_loss: 0.9299\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9279 - val_loss: 0.9311\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9284 - val_loss: 0.9288\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9277 - val_loss: 0.9297\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9267 - val_loss: 0.9295\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9279 - val_loss: 0.9292\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9263 - val_loss: 0.9293\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9272 - val_loss: 0.9279\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9260 - val_loss: 0.9283\n",
      "Top-2 accuracy = 0.833\n",
      "21\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0408 - val_loss: 0.9891\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9691 - val_loss: 0.9812\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9552 - val_loss: 0.9752\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9524 - val_loss: 0.9530\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9444 - val_loss: 0.9395\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9437 - val_loss: 0.9389\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9398 - val_loss: 0.9390\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9403 - val_loss: 0.9353\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9392 - val_loss: 0.9355\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9357 - val_loss: 0.9566\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9414 - val_loss: 0.9557\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9387 - val_loss: 0.9405\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9369 - val_loss: 0.9369\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9314 - val_loss: 0.9325\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9291 - val_loss: 0.9315\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9288 - val_loss: 0.9478\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9413 - val_loss: 0.9343\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9283 - val_loss: 0.9258\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9271 - val_loss: 0.9341\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9255 - val_loss: 0.9271\n",
      "Top-2 accuracy = 0.83\n",
      "22\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0900 - val_loss: 1.0827\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0770 - val_loss: 1.0737\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0700 - val_loss: 1.0690\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0663 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0647 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0641 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "23\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0677 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0662\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "24\n",
      "robustw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0607 - val_loss: 1.0079\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9739 - val_loss: 0.9591\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9505 - val_loss: 0.9491\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9459 - val_loss: 0.9446\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.9422\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9384 - val_loss: 0.9417\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9427\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9517\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9355 - val_loss: 0.9354\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9312 - val_loss: 0.9332\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9293 - val_loss: 0.9329\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9286 - val_loss: 0.9313\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9278 - val_loss: 0.9299\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9273 - val_loss: 0.9302\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9261 - val_loss: 0.9292\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9256 - val_loss: 0.9287\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9258 - val_loss: 0.9309\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9250 - val_loss: 0.9367\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9262 - val_loss: 0.9315\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9255 - val_loss: 0.9284\n",
      "Top-2 accuracy = 0.83\n",
      "25\n",
      "normalizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0464 - val_loss: 1.0024\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9680 - val_loss: 0.9487\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9343 - val_loss: 0.9297\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9258 - val_loss: 0.9420\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9261 - val_loss: 0.9323\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9267 - val_loss: 0.9303\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9243 - val_loss: 0.9293\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 0.9300\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9237 - val_loss: 0.9315\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9229 - val_loss: 0.9279\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9229 - val_loss: 0.9277\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9227 - val_loss: 0.9268\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.9267\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9265\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9243 - val_loss: 0.9310\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9232 - val_loss: 0.9293\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9230 - val_loss: 0.9258\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9228 - val_loss: 0.9262\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9220 - val_loss: 0.9266\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9225 - val_loss: 0.9274\n",
      "Top-2 accuracy = 0.829\n",
      "26\n",
      "normalizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0833 - val_loss: 1.0718\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0661 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "27\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0737 - val_loss: 1.0665\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0659\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "28\n",
      "minmaxI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0650 - val_loss: 1.0656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Top-2 accuracy = 0.752\n",
      "29\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0899 - val_loss: 1.0812\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0735 - val_loss: 1.0689\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0654 - val_loss: 1.0659\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "0\n",
      "normalizej|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0685 - val_loss: 1.0658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0658\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0662\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0658\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "1\n",
      "standardizeG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0794 - val_loss: 1.0694\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0606 - val_loss: 1.0457\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0084 - val_loss: 0.9810\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9581 - val_loss: 0.9463\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 0.9350\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9304 - val_loss: 0.9322\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9273 - val_loss: 0.9331\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9276 - val_loss: 0.9275\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9244 - val_loss: 0.9263\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9234 - val_loss: 0.9299\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9225 - val_loss: 0.9253\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9230 - val_loss: 0.9266\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9216 - val_loss: 0.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9230 - val_loss: 0.9248\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9207 - val_loss: 0.9245\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9208 - val_loss: 0.9238\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9210 - val_loss: 0.9248\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9212 - val_loss: 0.9242\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9211 - val_loss: 0.9259\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9209 - val_loss: 0.9239\n",
      "Top-2 accuracy = 0.83\n",
      "2\n",
      "normalizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0760 - val_loss: 1.0640\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0170 - val_loss: 0.9599\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9452 - val_loss: 0.9391\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 0.9339\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9322 - val_loss: 0.9322\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9311 - val_loss: 0.9312\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 0.9294\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9290 - val_loss: 0.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9348\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9286 - val_loss: 0.9270\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9261 - val_loss: 0.9304\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9260 - val_loss: 0.9265\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.9260\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9239 - val_loss: 0.9271\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9255\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9231 - val_loss: 0.9246\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9228 - val_loss: 0.9320\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9232 - val_loss: 0.9279\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.9243\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.9241\n",
      "Top-2 accuracy = 0.829\n",
      "3\n",
      "maxabsw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 1.0867 - val_loss: 1.0711\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0646 - val_loss: 1.0660\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "4\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0662 - val_loss: 1.0647\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0226 - val_loss: 0.9799\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9713 - val_loss: 1.0080\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9987 - val_loss: 1.0085\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0195 - val_loss: 1.0316\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0374 - val_loss: 1.0463\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0428 - val_loss: 1.0373\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0227 - val_loss: 1.0103\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0095 - val_loss: 1.0086\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0042 - val_loss: 0.9911\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0646 - val_loss: 1.0659\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0640 - val_loss: 1.0658\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0664\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0640 - val_loss: 1.0660\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0352 - val_loss: 0.9905\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9897 - val_loss: 0.9871\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9902 - val_loss: 0.9928\n",
      "Top-2 accuracy = 0.818\n",
      "5\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0072 - val_loss: 0.9500\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9329\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9275 - val_loss: 0.9288\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9334\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9257 - val_loss: 0.9286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9243\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9209 - val_loss: 0.9242\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9205 - val_loss: 0.9242\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9215 - val_loss: 0.9244\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9220 - val_loss: 0.9247\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9237\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9233\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9219\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9246\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9232\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9239\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9234\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.9229\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9259\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9211\n",
      "Top-2 accuracy = 0.835\n",
      "6\n",
      "normalizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0664 - val_loss: 1.0343\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9836 - val_loss: 0.9546\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9436 - val_loss: 0.9410\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9366 - val_loss: 0.9367\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9343\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9316 - val_loss: 0.9324\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 0.9297\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9286\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9280\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 0.9278\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9247 - val_loss: 0.9279\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9245 - val_loss: 0.9263\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9234 - val_loss: 0.9252\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9219 - val_loss: 0.9260\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9234\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9251\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9232\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9202 - val_loss: 0.9248\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9203 - val_loss: 0.9223\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.9224\n",
      "Top-2 accuracy = 0.838\n",
      "7\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2678 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0885 - val_loss: 1.0779\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0710 - val_loss: 1.0664\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0611 - val_loss: 1.0566\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0449 - val_loss: 1.0318\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0127 - val_loss: 0.9970\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9813 - val_loss: 0.9784\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9678 - val_loss: 0.9689\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9589 - val_loss: 0.9582\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9523 - val_loss: 0.9523\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9469 - val_loss: 0.9486\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9441 - val_loss: 0.9457\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9416 - val_loss: 0.9442\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9410 - val_loss: 0.9502\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9403 - val_loss: 0.9411\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 0.9395\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9390\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9362 - val_loss: 0.9368\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9347 - val_loss: 0.9372\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9354 - val_loss: 0.9367\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9335 - val_loss: 0.9380\n",
      "Top-2 accuracy = 0.828\n",
      "8\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0636 - val_loss: 1.0578\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0337 - val_loss: 1.0209\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0093 - val_loss: 1.0132\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0027 - val_loss: 1.0089\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 0.9925\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9835 - val_loss: 0.9830\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9787 - val_loss: 0.9800\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9753 - val_loss: 0.9772\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9720 - val_loss: 0.9729\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9703 - val_loss: 0.9711\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9670 - val_loss: 0.9660\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9611 - val_loss: 0.9827\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9641 - val_loss: 0.9678\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9623 - val_loss: 0.9648\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9611 - val_loss: 0.9661\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9576 - val_loss: 0.9587\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9557\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9518 - val_loss: 0.9624\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9523 - val_loss: 0.9549\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9505 - val_loss: 0.9516\n",
      "Top-2 accuracy = 0.833\n",
      "9\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0739 - val_loss: 1.0500\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0213 - val_loss: 0.9875\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9682 - val_loss: 0.9619\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 0.9543\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9490 - val_loss: 0.9446\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9416\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9406\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9400\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.9407\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9365 - val_loss: 0.9374\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9364\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9349 - val_loss: 0.9356\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9357\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9333 - val_loss: 0.9335\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9329\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9322 - val_loss: 0.9325\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9314 - val_loss: 0.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9318\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9317\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9301 - val_loss: 0.9306\n",
      "Top-2 accuracy = 0.834\n",
      "10\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0339 - val_loss: 0.9749\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9515 - val_loss: 0.9454\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9365 - val_loss: 0.9331\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9298 - val_loss: 0.9311\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9295 - val_loss: 0.9298\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9277 - val_loss: 0.9309\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9271 - val_loss: 0.9295\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9262 - val_loss: 0.9279\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9262 - val_loss: 0.9318\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9261 - val_loss: 0.9278\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9260 - val_loss: 0.9307\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9250 - val_loss: 0.9267\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 0.9263\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9231 - val_loss: 0.9276\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9236 - val_loss: 0.9257\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9223 - val_loss: 0.9305\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9267 - val_loss: 0.9252\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9218 - val_loss: 0.9231\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9207 - val_loss: 0.9246\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9205 - val_loss: 0.9224\n",
      "Top-2 accuracy = 0.836\n",
      "11\n",
      "minmaxf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0899 - val_loss: 1.0827\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0769 - val_loss: 1.0736\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0698 - val_loss: 1.0689\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0662 - val_loss: 1.0668\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0646 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "12\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0686 - val_loss: 1.0655\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0611 - val_loss: 1.0463\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9906 - val_loss: 0.9560\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9419 - val_loss: 0.9389\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9419\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9451\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9339 - val_loss: 0.9413\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9332 - val_loss: 0.9341\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9368\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9322 - val_loss: 0.9326\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9309 - val_loss: 0.9337\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9312 - val_loss: 0.9328\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9321 - val_loss: 0.9332\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9308 - val_loss: 0.9351\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9304 - val_loss: 0.9381\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9316 - val_loss: 0.9321\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9299 - val_loss: 0.9317\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9293 - val_loss: 0.9357\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9298 - val_loss: 0.9308\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9283 - val_loss: 0.9381\n",
      "Top-2 accuracy = 0.832\n",
      "13\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0607 - val_loss: 1.0122\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9842 - val_loss: 0.9627\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 0.9432\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 0.9355\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9308 - val_loss: 0.9324\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9283 - val_loss: 0.9312\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9296\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9253 - val_loss: 0.9280\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.9271\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9227 - val_loss: 0.9269\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9229 - val_loss: 0.9260\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9251\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9245\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.9243\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.9232\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 0.9248\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.9233\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9189 - val_loss: 0.9224\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9189 - val_loss: 0.9242\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.9232\n",
      "Top-2 accuracy = 0.83\n",
      "14\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0744 - val_loss: 1.0658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0636 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0636 - val_loss: 1.0665\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0636 - val_loss: 1.0662\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "15\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0722 - val_loss: 1.0634\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0214 - val_loss: 0.9948\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9971 - val_loss: 0.9938\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9934 - val_loss: 0.9916\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9937 - val_loss: 0.9886\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0490 - val_loss: 1.0205\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0194 - val_loss: 0.9968\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0209 - val_loss: 1.0206\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9952 - val_loss: 0.9868\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9887 - val_loss: 1.0193\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0226 - val_loss: 1.0524\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0517 - val_loss: 1.0552\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0542 - val_loss: 1.0588\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0548 - val_loss: 1.0579\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0545 - val_loss: 1.0581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0547 - val_loss: 1.0581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0549 - val_loss: 1.0580\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0546 - val_loss: 1.0581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0547 - val_loss: 1.0581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0548 - val_loss: 1.0579\n",
      "Top-2 accuracy = 0.751\n",
      "16\n",
      "robustR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0056\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9598 - val_loss: 0.9403\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9328 - val_loss: 0.9342\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.9366\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9285 - val_loss: 0.9317\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9269 - val_loss: 0.9290\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 0.9289\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 0.9291\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9249 - val_loss: 0.9280\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.9280\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9288\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9249 - val_loss: 0.9278\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9243 - val_loss: 0.9323\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9271\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9234 - val_loss: 0.9288\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9232 - val_loss: 0.9287\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9229 - val_loss: 0.9274\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.9276\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9236 - val_loss: 0.9263\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.9272\n",
      "Top-2 accuracy = 0.834\n",
      "17\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0606 - val_loss: 1.0210\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9918 - val_loss: 0.9756\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9608 - val_loss: 0.9540\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9467 - val_loss: 0.9450\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9438\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9405 - val_loss: 0.9449\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9409\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 0.9471\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 0.9348\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9329 - val_loss: 0.9403\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9359 - val_loss: 0.9326\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9310 - val_loss: 0.9356\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9313 - val_loss: 0.9323\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9309 - val_loss: 0.9310\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9301 - val_loss: 0.9314\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9304 - val_loss: 0.9311\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 0.9317\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9311 - val_loss: 0.9304\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9287 - val_loss: 0.9309\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9287 - val_loss: 0.9300\n",
      "Top-2 accuracy = 0.836\n",
      "18\n",
      "robustp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0543 - val_loss: 0.9756\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9475 - val_loss: 0.9360\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9292 - val_loss: 0.9279\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9262 - val_loss: 0.9261\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9253 - val_loss: 0.9280\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9254 - val_loss: 0.9262\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9237 - val_loss: 0.9244\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9231 - val_loss: 0.9258\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 0.9263\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9226 - val_loss: 0.9248\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9207 - val_loss: 0.9257\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9203 - val_loss: 0.9241\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9203 - val_loss: 0.9234\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9196 - val_loss: 0.9406\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9238 - val_loss: 0.9240\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9200 - val_loss: 0.9291\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9207 - val_loss: 0.9322\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9208 - val_loss: 0.9252\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9193 - val_loss: 0.9249\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9195 - val_loss: 0.9241\n",
      "Top-2 accuracy = 0.831\n",
      "19\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0628 - val_loss: 1.0371\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9861 - val_loss: 0.9634\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9531 - val_loss: 0.9574\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9456 - val_loss: 0.9471\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9417 - val_loss: 0.9385\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9353 - val_loss: 0.9341\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9342 - val_loss: 0.9335\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9312 - val_loss: 0.9311\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9305 - val_loss: 0.9323\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9288 - val_loss: 0.9295\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9275 - val_loss: 0.9286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9266 - val_loss: 0.9289\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9260 - val_loss: 0.9358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9266 - val_loss: 0.9271\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9241 - val_loss: 0.9267\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 0.9257\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9229 - val_loss: 0.9263\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9232 - val_loss: 0.9277\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9239 - val_loss: 0.9246\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9217 - val_loss: 0.9277\n",
      "Top-2 accuracy = 0.831\n",
      "20\n",
      "minmaxr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0866 - val_loss: 1.0781\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0723 - val_loss: 1.0701\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0665 - val_loss: 1.0669\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0644 - val_loss: 1.0659\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0659\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "21\n",
      "standardizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0726 - val_loss: 1.0504\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0291 - val_loss: 1.0082\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9872 - val_loss: 0.9728\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9608 - val_loss: 0.9583\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9529\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9443\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9406 - val_loss: 0.9418\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9382\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 0.9390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9353 - val_loss: 0.9370\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9332 - val_loss: 0.9354\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9385\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9330 - val_loss: 0.9345\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9317 - val_loss: 0.9342\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9311 - val_loss: 0.9334\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9305 - val_loss: 0.9338\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9308 - val_loss: 0.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 0.9322\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 0.9328\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 0.9320\n",
      "Top-2 accuracy = 0.833\n",
      "22\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0696 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0636 - val_loss: 1.0658\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0615 - val_loss: 1.0347\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0542 - val_loss: 1.0658\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "23\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0801 - val_loss: 1.0720\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0668 - val_loss: 1.0665\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "24\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0029 - val_loss: 0.9667\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9413 - val_loss: 0.9376\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9345 - val_loss: 0.9360\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9323 - val_loss: 0.9384\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9271 - val_loss: 0.9321\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9287 - val_loss: 0.9320\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9290 - val_loss: 0.9317\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9242 - val_loss: 0.9362\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9252 - val_loss: 0.9397\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.9273 - val_loss: 0.9305\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.9235 - val_loss: 0.9310\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9227 - val_loss: 0.9339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9230 - val_loss: 0.9265\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9224 - val_loss: 0.9309\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9203 - val_loss: 0.9269\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9200 - val_loss: 0.9255\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9211 - val_loss: 0.9266\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9207 - val_loss: 0.9280\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9192 - val_loss: 0.9262\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9190 - val_loss: 0.9245\n",
      "Top-2 accuracy = 0.831\n",
      "25\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0606 - val_loss: 1.0138\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9717 - val_loss: 0.9531\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9392 - val_loss: 0.9377\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9289 - val_loss: 0.9311\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 0.9291\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9230 - val_loss: 0.9282\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9223 - val_loss: 0.9265\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9207 - val_loss: 0.9278\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9252\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 0.9268\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9252\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9235\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.9244\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9269\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.9271\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9237\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9237\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9172 - val_loss: 0.9245\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 0.9232\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9226\n",
      "Top-2 accuracy = 0.83\n",
      "26\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0299 - val_loss: 0.9683\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9614 - val_loss: 0.9477\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9456 - val_loss: 0.9453\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9382 - val_loss: 0.9337\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9345 - val_loss: 0.9322\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9327 - val_loss: 0.9348\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9315 - val_loss: 0.9312\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9339 - val_loss: 0.9435\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9298 - val_loss: 0.9291\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9278 - val_loss: 0.9413\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9337 - val_loss: 0.9294\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9270 - val_loss: 0.9332\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9297 - val_loss: 0.9358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9292 - val_loss: 0.9293\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9283 - val_loss: 0.9282\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9293 - val_loss: 0.9288\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9295 - val_loss: 0.9297\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9264 - val_loss: 0.9514\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9409 - val_loss: 0.9409\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9313 - val_loss: 0.9368\n",
      "Top-2 accuracy = 0.831\n",
      "27\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0760 - val_loss: 1.0667\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0611 - val_loss: 1.0477\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0152 - val_loss: 1.0054\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0108 - val_loss: 1.0116\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0159 - val_loss: 1.0580\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0535 - val_loss: 1.0573\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0541 - val_loss: 1.0573\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0541 - val_loss: 1.0573\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0540 - val_loss: 1.0565\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0535 - val_loss: 1.0562\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0534 - val_loss: 1.0563\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0514 - val_loss: 1.0517\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0505 - val_loss: 1.0517\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0505 - val_loss: 1.0518\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0505 - val_loss: 1.0517\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0504 - val_loss: 1.0524\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0507 - val_loss: 1.0524\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0505 - val_loss: 1.0517\n",
      "Top-2 accuracy = 0.761\n",
      "28\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0317 - val_loss: 0.9793\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9552 - val_loss: 0.9455\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9373\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9316 - val_loss: 0.9313\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9276 - val_loss: 0.9288\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9257 - val_loss: 0.9268\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9247 - val_loss: 0.9270\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9234 - val_loss: 0.9265\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9246 - val_loss: 0.9254\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9209 - val_loss: 0.9257\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9208 - val_loss: 0.9245\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9224 - val_loss: 0.9253\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9197 - val_loss: 0.9238\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9205 - val_loss: 0.9242\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9203 - val_loss: 0.9260\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9301\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9200 - val_loss: 0.9244\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9190 - val_loss: 0.9245\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9191 - val_loss: 0.9245\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9198 - val_loss: 0.9252\n",
      "Top-2 accuracy = 0.833\n",
      "29\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0223 - val_loss: 0.9639\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9469 - val_loss: 0.9414\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9393 - val_loss: 0.9390\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9371 - val_loss: 0.9378\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9356 - val_loss: 0.9346\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9319 - val_loss: 0.9330\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9312 - val_loss: 0.9330\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9313 - val_loss: 0.9363\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9307 - val_loss: 0.9320\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9293 - val_loss: 0.9309\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9294 - val_loss: 0.9457\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9334 - val_loss: 0.9343\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9293 - val_loss: 0.9309\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9291 - val_loss: 0.9329\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9280 - val_loss: 0.9352\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9291 - val_loss: 0.9317\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9286 - val_loss: 0.9349\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9281 - val_loss: 0.9294\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9280 - val_loss: 0.9324\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9281 - val_loss: 0.9304\n",
      "Top-2 accuracy = 0.838\n",
      "0\n",
      "robustV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0748 - val_loss: 1.0589\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0394 - val_loss: 1.0079\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9926 - val_loss: 0.9844\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9856 - val_loss: 0.9836\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9858 - val_loss: 0.9810\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9832 - val_loss: 0.9818\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9836 - val_loss: 0.9810\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9832 - val_loss: 0.9803\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9836 - val_loss: 0.9839\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9856 - val_loss: 0.9826\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9854 - val_loss: 0.9823\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9866 - val_loss: 0.9845\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9899 - val_loss: 0.9900\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9848 - val_loss: 0.9734\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9693 - val_loss: 0.9705\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9680 - val_loss: 0.9700\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9692 - val_loss: 0.9706\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9708 - val_loss: 0.9705\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9712 - val_loss: 0.9690\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9680 - val_loss: 0.9699\n",
      "Top-2 accuracy = 0.824\n",
      "1\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0276 - val_loss: 0.9780\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9553 - val_loss: 0.9483\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9419 - val_loss: 0.9413\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9371 - val_loss: 0.9383\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9330 - val_loss: 0.9423\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9360 - val_loss: 0.9344\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9308 - val_loss: 0.9498\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9307 - val_loss: 0.9330\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9299 - val_loss: 0.9314\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9277 - val_loss: 0.9316\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9281 - val_loss: 0.9292\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9261 - val_loss: 0.9361\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9278 - val_loss: 0.9288\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9264 - val_loss: 0.9310\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9274 - val_loss: 0.9293\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9249 - val_loss: 0.9307\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9254 - val_loss: 0.9317\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9245 - val_loss: 0.9273\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9244 - val_loss: 0.9281\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9249 - val_loss: 0.9318\n",
      "Top-2 accuracy = 0.825\n",
      "2\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0636 - val_loss: 1.0227\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9954 - val_loss: 0.9807\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9611 - val_loss: 0.9539\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9470 - val_loss: 0.9523\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9402 - val_loss: 0.9401\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9354 - val_loss: 0.9459\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9364 - val_loss: 0.9445\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9341 - val_loss: 0.9403\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9334 - val_loss: 0.9472\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9326 - val_loss: 0.9361\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9315 - val_loss: 0.9584\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9340 - val_loss: 0.9389\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9306 - val_loss: 0.9377\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9304 - val_loss: 0.9459\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9445\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9301 - val_loss: 0.9343\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9300 - val_loss: 0.9345\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9293 - val_loss: 0.9354\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9287 - val_loss: 0.9335\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9310 - val_loss: 0.9327\n",
      "Top-2 accuracy = 0.827\n",
      "3\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0657 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0658\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0661\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "4\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0493 - val_loss: 1.0028\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9753 - val_loss: 0.9608\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9528 - val_loss: 0.9511\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9440 - val_loss: 0.9451\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9375 - val_loss: 0.9393\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9333 - val_loss: 0.9389\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9333 - val_loss: 0.9368\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9327 - val_loss: 0.9331\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9297 - val_loss: 0.9327\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9290 - val_loss: 0.9347\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9288 - val_loss: 0.9308\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9285 - val_loss: 0.9328\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9281 - val_loss: 0.9305\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9270 - val_loss: 0.9293\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9256 - val_loss: 0.9360\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9266 - val_loss: 0.9304\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9264 - val_loss: 0.9454\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9282 - val_loss: 0.9312\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9277 - val_loss: 0.9378\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9253 - val_loss: 0.9302\n",
      "Top-2 accuracy = 0.833\n",
      "5\n",
      "standardizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.9928 - val_loss: 0.9504\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9375 - val_loss: 0.9476\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9278 - val_loss: 0.9279\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9225 - val_loss: 0.9254\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9214 - val_loss: 0.9245\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9196 - val_loss: 0.9253\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9201 - val_loss: 0.9247\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9189 - val_loss: 0.9231\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9191 - val_loss: 0.9424\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9208 - val_loss: 0.9243\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9182 - val_loss: 0.9265\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9175 - val_loss: 0.9229\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9170 - val_loss: 0.9346\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9174 - val_loss: 0.9331\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9172 - val_loss: 0.9227\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9164 - val_loss: 0.9331\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9187 - val_loss: 0.9294\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9162 - val_loss: 0.9218\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9165 - val_loss: 0.9214\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9155 - val_loss: 0.9246\n",
      "Top-2 accuracy = 0.835\n",
      "6\n",
      "normalizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0793 - val_loss: 1.0673\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0641 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "7\n",
      "maxabsj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0809 - val_loss: 1.0661\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 1.0655\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0438 - val_loss: 1.0118\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9760 - val_loss: 0.9642\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9558 - val_loss: 0.9565\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9517 - val_loss: 0.9533\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9523\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 0.9507\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9461 - val_loss: 0.9514\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9457 - val_loss: 0.9501\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9456 - val_loss: 0.9503\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9449 - val_loss: 0.9484\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9440 - val_loss: 0.9482\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9436 - val_loss: 0.9475\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9484\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9438 - val_loss: 0.9468\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9424 - val_loss: 0.9479\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 0.9483\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9424 - val_loss: 0.9479\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9477\n",
      "Top-2 accuracy = 0.827\n",
      "8\n",
      "minmaxF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0720 - val_loss: 1.0658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "9\n",
      "normalizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0684 - val_loss: 1.0663\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0659\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0640 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "10\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0691 - val_loss: 1.0656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0623 - val_loss: 1.0572\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0136 - val_loss: 1.0083\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0106 - val_loss: 0.9865\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9813 - val_loss: 0.9749\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9681 - val_loss: 0.9889\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9655 - val_loss: 0.9633\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9627 - val_loss: 0.9741\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9611 - val_loss: 0.9612\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9620 - val_loss: 0.9662\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9585 - val_loss: 0.9676\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9586 - val_loss: 0.9596\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9590 - val_loss: 0.9706\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9591 - val_loss: 0.9633\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9573 - val_loss: 0.9624\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9587 - val_loss: 0.9613\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9571 - val_loss: 0.9582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9566 - val_loss: 0.9635\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9586 - val_loss: 0.9624\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9564 - val_loss: 0.9728\n",
      "Top-2 accuracy = 0.817\n",
      "11\n",
      "maxabsD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0761 - val_loss: 1.0656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "12\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0740 - val_loss: 1.0662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0632 - val_loss: 1.0593\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0048 - val_loss: 0.9748\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9734 - val_loss: 0.9742\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9714 - val_loss: 0.9681\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9630 - val_loss: 0.9566\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9495 - val_loss: 0.9509\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9475 - val_loss: 0.9564\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9460 - val_loss: 0.9471\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9432 - val_loss: 0.9461\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9427 - val_loss: 0.9496\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9438 - val_loss: 0.9448\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9423 - val_loss: 0.9431\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9406 - val_loss: 0.9428\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9422 - val_loss: 0.9460\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9407 - val_loss: 0.9438\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9390 - val_loss: 0.9406\n",
      "Top-2 accuracy = 0.828\n",
      "13\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0475 - val_loss: 0.9980\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9649 - val_loss: 0.9518\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9357 - val_loss: 0.9379\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9284 - val_loss: 0.9311\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9261 - val_loss: 0.9292\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 0.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9241 - val_loss: 0.9340\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9240 - val_loss: 0.9377\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9254 - val_loss: 0.9261\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9227 - val_loss: 0.9261\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9231 - val_loss: 0.9254\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9218 - val_loss: 0.9251\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9222 - val_loss: 0.9289\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9217 - val_loss: 0.9248\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9219 - val_loss: 0.9255\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9207 - val_loss: 0.9250\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9208 - val_loss: 0.9245\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9205 - val_loss: 0.9266\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9222 - val_loss: 0.9405\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9240 - val_loss: 0.9240\n",
      "Top-2 accuracy = 0.826\n",
      "14\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0736 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0632 - val_loss: 1.0584\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0015 - val_loss: 0.9715\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9584 - val_loss: 0.9561\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9505 - val_loss: 0.9535\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9475 - val_loss: 0.9503\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9444 - val_loss: 0.9475\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9411 - val_loss: 0.9436\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9390 - val_loss: 0.9426\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9372 - val_loss: 0.9402\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 0.9403\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9378\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9337 - val_loss: 0.9374\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9323 - val_loss: 0.9350\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9308 - val_loss: 0.9327\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9295 - val_loss: 0.9329\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.9396\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9275 - val_loss: 0.9347\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9255 - val_loss: 0.9286\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.9278\n",
      "Top-2 accuracy = 0.836\n",
      "15\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0740 - val_loss: 1.0662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "16\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0539 - val_loss: 1.0237\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9926 - val_loss: 0.9707\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9532 - val_loss: 0.9467\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9396 - val_loss: 0.9390\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9341 - val_loss: 0.9371\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9314 - val_loss: 0.9337\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9308 - val_loss: 0.9321\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9275 - val_loss: 0.9303\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9262 - val_loss: 0.9292\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9259 - val_loss: 0.9298\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9247 - val_loss: 0.9309\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9237 - val_loss: 0.9304\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 0.9272\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 0.9287\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9224 - val_loss: 0.9281\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9230 - val_loss: 0.9275\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 0.9266\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9220 - val_loss: 0.9297\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9224 - val_loss: 0.9263\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9213 - val_loss: 0.9292\n",
      "Top-2 accuracy = 0.823\n",
      "17\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0410 - val_loss: 0.9728\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9578 - val_loss: 0.9471\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9391 - val_loss: 0.9369\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9361 - val_loss: 0.9344\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9304 - val_loss: 0.9298\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9264 - val_loss: 0.9337\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9269 - val_loss: 0.9329\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9238 - val_loss: 0.9311\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9256 - val_loss: 0.9275\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9230 - val_loss: 0.9260\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9230 - val_loss: 0.9375\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9271 - val_loss: 0.9250\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9217 - val_loss: 0.9241\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9216 - val_loss: 0.9267\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9202 - val_loss: 0.9248\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9198 - val_loss: 0.9312\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9245 - val_loss: 0.9303\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9203 - val_loss: 0.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9193 - val_loss: 0.9240\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9198 - val_loss: 0.9238\n",
      "Top-2 accuracy = 0.837\n",
      "18\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0797 - val_loss: 1.0713\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0664 - val_loss: 1.0665\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "19\n",
      "minmaxp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0674 - val_loss: 1.0659\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0639 - val_loss: 1.0660\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0640 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0571 - val_loss: 1.0659\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0660\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0641 - val_loss: 1.0658\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0641 - val_loss: 1.0658\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0660\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0659\n",
      "Top-2 accuracy = 0.752\n",
      "20\n",
      "normalizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0880 - val_loss: 1.0773\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0653 - val_loss: 1.0528\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0363 - val_loss: 1.0203\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 0.9911\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9788 - val_loss: 0.9748\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9673 - val_loss: 0.9690\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9612 - val_loss: 0.9643\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9581 - val_loss: 0.9643\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9561 - val_loss: 0.9589\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 0.9584\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9534 - val_loss: 0.9574\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9527 - val_loss: 0.9574\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9527 - val_loss: 0.9559\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9520 - val_loss: 0.9556\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9515 - val_loss: 0.9554\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9511 - val_loss: 0.9562\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9549\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.9556\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.9545\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9543\n",
      "Top-2 accuracy = 0.826\n",
      "21\n",
      "maxabsw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0761 - val_loss: 1.0658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0636 - val_loss: 1.0659\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0662\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "22\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0706 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0658\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0641 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0641 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "23\n",
      "robustF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0623 - val_loss: 1.0232\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0071 - val_loss: 1.0026\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9911 - val_loss: 0.9918\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9842 - val_loss: 0.9922\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9895 - val_loss: 0.9992\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9902 - val_loss: 0.9949\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9956 - val_loss: 0.9939\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9881 - val_loss: 0.9897\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9925 - val_loss: 0.9964\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0004 - val_loss: 1.0078\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0023 - val_loss: 1.0059\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0145 - val_loss: 1.0273\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0277 - val_loss: 1.0353\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0310 - val_loss: 1.0364\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0147 - val_loss: 1.0102\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0342 - val_loss: 1.0531\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0528 - val_loss: 1.0525\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0456 - val_loss: 1.0430\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0438 - val_loss: 1.0482\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0358 - val_loss: 1.0353\n",
      "Top-2 accuracy = 0.768\n",
      "24\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0287 - val_loss: 0.9787\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9742 - val_loss: 0.9762\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9714 - val_loss: 0.9824\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9748 - val_loss: 0.9739\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9694 - val_loss: 0.9781\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9785 - val_loss: 0.9863\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9743 - val_loss: 0.9748\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9694 - val_loss: 0.9780\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9762 - val_loss: 0.9774\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9758 - val_loss: 0.9928\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9837 - val_loss: 0.9969\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9940 - val_loss: 1.0031\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0031 - val_loss: 1.0065\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0008 - val_loss: 0.9996\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9962 - val_loss: 0.9841\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9679 - val_loss: 0.9687\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9723 - val_loss: 0.9904\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9871 - val_loss: 0.9892\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9778 - val_loss: 0.9709\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9684 - val_loss: 0.9733\n",
      "Top-2 accuracy = 0.825\n",
      "25\n",
      "maxabsH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0043 - val_loss: 0.9598\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9441 - val_loss: 0.9379\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9282 - val_loss: 0.9461\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9262 - val_loss: 0.9288\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9216 - val_loss: 0.9250\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9200 - val_loss: 0.9320\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9192 - val_loss: 0.9626\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9242 - val_loss: 0.9232\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9191 - val_loss: 0.9249\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9206 - val_loss: 0.9225\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9182 - val_loss: 0.9230\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9175 - val_loss: 0.9225\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9179 - val_loss: 0.9213\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9172 - val_loss: 0.9290\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9168 - val_loss: 0.9257\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9170 - val_loss: 0.9235\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9162 - val_loss: 0.9225\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9171 - val_loss: 0.9217\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9161 - val_loss: 0.9243\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9169 - val_loss: 0.9360\n",
      "Top-2 accuracy = 0.822\n",
      "26\n",
      "robusty|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 1.0713 - val_loss: 1.0658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0638 - val_loss: 1.0662\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0637 - val_loss: 1.0661\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "27\n",
      "normalizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 1.0677 - val_loss: 1.0658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0640 - val_loss: 1.0658\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0660\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "28\n",
      "minmaxI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0720 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0664\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0640 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0636 - val_loss: 1.0658\n",
      "Top-2 accuracy = 0.752\n",
      "29\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0898 - val_loss: 1.0826\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0769 - val_loss: 1.0736\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0698 - val_loss: 1.0690\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0663 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0646 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "0\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0764 - val_loss: 1.0659\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0661\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0633 - val_loss: 1.0618\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0478 - val_loss: 0.9894\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0174 - val_loss: 1.0640\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0658\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0641 - val_loss: 1.0661\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0671\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0644 - val_loss: 1.0658\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0643 - val_loss: 1.0657\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0660\n",
      "Top-2 accuracy = 0.752\n",
      "1\n",
      "maxabsf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0613 - val_loss: 1.0168\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9650 - val_loss: 0.9517\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9468 - val_loss: 0.9461\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9437\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9414 - val_loss: 0.9437\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9384 - val_loss: 0.9390\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9351 - val_loss: 0.9346\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9339\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9297 - val_loss: 0.9390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9318\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 0.9323\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9292 - val_loss: 0.9316\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 0.9326\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9272 - val_loss: 0.9301\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9257 - val_loss: 0.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9252 - val_loss: 0.9310\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9249 - val_loss: 0.9284\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9258 - val_loss: 0.9281\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 0.9379\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9280 - val_loss: 0.9279\n",
      "Top-2 accuracy = 0.83\n",
      "2\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0793 - val_loss: 1.0670\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0640 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Top-2 accuracy = 0.752\n",
      "3\n",
      "robustf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.0684 - val_loss: 1.0662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0640 - val_loss: 1.0663\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0663\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0640 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Top-2 accuracy = 0.752\n",
      "4\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0335 - val_loss: 0.9817\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9696 - val_loss: 0.9695\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9593 - val_loss: 0.9668\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9583 - val_loss: 1.0012\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9489 - val_loss: 0.9403\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9373 - val_loss: 0.9461\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9317 - val_loss: 0.9448\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9292 - val_loss: 0.9316\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9298 - val_loss: 0.9312\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9259 - val_loss: 0.9301\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9254 - val_loss: 0.9282\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9240 - val_loss: 0.9305\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9227 - val_loss: 0.9286\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9238 - val_loss: 0.9266\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9242 - val_loss: 0.9249\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9220 - val_loss: 0.9246\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9243 - val_loss: 0.9247\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9234 - val_loss: 0.9236\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9211 - val_loss: 0.9232\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9230 - val_loss: 0.9251\n",
      "Top-2 accuracy = 0.83\n",
      "5\n",
      "robustX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0282 - val_loss: 0.9613\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9461 - val_loss: 0.9528\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9427 - val_loss: 0.9446\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9374 - val_loss: 0.9364\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9324 - val_loss: 0.9311\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9301 - val_loss: 0.9523\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9329 - val_loss: 0.9261\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9248 - val_loss: 0.9270\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9226 - val_loss: 0.9257\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9230 - val_loss: 0.9368\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9217 - val_loss: 0.9246\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9208 - val_loss: 0.9253\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9201 - val_loss: 0.9269\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9190 - val_loss: 0.9217\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9192 - val_loss: 0.9210\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9184 - val_loss: 0.9233\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9173 - val_loss: 0.9246\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9191 - val_loss: 0.9209\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9174 - val_loss: 0.9587\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9211 - val_loss: 0.9267\n",
      "Top-2 accuracy = 0.828\n",
      "6\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0698 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0624 - val_loss: 1.0575\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0044 - val_loss: 0.9682\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9551 - val_loss: 0.9470\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9438 - val_loss: 0.9542\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9433 - val_loss: 0.9450\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9413 - val_loss: 0.9430\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9403 - val_loss: 0.9417\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9391 - val_loss: 0.9411\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9373 - val_loss: 0.9390\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9374 - val_loss: 0.9372\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9430\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9370 - val_loss: 0.9367\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9354 - val_loss: 0.9408\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9352\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9354 - val_loss: 0.9383\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9344 - val_loss: 0.9337\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9365 - val_loss: 0.9355\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9349 - val_loss: 0.9371\n",
      "Top-2 accuracy = 0.829\n",
      "7\n",
      "standardizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0708 - val_loss: 1.0656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0662\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0642 - val_loss: 1.0658\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "8\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0710 - val_loss: 1.0449\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0085 - val_loss: 0.9833\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9675 - val_loss: 0.9560\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9494 - val_loss: 0.9540\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9441 - val_loss: 0.9467\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9426 - val_loss: 0.9411\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9370 - val_loss: 0.9371\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9363 - val_loss: 0.9362\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9347 - val_loss: 0.9378\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9350 - val_loss: 0.9359\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9338 - val_loss: 0.9368\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9333 - val_loss: 0.9351\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9336 - val_loss: 0.9367\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9342 - val_loss: 0.9351\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9328 - val_loss: 0.9367\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9324 - val_loss: 0.9356\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9327 - val_loss: 0.9327\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9301 - val_loss: 0.9366\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9304 - val_loss: 0.9325\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9298 - val_loss: 0.9312\n",
      "Top-2 accuracy = 0.836\n",
      "9\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0151 - val_loss: 0.9464\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9268 - val_loss: 0.9281\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9236 - val_loss: 0.9240\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9204 - val_loss: 0.9265\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9187 - val_loss: 0.9215\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9188 - val_loss: 0.9218\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9178 - val_loss: 0.9216\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9193 - val_loss: 0.9230\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9169 - val_loss: 0.9217\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9170 - val_loss: 0.9219\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9154 - val_loss: 0.9208\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9148 - val_loss: 0.9283\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9162 - val_loss: 0.9208\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9159 - val_loss: 0.9209\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9163 - val_loss: 0.9209\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9150 - val_loss: 0.9206\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9155 - val_loss: 0.9395\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9176 - val_loss: 0.9330\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9164 - val_loss: 0.9218\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9140 - val_loss: 0.9214\n",
      "Top-2 accuracy = 0.833\n",
      "10\n",
      "minmaxt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.0717 - val_loss: 1.0659\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0661\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0639 - val_loss: 1.0658\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "11\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0761 - val_loss: 1.0659\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "12\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0722 - val_loss: 1.0659\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0664\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0659\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0658\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0661\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0637 - val_loss: 1.0664\n",
      "Top-2 accuracy = 0.752\n",
      "13\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0888 - val_loss: 1.0694\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0456 - val_loss: 1.0149\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9852 - val_loss: 0.9761\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9652 - val_loss: 0.9655\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9611 - val_loss: 0.9614\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9552 - val_loss: 0.9601\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 0.9539\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9530\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9502\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9467 - val_loss: 0.9487\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9452 - val_loss: 0.9476\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.9459\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9465\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9492\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9445\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9434\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9426\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9402 - val_loss: 0.9418\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9412\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9393 - val_loss: 0.9407\n",
      "Top-2 accuracy = 0.833\n",
      "14\n",
      "minmaxg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0729 - val_loss: 1.0656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0660\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0641 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "15\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0898 - val_loss: 1.0826\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0772 - val_loss: 1.0738\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0700 - val_loss: 1.0691\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0664 - val_loss: 1.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0647 - val_loss: 1.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 1.0657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n",
      "16\n",
      "standardizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0843 - val_loss: 1.0754\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0691 - val_loss: 1.0665\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0640 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "17\n",
      "maxabsh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 18ms/step - loss: 1.0760 - val_loss: 1.0662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.0638 - val_loss: 1.0659\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0639 - val_loss: 1.0657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "18\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0777 - val_loss: 1.0659\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0626 - val_loss: 1.0595\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0221 - val_loss: 0.9854\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9791 - val_loss: 0.9788\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9730 - val_loss: 0.9726\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9694 - val_loss: 0.9699\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9687 - val_loss: 0.9675\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9646 - val_loss: 0.9671\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9639 - val_loss: 0.9668\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9636 - val_loss: 0.9669\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9636 - val_loss: 0.9666\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9637 - val_loss: 0.9666\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9636 - val_loss: 0.9666\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9636 - val_loss: 0.9667\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9636 - val_loss: 0.9669\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9637 - val_loss: 0.9670\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9636 - val_loss: 0.9673\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9637 - val_loss: 0.9669\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9637 - val_loss: 0.9669\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9637 - val_loss: 0.9668\n",
      "Top-2 accuracy = 0.826\n",
      "19\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0251 - val_loss: 0.9773\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9618 - val_loss: 0.9559\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9537 - val_loss: 0.9547\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9556\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9521\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9511 - val_loss: 0.9513\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9516\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9521\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9474 - val_loss: 0.9504\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9471 - val_loss: 0.9518\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9510\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9511\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9562\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9505\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9463 - val_loss: 0.9515\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9467 - val_loss: 0.9517\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9508\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9486\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9468 - val_loss: 0.9483\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 0.9471\n",
      "Top-2 accuracy = 0.835\n",
      "20\n",
      "maxabsV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0847 - val_loss: 1.0725\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0660 - val_loss: 1.0659\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0658\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Top-2 accuracy = 0.752\n",
      "21\n",
      "normalizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0148 - val_loss: 0.9510\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9372 - val_loss: 0.9358\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9278 - val_loss: 0.9317\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9274 - val_loss: 0.9275\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9239 - val_loss: 0.9269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 0.9334\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9257 - val_loss: 0.9275\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9215 - val_loss: 0.9296\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9218 - val_loss: 0.9242\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9207 - val_loss: 0.9314\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 0.9261\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9213 - val_loss: 0.9262\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9198 - val_loss: 0.9239\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9197 - val_loss: 0.9241\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9196 - val_loss: 0.9238\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9194 - val_loss: 0.9231\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9207 - val_loss: 0.9240\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9182 - val_loss: 0.9321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9229 - val_loss: 0.9246\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9182 - val_loss: 0.9273\n",
      "Top-2 accuracy = 0.831\n",
      "22\n",
      "maxabsR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0773 - val_loss: 1.0663\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0621 - val_loss: 1.0480\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0116 - val_loss: 0.9884\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9810 - val_loss: 0.9787\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9767 - val_loss: 0.9758\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9748 - val_loss: 0.9746\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9731 - val_loss: 0.9752\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9671 - val_loss: 0.9686\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9651 - val_loss: 0.9764\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9755 - val_loss: 0.9762\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9750 - val_loss: 0.9767\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9746 - val_loss: 0.9766\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9749 - val_loss: 0.9767\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9744 - val_loss: 0.9767\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9745 - val_loss: 0.9768\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9706 - val_loss: 0.9713\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9709 - val_loss: 0.9757\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9744 - val_loss: 0.9824\n",
      "Top-2 accuracy = 0.823\n",
      "23\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0733 - val_loss: 1.0656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0640 - val_loss: 1.0659\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0639 - val_loss: 1.0656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0662\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0658\n",
      "Top-2 accuracy = 0.752\n",
      "24\n",
      "maxabsc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0438 - val_loss: 0.9876\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9588 - val_loss: 0.9457\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 0.9389\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9275 - val_loss: 0.9298\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9232 - val_loss: 0.9273\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9217 - val_loss: 0.9256\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.9253\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.9246\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9243\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 0.9245\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9239\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.9254\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9239\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.9232\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9238\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.9277\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9284\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9228\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.9231\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9171 - val_loss: 0.9223\n",
      "Top-2 accuracy = 0.836\n",
      "25\n",
      "maxabsW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0483 - val_loss: 0.9718\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9417 - val_loss: 0.9325\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9290 - val_loss: 0.9276\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9237 - val_loss: 0.9281\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9237 - val_loss: 0.9325\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9222 - val_loss: 0.9329\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9222 - val_loss: 0.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9206 - val_loss: 0.9260\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9226 - val_loss: 0.9242\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9210 - val_loss: 0.9237\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9192 - val_loss: 0.9235\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9191 - val_loss: 0.9225\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9192 - val_loss: 0.9248\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9191 - val_loss: 0.9231\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9183 - val_loss: 0.9227\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9166 - val_loss: 0.9225\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9172 - val_loss: 0.9227\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9185 - val_loss: 0.9236\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9179 - val_loss: 0.9229\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9170 - val_loss: 0.9340\n",
      "Top-2 accuracy = 0.818\n",
      "26\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0755 - val_loss: 1.0152\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9848 - val_loss: 0.9701\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9597 - val_loss: 0.9613\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9462 - val_loss: 0.9413\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9352 - val_loss: 0.9448\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9334 - val_loss: 0.9326\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9289 - val_loss: 0.9296\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9266 - val_loss: 0.9280\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9284 - val_loss: 0.9520\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9325 - val_loss: 0.9282\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9262 - val_loss: 0.9307\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9272 - val_loss: 0.9279\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9245 - val_loss: 0.9274\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9243 - val_loss: 0.9259\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9229 - val_loss: 0.9323\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9242 - val_loss: 0.9305\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9227 - val_loss: 0.9258\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9232 - val_loss: 0.9282\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9214 - val_loss: 0.9241\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9208 - val_loss: 0.9244\n",
      "Top-2 accuracy = 0.831\n",
      "27\n",
      "normalizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0663 - val_loss: 1.0657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0460 - val_loss: 1.0099\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9744 - val_loss: 0.9572\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9521\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9432\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 0.9424\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.9400\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 0.9384\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9364 - val_loss: 0.9375\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9442\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9377\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9346 - val_loss: 0.9363\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9340 - val_loss: 0.9351\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9349 - val_loss: 0.9347\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9334 - val_loss: 0.9354\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9386\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 0.9362\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9328 - val_loss: 0.9341\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9331\n",
      "Top-2 accuracy = 0.834\n",
      "28\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0646 - val_loss: 1.0233\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9938 - val_loss: 0.9778\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9591 - val_loss: 0.9532\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9438 - val_loss: 0.9438\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9358 - val_loss: 0.9366\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9336 - val_loss: 0.9370\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9272 - val_loss: 0.9339\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9253 - val_loss: 0.9339\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9223 - val_loss: 0.9297\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9237 - val_loss: 0.9306\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9215 - val_loss: 0.9252\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9203 - val_loss: 0.9289\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9197 - val_loss: 0.9317\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9210 - val_loss: 0.9247\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.9246\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9190 - val_loss: 0.9250\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9187 - val_loss: 0.9253\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9185 - val_loss: 0.9252\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9185 - val_loss: 0.9239\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9177 - val_loss: 0.9337\n",
      "Top-2 accuracy = 0.829\n",
      "29\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0814 - val_loss: 1.0675\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0638 - val_loss: 1.0660\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0659\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 1.0657\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0636 - val_loss: 1.0656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0637 - val_loss: 1.0656\n",
      "Top-2 accuracy = 0.752\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"accuracy\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [MulticlassDL(n_classes=3, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20)],\n",
    "    \"post_train_hooks\": [top2_hook],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"eclipse-3class\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        MulticlassDL(n_classes=3, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.5624535740814811\n",
      "Top-2 Accuracy: 0.8387520713102108\n"
     ]
    }
   ],
   "source": [
    "interp = DODGEInterpreter(files=['./eclipse-3class.txt'], max_by=0, \n",
    "                          metrics=['accuracy'])\n",
    "results = interp.interpret()['eclipse-3class.txt']\n",
    "print('Top-1 Accuracy:', np.median(results['accuracy']))\n",
    "print('Top-2 Accuracy:', np.median(np.amax(np.array(top2).reshape(10,30), axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = np.where(data.y_train < 1, 0, np.where(data.y_train < 3, 1, np.where(data.y_train < 6, 2, np.where(data.y_train < 21, 3, 4))))\n",
    "data.y_test = np.where(data.y_test < 1, 0, np.where(data.y_test < 3, 1, np.where(data.y_test < 6, 2, np.where(data.y_test < 21, 3, 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y_train = to_categorical(data.y_train, num_classes=5)\n",
    "data.y_test = to_categorical(data.y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x16f1faa90>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1733cbd00>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2174c0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d217520>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1766c74c0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x16ef4a400>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d217a60>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x171319b20>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x171319c70>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x151725220>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x159dbca90>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b132550>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b085c10>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b085bb0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b085c70>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x159d41cd0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15ac3cd00>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x159ae6430>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b1cd700>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15af56d90>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15af56100>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15af56e50>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15af56e20>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a71c0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b356a30>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b356970>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b3560d0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b356f70>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b356c70>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b356670>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b3568b0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b356640>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b096ca0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b096af0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b096790>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b0961c0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b096550>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b096e20>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b096880>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b096b50>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x171319a90>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b2915b0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b2913a0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b291040>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b2917f0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b2919a0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x150e47c40>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x175da18e0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1648dedf0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x172862b50>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17148b790>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3115 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5647 - val_loss: 1.5091\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4838 - val_loss: 1.4706\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4580 - val_loss: 1.4544\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4450 - val_loss: 1.4447\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4362 - val_loss: 1.4387\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4309 - val_loss: 1.4335\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4310\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4299\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4289\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4236 - val_loss: 1.4277\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4266\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4214 - val_loss: 1.4260\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4210 - val_loss: 1.4258\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4202 - val_loss: 1.4246\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4195 - val_loss: 1.4240\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4191 - val_loss: 1.4244\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4187 - val_loss: 1.4243\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4183 - val_loss: 1.4242\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4178 - val_loss: 1.4226\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4172 - val_loss: 1.4239\n",
      "Top-2 accuracy = 0.616\n",
      "1\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3121 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5909 - val_loss: 1.5725\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5575 - val_loss: 1.5454\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5326 - val_loss: 1.5219\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5100 - val_loss: 1.4992\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4930 - val_loss: 1.4870\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4838 - val_loss: 1.4799\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4739 - val_loss: 1.4653\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4597 - val_loss: 1.4574\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4533 - val_loss: 1.4526\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4493 - val_loss: 1.4493\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4467 - val_loss: 1.4471\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4431 - val_loss: 1.4428\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4397 - val_loss: 1.4415\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4380 - val_loss: 1.4400\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4370 - val_loss: 1.4392\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4362 - val_loss: 1.4383\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4353 - val_loss: 1.4391\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4352 - val_loss: 1.4373\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4370\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4363\n",
      "Top-2 accuracy = 0.611\n",
      "2\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3126 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5865 - val_loss: 1.5592\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5250 - val_loss: 1.4973\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4825 - val_loss: 1.4755\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4676 - val_loss: 1.4622\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4562 - val_loss: 1.4540\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4472 - val_loss: 1.4449\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4404 - val_loss: 1.4400\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4365 - val_loss: 1.4371\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4344 - val_loss: 1.4356\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4358\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4346\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4340\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4305 - val_loss: 1.4344\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4299 - val_loss: 1.4332\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4296 - val_loss: 1.4325\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4292 - val_loss: 1.4328\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4285 - val_loss: 1.4320\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4275 - val_loss: 1.4316\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4275 - val_loss: 1.4317\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4270 - val_loss: 1.4312\n",
      "Top-2 accuracy = 0.615\n",
      "3\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3133 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5843 - val_loss: 1.5685\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5580 - val_loss: 1.5526\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5433 - val_loss: 1.5426\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5336 - val_loss: 1.5353\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5261 - val_loss: 1.5290\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5198 - val_loss: 1.5233\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5145 - val_loss: 1.5179\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5091 - val_loss: 1.5125\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5036 - val_loss: 1.5069\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4981 - val_loss: 1.5013\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4919 - val_loss: 1.4933\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4853 - val_loss: 1.4861\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4783 - val_loss: 1.4793\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4727 - val_loss: 1.4738\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4679 - val_loss: 1.4692\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4617 - val_loss: 1.4616\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4562 - val_loss: 1.4561\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4517 - val_loss: 1.4523\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4482 - val_loss: 1.4487\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4453 - val_loss: 1.4461\n",
      "Top-2 accuracy = 0.613\n",
      "4\n",
      "maxabsh|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3140 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5827 - val_loss: 1.5566\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5338 - val_loss: 1.5158\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5019 - val_loss: 1.4936\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4838 - val_loss: 1.4788\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4714 - val_loss: 1.4698\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4634 - val_loss: 1.4620\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4567 - val_loss: 1.4553\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4511 - val_loss: 1.4494\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4462 - val_loss: 1.4453\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4420 - val_loss: 1.4408\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4389 - val_loss: 1.4375\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4360 - val_loss: 1.4356\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4339 - val_loss: 1.4344\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4319 - val_loss: 1.4322\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4305 - val_loss: 1.4312\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4294 - val_loss: 1.4318\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4286 - val_loss: 1.4299\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4276 - val_loss: 1.4289\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4272 - val_loss: 1.4288\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4268 - val_loss: 1.4286\n",
      "Top-2 accuracy = 0.611\n",
      "5\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3145 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6998 - val_loss: 1.6242\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6102 - val_loss: 1.5978\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5921 - val_loss: 1.5845\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5769 - val_loss: 1.5687\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5580 - val_loss: 1.5470\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5332 - val_loss: 1.5202\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5064 - val_loss: 1.4973\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4877 - val_loss: 1.4836\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4780 - val_loss: 1.4776\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4729 - val_loss: 1.4737\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4694 - val_loss: 1.4708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4667 - val_loss: 1.4681\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4643 - val_loss: 1.4660\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4623 - val_loss: 1.4641\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4604 - val_loss: 1.4618\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4585 - val_loss: 1.4598\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4569 - val_loss: 1.4573\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4547 - val_loss: 1.4552\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4528 - val_loss: 1.4538\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4513 - val_loss: 1.4527\n",
      "Top-2 accuracy = 0.595\n",
      "6\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3150 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 16087294935040.0000 - val_loss: 2165903982592.0000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3541421785088.0000 - val_loss: 4324637016064.0000\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4932644110336.0000 - val_loss: 5473607614464.0000\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4681864052736.0000 - val_loss: 2987023663104.0000\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2942127046656.0000 - val_loss: 2908020801536.0000\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3768996593664.0000 - val_loss: 3307565219840.0000\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4431218212864.0000 - val_loss: 3936169754624.0000\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3395301408768.0000 - val_loss: 3318025551872.0000\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3705510297600.0000 - val_loss: 5099232952320.0000\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4166652002304.0000 - val_loss: 1709639991296.0000\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3645608558592.0000 - val_loss: 7356001812480.0000\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5561954336768.0000 - val_loss: 3009377992704.0000\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4171024564224.0000 - val_loss: 3744211402752.0000\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3348398342144.0000 - val_loss: 3762736070656.0000\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3673958907904.0000 - val_loss: 1629692887040.0000\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4020233043968.0000 - val_loss: 5622764404736.0000\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2769293672448.0000 - val_loss: 2484097777664.0000\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2991402778624.0000 - val_loss: 5238726590464.0000\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2944257753088.0000 - val_loss: 1947821801472.0000\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3247683141632.0000 - val_loss: 6581995438080.0000\n",
      "Top-2 accuracy = 0.518\n",
      "7\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3154 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5534 - val_loss: 1.4914\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4670 - val_loss: 1.4582\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4472 - val_loss: 1.4441\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4369 - val_loss: 1.4374\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4338\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4309\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4292\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4231 - val_loss: 1.4269\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4264\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4201 - val_loss: 1.4270\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4194 - val_loss: 1.4255\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4194 - val_loss: 1.4246\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4180 - val_loss: 1.4244\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4167 - val_loss: 1.4235\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4161 - val_loss: 1.4242\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4158 - val_loss: 1.4248\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4152 - val_loss: 1.4251\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.4247\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4146 - val_loss: 1.4226\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4132 - val_loss: 1.4221\n",
      "Top-2 accuracy = 0.619\n",
      "8\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3160 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6208 - val_loss: 1.6014\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5945 - val_loss: 1.5888\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5768 - val_loss: 1.5651\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5394 - val_loss: 1.5192\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5038 - val_loss: 1.4954\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4844 - val_loss: 1.4806\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4714 - val_loss: 1.4710\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4616 - val_loss: 1.4633\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4543 - val_loss: 1.4567\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4473 - val_loss: 1.4513\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4427 - val_loss: 1.4470\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4394 - val_loss: 1.4436\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4415\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4346 - val_loss: 1.4402\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4333 - val_loss: 1.4392\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4321 - val_loss: 1.4390\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4312 - val_loss: 1.4380\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4302 - val_loss: 1.4374\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4296 - val_loss: 1.4370\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4288 - val_loss: 1.4364\n",
      "Top-2 accuracy = 0.615\n",
      "9\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3165 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5462 - val_loss: 1.4924\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4694 - val_loss: 1.4559\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4478 - val_loss: 1.4412\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4370 - val_loss: 1.4345\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4318 - val_loss: 1.4294\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4283 - val_loss: 1.4285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4259 - val_loss: 1.4256\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4241\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4227 - val_loss: 1.4237\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4216 - val_loss: 1.4228\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4223\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4199 - val_loss: 1.4222\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4194 - val_loss: 1.4212\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4192 - val_loss: 1.4223\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4186 - val_loss: 1.4205\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4185 - val_loss: 1.4204\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4181 - val_loss: 1.4212\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4173 - val_loss: 1.4216\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4173 - val_loss: 1.4200\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4170 - val_loss: 1.4204\n",
      "Top-2 accuracy = 0.618\n",
      "10\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3170 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5762 - val_loss: 1.5396\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5146 - val_loss: 1.4944\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4838 - val_loss: 1.4786\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4724 - val_loss: 1.4706\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4662 - val_loss: 1.4656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4609 - val_loss: 1.4605\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4571 - val_loss: 1.4570\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4543 - val_loss: 1.4534\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4514 - val_loss: 1.4525\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4484 - val_loss: 1.4491\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4460 - val_loss: 1.4463\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4435 - val_loss: 1.4438\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4412 - val_loss: 1.4409\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4383 - val_loss: 1.4383\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4360 - val_loss: 1.4359\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4340 - val_loss: 1.4343\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4320 - val_loss: 1.4319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4303 - val_loss: 1.4303\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4286 - val_loss: 1.4302\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4280 - val_loss: 1.4289\n",
      "Top-2 accuracy = 0.615\n",
      "11\n",
      "minmaxF|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3173 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5895 - val_loss: 1.5704\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5296 - val_loss: 1.4892\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4732 - val_loss: 1.4656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4593 - val_loss: 1.4597\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4521 - val_loss: 1.4536\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4469 - val_loss: 1.4461\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4429 - val_loss: 1.4425\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4404 - val_loss: 1.4403\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4373 - val_loss: 1.4392\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4358 - val_loss: 1.4371\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4341 - val_loss: 1.4346\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4326 - val_loss: 1.4344\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4328\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4312 - val_loss: 1.4321\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4305 - val_loss: 1.4317\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4296 - val_loss: 1.4308\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4289 - val_loss: 1.4299\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4283 - val_loss: 1.4291\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4276 - val_loss: 1.4299\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4269 - val_loss: 1.4283\n",
      "Top-2 accuracy = 0.613\n",
      "12\n",
      "robustw|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3178 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.4782 - val_loss: 1.8701\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7285 - val_loss: 1.6501\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6237 - val_loss: 1.6116\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5997 - val_loss: 1.5948\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5850 - val_loss: 1.5792\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5706 - val_loss: 1.5643\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5559 - val_loss: 1.5505\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5442 - val_loss: 1.5395\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5342 - val_loss: 1.5310\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5260 - val_loss: 1.5239\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5192 - val_loss: 1.5178\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5134 - val_loss: 1.5131\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5082 - val_loss: 1.5094\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5038 - val_loss: 1.5050\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4998 - val_loss: 1.5019\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4964 - val_loss: 1.4983\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4931 - val_loss: 1.4952\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4899 - val_loss: 1.4924\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4867 - val_loss: 1.4892\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4840 - val_loss: 1.4861\n",
      "Top-2 accuracy = 0.589\n",
      "13\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3182 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6254 - val_loss: 1.5974\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5873 - val_loss: 1.5798\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5673 - val_loss: 1.5567\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5384 - val_loss: 1.5262\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5099 - val_loss: 1.5006\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4910 - val_loss: 1.4862\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4793 - val_loss: 1.4748\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4701 - val_loss: 1.4663\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4631 - val_loss: 1.4600\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4572 - val_loss: 1.4544\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4521 - val_loss: 1.4508\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4486 - val_loss: 1.4470\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4456 - val_loss: 1.4454\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4434 - val_loss: 1.4434\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4412 - val_loss: 1.4408\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4393 - val_loss: 1.4389\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4379 - val_loss: 1.4374\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4362 - val_loss: 1.4359\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4351 - val_loss: 1.4352\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4345 - val_loss: 1.4343\n",
      "Top-2 accuracy = 0.613\n",
      "14\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3187 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6127 - val_loss: 1.5991\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5942 - val_loss: 1.5901\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5777 - val_loss: 1.5547\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5228 - val_loss: 1.4953\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4856 - val_loss: 1.4806\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4729 - val_loss: 1.4708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4660 - val_loss: 1.4669\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4617 - val_loss: 1.4620\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4581 - val_loss: 1.4587\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4555 - val_loss: 1.4582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4529 - val_loss: 1.4541\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4507 - val_loss: 1.4520\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4488 - val_loss: 1.4501\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4463 - val_loss: 1.4473\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4435 - val_loss: 1.4447\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4404 - val_loss: 1.4416\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4383 - val_loss: 1.4392\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4367 - val_loss: 1.4381\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4352 - val_loss: 1.4366\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4346 - val_loss: 1.4362\n",
      "Top-2 accuracy = 0.611\n",
      "15\n",
      "minmaxn|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3193 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6005 - val_loss: 1.5989\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5960 - val_loss: 1.5926\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5836 - val_loss: 1.5714\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5519 - val_loss: 1.5304\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5171 - val_loss: 1.5031\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4951 - val_loss: 1.4864\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4801 - val_loss: 1.4756\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4707 - val_loss: 1.4681\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4642 - val_loss: 1.4632\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4602 - val_loss: 1.4589\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4565 - val_loss: 1.4563\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4542 - val_loss: 1.4548\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4520 - val_loss: 1.4520\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4508 - val_loss: 1.4515\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4498 - val_loss: 1.4512\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4490 - val_loss: 1.4502\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4488 - val_loss: 1.4497\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4485 - val_loss: 1.4490\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4480 - val_loss: 1.4491\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4476 - val_loss: 1.4485\n",
      "Top-2 accuracy = 0.604\n",
      "16\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3199 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5977 - val_loss: 1.5909\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5779 - val_loss: 1.5628\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5405 - val_loss: 1.5259\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5099 - val_loss: 1.4994\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4918 - val_loss: 1.4862\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4813 - val_loss: 1.4770\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4735 - val_loss: 1.4688\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4666 - val_loss: 1.4630\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4610 - val_loss: 1.4581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4585 - val_loss: 1.4547\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4533 - val_loss: 1.4511\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4504 - val_loss: 1.4481\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4479 - val_loss: 1.4465\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4466 - val_loss: 1.4456\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4449 - val_loss: 1.4477\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4449 - val_loss: 1.4446\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4437 - val_loss: 1.4429\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4431 - val_loss: 1.4449\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4433 - val_loss: 1.4420\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4418 - val_loss: 1.4424\n",
      "Top-2 accuracy = 0.608\n",
      "17\n",
      "robustV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3205 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5715 - val_loss: 1.5107\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4930 - val_loss: 1.4813\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4717 - val_loss: 1.4685\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4598 - val_loss: 1.4595\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4524 - val_loss: 1.4534\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4473 - val_loss: 1.4485\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4451\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4387 - val_loss: 1.4432\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4403\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4333 - val_loss: 1.4365\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4359\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4330\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4326\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4339\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4249 - val_loss: 1.4316\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4305\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4231 - val_loss: 1.4301\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4228 - val_loss: 1.4306\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4225 - val_loss: 1.4289\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4211 - val_loss: 1.4302\n",
      "Top-2 accuracy = 0.612\n",
      "18\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3210 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6277 - val_loss: 1.5645\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5419 - val_loss: 1.5235\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5101 - val_loss: 1.5001\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4921 - val_loss: 1.4862\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4799 - val_loss: 1.4761\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4709 - val_loss: 1.4675\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4641 - val_loss: 1.4621\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4598 - val_loss: 1.4585\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4562 - val_loss: 1.4550\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4533 - val_loss: 1.4520\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4499 - val_loss: 1.4491\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4476 - val_loss: 1.4473\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4454 - val_loss: 1.4456\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4431 - val_loss: 1.4433\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4409 - val_loss: 1.4410\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4390 - val_loss: 1.4393\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4375 - val_loss: 1.4377\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4358 - val_loss: 1.4365\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4354 - val_loss: 1.4365\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4339 - val_loss: 1.4360\n",
      "Top-2 accuracy = 0.61\n",
      "19\n",
      "normalizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5818 - val_loss: 1.5594\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5380 - val_loss: 1.5213\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5032 - val_loss: 1.4916\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4788 - val_loss: 1.4735\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4666 - val_loss: 1.4642\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4580 - val_loss: 1.4574\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4538 - val_loss: 1.4552\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4512 - val_loss: 1.4557\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4488 - val_loss: 1.4516\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4473 - val_loss: 1.4531\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4509\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4461 - val_loss: 1.4478\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4446 - val_loss: 1.4474\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4443 - val_loss: 1.4479\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4432 - val_loss: 1.4465\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4465\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4425 - val_loss: 1.4461\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4422 - val_loss: 1.4457\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4420 - val_loss: 1.4451\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.4418 - val_loss: 1.4458\n",
      "Top-2 accuracy = 0.607\n",
      "20\n",
      "minmaxb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3219 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5942 - val_loss: 1.5800\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5595 - val_loss: 1.5396\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5231 - val_loss: 1.5113\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5037 - val_loss: 1.4986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4930 - val_loss: 1.4904\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4871 - val_loss: 1.4866\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4833 - val_loss: 1.4832\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4811 - val_loss: 1.4810\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4789 - val_loss: 1.4794\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4777 - val_loss: 1.4773\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4761 - val_loss: 1.4767\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4760 - val_loss: 1.4754\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4749 - val_loss: 1.4737\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4730 - val_loss: 1.4735\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4722 - val_loss: 1.4713\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4712 - val_loss: 1.4703\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4702 - val_loss: 1.4709\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4695 - val_loss: 1.4686\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4686 - val_loss: 1.4678\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4678 - val_loss: 1.4689\n",
      "Top-2 accuracy = 0.591\n",
      "21\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5906 - val_loss: 1.5617\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5152 - val_loss: 1.4930\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4739 - val_loss: 1.4620\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4596 - val_loss: 1.4567\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4536 - val_loss: 1.4514\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4484 - val_loss: 1.4463\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4471\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4447 - val_loss: 1.4468\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4426 - val_loss: 1.4405\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4412 - val_loss: 1.4468\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4427 - val_loss: 1.4406\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4392 - val_loss: 1.4445\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4371\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.4425\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4382 - val_loss: 1.4449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4383 - val_loss: 1.4383\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4353\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4365 - val_loss: 1.4451\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4359 - val_loss: 1.4397\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4347 - val_loss: 1.4368\n",
      "Top-2 accuracy = 0.611\n",
      "22\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3227 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5622 - val_loss: 1.5224\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5017 - val_loss: 1.4969\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4791 - val_loss: 1.4749\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4681 - val_loss: 1.4649\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4614 - val_loss: 1.4704\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4623 - val_loss: 1.4584\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4542 - val_loss: 1.4540\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4508 - val_loss: 1.4514\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4479 - val_loss: 1.4487\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4561\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4463 - val_loss: 1.4451\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4436 - val_loss: 1.4430\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4424\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4411 - val_loss: 1.4475\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4415 - val_loss: 1.4398\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4405 - val_loss: 1.4411\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4390 - val_loss: 1.4382\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4368 - val_loss: 1.4452\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4365 - val_loss: 1.4359\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4407\n",
      "Top-2 accuracy = 0.608\n",
      "23\n",
      "robustK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6043 - val_loss: 1.5992\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5831 - val_loss: 1.5557\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5222 - val_loss: 1.5030\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4888 - val_loss: 1.4828\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4745 - val_loss: 1.4732\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4668 - val_loss: 1.4663\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4604 - val_loss: 1.4601\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4555 - val_loss: 1.4563\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4523 - val_loss: 1.4531\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4507 - val_loss: 1.4509\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4494 - val_loss: 1.4499\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4499 - val_loss: 1.4503\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4480 - val_loss: 1.4487\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4490\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4482\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4477\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4463 - val_loss: 1.4475\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4460 - val_loss: 1.4476\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4457 - val_loss: 1.4467\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4466\n",
      "Top-2 accuracy = 0.602\n",
      "24\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5813 - val_loss: 1.5023\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4672 - val_loss: 1.4555\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4450 - val_loss: 1.4419\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4384\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4353\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4342\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4330 - val_loss: 1.4334\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4333\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4376\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4352\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4375\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4337\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4345\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4309\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4352\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4352\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4301\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4296\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4319\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4298\n",
      "Top-2 accuracy = 0.613\n",
      "25\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3246 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5756 - val_loss: 1.5398\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5120 - val_loss: 1.4918\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4743 - val_loss: 1.4676\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4582 - val_loss: 1.4568\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4502 - val_loss: 1.4506\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4450 - val_loss: 1.4461\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4409 - val_loss: 1.4423\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4378 - val_loss: 1.4395\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4350 - val_loss: 1.4376\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4333 - val_loss: 1.4350\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4309 - val_loss: 1.4333\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4297 - val_loss: 1.4323\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4276 - val_loss: 1.4310\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4268 - val_loss: 1.4292\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4260 - val_loss: 1.4282\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4248 - val_loss: 1.4280\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4240 - val_loss: 1.4275\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4236 - val_loss: 1.4266\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4228 - val_loss: 1.4264\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4222 - val_loss: 1.4268\n",
      "Top-2 accuracy = 0.616\n",
      "26\n",
      "minmaxW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5854 - val_loss: 1.5388\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4860 - val_loss: 1.4583\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4540 - val_loss: 1.4529\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4490 - val_loss: 1.4544\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4476 - val_loss: 1.4465\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4427 - val_loss: 1.4428\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4407\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4387 - val_loss: 1.4425\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4376 - val_loss: 1.4390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4378 - val_loss: 1.4386\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4393\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4387\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4370 - val_loss: 1.4381\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4376\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4358 - val_loss: 1.4372\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4386\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4367\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4360\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4355 - val_loss: 1.4406\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4353 - val_loss: 1.4357\n",
      "Top-2 accuracy = 0.61\n",
      "27\n",
      "normalizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6007 - val_loss: 1.5985\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5981\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5932 - val_loss: 1.5820\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5505 - val_loss: 1.5224\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5098 - val_loss: 1.4946\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4871 - val_loss: 1.4763\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4697 - val_loss: 1.4634\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4601 - val_loss: 1.4566\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4547 - val_loss: 1.4532\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4526 - val_loss: 1.4515\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4509 - val_loss: 1.4498\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4492 - val_loss: 1.4490\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4491 - val_loss: 1.4485\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4489 - val_loss: 1.4486\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4482\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4484 - val_loss: 1.4490\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4493 - val_loss: 1.4498\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4482 - val_loss: 1.4575\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4510 - val_loss: 1.4482\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4481 - val_loss: 1.4496\n",
      "Top-2 accuracy = 0.605\n",
      "28\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5648 - val_loss: 1.4927\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4659 - val_loss: 1.4457\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4420\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4341\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4327\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4425\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4342\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4287 - val_loss: 1.4353\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4354\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4371\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4306\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4302\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4300\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4304\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4369\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4286 - val_loss: 1.4311\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4302\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4293\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4300\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4264 - val_loss: 1.4320\n",
      "Top-2 accuracy = 0.611\n",
      "29\n",
      "standardizeF|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3266 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5639 - val_loss: 1.5164\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4890 - val_loss: 1.4731\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4620 - val_loss: 1.4561\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4491 - val_loss: 1.4472\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4433 - val_loss: 1.4435\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4404 - val_loss: 1.4421\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4386 - val_loss: 1.4408\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4371 - val_loss: 1.4395\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4357 - val_loss: 1.4378\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4341 - val_loss: 1.4367\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4334 - val_loss: 1.4361\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4321 - val_loss: 1.4357\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4311 - val_loss: 1.4349\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4299 - val_loss: 1.4353\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4293 - val_loss: 1.4340\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4288 - val_loss: 1.4342\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4282 - val_loss: 1.4332\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4274 - val_loss: 1.4318\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4268 - val_loss: 1.4313\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4272 - val_loss: 1.4310\n",
      "Top-2 accuracy = 0.614\n",
      "0\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3272 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5626 - val_loss: 1.4961\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4752 - val_loss: 1.4566\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4492 - val_loss: 1.4416\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4390 - val_loss: 1.4375\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4343\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4327\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4305\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4302\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4278\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4242 - val_loss: 1.4272\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4236 - val_loss: 1.4270\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4226 - val_loss: 1.4256\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4263\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4210 - val_loss: 1.4241\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4206 - val_loss: 1.4236\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4201 - val_loss: 1.4238\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4196 - val_loss: 1.4229\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.4246\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4190 - val_loss: 1.4230\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.4226\n",
      "Top-2 accuracy = 0.614\n",
      "1\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3278 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6302 - val_loss: 1.5793\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5493 - val_loss: 1.5236\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5045 - val_loss: 1.4901\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4821 - val_loss: 1.4757\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4709 - val_loss: 1.4657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4623 - val_loss: 1.4577\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4555 - val_loss: 1.4525\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4502 - val_loss: 1.4473\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4454 - val_loss: 1.4432\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4409 - val_loss: 1.4393\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4375 - val_loss: 1.4369\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4349 - val_loss: 1.4349\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4331 - val_loss: 1.4336\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4315 - val_loss: 1.4324\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4302 - val_loss: 1.4310\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4291 - val_loss: 1.4309\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4282 - val_loss: 1.4303\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4276 - val_loss: 1.4295\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4270 - val_loss: 1.4289\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4264 - val_loss: 1.4289\n",
      "Top-2 accuracy = 0.614\n",
      "2\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5970 - val_loss: 1.5883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5673 - val_loss: 1.5472\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5246 - val_loss: 1.5081\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4922 - val_loss: 1.4789\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4675 - val_loss: 1.4603\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4548 - val_loss: 1.4531\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4508 - val_loss: 1.4507\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4476 - val_loss: 1.4528\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4487\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4458\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4451 - val_loss: 1.4450\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4447 - val_loss: 1.4447\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4439\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4443 - val_loss: 1.4434\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4428 - val_loss: 1.4420\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4423 - val_loss: 1.4422\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4423 - val_loss: 1.4404\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4417 - val_loss: 1.4391\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4409 - val_loss: 1.4396\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4406 - val_loss: 1.4382\n",
      "Top-2 accuracy = 0.605\n",
      "3\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5620 - val_loss: 1.5098\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4795 - val_loss: 1.4622\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4564 - val_loss: 1.4541\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4503 - val_loss: 1.4496\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4455\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4438 - val_loss: 1.4475\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4414 - val_loss: 1.4393\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4377\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4379 - val_loss: 1.4366\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4362 - val_loss: 1.4351\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4353 - val_loss: 1.4340\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4337\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4324\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4321 - val_loss: 1.4313\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4314 - val_loss: 1.4322\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4302\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4291\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4286\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4281\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4273\n",
      "Top-2 accuracy = 0.612\n",
      "4\n",
      "maxabsc|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3291 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6055 - val_loss: 1.6028\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6006 - val_loss: 1.6000\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5985 - val_loss: 1.5990\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5976 - val_loss: 1.5987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "5\n",
      "minmaxR|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3297 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5792 - val_loss: 1.5404\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5098 - val_loss: 1.4896\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4834 - val_loss: 1.4756\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4727 - val_loss: 1.4668\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4649 - val_loss: 1.4607\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4598 - val_loss: 1.4574\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4549 - val_loss: 1.4529\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4508 - val_loss: 1.4504\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4478 - val_loss: 1.4525\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4466 - val_loss: 1.4463\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4442 - val_loss: 1.4466\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4427 - val_loss: 1.4452\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4418 - val_loss: 1.4423\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4416\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4398 - val_loss: 1.4407\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4387 - val_loss: 1.4410\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4396\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4383 - val_loss: 1.4397\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4379 - val_loss: 1.4397\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4377 - val_loss: 1.4390\n",
      "Top-2 accuracy = 0.604\n",
      "6\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6005 - val_loss: 1.5886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5593 - val_loss: 1.5270\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5112 - val_loss: 1.5028\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4915 - val_loss: 1.4843\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4764 - val_loss: 1.4712\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4669 - val_loss: 1.4645\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4619 - val_loss: 1.4608\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4586 - val_loss: 1.4572\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4565 - val_loss: 1.4557\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4551 - val_loss: 1.4545\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4540 - val_loss: 1.4538\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4535 - val_loss: 1.4533\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4535 - val_loss: 1.4526\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4530 - val_loss: 1.4535\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4526 - val_loss: 1.4523\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4524 - val_loss: 1.4523\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4521 - val_loss: 1.4518\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4519 - val_loss: 1.4528\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4518 - val_loss: 1.4521\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4520 - val_loss: 1.4513\n",
      "Top-2 accuracy = 0.597\n",
      "7\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5500 - val_loss: 1.4767\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4547 - val_loss: 1.4445\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4412 - val_loss: 1.4411\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4385\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4352 - val_loss: 1.4366\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4350\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4330 - val_loss: 1.4356\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4359\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4330\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4332\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4326\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4348\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4361\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4331\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4323\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4306\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4316\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4329\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4298\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4305\n",
      "Top-2 accuracy = 0.613\n",
      "8\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3314 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7510 - val_loss: 1.5385\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5145 - val_loss: 1.4906\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4729 - val_loss: 1.4609\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4531 - val_loss: 1.4500\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4447 - val_loss: 1.4447\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4406 - val_loss: 1.4421\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4365 - val_loss: 1.4388\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4366\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4358\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4347\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4330\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4305\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4317\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4294\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4304\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4232 - val_loss: 1.4284\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4218 - val_loss: 1.4264\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4267\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4198 - val_loss: 1.4263\n",
      "Top-2 accuracy = 0.611\n",
      "9\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5477 - val_loss: 1.4791\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4636 - val_loss: 1.4556\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4463 - val_loss: 1.4429\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4371\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4352\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4344\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4337\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4333\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4309\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4317\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4356\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4313\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4292\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4291\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4294\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4233 - val_loss: 1.4290\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4271\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4218 - val_loss: 1.4265\n",
      "Top-2 accuracy = 0.615\n",
      "10\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3327 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5888 - val_loss: 1.5565\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5225 - val_loss: 1.4902\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4765 - val_loss: 1.4643\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4578 - val_loss: 1.4497\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4471 - val_loss: 1.4413\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4405 - val_loss: 1.4377\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4336\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4316\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4308\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4274\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4264\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4238 - val_loss: 1.4265\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4226 - val_loss: 1.4241\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4246\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4212 - val_loss: 1.4248\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4247\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4206 - val_loss: 1.4234\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4201 - val_loss: 1.4235\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4227\n",
      "Top-2 accuracy = 0.619\n",
      "11\n",
      "robustv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6091 - val_loss: 1.6027\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5985 - val_loss: 1.5913\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5690 - val_loss: 1.5392\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5093 - val_loss: 1.4860\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4745 - val_loss: 1.4668\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4619 - val_loss: 1.4593\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4558 - val_loss: 1.4565\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4525 - val_loss: 1.4533\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4510 - val_loss: 1.4511\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4492 - val_loss: 1.4506\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4478 - val_loss: 1.4497\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4469 - val_loss: 1.4485\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4467 - val_loss: 1.4474\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4455 - val_loss: 1.4464\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4446 - val_loss: 1.4450\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4436 - val_loss: 1.4438\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4422\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4406 - val_loss: 1.4408\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4389 - val_loss: 1.4389\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.4365\n",
      "Top-2 accuracy = 0.608\n",
      "12\n",
      "minmaxP|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3338 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5455 - val_loss: 1.4876\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4749 - val_loss: 1.4642\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4602 - val_loss: 1.4546\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4529 - val_loss: 1.4484\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4479 - val_loss: 1.4437\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4431 - val_loss: 1.4430\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4418 - val_loss: 1.4400\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4376 - val_loss: 1.4372\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4356 - val_loss: 1.4356\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4336 - val_loss: 1.4377\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4337 - val_loss: 1.4318\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4322\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4288 - val_loss: 1.4304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4285 - val_loss: 1.4283\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4270 - val_loss: 1.4302\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4282 - val_loss: 1.4272\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4262 - val_loss: 1.4262\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4250 - val_loss: 1.4272\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4268\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4243 - val_loss: 1.4279\n",
      "Top-2 accuracy = 0.613\n",
      "13\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3343 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5933 - val_loss: 1.5662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5171 - val_loss: 1.4841\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4736 - val_loss: 1.4675\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4618 - val_loss: 1.4596\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4570 - val_loss: 1.4570\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4515 - val_loss: 1.4517\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4472 - val_loss: 1.4494\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4437 - val_loss: 1.4443\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4411\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4389\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4347 - val_loss: 1.4371\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4334\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4331\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4315 - val_loss: 1.4402\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4289\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4295\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4277\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4280\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4283\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4265\n",
      "Top-2 accuracy = 0.615\n",
      "14\n",
      "normalizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6034 - val_loss: 1.5990\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5934 - val_loss: 1.5778\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5211 - val_loss: 1.4778\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4647 - val_loss: 1.4568\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4544 - val_loss: 1.4533\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4514 - val_loss: 1.4502\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4489 - val_loss: 1.4495\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4483 - val_loss: 1.4485\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4480\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4495\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4483\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4469 - val_loss: 1.4468\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4465 - val_loss: 1.4474\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4465 - val_loss: 1.4497\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4469\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4468 - val_loss: 1.4475\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4462 - val_loss: 1.4460\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4475\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4456\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4458\n",
      "Top-2 accuracy = 0.604\n",
      "15\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3354 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6279 - val_loss: 1.5901\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5666 - val_loss: 1.5404\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5194 - val_loss: 1.5025\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4931 - val_loss: 1.4869\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4821 - val_loss: 1.4796\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4769 - val_loss: 1.4749\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4725 - val_loss: 1.4709\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4694 - val_loss: 1.4686\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4673 - val_loss: 1.4674\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4654 - val_loss: 1.4653\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4641 - val_loss: 1.4626\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4617 - val_loss: 1.4611\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4605 - val_loss: 1.4592\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4585 - val_loss: 1.4569\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4559 - val_loss: 1.4540\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4531 - val_loss: 1.4507\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4497 - val_loss: 1.4481\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4473 - val_loss: 1.4464\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4448 - val_loss: 1.4440\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4433 - val_loss: 1.4418\n",
      "Top-2 accuracy = 0.61\n",
      "16\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5764 - val_loss: 1.5329\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4932 - val_loss: 1.4631\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4540 - val_loss: 1.4488\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4436 - val_loss: 1.4427\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4369 - val_loss: 1.4367\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4342\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4314\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4289\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4282\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4271\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4236 - val_loss: 1.4265\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4228 - val_loss: 1.4262\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4221 - val_loss: 1.4262\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4271\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4210 - val_loss: 1.4252\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4209 - val_loss: 1.4249\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4205 - val_loss: 1.4256\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4198 - val_loss: 1.4246\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4196 - val_loss: 1.4244\n",
      "Top-2 accuracy = 0.618\n",
      "17\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5660 - val_loss: 1.5195\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4932 - val_loss: 1.4773\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4668 - val_loss: 1.4608\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4566 - val_loss: 1.4545\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4521 - val_loss: 1.4504\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4496 - val_loss: 1.4484\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4481 - val_loss: 1.4472\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4470 - val_loss: 1.4462\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4467 - val_loss: 1.4465\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4461 - val_loss: 1.4450\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4448 - val_loss: 1.4441\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4442 - val_loss: 1.4430\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4428\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4432\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4423 - val_loss: 1.4417\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4418 - val_loss: 1.4411\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4414 - val_loss: 1.4418\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4413 - val_loss: 1.4409\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4406 - val_loss: 1.4400\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4403 - val_loss: 1.4403\n",
      "Top-2 accuracy = 0.609\n",
      "18\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3363 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6916 - val_loss: 1.6145\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5926 - val_loss: 1.5784\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5630 - val_loss: 1.5481\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5267 - val_loss: 1.5073\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4923 - val_loss: 1.4804\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4717 - val_loss: 1.4655\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4604 - val_loss: 1.4562\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4530 - val_loss: 1.4503\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4478 - val_loss: 1.4458\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4440 - val_loss: 1.4428\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4415 - val_loss: 1.4403\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4396 - val_loss: 1.4392\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4381 - val_loss: 1.4380\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4369 - val_loss: 1.4364\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4360 - val_loss: 1.4357\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4354\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4343 - val_loss: 1.4349\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4336 - val_loss: 1.4341\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4327 - val_loss: 1.4336\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4323 - val_loss: 1.4331\n",
      "Top-2 accuracy = 0.608\n",
      "19\n",
      "standardizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5354 - val_loss: 1.4777\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4592 - val_loss: 1.4493\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4437 - val_loss: 1.4408\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4368 - val_loss: 1.4355\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4334\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4326\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4350\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4302\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4312\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4297\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4295\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4247 - val_loss: 1.4303\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4314\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4249 - val_loss: 1.4323\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4228 - val_loss: 1.4287\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4230 - val_loss: 1.4337\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4221 - val_loss: 1.4399\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4227 - val_loss: 1.4300\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4329\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4280\n",
      "Top-2 accuracy = 0.616\n",
      "20\n",
      "maxabsW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5914 - val_loss: 1.5745\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5516 - val_loss: 1.5361\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5140 - val_loss: 1.4987\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4818 - val_loss: 1.4720\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4641 - val_loss: 1.4595\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4558 - val_loss: 1.4538\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4514 - val_loss: 1.4513\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4491 - val_loss: 1.4506\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4484 - val_loss: 1.4483\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4481 - val_loss: 1.4486\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4471 - val_loss: 1.4485\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4465 - val_loss: 1.4472\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4461 - val_loss: 1.4473\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4459 - val_loss: 1.4480\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4470 - val_loss: 1.4471\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4456 - val_loss: 1.4468\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4458 - val_loss: 1.4467\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4452 - val_loss: 1.4500\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4465 - val_loss: 1.4476\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4460 - val_loss: 1.4464\n",
      "Top-2 accuracy = 0.605\n",
      "21\n",
      "standardizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6015 - val_loss: 1.5846\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5514 - val_loss: 1.5150\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4929 - val_loss: 1.4750\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4649 - val_loss: 1.4593\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4538 - val_loss: 1.4531\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4496 - val_loss: 1.4495\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4478\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4490\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4456\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4477\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4454 - val_loss: 1.4445\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4438 - val_loss: 1.4442\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4435 - val_loss: 1.4444\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4440 - val_loss: 1.4461\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4435 - val_loss: 1.4442\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4437\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4428 - val_loss: 1.4435\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4428 - val_loss: 1.4455\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4429 - val_loss: 1.4433\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4424 - val_loss: 1.4434\n",
      "Top-2 accuracy = 0.604\n",
      "22\n",
      "standardizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5867 - val_loss: 1.5529\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5315 - val_loss: 1.5164\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5090 - val_loss: 1.5041\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5014 - val_loss: 1.4981\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4813 - val_loss: 1.4674\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4617 - val_loss: 1.4580\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4550 - val_loss: 1.4531\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4532 - val_loss: 1.4514\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4504 - val_loss: 1.4502\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4492 - val_loss: 1.4493\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4490 - val_loss: 1.4504\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4478 - val_loss: 1.4489\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4479 - val_loss: 1.4485\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4472\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4484\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4463 - val_loss: 1.4473\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4461 - val_loss: 1.4473\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4460 - val_loss: 1.4464\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4461 - val_loss: 1.4472\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4464\n",
      "Top-2 accuracy = 0.603\n",
      "23\n",
      "minmaxK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5533 - val_loss: 1.4789\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4642 - val_loss: 1.4563\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4512 - val_loss: 1.4508\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4485 - val_loss: 1.4514\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4487 - val_loss: 1.4475\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4463 - val_loss: 1.4468\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4463 - val_loss: 1.4524\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4458\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4454 - val_loss: 1.4444\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4441 - val_loss: 1.4440\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4562\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4425 - val_loss: 1.4390\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4401\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4385 - val_loss: 1.4367\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4353 - val_loss: 1.4372\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4321\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4321 - val_loss: 1.4335\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4401\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4366\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4319\n",
      "Top-2 accuracy = 0.614\n",
      "24\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5737 - val_loss: 1.5101\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4751 - val_loss: 1.4553\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4499 - val_loss: 1.4466\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4437 - val_loss: 1.4438\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4402 - val_loss: 1.4401\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4378 - val_loss: 1.4389\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4363 - val_loss: 1.4379\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4355 - val_loss: 1.4372\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4346 - val_loss: 1.4368\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4380\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4365\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4363\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4361\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4358\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4362\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4359\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4378\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4366\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4357\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4345\n",
      "Top-2 accuracy = 0.613\n",
      "25\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3400 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5631 - val_loss: 1.4931\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4657 - val_loss: 1.4574\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4497 - val_loss: 1.4489\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4427\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4362 - val_loss: 1.4363\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4321 - val_loss: 1.4345\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4309\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4296\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4288\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4231 - val_loss: 1.4279\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4211 - val_loss: 1.4270\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4293\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.4259\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4183 - val_loss: 1.4256\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4175 - val_loss: 1.4248\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4169 - val_loss: 1.4268\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4163 - val_loss: 1.4241\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4156 - val_loss: 1.4279\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4153 - val_loss: 1.4250\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4153 - val_loss: 1.4243\n",
      "Top-2 accuracy = 0.618\n",
      "26\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5819 - val_loss: 1.5425\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5049 - val_loss: 1.4667\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4611 - val_loss: 1.4539\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4501 - val_loss: 1.4464\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4469 - val_loss: 1.4426\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4444 - val_loss: 1.4423\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4413\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4409 - val_loss: 1.4398\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4395 - val_loss: 1.4390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4386 - val_loss: 1.4379\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4367\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4362\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4356\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4359\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4359\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4333 - val_loss: 1.4342\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4355\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4348\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4322\n",
      "Top-2 accuracy = 0.612\n",
      "27\n",
      "normalizeQ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3413 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6027 - val_loss: 1.5944\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5825 - val_loss: 1.5659\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5543 - val_loss: 1.5422\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5338 - val_loss: 1.5256\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5181 - val_loss: 1.5118\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5050 - val_loss: 1.4998\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4938 - val_loss: 1.4906\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4846 - val_loss: 1.4812\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4761 - val_loss: 1.4739\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4693 - val_loss: 1.4681\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4632 - val_loss: 1.4639\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4590 - val_loss: 1.4594\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4553 - val_loss: 1.4574\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4526 - val_loss: 1.4546\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4504 - val_loss: 1.4527\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4489 - val_loss: 1.4514\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4472 - val_loss: 1.4502\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4459 - val_loss: 1.4485\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4447 - val_loss: 1.4484\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4477\n",
      "Top-2 accuracy = 0.609\n",
      "28\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3419 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5815 - val_loss: 1.5548\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5279 - val_loss: 1.5068\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4939 - val_loss: 1.4837\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4769 - val_loss: 1.4707\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4664 - val_loss: 1.4617\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4583 - val_loss: 1.4561\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4541 - val_loss: 1.4526\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4503 - val_loss: 1.4497\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4488 - val_loss: 1.4482\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4469\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4459 - val_loss: 1.4456\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4448 - val_loss: 1.4453\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4440 - val_loss: 1.4443\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4438\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4422 - val_loss: 1.4431\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4420\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4413 - val_loss: 1.4416\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4406 - val_loss: 1.4409\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4399 - val_loss: 1.4399\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4397\n",
      "Top-2 accuracy = 0.611\n",
      "29\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5524 - val_loss: 1.4915\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4517 - val_loss: 1.4368\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4325\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4286\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4308\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4258 - val_loss: 1.4279\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4288\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4205 - val_loss: 1.4290\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4199 - val_loss: 1.4289\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4177 - val_loss: 1.4249\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4166 - val_loss: 1.4240\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4149 - val_loss: 1.4235\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4165 - val_loss: 1.4245\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4145 - val_loss: 1.4228\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4146 - val_loss: 1.4260\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4130 - val_loss: 1.4237\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4124 - val_loss: 1.4234\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4118 - val_loss: 1.4266\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4125 - val_loss: 1.4221\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4116 - val_loss: 1.4240\n",
      "Top-2 accuracy = 0.618\n",
      "0\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3432 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6111 - val_loss: 1.6027\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5986 - val_loss: 1.5951\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5868 - val_loss: 1.5759\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5573 - val_loss: 1.5394\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5211 - val_loss: 1.5066\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4925 - val_loss: 1.4841\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4738 - val_loss: 1.4688\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4611 - val_loss: 1.4593\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4530 - val_loss: 1.4526\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4480\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4432 - val_loss: 1.4441\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4414\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4388\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4349 - val_loss: 1.4369\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4353\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4341\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4330\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4317\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4314\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4308\n",
      "Top-2 accuracy = 0.615\n",
      "1\n",
      "normalizeS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3436 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5849 - val_loss: 1.5483\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5042 - val_loss: 1.4797\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4680 - val_loss: 1.4623\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4547 - val_loss: 1.4538\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4460 - val_loss: 1.4465\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4436\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4421\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4405\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4359 - val_loss: 1.4370\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4361\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4359\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4341\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4342\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4322\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4322\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4317\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4300\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4303\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4306\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4295\n",
      "Top-2 accuracy = 0.616\n",
      "2\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5858 - val_loss: 1.5353\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4855 - val_loss: 1.4613\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4560 - val_loss: 1.4497\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4487 - val_loss: 1.4516\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4458 - val_loss: 1.4377\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4376 - val_loss: 1.4518\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4418 - val_loss: 1.4362\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4358 - val_loss: 1.4341\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4322 - val_loss: 1.4481\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4344 - val_loss: 1.4428\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4342 - val_loss: 1.4338\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4320 - val_loss: 1.4494\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4322 - val_loss: 1.4378\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4302 - val_loss: 1.4328\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4349\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4292 - val_loss: 1.4345\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.4330\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4295\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4279 - val_loss: 1.4322\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4298 - val_loss: 1.4296\n",
      "Top-2 accuracy = 0.612\n",
      "3\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5547 - val_loss: 1.5151\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5428 - val_loss: 1.5275\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5333 - val_loss: 1.5176\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4935 - val_loss: 1.4831\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4878 - val_loss: 1.4865\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4842 - val_loss: 1.4947\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4873 - val_loss: 1.4907\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4792 - val_loss: 1.4772\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4768 - val_loss: 1.4772\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4750 - val_loss: 1.4789\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4769 - val_loss: 1.4760\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4717 - val_loss: 1.4698\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4709 - val_loss: 1.4740\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4704 - val_loss: 1.4712\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4782 - val_loss: 1.4788\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4696 - val_loss: 1.4717\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4644 - val_loss: 1.4629\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4643 - val_loss: 1.4671\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4631 - val_loss: 1.4643\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4623 - val_loss: 1.4641\n",
      "Top-2 accuracy = 0.597\n",
      "4\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5506 - val_loss: 1.4957\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4749 - val_loss: 1.4599\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4532 - val_loss: 1.4496\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4465 - val_loss: 1.4446\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4429 - val_loss: 1.4423\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4411 - val_loss: 1.4404\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4397 - val_loss: 1.4395\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4395 - val_loss: 1.4395\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4392 - val_loss: 1.4390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4386\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4385 - val_loss: 1.4386\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4383\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4381 - val_loss: 1.4386\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4378 - val_loss: 1.4382\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4376 - val_loss: 1.4377\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4374\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4379\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4377\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4369 - val_loss: 1.4374\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4372\n",
      "Top-2 accuracy = 0.613\n",
      "5\n",
      "normalizeW|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3458 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5928 - val_loss: 1.5683\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5302 - val_loss: 1.4958\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4811 - val_loss: 1.4723\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4680 - val_loss: 1.4651\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4608 - val_loss: 1.4582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4553 - val_loss: 1.4527\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4512 - val_loss: 1.4493\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4476 - val_loss: 1.4460\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4448 - val_loss: 1.4445\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4423 - val_loss: 1.4409\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4396 - val_loss: 1.4396\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4368 - val_loss: 1.4358\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4348 - val_loss: 1.4342\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4332 - val_loss: 1.4342\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4323 - val_loss: 1.4322\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4312 - val_loss: 1.4321\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4301 - val_loss: 1.4319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4299 - val_loss: 1.4310\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4289 - val_loss: 1.4301\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4280 - val_loss: 1.4299\n",
      "Top-2 accuracy = 0.613\n",
      "6\n",
      "maxabsq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5868 - val_loss: 1.5574\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5145 - val_loss: 1.4762\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4631 - val_loss: 1.4542\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4491 - val_loss: 1.4464\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4442 - val_loss: 1.4430\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4413 - val_loss: 1.4420\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4392 - val_loss: 1.4394\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4370 - val_loss: 1.4370\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4357\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4336\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4331\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4322\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4318\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4309\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4315\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4311\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4295\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4293\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4294\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4293\n",
      "Top-2 accuracy = 0.612\n",
      "7\n",
      "maxabse|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5995 - val_loss: 1.5964\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5841 - val_loss: 1.5683\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5466 - val_loss: 1.5280\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5084 - val_loss: 1.4931\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4825 - val_loss: 1.4764\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4690 - val_loss: 1.4655\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4609 - val_loss: 1.4605\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4569 - val_loss: 1.4575\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4546 - val_loss: 1.4553\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4517 - val_loss: 1.4523\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4501 - val_loss: 1.4513\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4494 - val_loss: 1.4505\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4489 - val_loss: 1.4498\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4483 - val_loss: 1.4502\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4497 - val_loss: 1.4484\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4482\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4472 - val_loss: 1.4498\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4489\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4468 - val_loss: 1.4494\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4469 - val_loss: 1.4496\n",
      "Top-2 accuracy = 0.605\n",
      "8\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5393 - val_loss: 1.4615\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4399 - val_loss: 1.4342\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4296\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4288\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4318\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4265\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4279\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4251\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4255\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4209 - val_loss: 1.4242\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4243\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4197 - val_loss: 1.4276\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4211 - val_loss: 1.4236\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4181 - val_loss: 1.4252\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4185 - val_loss: 1.4217\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4170 - val_loss: 1.4222\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4164 - val_loss: 1.4211\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4169 - val_loss: 1.4219\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4161 - val_loss: 1.4215\n",
      "Top-2 accuracy = 0.619\n",
      "9\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3477 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5998 - val_loss: 1.5911\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5802 - val_loss: 1.5731\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5627 - val_loss: 1.5562\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5458 - val_loss: 1.5388\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5251 - val_loss: 1.5154\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5059 - val_loss: 1.5024\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4945 - val_loss: 1.4895\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4833 - val_loss: 1.4808\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4764 - val_loss: 1.4741\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4707 - val_loss: 1.4688\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4658 - val_loss: 1.4636\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4607 - val_loss: 1.4588\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4559 - val_loss: 1.4541\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4519 - val_loss: 1.4509\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4497 - val_loss: 1.4494\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4485 - val_loss: 1.4482\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4476 - val_loss: 1.4473\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4467 - val_loss: 1.4467\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4457 - val_loss: 1.4459\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4449 - val_loss: 1.4451\n",
      "Top-2 accuracy = 0.605\n",
      "10\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5848 - val_loss: 1.5367\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4908 - val_loss: 1.4630\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4481 - val_loss: 1.4463\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4368 - val_loss: 1.4386\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4423\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4335\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4319\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4310\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4277 - val_loss: 1.4316\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4272 - val_loss: 1.4305\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4281 - val_loss: 1.4307\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4264 - val_loss: 1.4312\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4295\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4295\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4299\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4243 - val_loss: 1.4307\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4247 - val_loss: 1.4282\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4290\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4310\n",
      "Top-2 accuracy = 0.612\n",
      "11\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5549 - val_loss: 1.5017\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4715 - val_loss: 1.4598\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4473 - val_loss: 1.4400\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4405 - val_loss: 1.4446\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4386 - val_loss: 1.4560\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4409 - val_loss: 1.4423\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4362 - val_loss: 1.4341\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4353 - val_loss: 1.4340\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4343 - val_loss: 1.4367\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4357 - val_loss: 1.4368\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4345 - val_loss: 1.4328\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4338 - val_loss: 1.4352\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4338 - val_loss: 1.4376\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4326 - val_loss: 1.4381\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4352 - val_loss: 1.4349\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4335 - val_loss: 1.4323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4341 - val_loss: 1.4338\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4343 - val_loss: 1.4353\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4323 - val_loss: 1.4341\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4311 - val_loss: 1.4328\n",
      "Top-2 accuracy = 0.613\n",
      "12\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3494 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5923 - val_loss: 1.5657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5453 - val_loss: 1.5287\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5089 - val_loss: 1.4954\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4847 - val_loss: 1.4759\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4677 - val_loss: 1.4623\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4569 - val_loss: 1.4546\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4513 - val_loss: 1.4510\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4501\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4477 - val_loss: 1.4483\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4468 - val_loss: 1.4483\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4466 - val_loss: 1.4475\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4460 - val_loss: 1.4481\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4476\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4455 - val_loss: 1.4467\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4452 - val_loss: 1.4466\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4448 - val_loss: 1.4466\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4461\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4443 - val_loss: 1.4462\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4459\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4440 - val_loss: 1.4460\n",
      "Top-2 accuracy = 0.607\n",
      "13\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5580 - val_loss: 1.4992\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4677 - val_loss: 1.4444\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4353 - val_loss: 1.4369\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4325\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4294\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4281\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.4280\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4253\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4222 - val_loss: 1.4255\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4212 - val_loss: 1.4260\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4206 - val_loss: 1.4284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4190 - val_loss: 1.4302\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4190 - val_loss: 1.4239\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4182 - val_loss: 1.4237\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4181 - val_loss: 1.4250\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.4237\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4172 - val_loss: 1.4242\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4168 - val_loss: 1.4229\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4170 - val_loss: 1.4220\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4157 - val_loss: 1.4236\n",
      "Top-2 accuracy = 0.616\n",
      "14\n",
      "maxabsM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5992 - val_loss: 1.5945\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5704 - val_loss: 1.5279\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4982 - val_loss: 1.4730\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4635 - val_loss: 1.4557\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4527 - val_loss: 1.4506\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4488 - val_loss: 1.4488\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4472 - val_loss: 1.4474\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4474\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4459 - val_loss: 1.4464\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4447 - val_loss: 1.4468\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4442 - val_loss: 1.4453\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4443 - val_loss: 1.4443\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4434 - val_loss: 1.4452\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4427 - val_loss: 1.4437\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4429\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4425\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4410 - val_loss: 1.4415\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4408 - val_loss: 1.4434\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4400 - val_loss: 1.4406\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4392 - val_loss: 1.4405\n",
      "Top-2 accuracy = 0.608\n",
      "15\n",
      "normalizen|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3511 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5867 - val_loss: 1.5549\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5191 - val_loss: 1.4921\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4797 - val_loss: 1.4722\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4661 - val_loss: 1.4623\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4585 - val_loss: 1.4566\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4531 - val_loss: 1.4517\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4487 - val_loss: 1.4486\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4450 - val_loss: 1.4439\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4411\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4385 - val_loss: 1.4388\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4358 - val_loss: 1.4356\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4337 - val_loss: 1.4339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4317 - val_loss: 1.4335\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4304 - val_loss: 1.4315\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4293 - val_loss: 1.4311\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4281 - val_loss: 1.4294\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4273 - val_loss: 1.4291\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4269 - val_loss: 1.4286\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4260 - val_loss: 1.4280\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4252 - val_loss: 1.4277\n",
      "Top-2 accuracy = 0.614\n",
      "16\n",
      "normalizez|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3515 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5955 - val_loss: 1.5765\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5322 - val_loss: 1.4916\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4744 - val_loss: 1.4666\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4595 - val_loss: 1.4571\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4517 - val_loss: 1.4498\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4465 - val_loss: 1.4452\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4426 - val_loss: 1.4418\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4395 - val_loss: 1.4390\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4373 - val_loss: 1.4375\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4370\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4348 - val_loss: 1.4353\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4338 - val_loss: 1.4357\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4330\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4321\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4295 - val_loss: 1.4319\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4308\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4284 - val_loss: 1.4314\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4274 - val_loss: 1.4294\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4265 - val_loss: 1.4301\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4258 - val_loss: 1.4289\n",
      "Top-2 accuracy = 0.614\n",
      "17\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5205 - val_loss: 1.4572\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4424\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4364 - val_loss: 1.4391\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4348\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4340\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4322\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4401\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4314\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4301\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4303\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4307\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4299\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4327\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4334\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4296\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4318\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4367\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4294\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4381\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4280\n",
      "Top-2 accuracy = 0.614\n",
      "18\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5407 - val_loss: 1.4991\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4661 - val_loss: 1.4488\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4445 - val_loss: 1.4438\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4406 - val_loss: 1.4383\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4354 - val_loss: 1.4346\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4336 - val_loss: 1.4370\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4316 - val_loss: 1.4301\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4294 - val_loss: 1.4307\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4312 - val_loss: 1.4287\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4295 - val_loss: 1.4537\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4307 - val_loss: 1.4313\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4295 - val_loss: 1.4285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4286 - val_loss: 1.4281\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4361\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4275 - val_loss: 1.4274\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4283\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4285 - val_loss: 1.4348\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4295 - val_loss: 1.4306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4311\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4319\n",
      "Top-2 accuracy = 0.609\n",
      "19\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6071 - val_loss: 1.6029\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6005 - val_loss: 1.5998\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5960 - val_loss: 1.5890\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5604 - val_loss: 1.5354\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5259 - val_loss: 1.5183\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5117 - val_loss: 1.5063\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5018 - val_loss: 1.4988\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4943 - val_loss: 1.4913\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4879 - val_loss: 1.4856\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4824 - val_loss: 1.4820\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4783 - val_loss: 1.4770\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4736 - val_loss: 1.4730\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4701 - val_loss: 1.4693\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4664 - val_loss: 1.4658\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4633 - val_loss: 1.4625\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4604 - val_loss: 1.4599\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4580 - val_loss: 1.4573\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4555 - val_loss: 1.4548\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4533 - val_loss: 1.4542\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4513 - val_loss: 1.4512\n",
      "Top-2 accuracy = 0.608\n",
      "20\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5769 - val_loss: 1.5373\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5064 - val_loss: 1.4840\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4716 - val_loss: 1.4654\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4585 - val_loss: 1.4550\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4503 - val_loss: 1.4481\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4461 - val_loss: 1.4451\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4437 - val_loss: 1.4428\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4429 - val_loss: 1.4419\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4427 - val_loss: 1.4438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4414 - val_loss: 1.4408\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4406 - val_loss: 1.4407\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4404 - val_loss: 1.4398\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4395 - val_loss: 1.4395\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4395 - val_loss: 1.4406\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4388\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4390 - val_loss: 1.4390\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4383 - val_loss: 1.4388\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4376 - val_loss: 1.4380\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.4408\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4370 - val_loss: 1.4376\n",
      "Top-2 accuracy = 0.611\n",
      "21\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5846 - val_loss: 1.5411\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4944 - val_loss: 1.4676\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4605 - val_loss: 1.4577\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4547 - val_loss: 1.4519\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4434\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4407 - val_loss: 1.4441\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4397 - val_loss: 1.4408\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4385 - val_loss: 1.4382\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4373\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4381\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4353 - val_loss: 1.4354\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4355 - val_loss: 1.4358\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4367\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 1.4346\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4355\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4333\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4343\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4339 - val_loss: 1.4352\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4333\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4334\n",
      "Top-2 accuracy = 0.613\n",
      "22\n",
      "robusty|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3546 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5763 - val_loss: 1.5277\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4946 - val_loss: 1.4722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4623 - val_loss: 1.4584\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4512 - val_loss: 1.4505\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4469\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4404 - val_loss: 1.4439\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4374 - val_loss: 1.4395\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4341 - val_loss: 1.4396\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4315 - val_loss: 1.4361\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4336\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4285 - val_loss: 1.4346\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4275 - val_loss: 1.4342\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4252 - val_loss: 1.4323\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4239 - val_loss: 1.4313\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4237 - val_loss: 1.4304\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4232 - val_loss: 1.4310\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4305\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4216 - val_loss: 1.4305\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4205 - val_loss: 1.4296\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4193 - val_loss: 1.4282\n",
      "Top-2 accuracy = 0.618\n",
      "23\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5562 - val_loss: 1.4893\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4673 - val_loss: 1.4597\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4550 - val_loss: 1.4545\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4510 - val_loss: 1.4521\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4488 - val_loss: 1.4502\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4473 - val_loss: 1.4488\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4462 - val_loss: 1.4477\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4481\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4442 - val_loss: 1.4450\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4426 - val_loss: 1.4438\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4410 - val_loss: 1.4432\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4400 - val_loss: 1.4426\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4393 - val_loss: 1.4409\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4394\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4358 - val_loss: 1.4377\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4361\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4358\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4350\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4340\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4338\n",
      "Top-2 accuracy = 0.612\n",
      "24\n",
      "robustY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5553 - val_loss: 1.4810\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4600 - val_loss: 1.4387\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4344 - val_loss: 1.4341\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4305 - val_loss: 1.4286\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4288 - val_loss: 1.4305\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4282 - val_loss: 1.4286\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4454\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4280\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4272\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4236 - val_loss: 1.4264\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4225 - val_loss: 1.4284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.4275\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4223 - val_loss: 1.4254\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4205 - val_loss: 1.4274\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4204 - val_loss: 1.4324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4215 - val_loss: 1.4250\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4178 - val_loss: 1.4231\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4196 - val_loss: 1.4256\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4176 - val_loss: 1.4214\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4167 - val_loss: 1.4261\n",
      "Top-2 accuracy = 0.618\n",
      "25\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5850 - val_loss: 1.5529\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5314 - val_loss: 1.5099\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4853 - val_loss: 1.4686\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4597 - val_loss: 1.4572\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4541 - val_loss: 1.4547\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4514 - val_loss: 1.4518\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4498 - val_loss: 1.4506\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4492 - val_loss: 1.4491\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4484\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4465 - val_loss: 1.4468\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4449 - val_loss: 1.4470\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4444 - val_loss: 1.4451\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4433\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4432\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4402 - val_loss: 1.4409\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4390 - val_loss: 1.4398\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4389\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4362 - val_loss: 1.4382\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4381\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 1.4364\n",
      "Top-2 accuracy = 0.613\n",
      "26\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5391 - val_loss: 1.4788\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4587 - val_loss: 1.4512\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4397 - val_loss: 1.4335\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4317 - val_loss: 1.4346\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4294 - val_loss: 1.4304\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4282 - val_loss: 1.4290\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4264 - val_loss: 1.4295\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4273 - val_loss: 1.4429\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4308 - val_loss: 1.4298\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4306\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4334\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4271 - val_loss: 1.4291\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4292\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4244 - val_loss: 1.4280\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4245 - val_loss: 1.4271\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4237 - val_loss: 1.4280\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4238 - val_loss: 1.4314\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4232 - val_loss: 1.4296\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4246 - val_loss: 1.4263\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4230 - val_loss: 1.4274\n",
      "Top-2 accuracy = 0.614\n",
      "27\n",
      "robusth|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5454 - val_loss: 1.4761\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4585 - val_loss: 1.4471\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4429 - val_loss: 1.4393\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4378 - val_loss: 1.4361\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4333 - val_loss: 1.4377\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4312\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4305 - val_loss: 1.4302\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4294\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4277 - val_loss: 1.4321\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4302\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4258 - val_loss: 1.4315\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4234 - val_loss: 1.4263\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4214 - val_loss: 1.4261\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4206 - val_loss: 1.4245\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4194 - val_loss: 1.4249\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4190 - val_loss: 1.4244\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4185 - val_loss: 1.4253\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4182 - val_loss: 1.4276\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4177 - val_loss: 1.4238\n",
      "Top-2 accuracy = 0.619\n",
      "28\n",
      "normalizei|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5949 - val_loss: 1.5725\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5339 - val_loss: 1.4939\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4747 - val_loss: 1.4623\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4543 - val_loss: 1.4526\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4482 - val_loss: 1.4470\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4440\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4431 - val_loss: 1.4430\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4419 - val_loss: 1.4422\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4411 - val_loss: 1.4415\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4405 - val_loss: 1.4409\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4399 - val_loss: 1.4417\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4400 - val_loss: 1.4413\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4400 - val_loss: 1.4397\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4394 - val_loss: 1.4397\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4392\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4413\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4397\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4385 - val_loss: 1.4394\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4386 - val_loss: 1.4390\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4400 - val_loss: 1.4387\n",
      "Top-2 accuracy = 0.611\n",
      "29\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5754 - val_loss: 1.5186\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4816 - val_loss: 1.4611\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4507 - val_loss: 1.4486\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4407 - val_loss: 1.4409\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.4422\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4362 - val_loss: 1.4355\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4377\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4353\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4373\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4372\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4341\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4339\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4360\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4322\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4343\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4332\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4321\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4351\n",
      "Top-2 accuracy = 0.612\n",
      "0\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5532 - val_loss: 1.5039\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4689 - val_loss: 1.4511\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4434 - val_loss: 1.4419\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4371 - val_loss: 1.4396\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4343 - val_loss: 1.4439\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4343 - val_loss: 1.4441\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4343 - val_loss: 1.4342\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4319 - val_loss: 1.4363\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4306 - val_loss: 1.4370\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4299 - val_loss: 1.4343\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4307 - val_loss: 1.4349\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4305 - val_loss: 1.4362\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4291 - val_loss: 1.4319\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4284 - val_loss: 1.4332\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4324 - val_loss: 1.4323\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4277 - val_loss: 1.4316\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4279 - val_loss: 1.4315\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4263 - val_loss: 1.4322\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4275 - val_loss: 1.4324\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4279 - val_loss: 1.4297\n",
      "Top-2 accuracy = 0.615\n",
      "1\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3593 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5831 - val_loss: 1.5537\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5217 - val_loss: 1.4939\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4830 - val_loss: 1.4740\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4693 - val_loss: 1.4642\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4621 - val_loss: 1.4582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4566 - val_loss: 1.4534\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4522 - val_loss: 1.4494\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4479 - val_loss: 1.4453\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4437 - val_loss: 1.4419\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4403 - val_loss: 1.4389\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4372 - val_loss: 1.4373\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4349 - val_loss: 1.4349\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4328 - val_loss: 1.4333\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4315 - val_loss: 1.4319\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4297 - val_loss: 1.4308\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4285 - val_loss: 1.4294\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4277 - val_loss: 1.4291\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4268 - val_loss: 1.4284\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4262 - val_loss: 1.4279\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4254 - val_loss: 1.4273\n",
      "Top-2 accuracy = 0.614\n",
      "2\n",
      "normalizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5694 - val_loss: 1.5154\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4820 - val_loss: 1.4480\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4392 - val_loss: 1.4365\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4352 - val_loss: 1.4368\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4320 - val_loss: 1.4308\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4332 - val_loss: 1.4315\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4305 - val_loss: 1.4342\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4315 - val_loss: 1.4294\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4301 - val_loss: 1.4301\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4313 - val_loss: 1.4349\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4295 - val_loss: 1.4420\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4285 - val_loss: 1.4325\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4280 - val_loss: 1.4315\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4276 - val_loss: 1.4268\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4269 - val_loss: 1.4286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4274 - val_loss: 1.4281\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4266 - val_loss: 1.4292\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4293 - val_loss: 1.4295\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4268 - val_loss: 1.4274\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4296 - val_loss: 1.4289\n",
      "Top-2 accuracy = 0.615\n",
      "3\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3603 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5607 - val_loss: 1.5146\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4895 - val_loss: 1.4752\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4605 - val_loss: 1.4550\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4463\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4402 - val_loss: 1.4401\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4359 - val_loss: 1.4364\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4369\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4327\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4309\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4306\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4292\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4231 - val_loss: 1.4286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4281\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4218 - val_loss: 1.4265\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4282\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4198 - val_loss: 1.4263\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.4255\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4181 - val_loss: 1.4242\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4180 - val_loss: 1.4252\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4171 - val_loss: 1.4252\n",
      "Top-2 accuracy = 0.613\n",
      "4\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5281 - val_loss: 1.4689\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4509 - val_loss: 1.4462\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4431 - val_loss: 1.4439\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4386 - val_loss: 1.4377\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4337 - val_loss: 1.4339\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4308 - val_loss: 1.4296\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4330\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4291\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4281 - val_loss: 1.4314\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4273 - val_loss: 1.4282\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4261 - val_loss: 1.4329\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4261 - val_loss: 1.4306\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4258 - val_loss: 1.4277\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4251 - val_loss: 1.4290\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4251 - val_loss: 1.4293\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4306\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4261 - val_loss: 1.4298\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4273 - val_loss: 1.4334\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4258 - val_loss: 1.4281\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4251 - val_loss: 1.4339\n",
      "Top-2 accuracy = 0.612\n",
      "5\n",
      "robustp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5452 - val_loss: 1.4646\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4451 - val_loss: 1.4397\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4347 - val_loss: 1.4360\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4361\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4347\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4344\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4328\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4325\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4312\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4307\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4299\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4329\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4282\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4282\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4197 - val_loss: 1.4279\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4179 - val_loss: 1.4269\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4187 - val_loss: 1.4258\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4177 - val_loss: 1.4250\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4169 - val_loss: 1.4243\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4158 - val_loss: 1.4258\n",
      "Top-2 accuracy = 0.62\n",
      "6\n",
      "minmaxG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5810\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5220 - val_loss: 1.4898\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4644 - val_loss: 1.4604\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4518 - val_loss: 1.4488\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4490 - val_loss: 1.4701\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4569 - val_loss: 1.4496\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4480 - val_loss: 1.4507\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4500 - val_loss: 1.4463\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4468 - val_loss: 1.4460\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4463 - val_loss: 1.4480\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4466 - val_loss: 1.4492\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4465 - val_loss: 1.4538\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4469 - val_loss: 1.4452\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4465 - val_loss: 1.4465\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4453 - val_loss: 1.4459\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4451 - val_loss: 1.4453\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4454 - val_loss: 1.4456\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4446 - val_loss: 1.4459\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4451 - val_loss: 1.4443\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4443 - val_loss: 1.4450\n",
      "Top-2 accuracy = 0.607\n",
      "7\n",
      "standardizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5493 - val_loss: 1.4908\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4633 - val_loss: 1.4522\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4438 - val_loss: 1.4428\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4363\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4342\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4326\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4306\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4321\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4289\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4279\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4273\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.4264\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4260\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4270\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4249\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4223 - val_loss: 1.4256\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4222 - val_loss: 1.4243\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4207 - val_loss: 1.4239\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4206 - val_loss: 1.4231\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4204 - val_loss: 1.4228\n",
      "Top-2 accuracy = 0.617\n",
      "8\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6000 - val_loss: 1.5654\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5053 - val_loss: 1.4694\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4555 - val_loss: 1.4508\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4443 - val_loss: 1.4442\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4396 - val_loss: 1.4389\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4368 - val_loss: 1.4374\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4347 - val_loss: 1.4364\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4330 - val_loss: 1.4335\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4328\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4319\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4308\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4304\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4307\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4308\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4313\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4302\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4294\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4297\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4315\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4296\n",
      "Top-2 accuracy = 0.615\n",
      "9\n",
      "standardizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5712 - val_loss: 1.5416\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5193 - val_loss: 1.4968\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4764 - val_loss: 1.4633\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4553 - val_loss: 1.4513\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4488 - val_loss: 1.4490\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4467 - val_loss: 1.4467\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4457 - val_loss: 1.4467\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4454 - val_loss: 1.4462\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4452 - val_loss: 1.4466\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4447 - val_loss: 1.4462\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4447 - val_loss: 1.4452\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4444 - val_loss: 1.4483\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4466 - val_loss: 1.4472\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4448 - val_loss: 1.4478\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4438 - val_loss: 1.4453\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4437 - val_loss: 1.4455\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4450 - val_loss: 1.4457\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4442 - val_loss: 1.4452\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4436 - val_loss: 1.4456\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4436 - val_loss: 1.4458\n",
      "Top-2 accuracy = 0.604\n",
      "10\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3637 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5961 - val_loss: 1.5755\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5457 - val_loss: 1.5170\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4995 - val_loss: 1.4883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4782 - val_loss: 1.4758\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4676 - val_loss: 1.4667\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4598 - val_loss: 1.4592\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4532 - val_loss: 1.4535\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4483 - val_loss: 1.4485\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4442 - val_loss: 1.4452\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4409 - val_loss: 1.4409\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4378 - val_loss: 1.4385\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4365\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4347\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4339\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4323\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4312\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4312\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4296\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4290\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4285\n",
      "Top-2 accuracy = 0.618\n",
      "11\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5568 - val_loss: 1.4855\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4607 - val_loss: 1.4510\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4443 - val_loss: 1.4426\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4423 - val_loss: 1.4405\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4415 - val_loss: 1.4387\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4361 - val_loss: 1.4455\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4321 - val_loss: 1.4577\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4347 - val_loss: 1.4314\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4311 - val_loss: 1.4311\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4287 - val_loss: 1.4319\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4290 - val_loss: 1.4326\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4276 - val_loss: 1.4350\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4298 - val_loss: 1.4328\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4281 - val_loss: 1.4287\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4274 - val_loss: 1.4275\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4266 - val_loss: 1.4389\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4260 - val_loss: 1.4345\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4251 - val_loss: 1.4373\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4262 - val_loss: 1.4304\n",
      "Top-2 accuracy = 0.609\n",
      "12\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5637 - val_loss: 1.5112\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4752 - val_loss: 1.4554\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4467 - val_loss: 1.4437\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4387\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4358 - val_loss: 1.4341\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4322\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4306\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4306\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4282\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4273\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4270\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4249 - val_loss: 1.4264\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.4260\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4238 - val_loss: 1.4250\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4233 - val_loss: 1.4256\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4243\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4254\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4232\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4236\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4241\n",
      "Top-2 accuracy = 0.62\n",
      "13\n",
      "standardized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5553 - val_loss: 1.4953\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4714 - val_loss: 1.4569\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4497 - val_loss: 1.4489\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4453 - val_loss: 1.4468\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4444 - val_loss: 1.4452\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4419 - val_loss: 1.4450\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4413 - val_loss: 1.4426\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4399 - val_loss: 1.4416\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4407\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4383 - val_loss: 1.4401\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4398\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4369 - val_loss: 1.4419\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4385\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4355 - val_loss: 1.4373\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4374\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4343 - val_loss: 1.4370\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4359\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4363\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4353\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4345\n",
      "Top-2 accuracy = 0.613\n",
      "14\n",
      "standardizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5489 - val_loss: 1.4996\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4745 - val_loss: 1.4596\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4506 - val_loss: 1.4488\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4454 - val_loss: 1.4461\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4451 - val_loss: 1.4607\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4463 - val_loss: 1.4461\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4451 - val_loss: 1.4472\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4438 - val_loss: 1.4458\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4436 - val_loss: 1.4459\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4436 - val_loss: 1.4458\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4435 - val_loss: 1.4461\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4438 - val_loss: 1.4451\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4434 - val_loss: 1.4456\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4455 - val_loss: 1.4462\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4428 - val_loss: 1.4452\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4423 - val_loss: 1.4453\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4429 - val_loss: 1.4464\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4428 - val_loss: 1.4452\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4429 - val_loss: 1.4469\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4442 - val_loss: 1.4458\n",
      "Top-2 accuracy = 0.605\n",
      "15\n",
      "maxabso|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5199 - val_loss: 1.4645\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4475 - val_loss: 1.4378\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4342 - val_loss: 1.4337\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4314 - val_loss: 1.4328\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4292 - val_loss: 1.4360\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4303 - val_loss: 1.4310\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4385\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4311\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4284 - val_loss: 1.4311\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4334\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4304\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4264 - val_loss: 1.4307\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4298\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4316\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4310\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4318\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4315\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4248 - val_loss: 1.4301\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4249 - val_loss: 1.4308\n",
      "Top-2 accuracy = 0.613\n",
      "16\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6007 - val_loss: 1.5886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5723 - val_loss: 1.5522\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5370 - val_loss: 1.5222\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5135 - val_loss: 1.5036\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4976 - val_loss: 1.4912\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4877 - val_loss: 1.4838\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4807 - val_loss: 1.4784\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4753 - val_loss: 1.4738\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4711 - val_loss: 1.4704\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4676 - val_loss: 1.4675\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4646 - val_loss: 1.4662\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4626 - val_loss: 1.4630\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4604 - val_loss: 1.4618\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4585 - val_loss: 1.4604\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4575 - val_loss: 1.4585\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4559 - val_loss: 1.4575\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4549 - val_loss: 1.4561\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4539 - val_loss: 1.4561\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4532 - val_loss: 1.4545\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4520 - val_loss: 1.4539\n",
      "Top-2 accuracy = 0.604\n",
      "17\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6013 - val_loss: 1.5946\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5738 - val_loss: 1.5375\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5133 - val_loss: 1.4886\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4693 - val_loss: 1.4598\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4524 - val_loss: 1.4525\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4481 - val_loss: 1.4495\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4455 - val_loss: 1.4464\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4435 - val_loss: 1.4442\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4417 - val_loss: 1.4441\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4405 - val_loss: 1.4409\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4396 - val_loss: 1.4411\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4386 - val_loss: 1.4395\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4377 - val_loss: 1.4392\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4368 - val_loss: 1.4372\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4363 - val_loss: 1.4376\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4378\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4369\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4362\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4363\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4339 - val_loss: 1.4360\n",
      "Top-2 accuracy = 0.61\n",
      "18\n",
      "robustN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5939 - val_loss: 1.5779\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5552 - val_loss: 1.5359\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5160 - val_loss: 1.5032\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4899 - val_loss: 1.4823\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4691 - val_loss: 1.4617\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4533 - val_loss: 1.4510\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4449 - val_loss: 1.4447\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4409 - val_loss: 1.4410\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4398\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4377 - val_loss: 1.4384\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4369 - val_loss: 1.4382\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4364 - val_loss: 1.4384\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4362 - val_loss: 1.4389\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4363 - val_loss: 1.4370\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4368\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4371\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4363 - val_loss: 1.4365\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4347 - val_loss: 1.4380\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4355 - val_loss: 1.4359\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4353 - val_loss: 1.4358\n",
      "Top-2 accuracy = 0.608\n",
      "19\n",
      "minmaxp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.6056 - val_loss: 1.6026\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6002 - val_loss: 1.5999\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5982 - val_loss: 1.5991\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5976 - val_loss: 1.5987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Top-2 accuracy = 0.456\n",
      "20\n",
      "minmaxa|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 1.6005 - val_loss: 1.5992\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5988\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "21\n",
      "standardizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5493 - val_loss: 1.4962\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4683 - val_loss: 1.4521\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4433 - val_loss: 1.4408\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4368 - val_loss: 1.4373\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4357 - val_loss: 1.4370\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4333 - val_loss: 1.4350\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4328 - val_loss: 1.4350\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4308 - val_loss: 1.4341\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4290 - val_loss: 1.4341\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4281 - val_loss: 1.4314\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4270 - val_loss: 1.4313\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4273 - val_loss: 1.4299\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4298\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4249 - val_loss: 1.4291\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4306\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4249 - val_loss: 1.4276\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4232 - val_loss: 1.4275\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4225 - val_loss: 1.4274\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4221 - val_loss: 1.4271\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4227 - val_loss: 1.4267\n",
      "Top-2 accuracy = 0.616\n",
      "22\n",
      "minmaxX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5766 - val_loss: 1.5428\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5195 - val_loss: 1.4971\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4682 - val_loss: 1.4539\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4412 - val_loss: 1.4444\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4379 - val_loss: 1.4378\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4323 - val_loss: 1.4366\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4333 - val_loss: 1.4459\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4318 - val_loss: 1.4340\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4310 - val_loss: 1.4385\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4320 - val_loss: 1.4387\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4311 - val_loss: 1.4331\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4288 - val_loss: 1.4345\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4312 - val_loss: 1.4341\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4295 - val_loss: 1.4366\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4300 - val_loss: 1.4334\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4271 - val_loss: 1.4309\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4306 - val_loss: 1.4356\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4311 - val_loss: 1.4328\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4295 - val_loss: 1.4333\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4271 - val_loss: 1.4470\n",
      "Top-2 accuracy = 0.602\n",
      "23\n",
      "minmaxQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5923 - val_loss: 1.5523\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4894 - val_loss: 1.4585\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4529 - val_loss: 1.4514\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4461 - val_loss: 1.4521\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4432 - val_loss: 1.4432\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4393\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4396\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4365 - val_loss: 1.4402\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4367\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4375\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4336 - val_loss: 1.4362\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4336 - val_loss: 1.4339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4343\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4344\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4361\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4357\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4331\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4338\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4391\n",
      "Top-2 accuracy = 0.605\n",
      "24\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6013 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5977 - val_loss: 1.5984\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5981\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5962 - val_loss: 1.5955\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5862 - val_loss: 1.5633\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5320 - val_loss: 1.5042\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4891 - val_loss: 1.4770\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4691 - val_loss: 1.4645\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4601 - val_loss: 1.4574\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4548 - val_loss: 1.4537\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4521 - val_loss: 1.4522\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4507 - val_loss: 1.4509\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4497 - val_loss: 1.4497\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4491 - val_loss: 1.4496\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4487 - val_loss: 1.4490\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4488\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4482 - val_loss: 1.4496\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4481 - val_loss: 1.4490\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4482 - val_loss: 1.4487\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4481 - val_loss: 1.4486\n",
      "Top-2 accuracy = 0.604\n",
      "25\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5886 - val_loss: 1.5524\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5269 - val_loss: 1.5013\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4874 - val_loss: 1.4757\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4671 - val_loss: 1.4615\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4570 - val_loss: 1.4554\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4527 - val_loss: 1.4510\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4491 - val_loss: 1.4490\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4479 - val_loss: 1.4495\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4473 - val_loss: 1.4475\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4463 - val_loss: 1.4492\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4469\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4462 - val_loss: 1.4464\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4457 - val_loss: 1.4463\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4458 - val_loss: 1.4471\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4460 - val_loss: 1.4467\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4463 - val_loss: 1.4461\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4457 - val_loss: 1.4471\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4463\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4449 - val_loss: 1.4478\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4455 - val_loss: 1.4457\n",
      "Top-2 accuracy = 0.605\n",
      "26\n",
      "maxabsW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5378 - val_loss: 1.4600\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4403 - val_loss: 1.4370\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4315 - val_loss: 1.4342\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4282 - val_loss: 1.4431\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4300 - val_loss: 1.4322\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4294\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4245 - val_loss: 1.4300\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4246 - val_loss: 1.4283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4238 - val_loss: 1.4295\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.4266\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4289\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4237 - val_loss: 1.4263\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4207 - val_loss: 1.4260\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4203 - val_loss: 1.4322\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4204 - val_loss: 1.4233\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4175 - val_loss: 1.4233\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4175 - val_loss: 1.4255\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4167 - val_loss: 1.4238\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4164 - val_loss: 1.4238\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4155 - val_loss: 1.4277\n",
      "Top-2 accuracy = 0.615\n",
      "27\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5497 - val_loss: 1.4875\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4598 - val_loss: 1.4423\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4333 - val_loss: 1.4344\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4292 - val_loss: 1.4338\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4277 - val_loss: 1.4308\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4270 - val_loss: 1.4331\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4265 - val_loss: 1.4302\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4264 - val_loss: 1.4310\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4283\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4241 - val_loss: 1.4324\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4247 - val_loss: 1.4293\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4241 - val_loss: 1.4289\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4242 - val_loss: 1.4296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4238 - val_loss: 1.4280\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.4297\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4232 - val_loss: 1.4279\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4225 - val_loss: 1.4283\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4222 - val_loss: 1.4290\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4223 - val_loss: 1.4309\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4222 - val_loss: 1.4282\n",
      "Top-2 accuracy = 0.614\n",
      "28\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.6017 - val_loss: 1.5907\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5737 - val_loss: 1.5599\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5472 - val_loss: 1.5380\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5292 - val_loss: 1.5239\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5165 - val_loss: 1.5135\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5081 - val_loss: 1.5039\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4926 - val_loss: 1.4854\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4759 - val_loss: 1.4743\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4688 - val_loss: 1.4675\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4624 - val_loss: 1.4619\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4572 - val_loss: 1.4572\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4538 - val_loss: 1.4538\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4523 - val_loss: 1.4520\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4501 - val_loss: 1.4501\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4486 - val_loss: 1.4479\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4476 - val_loss: 1.4472\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4480 - val_loss: 1.4495\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4453 - val_loss: 1.4442\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4442 - val_loss: 1.4434\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4433 - val_loss: 1.4525\n",
      "Top-2 accuracy = 0.603\n",
      "29\n",
      "minmaxF|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3741 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6051 - val_loss: 1.6022\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5995 - val_loss: 1.5994\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5972 - val_loss: 1.5968\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5883 - val_loss: 1.5760\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5495 - val_loss: 1.5232\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5057 - val_loss: 1.4925\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4869 - val_loss: 1.4797\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4770 - val_loss: 1.4722\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4708 - val_loss: 1.4671\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4664 - val_loss: 1.4629\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4630 - val_loss: 1.4594\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4598 - val_loss: 1.4568\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4575 - val_loss: 1.4545\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4556 - val_loss: 1.4532\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4540 - val_loss: 1.4520\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4532 - val_loss: 1.4507\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4521 - val_loss: 1.4504\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4517 - val_loss: 1.4499\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4514 - val_loss: 1.4501\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4508 - val_loss: 1.4496\n",
      "Top-2 accuracy = 0.603\n",
      "0\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5681 - val_loss: 1.5098\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4793 - val_loss: 1.4599\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4495 - val_loss: 1.4498\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4400 - val_loss: 1.4364\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4353 - val_loss: 1.4387\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4347 - val_loss: 1.4325\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4355\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4334 - val_loss: 1.4310\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4294 - val_loss: 1.4288\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4286 - val_loss: 1.4287\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4283 - val_loss: 1.4294\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4384\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4281 - val_loss: 1.4271\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4268 - val_loss: 1.4313\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4292\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4243\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4259\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4255\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4238 - val_loss: 1.4295\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4244\n",
      "Top-2 accuracy = 0.616\n",
      "1\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5399 - val_loss: 1.4797\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4546 - val_loss: 1.4422\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4321\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4287\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4275\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4275\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4253 - val_loss: 1.4252\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4238 - val_loss: 1.4256\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4253\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4233 - val_loss: 1.4254\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4222 - val_loss: 1.4241\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4223 - val_loss: 1.4232\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4232\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4301\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4234\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4309\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4223\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4249\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4238\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4199 - val_loss: 1.4267\n",
      "Top-2 accuracy = 0.612\n",
      "2\n",
      "standardizej|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5537 - val_loss: 1.4960\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4742 - val_loss: 1.4539\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4434 - val_loss: 1.4351\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4388 - val_loss: 1.4392\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4356 - val_loss: 1.4370\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4316 - val_loss: 1.4572\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4481 - val_loss: 1.4433\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4347 - val_loss: 1.4391\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4331 - val_loss: 1.4707\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4318 - val_loss: 1.4297\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4288 - val_loss: 1.4304\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4280 - val_loss: 1.4404\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4330 - val_loss: 1.4332\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4281 - val_loss: 1.4315\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4275 - val_loss: 1.4285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4268 - val_loss: 1.4282\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4262 - val_loss: 1.4373\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4276 - val_loss: 1.4274\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4279 - val_loss: 1.4299\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4253 - val_loss: 1.4315\n",
      "Top-2 accuracy = 0.614\n",
      "3\n",
      "minmaxG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5494 - val_loss: 1.4791\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4556 - val_loss: 1.4457\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4396 - val_loss: 1.4433\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4359 - val_loss: 1.4387\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4343 - val_loss: 1.4374\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4336 - val_loss: 1.4346\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4351\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4360\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4329\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4324\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4324\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4287 - val_loss: 1.4307\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4302\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4304\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4294\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4298\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4303\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4286\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4271\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4283\n",
      "Top-2 accuracy = 0.615\n",
      "4\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5730 - val_loss: 1.5140\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4780 - val_loss: 1.4596\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4514 - val_loss: 1.4459\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4420 - val_loss: 1.4419\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4387 - val_loss: 1.4397\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4365 - val_loss: 1.4388\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4339 - val_loss: 1.4354\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4332\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4324\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4325\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4312\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4299\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4288\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4317\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4247 - val_loss: 1.4278\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4277\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4269\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4214 - val_loss: 1.4272\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4206 - val_loss: 1.4275\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4198 - val_loss: 1.4281\n",
      "Top-2 accuracy = 0.615\n",
      "5\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5852 - val_loss: 1.5560\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5391 - val_loss: 1.5153\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4970 - val_loss: 1.4793\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4684 - val_loss: 1.4636\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4558 - val_loss: 1.4545\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4479 - val_loss: 1.4499\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4443\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4404 - val_loss: 1.4404\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4370 - val_loss: 1.4382\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4388\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4355 - val_loss: 1.4362\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4353\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4348\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4372\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4347\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4345\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4346\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4330\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4325\n",
      "Top-2 accuracy = 0.613\n",
      "6\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.6049 - val_loss: 1.6010\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5991 - val_loss: 1.5988\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5977 - val_loss: 1.5985\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5975 - val_loss: 1.5985\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Top-2 accuracy = 0.456\n",
      "7\n",
      "minmaxZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5794 - val_loss: 1.5254\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4860 - val_loss: 1.4682\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4568 - val_loss: 1.4511\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4454 - val_loss: 1.4436\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4393 - val_loss: 1.4395\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4365 - val_loss: 1.4380\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4349 - val_loss: 1.4389\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 1.4422\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4330 - val_loss: 1.4471\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4366\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4387\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4366\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4360\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4571\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4334\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4355\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4330\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4320\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4358\n",
      "Top-2 accuracy = 0.609\n",
      "8\n",
      "normalizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5930 - val_loss: 1.5628\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5114 - val_loss: 1.4722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4598 - val_loss: 1.4566\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4482 - val_loss: 1.4466\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4434 - val_loss: 1.4444\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4412\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4382\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4370 - val_loss: 1.4372\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4359 - val_loss: 1.4371\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4354\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4351\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4340\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4345\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4347\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4329\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4336\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4338\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4334\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4314 - val_loss: 1.4324\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4321\n",
      "Top-2 accuracy = 0.613\n",
      "9\n",
      "minmaxs|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5967 - val_loss: 1.5740\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5473 - val_loss: 1.5218\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4987 - val_loss: 1.4859\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4750 - val_loss: 1.4695\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4631 - val_loss: 1.4629\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4576 - val_loss: 1.4548\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4524 - val_loss: 1.4570\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4507 - val_loss: 1.4507\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4492 - val_loss: 1.4493\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4491 - val_loss: 1.4510\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4487 - val_loss: 1.4483\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4478 - val_loss: 1.4496\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4484 - val_loss: 1.4482\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4479 - val_loss: 1.4484\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4473 - val_loss: 1.4521\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4477 - val_loss: 1.4481\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4474 - val_loss: 1.4514\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4522 - val_loss: 1.4506\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4475 - val_loss: 1.4477\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4474 - val_loss: 1.4482\n",
      "Top-2 accuracy = 0.602\n",
      "10\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6056 - val_loss: 1.6029\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6006 - val_loss: 1.6001\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5986 - val_loss: 1.5990\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5977 - val_loss: 1.5987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "11\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6003 - val_loss: 1.5979\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5502 - val_loss: 1.4767\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4592 - val_loss: 1.4530\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4476 - val_loss: 1.4537\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4447 - val_loss: 1.4484\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4439 - val_loss: 1.4448\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4426 - val_loss: 1.4438\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4425 - val_loss: 1.4445\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4553\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4426 - val_loss: 1.4427\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4407 - val_loss: 1.4435\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4415 - val_loss: 1.4423\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4414 - val_loss: 1.4548\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4551\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4513 - val_loss: 1.4429\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4405 - val_loss: 1.4445\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4408 - val_loss: 1.4418\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4397 - val_loss: 1.4412\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4408 - val_loss: 1.4418\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4403 - val_loss: 1.4414\n",
      "Top-2 accuracy = 0.61\n",
      "12\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6009 - val_loss: 1.5849\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5602 - val_loss: 1.5410\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5231 - val_loss: 1.5110\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4936 - val_loss: 1.4854\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4706 - val_loss: 1.4637\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4572 - val_loss: 1.4545\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4518 - val_loss: 1.4661\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4510 - val_loss: 1.4504\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4510 - val_loss: 1.4491\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4505\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4487 - val_loss: 1.4483\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4487\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4478 - val_loss: 1.4484\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4483 - val_loss: 1.4487\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4478\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4575\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4482\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4488\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4480 - val_loss: 1.4486\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4493\n",
      "Top-2 accuracy = 0.602\n",
      "13\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5989 - val_loss: 1.5859\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5643 - val_loss: 1.5403\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5238 - val_loss: 1.5062\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4901 - val_loss: 1.4746\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4673 - val_loss: 1.4601\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4553 - val_loss: 1.4524\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4493 - val_loss: 1.4490\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4465 - val_loss: 1.4472\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4453 - val_loss: 1.4455\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4442 - val_loss: 1.4450\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4448\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4440\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4428 - val_loss: 1.4439\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4432\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4422 - val_loss: 1.4449\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4435\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4420 - val_loss: 1.4435\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4423 - val_loss: 1.4431\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4439\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4448\n",
      "Top-2 accuracy = 0.607\n",
      "14\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5984 - val_loss: 1.5720\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5037 - val_loss: 1.4706\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4661 - val_loss: 1.4601\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4560 - val_loss: 1.4561\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4465 - val_loss: 1.4471\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4355 - val_loss: 1.4398\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4330 - val_loss: 1.4358\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4315 - val_loss: 1.4363\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4285 - val_loss: 1.4332\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4277 - val_loss: 1.4343\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4274 - val_loss: 1.4348\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4271 - val_loss: 1.4337\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4319\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4244 - val_loss: 1.4307\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4229 - val_loss: 1.4329\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4230 - val_loss: 1.4358\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4219 - val_loss: 1.4328\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4224 - val_loss: 1.4294\n",
      "Top-2 accuracy = 0.612\n",
      "15\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5921 - val_loss: 1.5617\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5257 - val_loss: 1.4995\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4844 - val_loss: 1.4756\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4671 - val_loss: 1.4638\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4582 - val_loss: 1.4582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4529 - val_loss: 1.4519\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4479 - val_loss: 1.4471\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4438 - val_loss: 1.4457\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4425 - val_loss: 1.4434\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4415 - val_loss: 1.4430\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4409 - val_loss: 1.4420\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4413 - val_loss: 1.4411\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4411 - val_loss: 1.4402\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4397 - val_loss: 1.4404\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4394 - val_loss: 1.4403\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4394 - val_loss: 1.4397\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4392 - val_loss: 1.4407\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4393 - val_loss: 1.4396\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4398\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4408\n",
      "Top-2 accuracy = 0.608\n",
      "16\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5611 - val_loss: 1.5066\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4763 - val_loss: 1.4566\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4461 - val_loss: 1.4407\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4379 - val_loss: 1.4358\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4355 - val_loss: 1.4407\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4346 - val_loss: 1.4326\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4315 - val_loss: 1.4409\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4369 - val_loss: 1.4315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4311 - val_loss: 1.4327\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4322 - val_loss: 1.4315\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4384\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4304\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4303\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4286 - val_loss: 1.4379\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4291 - val_loss: 1.4301\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4290\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4272 - val_loss: 1.4354\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4276 - val_loss: 1.4291\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4276 - val_loss: 1.4311\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4266 - val_loss: 1.4299\n",
      "Top-2 accuracy = 0.614\n",
      "17\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5247 - val_loss: 1.4629\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4428 - val_loss: 1.4353\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4334 - val_loss: 1.4399\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4345 - val_loss: 1.4299\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4299 - val_loss: 1.4352\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4279 - val_loss: 1.4278\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4281 - val_loss: 1.4316\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4268 - val_loss: 1.4380\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4264 - val_loss: 1.4279\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4240 - val_loss: 1.4339\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4275\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4230 - val_loss: 1.4267\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4223 - val_loss: 1.4259\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4233 - val_loss: 1.4290\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4215 - val_loss: 1.4292\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4202 - val_loss: 1.4592\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4259 - val_loss: 1.4257\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4199 - val_loss: 1.4252\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4202 - val_loss: 1.4232\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4216 - val_loss: 1.4263\n",
      "Top-2 accuracy = 0.617\n",
      "18\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5878 - val_loss: 1.5448\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5004 - val_loss: 1.4698\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4606 - val_loss: 1.4530\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4490 - val_loss: 1.4466\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4430 - val_loss: 1.4417\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4413 - val_loss: 1.4406\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4375 - val_loss: 1.4346\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4340 - val_loss: 1.4444\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4294\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4300 - val_loss: 1.4340\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4314 - val_loss: 1.4337\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4313\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4287 - val_loss: 1.4287\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4282 - val_loss: 1.4277\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4273\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4296\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4278\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4288\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4279\n",
      "Top-2 accuracy = 0.613\n",
      "19\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5980 - val_loss: 1.5860\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5067 - val_loss: 1.4653\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4552 - val_loss: 1.4539\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4498 - val_loss: 1.4489\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4490 - val_loss: 1.4504\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4488 - val_loss: 1.4467\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4462 - val_loss: 1.4492\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4462 - val_loss: 1.4473\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4472 - val_loss: 1.4465\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4455 - val_loss: 1.4453\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4477 - val_loss: 1.4461\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4466 - val_loss: 1.4489\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4449 - val_loss: 1.4481\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4455 - val_loss: 1.4492\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4450 - val_loss: 1.4436\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4445 - val_loss: 1.4437\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4443 - val_loss: 1.4442\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4436 - val_loss: 1.4422\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4427 - val_loss: 1.4435\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4445 - val_loss: 1.4425\n",
      "Top-2 accuracy = 0.606\n",
      "20\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5838 - val_loss: 1.5434\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4985 - val_loss: 1.4738\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4634 - val_loss: 1.4587\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4538 - val_loss: 1.4518\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4492 - val_loss: 1.4484\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4460 - val_loss: 1.4456\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4435 - val_loss: 1.4447\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4435 - val_loss: 1.4447\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4402\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4397 - val_loss: 1.4398\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4380 - val_loss: 1.4396\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4376\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4368 - val_loss: 1.4377\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4375\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4364 - val_loss: 1.4352\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4386\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4358 - val_loss: 1.4342\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4340\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4333 - val_loss: 1.4339\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4333 - val_loss: 1.4335\n",
      "Top-2 accuracy = 0.61\n",
      "21\n",
      "normalizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5775 - val_loss: 1.5247\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4857 - val_loss: 1.4712\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4485 - val_loss: 1.4427\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4365 - val_loss: 1.4387\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4329\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4320\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4311\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4320\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4303 - val_loss: 1.4357\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4313\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4321\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4312\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4315\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4350\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4299\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4298\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4307\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4293\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4295\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4264 - val_loss: 1.4293\n",
      "Top-2 accuracy = 0.615\n",
      "22\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6055 - val_loss: 1.6030\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6007 - val_loss: 1.6001\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5986 - val_loss: 1.5991\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5977 - val_loss: 1.5987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "23\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5535 - val_loss: 1.4633\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4465 - val_loss: 1.4377\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4327 - val_loss: 1.4340\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4279 - val_loss: 1.4305\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4259 - val_loss: 1.4284\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4253 - val_loss: 1.4301\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4240 - val_loss: 1.4267\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4218 - val_loss: 1.4249\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4233 - val_loss: 1.4280\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4198 - val_loss: 1.4284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4217 - val_loss: 1.4249\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4185 - val_loss: 1.4287\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4188 - val_loss: 1.4273\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4188 - val_loss: 1.4305\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4161 - val_loss: 1.4244\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4168 - val_loss: 1.4228\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4157 - val_loss: 1.4267\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4148 - val_loss: 1.4229\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4154 - val_loss: 1.4244\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4160 - val_loss: 1.4339\n",
      "Top-2 accuracy = 0.613\n",
      "24\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5583 - val_loss: 1.4786\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4621 - val_loss: 1.4504\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4494 - val_loss: 1.4444\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4436 - val_loss: 1.4437\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4420 - val_loss: 1.4428\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4390 - val_loss: 1.4463\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4358 - val_loss: 1.4497\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4375 - val_loss: 1.4353\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4329 - val_loss: 1.4320\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4295 - val_loss: 1.4305\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4308\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4291 - val_loss: 1.4295\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4284 - val_loss: 1.4304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4279 - val_loss: 1.4312\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4281 - val_loss: 1.4297\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4291\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4272 - val_loss: 1.4283\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4261 - val_loss: 1.4351\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4285 - val_loss: 1.4304\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4276 - val_loss: 1.4311\n",
      "Top-2 accuracy = 0.61\n",
      "25\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5525 - val_loss: 1.5021\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4767 - val_loss: 1.4583\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4537 - val_loss: 1.4502\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4479 - val_loss: 1.4489\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4420 - val_loss: 1.4423\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4368 - val_loss: 1.4385\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 1.4355\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4342\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4351\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4350\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4327\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4312\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4310\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4313\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4302\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4294\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4287\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4289\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4280\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4295\n",
      "Top-2 accuracy = 0.615\n",
      "26\n",
      "standardizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5420 - val_loss: 1.4859\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4632 - val_loss: 1.4587\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4426 - val_loss: 1.4355\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4325 - val_loss: 1.4347\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4311 - val_loss: 1.4328\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4312 - val_loss: 1.4320\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4290 - val_loss: 1.4321\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4279 - val_loss: 1.4315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4293 - val_loss: 1.4326\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4262 - val_loss: 1.4324\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4285 - val_loss: 1.4334\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4282 - val_loss: 1.4530\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4302 - val_loss: 1.4343\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4263 - val_loss: 1.4298\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4254 - val_loss: 1.4302\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4247 - val_loss: 1.4291\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4242 - val_loss: 1.4351\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4284 - val_loss: 1.4311\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4249 - val_loss: 1.4300\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4251 - val_loss: 1.4305\n",
      "Top-2 accuracy = 0.614\n",
      "27\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5634 - val_loss: 1.5182\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4930 - val_loss: 1.4738\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4559 - val_loss: 1.4448\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4437 - val_loss: 1.4493\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4449 - val_loss: 1.4475\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4424 - val_loss: 1.4395\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4422 - val_loss: 1.4465\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4430 - val_loss: 1.4447\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4404 - val_loss: 1.4413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4394 - val_loss: 1.4467\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4435 - val_loss: 1.4398\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4412 - val_loss: 1.4429\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4403 - val_loss: 1.4345\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4328 - val_loss: 1.4321\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4319 - val_loss: 1.4395\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4306 - val_loss: 1.4297\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4285 - val_loss: 1.4288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4288 - val_loss: 1.4401\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4309 - val_loss: 1.4337\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4275 - val_loss: 1.4452\n",
      "Top-2 accuracy = 0.595\n",
      "28\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5464 - val_loss: 1.4810\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4630 - val_loss: 1.4578\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4528 - val_loss: 1.4519\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4494 - val_loss: 1.4538\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4488 - val_loss: 1.4492\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4497 - val_loss: 1.4492\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4485 - val_loss: 1.4485\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4493 - val_loss: 1.4476\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4478 - val_loss: 1.4512\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4489 - val_loss: 1.4507\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4472 - val_loss: 1.4475\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4474 - val_loss: 1.4611\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4499 - val_loss: 1.4470\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4466 - val_loss: 1.4472\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4475 - val_loss: 1.4463\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4462 - val_loss: 1.4469\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4467 - val_loss: 1.4466\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4459 - val_loss: 1.4475\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4460 - val_loss: 1.4481\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4469 - val_loss: 1.4461\n",
      "Top-2 accuracy = 0.603\n",
      "29\n",
      "minmaxU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5842 - val_loss: 1.5462\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5167 - val_loss: 1.4925\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4729 - val_loss: 1.4577\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4507 - val_loss: 1.4498\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4419 - val_loss: 1.4423\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4383 - val_loss: 1.4415\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4369 - val_loss: 1.4378\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4410\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4365\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4339 - val_loss: 1.4344\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4343 - val_loss: 1.4346\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4362\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4342\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4362\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4335\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4329\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4314 - val_loss: 1.4331\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4314 - val_loss: 1.4339\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4336\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4326\n",
      "Top-2 accuracy = 0.609\n",
      "0\n",
      "maxabsH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5697 - val_loss: 1.5102\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4776 - val_loss: 1.4597\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4504 - val_loss: 1.4476\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4415 - val_loss: 1.4373\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4353 - val_loss: 1.4341\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4330 - val_loss: 1.4391\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4332 - val_loss: 1.4343\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4304\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4290\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4272 - val_loss: 1.4325\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4276 - val_loss: 1.4293\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4281 - val_loss: 1.4270\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4267\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4292\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4270\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4260 - val_loss: 1.4271\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4272 - val_loss: 1.4261\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4248 - val_loss: 1.4417\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4262 - val_loss: 1.4269\n",
      "Top-2 accuracy = 0.616\n",
      "1\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5254 - val_loss: 1.4711\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4592 - val_loss: 1.4471\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4440 - val_loss: 1.4423\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4355 - val_loss: 1.4329\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4307 - val_loss: 1.4294\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4289 - val_loss: 1.4391\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4329 - val_loss: 1.4321\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4268 - val_loss: 1.4293\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4255 - val_loss: 1.4266\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4250 - val_loss: 1.4283\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4248 - val_loss: 1.4255\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4235 - val_loss: 1.4325\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4254 - val_loss: 1.4267\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4243 - val_loss: 1.4352\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4240 - val_loss: 1.4282\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4232 - val_loss: 1.4256\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4219 - val_loss: 1.4261\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4235 - val_loss: 1.4299\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4227 - val_loss: 1.4264\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4211 - val_loss: 1.4260\n",
      "Top-2 accuracy = 0.615\n",
      "2\n",
      "standardizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5963 - val_loss: 1.5674\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5309 - val_loss: 1.4914\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4701 - val_loss: 1.4590\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4483 - val_loss: 1.4439\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4403 - val_loss: 1.4414\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4376 - val_loss: 1.4377\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4362\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4336 - val_loss: 1.4348\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4340\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4338\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4366\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4335\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4327\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4326\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4325\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4328\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4349\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4355\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4323\n",
      "Top-2 accuracy = 0.612\n",
      "3\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6041 - val_loss: 1.6000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5978 - val_loss: 1.5987\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Top-2 accuracy = 0.456\n",
      "4\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5692 - val_loss: 1.5104\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4708 - val_loss: 1.4424\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4366 - val_loss: 1.4337\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4315 - val_loss: 1.4290\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4288 - val_loss: 1.4269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4307 - val_loss: 1.4282\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4283 - val_loss: 1.4306\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4284 - val_loss: 1.4281\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4262 - val_loss: 1.4281\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4266 - val_loss: 1.4293\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4272\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4342\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4278 - val_loss: 1.4289\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4313\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4290 - val_loss: 1.4271\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4271\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4275\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4264\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4270\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4249 - val_loss: 1.4266\n",
      "Top-2 accuracy = 0.613\n",
      "5\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5537 - val_loss: 1.4766\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4636 - val_loss: 1.4626\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4533 - val_loss: 1.4539\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4437 - val_loss: 1.4450\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4406 - val_loss: 1.4366\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4337 - val_loss: 1.4309\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4308 - val_loss: 1.4432\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4348 - val_loss: 1.4351\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4279 - val_loss: 1.4298\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4284 - val_loss: 1.4354\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4276 - val_loss: 1.4289\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4260 - val_loss: 1.4298\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4267 - val_loss: 1.4294\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4265 - val_loss: 1.4276\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4250 - val_loss: 1.4358\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4280 - val_loss: 1.4328\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4255 - val_loss: 1.4298\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4259 - val_loss: 1.4300\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4297 - val_loss: 1.4316\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4263 - val_loss: 1.4268\n",
      "Top-2 accuracy = 0.614\n",
      "6\n",
      "robustA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5489 - val_loss: 1.4918\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4725 - val_loss: 1.4586\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4496 - val_loss: 1.4448\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4426 - val_loss: 1.4414\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4387 - val_loss: 1.4362\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4350 - val_loss: 1.4404\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4352 - val_loss: 1.4334\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4310 - val_loss: 1.4319\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4295 - val_loss: 1.4323\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4308 - val_loss: 1.4310\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4289 - val_loss: 1.4336\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4283 - val_loss: 1.4316\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4302\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4302\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4276 - val_loss: 1.4294\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4259 - val_loss: 1.4346\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4271 - val_loss: 1.4288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4269 - val_loss: 1.4304\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4283\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4280\n",
      "Top-2 accuracy = 0.61\n",
      "7\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6051 - val_loss: 1.6020\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5995 - val_loss: 1.5994\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5977 - val_loss: 1.5989\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Top-2 accuracy = 0.456\n",
      "8\n",
      "maxabsh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5524 - val_loss: 1.4968\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4748 - val_loss: 1.4558\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4424 - val_loss: 1.4376\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4346 - val_loss: 1.4322\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4311\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4314\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.4342\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4359\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4304\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4286 - val_loss: 1.4317\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4429\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4290\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4280\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4331\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4296\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4286\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4326\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4282\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4299\n",
      "Top-2 accuracy = 0.614\n",
      "9\n",
      "maxabsq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5874 - val_loss: 1.5391\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4926 - val_loss: 1.4725\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4629 - val_loss: 1.4558\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4522 - val_loss: 1.4504\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4478 - val_loss: 1.4468\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4447 - val_loss: 1.4436\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4412\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4396\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4396 - val_loss: 1.4415\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4414\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4379 - val_loss: 1.4355\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4376\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4346 - val_loss: 1.4358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4355\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4378\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4329\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4327\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4343\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4311\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4309\n",
      "Top-2 accuracy = 0.61\n",
      "10\n",
      "minmaxW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6047 - val_loss: 1.5999\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5838 - val_loss: 1.5558\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5264 - val_loss: 1.4984\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4907 - val_loss: 1.4788\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4759 - val_loss: 1.4679\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4656 - val_loss: 1.4619\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4603 - val_loss: 1.4577\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4574 - val_loss: 1.4594\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4550 - val_loss: 1.4559\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4539 - val_loss: 1.4539\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4523 - val_loss: 1.4526\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4520 - val_loss: 1.4533\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4515 - val_loss: 1.4518\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4517 - val_loss: 1.4518\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4500 - val_loss: 1.4554\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4506 - val_loss: 1.4520\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4503 - val_loss: 1.4500\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4489 - val_loss: 1.4503\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4494 - val_loss: 1.4499\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4491 - val_loss: 1.4491\n",
      "Top-2 accuracy = 0.602\n",
      "11\n",
      "normalizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5989 - val_loss: 1.5985\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5976 - val_loss: 1.5985\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5773 - val_loss: 1.6276\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5056 - val_loss: 1.4833\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4660 - val_loss: 1.4733\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4572 - val_loss: 1.4541\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4538 - val_loss: 1.4596\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4515 - val_loss: 1.4526\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4508 - val_loss: 1.4498\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4489 - val_loss: 1.4487\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4480 - val_loss: 1.4491\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4478 - val_loss: 1.4490\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4486 - val_loss: 1.4471\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4491 - val_loss: 1.4559\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4498 - val_loss: 1.4470\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4469 - val_loss: 1.4481\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4489 - val_loss: 1.4513\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4468 - val_loss: 1.4455\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4464 - val_loss: 1.4504\n",
      "Top-2 accuracy = 0.606\n",
      "12\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5466 - val_loss: 1.4820\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4676 - val_loss: 1.4618\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4481 - val_loss: 1.4439\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4392 - val_loss: 1.4381\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4362 - val_loss: 1.4357\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4313 - val_loss: 1.4368\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4358 - val_loss: 1.4336\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4333 - val_loss: 1.4377\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4416 - val_loss: 1.4330\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4293 - val_loss: 1.4396\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4318 - val_loss: 1.4341\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4292 - val_loss: 1.4339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4290 - val_loss: 1.4318\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4275 - val_loss: 1.4434\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4307 - val_loss: 1.4300\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4252 - val_loss: 1.4290\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4266 - val_loss: 1.4310\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4289 - val_loss: 1.4322\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4274 - val_loss: 1.4415\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4274 - val_loss: 1.4312\n",
      "Top-2 accuracy = 0.615\n",
      "13\n",
      "minmaxI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5496 - val_loss: 1.4851\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4647 - val_loss: 1.4512\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4506 - val_loss: 1.4474\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4449 - val_loss: 1.4435\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4405 - val_loss: 1.4426\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4369 - val_loss: 1.4389\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4362 - val_loss: 1.4342\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4350 - val_loss: 1.4343\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4414\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4373\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4329 - val_loss: 1.4352\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4338\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4312 - val_loss: 1.4306\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4303\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4304 - val_loss: 1.4327\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4278 - val_loss: 1.4312\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4264 - val_loss: 1.4400\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4285 - val_loss: 1.4296\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4282\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4291\n",
      "Top-2 accuracy = 0.613\n",
      "14\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6057 - val_loss: 1.6031\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6008 - val_loss: 1.6003\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5986 - val_loss: 1.5991\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5977 - val_loss: 1.5987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "15\n",
      "maxabsF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6002 - val_loss: 1.5982\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5919 - val_loss: 1.5750\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5263 - val_loss: 1.4848\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4685 - val_loss: 1.4571\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4540 - val_loss: 1.4562\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4516 - val_loss: 1.4574\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4508 - val_loss: 1.4510\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4507 - val_loss: 1.4511\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4502 - val_loss: 1.4512\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4497 - val_loss: 1.4528\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4490 - val_loss: 1.4500\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4482 - val_loss: 1.4504\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4484 - val_loss: 1.4495\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4473 - val_loss: 1.4488\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4482 - val_loss: 1.4492\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4477 - val_loss: 1.4482\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4483 - val_loss: 1.4487\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4479 - val_loss: 1.4513\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4476 - val_loss: 1.4481\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4483\n",
      "Top-2 accuracy = 0.602\n",
      "16\n",
      "maxabsa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5478 - val_loss: 1.4864\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4590 - val_loss: 1.4453\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4425 - val_loss: 1.4359\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4407\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4330 - val_loss: 1.4315\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4300\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4311 - val_loss: 1.4405\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4306\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4301\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4286 - val_loss: 1.4340\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4272 - val_loss: 1.4277\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4279 - val_loss: 1.4274\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4274 - val_loss: 1.4305\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4282\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4261\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4259\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4280\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4267\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4243\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4264\n",
      "Top-2 accuracy = 0.614\n",
      "17\n",
      "normalizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5420 - val_loss: 1.4841\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4566 - val_loss: 1.4643\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4481 - val_loss: 1.4412\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4392 - val_loss: 1.4489\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4457 - val_loss: 1.4343\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4381 - val_loss: 1.4488\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4352 - val_loss: 1.4529\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4379 - val_loss: 1.4379\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4379 - val_loss: 1.4405\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4358 - val_loss: 1.4382\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4361 - val_loss: 1.4338\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4374 - val_loss: 1.4419\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4362 - val_loss: 1.4374\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4323 - val_loss: 1.4412\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4343 - val_loss: 1.4398\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4408 - val_loss: 1.4403\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4386 - val_loss: 1.4327\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4300 - val_loss: 1.4300\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4280 - val_loss: 1.4313\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4330 - val_loss: 1.4320\n",
      "Top-2 accuracy = 0.608\n",
      "18\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5788 - val_loss: 1.5162\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4808 - val_loss: 1.4620\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4580 - val_loss: 1.4867\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4565 - val_loss: 1.4496\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4450 - val_loss: 1.4450\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4425 - val_loss: 1.4434\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4416 - val_loss: 1.4391\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4374 - val_loss: 1.4398\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4382 - val_loss: 1.4438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4335 - val_loss: 1.4338\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4308 - val_loss: 1.4456\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4292 - val_loss: 1.4331\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4296 - val_loss: 1.4341\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4271 - val_loss: 1.4302\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4269 - val_loss: 1.4303\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4255 - val_loss: 1.4351\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4269 - val_loss: 1.4347\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4246 - val_loss: 1.4299\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4244 - val_loss: 1.4284\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4241 - val_loss: 1.4372\n",
      "Top-2 accuracy = 0.606\n",
      "19\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3997 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5994 - val_loss: 1.5914\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5812 - val_loss: 1.5684\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5528 - val_loss: 1.5345\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5178 - val_loss: 1.4993\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4861 - val_loss: 1.4757\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4682 - val_loss: 1.4611\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4592 - val_loss: 1.4556\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4548 - val_loss: 1.4524\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4519 - val_loss: 1.4507\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4501 - val_loss: 1.4488\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4487 - val_loss: 1.4482\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4477 - val_loss: 1.4474\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4470 - val_loss: 1.4466\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4461 - val_loss: 1.4465\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4456 - val_loss: 1.4457\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4450 - val_loss: 1.4453\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4445 - val_loss: 1.4450\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4441 - val_loss: 1.4451\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4437 - val_loss: 1.4446\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4439 - val_loss: 1.4442\n",
      "Top-2 accuracy = 0.606\n",
      "20\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5861 - val_loss: 1.5340\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5110 - val_loss: 1.4949\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4833 - val_loss: 1.4761\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4670 - val_loss: 1.4651\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4564 - val_loss: 1.4566\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4512 - val_loss: 1.4513\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4484 - val_loss: 1.4496\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4469 - val_loss: 1.4445\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4429 - val_loss: 1.4489\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4471 - val_loss: 1.4475\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4460 - val_loss: 1.4480\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4460 - val_loss: 1.4484\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4459 - val_loss: 1.4466\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4455 - val_loss: 1.4472\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4453 - val_loss: 1.4480\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4452 - val_loss: 1.4463\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4449 - val_loss: 1.4475\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4452 - val_loss: 1.4462\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4420 - val_loss: 1.4511\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4457 - val_loss: 1.4473\n",
      "Top-2 accuracy = 0.604\n",
      "21\n",
      "robustx|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5714 - val_loss: 1.5428\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5202 - val_loss: 1.5016\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4873 - val_loss: 1.4759\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4678 - val_loss: 1.4618\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4563 - val_loss: 1.4524\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4501 - val_loss: 1.4481\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4479 - val_loss: 1.4477\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4469 - val_loss: 1.4491\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4483 - val_loss: 1.4459\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4454 - val_loss: 1.4464\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4446 - val_loss: 1.4454\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4435 - val_loss: 1.4447\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4438 - val_loss: 1.4465\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4428 - val_loss: 1.4537\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4425 - val_loss: 1.4411\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4398 - val_loss: 1.4406\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4398 - val_loss: 1.4392\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4383 - val_loss: 1.4434\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4387 - val_loss: 1.4381\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4372 - val_loss: 1.4396\n",
      "Top-2 accuracy = 0.606\n",
      "22\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5861 - val_loss: 1.5639\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5418 - val_loss: 1.5200\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5045 - val_loss: 1.4848\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4690 - val_loss: 1.4509\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4405\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4363\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4352\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4349\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4333\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4331 - val_loss: 1.4346\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4340\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4334\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4352\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4323\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4322\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4346\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4316\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4309\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4332\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4307\n",
      "Top-2 accuracy = 0.612\n",
      "23\n",
      "maxabso|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5947 - val_loss: 1.5658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5315 - val_loss: 1.4908\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4725 - val_loss: 1.4550\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4504 - val_loss: 1.4406\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4370 - val_loss: 1.4343\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4316 - val_loss: 1.4486\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4305\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4432\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4288 - val_loss: 1.4366\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4285 - val_loss: 1.4342\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4316\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4265 - val_loss: 1.4291\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4298\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4288\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4353\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4261 - val_loss: 1.4368\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4277 - val_loss: 1.4352\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4295\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4290\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4319\n",
      "Top-2 accuracy = 0.607\n",
      "24\n",
      "normalizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5519 - val_loss: 1.4958\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4688 - val_loss: 1.4532\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4434 - val_loss: 1.4379\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4347 - val_loss: 1.4334\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4320 - val_loss: 1.4324\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4315 - val_loss: 1.4330\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4300\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4277 - val_loss: 1.4317\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4266 - val_loss: 1.4324\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4306\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4246 - val_loss: 1.4295\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4230 - val_loss: 1.4275\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4220 - val_loss: 1.4269\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4233 - val_loss: 1.4265\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4232 - val_loss: 1.4280\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4267\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4217 - val_loss: 1.4287\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4222 - val_loss: 1.4260\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4201 - val_loss: 1.4257\n",
      "Top-2 accuracy = 0.617\n",
      "25\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.6044 - val_loss: 1.6014\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5993 - val_loss: 1.5993\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5978 - val_loss: 1.5988\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "26\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5587 - val_loss: 1.4809\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4486 - val_loss: 1.4355\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4291 - val_loss: 1.4389\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4286 - val_loss: 1.4376\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4277 - val_loss: 1.4301\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4258 - val_loss: 1.4302\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4253 - val_loss: 1.4292\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4257 - val_loss: 1.4292\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4236 - val_loss: 1.4281\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4247 - val_loss: 1.4328\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4260 - val_loss: 1.4275\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4236 - val_loss: 1.4330\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4262 - val_loss: 1.4291\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4235 - val_loss: 1.4284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4231 - val_loss: 1.4321\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4232 - val_loss: 1.4281\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4213 - val_loss: 1.4282\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4216 - val_loss: 1.4428\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4262 - val_loss: 1.4273\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4208 - val_loss: 1.4317\n",
      "Top-2 accuracy = 0.608\n",
      "27\n",
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.6020 - val_loss: 1.5873\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5640 - val_loss: 1.5433\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5226 - val_loss: 1.5080\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4918 - val_loss: 1.4851\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4727 - val_loss: 1.4663\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4578 - val_loss: 1.4554\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4508 - val_loss: 1.4482\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4439 - val_loss: 1.4469\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4421 - val_loss: 1.4412\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4388 - val_loss: 1.4448\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4392 - val_loss: 1.4386\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4366 - val_loss: 1.4390\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4366 - val_loss: 1.4412\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4359 - val_loss: 1.4393\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4380 - val_loss: 1.4367\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4368 - val_loss: 1.4365\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4359 - val_loss: 1.4364\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4350 - val_loss: 1.4355\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4337 - val_loss: 1.4354\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4347 - val_loss: 1.4390\n",
      "Top-2 accuracy = 0.604\n",
      "28\n",
      "normalizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5518 - val_loss: 1.4841\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4566 - val_loss: 1.4498\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4442 - val_loss: 1.4473\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4430 - val_loss: 1.4449\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4419 - val_loss: 1.4417\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4414 - val_loss: 1.4467\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4424 - val_loss: 1.4465\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4423 - val_loss: 1.4448\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4407 - val_loss: 1.4425\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4396 - val_loss: 1.4437\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4392 - val_loss: 1.4413\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4384 - val_loss: 1.4400\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4385 - val_loss: 1.4392\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4366 - val_loss: 1.4412\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4346 - val_loss: 1.4323\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4306 - val_loss: 1.4315\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4288 - val_loss: 1.4301\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4286 - val_loss: 1.4297\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4281 - val_loss: 1.4315\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4262 - val_loss: 1.4283\n",
      "Top-2 accuracy = 0.613\n",
      "29\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5879 - val_loss: 1.5572\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5051 - val_loss: 1.4738\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4642 - val_loss: 1.4621\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4583 - val_loss: 1.4598\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4524 - val_loss: 1.4464\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4378\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4348\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4403\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4332\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4373\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4300\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4281 - val_loss: 1.4306\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4348\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4297\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4292\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4299\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4296\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4324\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4287\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4353\n",
      "Top-2 accuracy = 0.609\n",
      "0\n",
      "normalizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5532 - val_loss: 1.4757\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4535 - val_loss: 1.4411\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4323 - val_loss: 1.4335\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4282 - val_loss: 1.4277\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4247 - val_loss: 1.4279\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4272\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4240 - val_loss: 1.4304\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4233 - val_loss: 1.4292\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4230 - val_loss: 1.4326\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4249 - val_loss: 1.4294\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4232 - val_loss: 1.4270\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4227 - val_loss: 1.4260\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4217 - val_loss: 1.4257\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4214 - val_loss: 1.4267\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4220 - val_loss: 1.4308\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4282\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4227 - val_loss: 1.4275\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4220 - val_loss: 1.4256\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4213 - val_loss: 1.4273\n",
      "Top-2 accuracy = 0.616\n",
      "1\n",
      "robustv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5464 - val_loss: 1.4743\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4727 - val_loss: 1.4709\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4718 - val_loss: 1.4706\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4687 - val_loss: 1.4625\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4640 - val_loss: 1.4799\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4936 - val_loss: 1.5074\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4951 - val_loss: 1.4770\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4710 - val_loss: 1.4635\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4626 - val_loss: 1.4598\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4613 - val_loss: 1.4586\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4567 - val_loss: 1.4552\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4523 - val_loss: 1.4546\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4479 - val_loss: 1.4412\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4418 - val_loss: 1.4414\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4453 - val_loss: 1.4493\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4451 - val_loss: 1.4423\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4402 - val_loss: 1.4376\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4379 - val_loss: 1.4405\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4376 - val_loss: 1.4410\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4464 - val_loss: 1.4466\n",
      "Top-2 accuracy = 0.596\n",
      "2\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.6034 - val_loss: 1.6011\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5987 - val_loss: 1.5994\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5977 - val_loss: 1.5987\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5972 - val_loss: 1.5987\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5972 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Top-2 accuracy = 0.456\n",
      "3\n",
      "robusty|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5918 - val_loss: 1.5670\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5257 - val_loss: 1.4833\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4662 - val_loss: 1.4546\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4490 - val_loss: 1.4423\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4393 - val_loss: 1.4382\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4340\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4321\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4317\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4311\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4286 - val_loss: 1.4323\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4287 - val_loss: 1.4300\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4290\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4290\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4295\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4278\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4283\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4279\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4279\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4275\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4283\n",
      "Top-2 accuracy = 0.615\n",
      "4\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5599 - val_loss: 1.5044\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4793 - val_loss: 1.4606\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4566 - val_loss: 1.4570\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4446 - val_loss: 1.4419\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4376 - val_loss: 1.4373\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4333 - val_loss: 1.4325\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4338 - val_loss: 1.4353\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4309 - val_loss: 1.4315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4309 - val_loss: 1.4305\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4311 - val_loss: 1.4386\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4307 - val_loss: 1.4329\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4297 - val_loss: 1.4310\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4277 - val_loss: 1.4292\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4286 - val_loss: 1.4279\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4261 - val_loss: 1.4313\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4250 - val_loss: 1.4294\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4263 - val_loss: 1.4334\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4273 - val_loss: 1.4302\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4258 - val_loss: 1.4292\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4344 - val_loss: 1.4373\n",
      "Top-2 accuracy = 0.604\n",
      "5\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6037 - val_loss: 1.5999\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5978 - val_loss: 1.5980\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5923 - val_loss: 1.5798\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5485 - val_loss: 1.5244\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5111 - val_loss: 1.5010\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4943 - val_loss: 1.4891\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4847 - val_loss: 1.4812\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4781 - val_loss: 1.4763\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4737 - val_loss: 1.4729\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4698 - val_loss: 1.4694\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4668 - val_loss: 1.4673\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4646 - val_loss: 1.4649\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4622 - val_loss: 1.4629\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4604 - val_loss: 1.4611\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4591 - val_loss: 1.4595\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4576 - val_loss: 1.4588\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4567 - val_loss: 1.4578\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4557 - val_loss: 1.4564\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4546 - val_loss: 1.4558\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4539 - val_loss: 1.4549\n",
      "Top-2 accuracy = 0.602\n",
      "6\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5713 - val_loss: 1.5231\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4744 - val_loss: 1.4500\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4399 - val_loss: 1.4487\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4341 - val_loss: 1.4299\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4289\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4285 - val_loss: 1.4279\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4278 - val_loss: 1.4334\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4279 - val_loss: 1.4288\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4323\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4258 - val_loss: 1.4265\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4246 - val_loss: 1.4264\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4238 - val_loss: 1.4286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4311\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4262\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4275\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4240 - val_loss: 1.4277\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4243 - val_loss: 1.4288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4233 - val_loss: 1.4264\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4248 - val_loss: 1.4258\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4231 - val_loss: 1.4270\n",
      "Top-2 accuracy = 0.611\n",
      "7\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6141 - val_loss: 1.6029\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6002 - val_loss: 1.5971\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5912 - val_loss: 1.5803\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5579 - val_loss: 1.5287\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5050 - val_loss: 1.4805\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4696 - val_loss: 1.4638\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4616 - val_loss: 1.4619\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4598 - val_loss: 1.4625\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4573 - val_loss: 1.4564\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4533 - val_loss: 1.4538\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4522 - val_loss: 1.4529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4503 - val_loss: 1.4532\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4499 - val_loss: 1.4569\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4492 - val_loss: 1.4536\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4482 - val_loss: 1.4488\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4488 - val_loss: 1.4507\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4496\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4479 - val_loss: 1.4480\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4478 - val_loss: 1.4488\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4491\n",
      "Top-2 accuracy = 0.6\n",
      "8\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5410 - val_loss: 1.4769\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4566 - val_loss: 1.4399\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4339 - val_loss: 1.4383\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4302 - val_loss: 1.4326\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4292 - val_loss: 1.4298\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4267 - val_loss: 1.4307\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4266 - val_loss: 1.4334\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4268 - val_loss: 1.4307\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4294 - val_loss: 1.4287\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4249 - val_loss: 1.4314\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4260 - val_loss: 1.4346\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4392\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4246 - val_loss: 1.4287\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4244 - val_loss: 1.4307\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4254 - val_loss: 1.4297\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4250 - val_loss: 1.4332\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4240 - val_loss: 1.4566\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4283 - val_loss: 1.4285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4249 - val_loss: 1.4280\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4232 - val_loss: 1.4284\n",
      "Top-2 accuracy = 0.614\n",
      "9\n",
      "robustF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6023 - val_loss: 1.5917\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5669 - val_loss: 1.5425\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5195 - val_loss: 1.5011\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4860 - val_loss: 1.4787\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4692 - val_loss: 1.4667\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4606 - val_loss: 1.4601\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4556 - val_loss: 1.4557\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4525 - val_loss: 1.4537\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4512 - val_loss: 1.4527\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4500 - val_loss: 1.4510\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4492 - val_loss: 1.4499\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4483 - val_loss: 1.4497\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4484 - val_loss: 1.4490\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4493\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4469 - val_loss: 1.4482\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4468 - val_loss: 1.4479\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4461 - val_loss: 1.4476\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4467\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4444 - val_loss: 1.4456\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4438 - val_loss: 1.4454\n",
      "Top-2 accuracy = 0.607\n",
      "10\n",
      "minmaxg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5375 - val_loss: 1.4987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4604 - val_loss: 1.4505\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4416 - val_loss: 1.4452\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4344 - val_loss: 1.4423\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4352 - val_loss: 1.4437\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4330 - val_loss: 1.4330\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4288 - val_loss: 1.4383\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4289 - val_loss: 1.4340\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4288 - val_loss: 1.4319\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4277 - val_loss: 1.4320\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4252 - val_loss: 1.4298\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4434\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4279 - val_loss: 1.4307\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4284 - val_loss: 1.4292\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4239 - val_loss: 1.4270\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4229 - val_loss: 1.4294\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4227 - val_loss: 1.4260\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4215 - val_loss: 1.4253\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4229 - val_loss: 1.4257\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4212 - val_loss: 1.4270\n",
      "Top-2 accuracy = 0.613\n",
      "11\n",
      "robustz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.6020 - val_loss: 1.5988\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5976 - val_loss: 1.5986\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5984\n",
      "Top-2 accuracy = 0.456\n",
      "12\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5794 - val_loss: 1.5212\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4853 - val_loss: 1.4662\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4584 - val_loss: 1.4468\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4372 - val_loss: 1.4359\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4303 - val_loss: 1.4539\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4300 - val_loss: 1.4351\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4280 - val_loss: 1.4352\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4263 - val_loss: 1.4372\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4258 - val_loss: 1.4332\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4297\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4241 - val_loss: 1.4471\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4269 - val_loss: 1.4296\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4251 - val_loss: 1.4296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4237 - val_loss: 1.4439\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4292\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4236 - val_loss: 1.4360\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4250 - val_loss: 1.4275\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4236 - val_loss: 1.4285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4233 - val_loss: 1.4319\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4224 - val_loss: 1.4324\n",
      "Top-2 accuracy = 0.608\n",
      "13\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.6056 - val_loss: 1.6029\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6006 - val_loss: 1.6001\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5985 - val_loss: 1.5990\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5977 - val_loss: 1.5987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "14\n",
      "standardizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5748 - val_loss: 1.5178\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4877 - val_loss: 1.4684\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4610 - val_loss: 1.4589\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4528 - val_loss: 1.4506\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4483 - val_loss: 1.4512\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4478 - val_loss: 1.4496\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4473 - val_loss: 1.4481\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4468 - val_loss: 1.4478\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4479\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4472 - val_loss: 1.4486\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4467 - val_loss: 1.4469\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4464\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4460 - val_loss: 1.4472\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4464\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4467\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4465\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4459 - val_loss: 1.4465\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4468\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4472 - val_loss: 1.4462\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4455 - val_loss: 1.4462\n",
      "Top-2 accuracy = 0.606\n",
      "15\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5691 - val_loss: 1.5025\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4712 - val_loss: 1.4516\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4508\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4394\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4358 - val_loss: 1.4404\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4349 - val_loss: 1.4390\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4376 - val_loss: 1.4353\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4344\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4335\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4337\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4334\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4337\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4366\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4332\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4328\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4321 - val_loss: 1.4352\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4374\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4325\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4322\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4337\n",
      "Top-2 accuracy = 0.612\n",
      "16\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5780 - val_loss: 1.5484\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5256 - val_loss: 1.5077\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4957 - val_loss: 1.4845\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4797 - val_loss: 1.4722\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4685 - val_loss: 1.4660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4620 - val_loss: 1.4578\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4550 - val_loss: 1.4527\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4509 - val_loss: 1.4492\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4554\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4507 - val_loss: 1.4438\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4413\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4411 - val_loss: 1.4426\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4393 - val_loss: 1.4392\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4379 - val_loss: 1.4392\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4373\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4390 - val_loss: 1.4371\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4371\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4369\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4398\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4369\n",
      "Top-2 accuracy = 0.61\n",
      "17\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5731 - val_loss: 1.5197\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4681 - val_loss: 1.4461\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4315 - val_loss: 1.4321\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4283 - val_loss: 1.4404\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4281 - val_loss: 1.4318\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4266 - val_loss: 1.4291\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4271 - val_loss: 1.4308\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4295\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4262 - val_loss: 1.4295\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4403\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4291\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4293\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4307\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4287\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4246 - val_loss: 1.4294\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4249 - val_loss: 1.4292\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.4299\n",
      "Top-2 accuracy = 0.613\n",
      "18\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5908 - val_loss: 1.5620\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5302 - val_loss: 1.4991\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4809 - val_loss: 1.4687\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4597 - val_loss: 1.4562\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4508 - val_loss: 1.4497\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4466 - val_loss: 1.4468\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4443 - val_loss: 1.4452\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4428 - val_loss: 1.4443\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4422 - val_loss: 1.4434\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4413 - val_loss: 1.4435\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4412 - val_loss: 1.4420\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4406 - val_loss: 1.4429\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4409\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4396 - val_loss: 1.4410\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4392 - val_loss: 1.4418\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4402\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4386 - val_loss: 1.4401\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4386 - val_loss: 1.4401\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4386 - val_loss: 1.4395\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4382 - val_loss: 1.4402\n",
      "Top-2 accuracy = 0.606\n",
      "19\n",
      "normalizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5463 - val_loss: 1.4998\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4646 - val_loss: 1.4562\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4375 - val_loss: 1.4377\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4308 - val_loss: 1.4401\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4301 - val_loss: 1.4350\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4277 - val_loss: 1.4314\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4262 - val_loss: 1.4385\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4260 - val_loss: 1.4351\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4255 - val_loss: 1.4303\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4248 - val_loss: 1.4295\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4244 - val_loss: 1.4290\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4241 - val_loss: 1.4280\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4252 - val_loss: 1.4323\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4238 - val_loss: 1.4306\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4243 - val_loss: 1.4279\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4223 - val_loss: 1.4284\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4250 - val_loss: 1.4310\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4224 - val_loss: 1.4275\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4224 - val_loss: 1.4295\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4230 - val_loss: 1.4281\n",
      "Top-2 accuracy = 0.615\n",
      "20\n",
      "minmaxr|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5752 - val_loss: 1.5492\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5308 - val_loss: 1.5054\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4835 - val_loss: 1.4675\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4590 - val_loss: 1.4559\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4513 - val_loss: 1.4519\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4497 - val_loss: 1.4517\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4498 - val_loss: 1.4541\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4499 - val_loss: 1.4519\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4490 - val_loss: 1.4500\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4499 - val_loss: 1.4497\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4480 - val_loss: 1.4487\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4482 - val_loss: 1.4494\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4485 - val_loss: 1.4501\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4477 - val_loss: 1.4494\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4479 - val_loss: 1.4606\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4516 - val_loss: 1.4495\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4486 - val_loss: 1.4495\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4468 - val_loss: 1.4483\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4473 - val_loss: 1.4494\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4463 - val_loss: 1.4470\n",
      "Top-2 accuracy = 0.604\n",
      "21\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5627 - val_loss: 1.5022\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4898 - val_loss: 1.4787\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4747 - val_loss: 1.4717\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4581 - val_loss: 1.4555\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4540 - val_loss: 1.4548\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4494 - val_loss: 1.4462\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4476 - val_loss: 1.4516\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4456 - val_loss: 1.4485\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4496 - val_loss: 1.4479\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4480 - val_loss: 1.4629\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4477 - val_loss: 1.4459\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4430 - val_loss: 1.4436\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4378 - val_loss: 1.4392\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4380 - val_loss: 1.4395\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4361 - val_loss: 1.4408\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4359 - val_loss: 1.4577\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4452 - val_loss: 1.4357\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4348 - val_loss: 1.4408\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4346 - val_loss: 1.4372\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4347 - val_loss: 1.4410\n",
      "Top-2 accuracy = 0.603\n",
      "22\n",
      "maxabsv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5677 - val_loss: 1.5036\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4746 - val_loss: 1.4591\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4487 - val_loss: 1.4476\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4438 - val_loss: 1.4421\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4371 - val_loss: 1.4373\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4346 - val_loss: 1.4431\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4327 - val_loss: 1.4340\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4344 - val_loss: 1.4376\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4314 - val_loss: 1.4319\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4307 - val_loss: 1.4314\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4294 - val_loss: 1.4321\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4308 - val_loss: 1.4308\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4301 - val_loss: 1.4334\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4299 - val_loss: 1.4312\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4298 - val_loss: 1.4350\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4325 - val_loss: 1.4353\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4296 - val_loss: 1.4317\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4358 - val_loss: 1.4324\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4280 - val_loss: 1.4311\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4272 - val_loss: 1.4336\n",
      "Top-2 accuracy = 0.611\n",
      "23\n",
      "normalizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5992 - val_loss: 1.5876\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5722 - val_loss: 1.5580\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5440 - val_loss: 1.5337\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5211 - val_loss: 1.5120\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5014 - val_loss: 1.4958\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4841 - val_loss: 1.4787\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4703 - val_loss: 1.4663\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4569 - val_loss: 1.4560\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4515 - val_loss: 1.4509\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4477 - val_loss: 1.4514\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4476\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4454 - val_loss: 1.4468\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4450 - val_loss: 1.4483\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4484\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4455 - val_loss: 1.4462\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4442 - val_loss: 1.4466\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4444 - val_loss: 1.4466\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4444 - val_loss: 1.4460\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4438 - val_loss: 1.4479\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4440 - val_loss: 1.4468\n",
      "Top-2 accuracy = 0.605\n",
      "24\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5903 - val_loss: 1.5577\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5438 - val_loss: 1.5363\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5251 - val_loss: 1.5236\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5135 - val_loss: 1.5117\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5034 - val_loss: 1.5041\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4969 - val_loss: 1.4974\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4900 - val_loss: 1.4922\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4845 - val_loss: 1.4889\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4803 - val_loss: 1.4829\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4760 - val_loss: 1.4806\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4737 - val_loss: 1.4757\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4705 - val_loss: 1.4726\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4670 - val_loss: 1.4711\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4637 - val_loss: 1.4683\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4610 - val_loss: 1.4651\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4586 - val_loss: 1.4625\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4568 - val_loss: 1.4614\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4541 - val_loss: 1.4594\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4514 - val_loss: 1.4560\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4497 - val_loss: 1.4546\n",
      "Top-2 accuracy = 0.611\n",
      "25\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5876 - val_loss: 1.5597\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5308 - val_loss: 1.5027\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4845 - val_loss: 1.4696\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4606 - val_loss: 1.4548\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4501 - val_loss: 1.4477\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4441 - val_loss: 1.4438\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4414 - val_loss: 1.4420\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4398 - val_loss: 1.4405\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4389 - val_loss: 1.4394\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4381 - val_loss: 1.4393\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4373 - val_loss: 1.4384\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4368 - val_loss: 1.4382\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4369 - val_loss: 1.4375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4364 - val_loss: 1.4370\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4357 - val_loss: 1.4370\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4353 - val_loss: 1.4365\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4351 - val_loss: 1.4361\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4347 - val_loss: 1.4358\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4343 - val_loss: 1.4357\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4341 - val_loss: 1.4351\n",
      "Top-2 accuracy = 0.609\n",
      "26\n",
      "maxabsH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5593 - val_loss: 1.5212\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4917 - val_loss: 1.4655\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4519 - val_loss: 1.4414\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4361 - val_loss: 1.4365\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4321 - val_loss: 1.4331\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4312 - val_loss: 1.4295\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4286\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4287 - val_loss: 1.4281\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4278\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4274 - val_loss: 1.4279\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4281\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4273\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4307\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4279\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4264 - val_loss: 1.4270\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4313\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4281\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4339\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4271\n",
      "Top-2 accuracy = 0.614\n",
      "27\n",
      "standardizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5641 - val_loss: 1.4882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4576 - val_loss: 1.4491\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4351 - val_loss: 1.4502\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4318 - val_loss: 1.4325\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4308 - val_loss: 1.4323\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4291 - val_loss: 1.4316\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4273 - val_loss: 1.4430\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4293 - val_loss: 1.4322\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4271 - val_loss: 1.4359\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4260 - val_loss: 1.4287\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4254 - val_loss: 1.4413\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4267 - val_loss: 1.4275\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4243 - val_loss: 1.4278\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4250 - val_loss: 1.4266\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4235 - val_loss: 1.4304\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4242 - val_loss: 1.4268\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4227 - val_loss: 1.4288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4241 - val_loss: 1.4265\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4246 - val_loss: 1.4318\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4231 - val_loss: 1.4297\n",
      "Top-2 accuracy = 0.612\n",
      "28\n",
      "normalizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6029 - val_loss: 1.5854\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5550 - val_loss: 1.5347\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5184 - val_loss: 1.5096\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4937 - val_loss: 1.4858\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4712 - val_loss: 1.4678\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4539 - val_loss: 1.4539\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4431 - val_loss: 1.4471\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4385 - val_loss: 1.4406\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4349 - val_loss: 1.4421\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4369\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4371\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4358\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4411\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4346\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4378\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4340\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4355\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4300 - val_loss: 1.4339\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4333\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4344\n",
      "Top-2 accuracy = 0.61\n",
      "29\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5839 - val_loss: 1.5526\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5276 - val_loss: 1.5035\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4865 - val_loss: 1.4720\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4570 - val_loss: 1.4464\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4374 - val_loss: 1.4388\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4313 - val_loss: 1.4352\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4298 - val_loss: 1.4312\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4347\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4290\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4262 - val_loss: 1.4292\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4260 - val_loss: 1.4288\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4282 - val_loss: 1.4299\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4291\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4261 - val_loss: 1.4336\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4275\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4276\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4302\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4272\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.424 - 0s 2ms/step - loss: 1.4242 - val_loss: 1.4270\n",
      "Top-2 accuracy = 0.618\n",
      "0\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4220 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5608 - val_loss: 1.4996\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4704 - val_loss: 1.4550\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4435\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4389\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4344\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4333\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4350\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4291\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4240 - val_loss: 1.4284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4228 - val_loss: 1.4272\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4220 - val_loss: 1.4286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4210 - val_loss: 1.4278\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4201 - val_loss: 1.4263\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4196 - val_loss: 1.4252\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4195 - val_loss: 1.4293\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4180 - val_loss: 1.4255\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4171 - val_loss: 1.4259\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4171 - val_loss: 1.4237\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4162 - val_loss: 1.4256\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4156 - val_loss: 1.4240\n",
      "Top-2 accuracy = 0.618\n",
      "1\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5719 - val_loss: 1.5266\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5031 - val_loss: 1.4909\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4843 - val_loss: 1.4836\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4825 - val_loss: 1.4797\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4730 - val_loss: 1.4705\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4683 - val_loss: 1.4682\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4664 - val_loss: 1.4586\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4635 - val_loss: 1.4639\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4652 - val_loss: 1.4595\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4630 - val_loss: 1.4601\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4604 - val_loss: 1.4586\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4588 - val_loss: 1.4657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4591 - val_loss: 1.4569\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4585 - val_loss: 1.4553\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4573 - val_loss: 1.4561\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4585 - val_loss: 1.4562\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4566 - val_loss: 1.4556\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4573 - val_loss: 1.4595\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4577 - val_loss: 1.4596\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4560 - val_loss: 1.4541\n",
      "Top-2 accuracy = 0.605\n",
      "2\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5703 - val_loss: 1.5249\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5200 - val_loss: 1.4989\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4873 - val_loss: 1.4846\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4790 - val_loss: 1.4725\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4712 - val_loss: 1.4656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4671 - val_loss: 1.4614\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4559 - val_loss: 1.4524\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4498 - val_loss: 1.4508\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4488 - val_loss: 1.4474\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4431 - val_loss: 1.4458\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4419 - val_loss: 1.4406\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4361 - val_loss: 1.4395\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4354 - val_loss: 1.4386\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4357 - val_loss: 1.4374\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4333 - val_loss: 1.4381\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4331 - val_loss: 1.4336\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4323 - val_loss: 1.4340\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4324 - val_loss: 1.4337\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4343 - val_loss: 1.4385\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4306 - val_loss: 1.4400\n",
      "Top-2 accuracy = 0.606\n",
      "3\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.6015 - val_loss: 1.5985\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5974 - val_loss: 1.5988\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5975 - val_loss: 1.5987\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5975 - val_loss: 1.5985\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5975 - val_loss: 1.5987\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5983\n",
      "Top-2 accuracy = 0.456\n",
      "4\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5730 - val_loss: 1.5115\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4650 - val_loss: 1.4504\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4407 - val_loss: 1.4355\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4334 - val_loss: 1.4310\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4331 - val_loss: 1.4395\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4364 - val_loss: 1.4331\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4316 - val_loss: 1.4305\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4293 - val_loss: 1.4357\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4294 - val_loss: 1.4496\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4288 - val_loss: 1.4283\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4274 - val_loss: 1.4318\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4279 - val_loss: 1.4327\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4278 - val_loss: 1.4282\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4254 - val_loss: 1.4270\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4260 - val_loss: 1.4285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4265 - val_loss: 1.4273\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4257 - val_loss: 1.4315\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4268 - val_loss: 1.4279\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4251 - val_loss: 1.4284\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4240 - val_loss: 1.4307\n",
      "Top-2 accuracy = 0.608\n",
      "5\n",
      "robustc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5894 - val_loss: 1.5508\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4951 - val_loss: 1.4579\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4508 - val_loss: 1.4486\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4396 - val_loss: 1.4373\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4333 - val_loss: 1.4515\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4343 - val_loss: 1.4344\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4310 - val_loss: 1.4387\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.4337\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4276 - val_loss: 1.4333\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4274 - val_loss: 1.4348\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4282 - val_loss: 1.4328\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4341\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4268 - val_loss: 1.4303\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4259 - val_loss: 1.4326\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4345\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4320\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4311\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4300\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4240 - val_loss: 1.4316\n",
      "Top-2 accuracy = 0.614\n",
      "6\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5997 - val_loss: 1.5754\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5214 - val_loss: 1.4746\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4650 - val_loss: 1.4695\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4538 - val_loss: 1.4530\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4498 - val_loss: 1.4719\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4522 - val_loss: 1.4496\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4464 - val_loss: 1.4488\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4467 - val_loss: 1.4578\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4462 - val_loss: 1.4463\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4448 - val_loss: 1.4484\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4448 - val_loss: 1.4451\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4439 - val_loss: 1.4453\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4447 - val_loss: 1.4462\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4447 - val_loss: 1.4471\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4441 - val_loss: 1.4539\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4439 - val_loss: 1.4455\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4426 - val_loss: 1.4465\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4431 - val_loss: 1.4623\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4463 - val_loss: 1.4552\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4438 - val_loss: 1.4457\n",
      "Top-2 accuracy = 0.609\n",
      "7\n",
      "robustf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5399 - val_loss: 1.4875\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4650 - val_loss: 1.4531\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4478 - val_loss: 1.4469\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4439\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4411\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4417\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4390 - val_loss: 1.4399\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4377 - val_loss: 1.4391\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4368 - val_loss: 1.4391\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4360 - val_loss: 1.4370\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4356 - val_loss: 1.4372\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4348 - val_loss: 1.4364\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4345 - val_loss: 1.4359\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 1.4355\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4337 - val_loss: 1.4349\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4328 - val_loss: 1.4336\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4336\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4342\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4318 - val_loss: 1.4320\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4307\n",
      "Top-2 accuracy = 0.613\n",
      "8\n",
      "normalizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.6050 - val_loss: 1.6019\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5996 - val_loss: 1.5993\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5979 - val_loss: 1.5987\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "9\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5944 - val_loss: 1.5686\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5331 - val_loss: 1.5004\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4766 - val_loss: 1.4639\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4545 - val_loss: 1.4628\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4503 - val_loss: 1.4479\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4483 - val_loss: 1.4505\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4476 - val_loss: 1.4468\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4468 - val_loss: 1.4469\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4471 - val_loss: 1.4462\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4460 - val_loss: 1.4464\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4476 - val_loss: 1.4472\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4462 - val_loss: 1.4463\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4461 - val_loss: 1.4474\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4461 - val_loss: 1.4463\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4458 - val_loss: 1.4456\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4452 - val_loss: 1.4468\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4451 - val_loss: 1.4451\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4451 - val_loss: 1.4448\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4446 - val_loss: 1.4508\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4461 - val_loss: 1.4475\n",
      "Top-2 accuracy = 0.605\n",
      "10\n",
      "minmaxZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6045 - val_loss: 1.6001\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5932 - val_loss: 1.5807\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5506 - val_loss: 1.5158\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4994 - val_loss: 1.4853\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4743 - val_loss: 1.4646\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4604 - val_loss: 1.4645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4537 - val_loss: 1.4502\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4492 - val_loss: 1.4485\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4468 - val_loss: 1.4597\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4469 - val_loss: 1.4457\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4451 - val_loss: 1.4458\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4452 - val_loss: 1.4447\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4457 - val_loss: 1.4449\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4441 - val_loss: 1.4444\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4443 - val_loss: 1.4449\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4459 - val_loss: 1.4462\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4432 - val_loss: 1.4445\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4434 - val_loss: 1.4439\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4442 - val_loss: 1.4449\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4432 - val_loss: 1.4470\n",
      "Top-2 accuracy = 0.6\n",
      "11\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.6010 - val_loss: 1.5990\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5988\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5988\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "12\n",
      "normalizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5942 - val_loss: 1.5786\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5581 - val_loss: 1.5337\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5107 - val_loss: 1.4880\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4769 - val_loss: 1.4688\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4631 - val_loss: 1.4578\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4547 - val_loss: 1.4531\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4502 - val_loss: 1.4499\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4472 - val_loss: 1.4499\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4455 - val_loss: 1.4467\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4436 - val_loss: 1.4458\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4427 - val_loss: 1.4431\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4443\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4419 - val_loss: 1.4417\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4400 - val_loss: 1.4418\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4393 - val_loss: 1.4409\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4396 - val_loss: 1.4402\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4387 - val_loss: 1.4401\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4383 - val_loss: 1.4395\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4382 - val_loss: 1.4391\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4446\n",
      "Top-2 accuracy = 0.608\n",
      "13\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5858 - val_loss: 1.5554\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5391 - val_loss: 1.5231\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5102 - val_loss: 1.5033\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4986 - val_loss: 1.4975\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4921 - val_loss: 1.4895\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4880 - val_loss: 1.4901\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4855 - val_loss: 1.4867\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4822 - val_loss: 1.4817\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4789 - val_loss: 1.4796\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4768 - val_loss: 1.4754\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4730 - val_loss: 1.4726\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4708 - val_loss: 1.4724\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4695 - val_loss: 1.4702\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4679 - val_loss: 1.4701\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4689 - val_loss: 1.4725\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4676 - val_loss: 1.4692\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4662 - val_loss: 1.4678\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4669 - val_loss: 1.4665\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4632 - val_loss: 1.4632\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4640 - val_loss: 1.4608\n",
      "Top-2 accuracy = 0.598\n",
      "14\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.6027 - val_loss: 1.5997\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5980 - val_loss: 1.5986\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "15\n",
      "normalizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5465 - val_loss: 1.4832\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4628 - val_loss: 1.4549\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4434 - val_loss: 1.4405\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4372 - val_loss: 1.4375\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4348 - val_loss: 1.4365\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4318 - val_loss: 1.4451\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4318 - val_loss: 1.4341\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4294 - val_loss: 1.4329\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4299 - val_loss: 1.4327\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4285 - val_loss: 1.4362\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4304 - val_loss: 1.4360\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4288 - val_loss: 1.4374\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4302 - val_loss: 1.4297\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4260 - val_loss: 1.4501\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4292 - val_loss: 1.4283\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4260 - val_loss: 1.4346\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4279 - val_loss: 1.4298\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4253 - val_loss: 1.4317\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4260 - val_loss: 1.4299\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4258 - val_loss: 1.4281\n",
      "Top-2 accuracy = 0.614\n",
      "16\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5694 - val_loss: 1.5109\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4766 - val_loss: 1.4596\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4558 - val_loss: 1.4785\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4510 - val_loss: 1.4513\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4468 - val_loss: 1.4463\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4460 - val_loss: 1.4452\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4464 - val_loss: 1.4454\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4450 - val_loss: 1.4470\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4473 - val_loss: 1.4434\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4467 - val_loss: 1.4456\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4435 - val_loss: 1.4439\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4429 - val_loss: 1.4425\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4420 - val_loss: 1.4468\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4511 - val_loss: 1.4450\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4440 - val_loss: 1.4438\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4407 - val_loss: 1.4413\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4401 - val_loss: 1.4416\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4408 - val_loss: 1.4524\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4440 - val_loss: 1.4441\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4402 - val_loss: 1.4397\n",
      "Top-2 accuracy = 0.61\n",
      "17\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.6051 - val_loss: 1.6016\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5996 - val_loss: 1.5991\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5978 - val_loss: 1.5985\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Top-2 accuracy = 0.456\n",
      "18\n",
      "normalizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5902 - val_loss: 1.5698\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5240 - val_loss: 1.4938\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4793 - val_loss: 1.4629\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4553 - val_loss: 1.4513\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4445 - val_loss: 1.4498\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4388 - val_loss: 1.4382\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4349 - val_loss: 1.4957\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4361 - val_loss: 1.4332\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4334 - val_loss: 1.4356\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4310 - val_loss: 1.4311\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4306 - val_loss: 1.4368\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4313 - val_loss: 1.4305\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4318 - val_loss: 1.4379\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4293 - val_loss: 1.4324\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4294 - val_loss: 1.4346\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4294 - val_loss: 1.4278\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4278 - val_loss: 1.4416\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4291 - val_loss: 1.4316\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4288 - val_loss: 1.4272\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4265 - val_loss: 1.4367\n",
      "Top-2 accuracy = 0.611\n",
      "19\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5767 - val_loss: 1.5330\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4952 - val_loss: 1.4659\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4536 - val_loss: 1.4535\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4422 - val_loss: 1.4443\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4383 - val_loss: 1.4417\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4356 - val_loss: 1.4395\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4346 - val_loss: 1.4394\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4371 - val_loss: 1.4348\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4326 - val_loss: 1.4370\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4325 - val_loss: 1.4435\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4327 - val_loss: 1.4349\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4317 - val_loss: 1.4342\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4320 - val_loss: 1.4342\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4308 - val_loss: 1.4356\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4305 - val_loss: 1.4335\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4307 - val_loss: 1.4326\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4299 - val_loss: 1.4332\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.4328\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4304 - val_loss: 1.4315\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4304 - val_loss: 1.4316\n",
      "Top-2 accuracy = 0.612\n",
      "20\n",
      "normalizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5774 - val_loss: 1.5466\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5130 - val_loss: 1.4867\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4704 - val_loss: 1.4604\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4526 - val_loss: 1.4507\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4447 - val_loss: 1.4453\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4405 - val_loss: 1.4436\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4386 - val_loss: 1.4387\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4363 - val_loss: 1.4375\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4349 - val_loss: 1.4358\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 1.4353\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4345\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4336\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4334\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4327\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4319\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4315\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4323\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4298 - val_loss: 1.4310\n",
      "Top-2 accuracy = 0.615\n",
      "21\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5703 - val_loss: 1.5458\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5241 - val_loss: 1.4978\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4849 - val_loss: 1.4713\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4651 - val_loss: 1.4585\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4545 - val_loss: 1.4513\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4484 - val_loss: 1.4496\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4449 - val_loss: 1.4441\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4422\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4404\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4382 - val_loss: 1.4388\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4380\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4364 - val_loss: 1.4377\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4355 - val_loss: 1.4368\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4349 - val_loss: 1.4360\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4391\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4399\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4343 - val_loss: 1.4358\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4389\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4351\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4336 - val_loss: 1.4354\n",
      "Top-2 accuracy = 0.608\n",
      "22\n",
      "minmaxz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5771 - val_loss: 1.5572\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5357 - val_loss: 1.5190\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4945 - val_loss: 1.4748\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4675 - val_loss: 1.4653\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4542 - val_loss: 1.4464\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4466 - val_loss: 1.4435\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4462 - val_loss: 1.4419\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4410 - val_loss: 1.4450\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4419 - val_loss: 1.4438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4402 - val_loss: 1.4379\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4397 - val_loss: 1.4367\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4387 - val_loss: 1.4407\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4388 - val_loss: 1.4571\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4428 - val_loss: 1.4391\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4395 - val_loss: 1.4567\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4385 - val_loss: 1.4365\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4380 - val_loss: 1.4368\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4383 - val_loss: 1.4388\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4398 - val_loss: 1.4464\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4380 - val_loss: 1.4357\n",
      "Top-2 accuracy = 0.605\n",
      "23\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5431 - val_loss: 1.4729\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4470 - val_loss: 1.4407\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4318 - val_loss: 1.4338\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4289 - val_loss: 1.4326\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4289 - val_loss: 1.4477\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4272 - val_loss: 1.4366\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4260 - val_loss: 1.4301\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4252 - val_loss: 1.4311\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4241 - val_loss: 1.4284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4240 - val_loss: 1.4286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4239 - val_loss: 1.4286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4242 - val_loss: 1.4338\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4240 - val_loss: 1.4304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4252 - val_loss: 1.4286\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4226 - val_loss: 1.4280\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4236 - val_loss: 1.4338\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4237 - val_loss: 1.4372\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4265 - val_loss: 1.4350\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4230 - val_loss: 1.4324\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4239 - val_loss: 1.4291\n",
      "Top-2 accuracy = 0.615\n",
      "24\n",
      "standardizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.6013 - val_loss: 1.5902\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5689 - val_loss: 1.5423\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5095 - val_loss: 1.4887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4754 - val_loss: 1.4648\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4558 - val_loss: 1.4496\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4429 - val_loss: 1.4429\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4378 - val_loss: 1.4387\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4346 - val_loss: 1.4362\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4324 - val_loss: 1.4353\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4367\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4343\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4402\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4333\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4335\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4338\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4353\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4329\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4333\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4325\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4353\n",
      "Top-2 accuracy = 0.605\n",
      "25\n",
      "robustk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5692 - val_loss: 1.5076\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4683 - val_loss: 1.4485\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4412 - val_loss: 1.4437\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4367 - val_loss: 1.4375\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4339 - val_loss: 1.4319\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4312 - val_loss: 1.4351\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4311 - val_loss: 1.4310\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4295 - val_loss: 1.4316\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4281 - val_loss: 1.4295\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4287 - val_loss: 1.4323\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4295 - val_loss: 1.4312\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4290 - val_loss: 1.4312\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4272 - val_loss: 1.4310\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4277 - val_loss: 1.4309\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4262 - val_loss: 1.4315\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4270 - val_loss: 1.4282\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4272 - val_loss: 1.4289\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4252 - val_loss: 1.4305\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4268 - val_loss: 1.4340\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4277 - val_loss: 1.4281\n",
      "Top-2 accuracy = 0.614\n",
      "26\n",
      "standardizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5793 - val_loss: 1.5387\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5004 - val_loss: 1.4750\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4606 - val_loss: 1.4551\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4487 - val_loss: 1.4481\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4433 - val_loss: 1.4442\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4406 - val_loss: 1.4419\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4406\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4372 - val_loss: 1.4389\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4361 - val_loss: 1.4376\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4365\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4339 - val_loss: 1.4366\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4333 - val_loss: 1.4347\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4342\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4330\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4329\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4318\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4310\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4305\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4297\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4295\n",
      "Top-2 accuracy = 0.61\n",
      "27\n",
      "normalizeW|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6027 - val_loss: 1.5837\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5464 - val_loss: 1.5100\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4881 - val_loss: 1.4711\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4625 - val_loss: 1.4549\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4512 - val_loss: 1.4493\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4472\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4467 - val_loss: 1.4460\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4454 - val_loss: 1.4496\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4474\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4462 - val_loss: 1.4455\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4443 - val_loss: 1.4511\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4436 - val_loss: 1.4454\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4450 - val_loss: 1.4446\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4424 - val_loss: 1.4411\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4399 - val_loss: 1.4412\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4393 - val_loss: 1.4431\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4379 - val_loss: 1.4460\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4402 - val_loss: 1.4381\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4383 - val_loss: 1.4380\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4377\n",
      "Top-2 accuracy = 0.608\n",
      "28\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5846\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5435 - val_loss: 1.5032\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4732 - val_loss: 1.4577\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4492 - val_loss: 1.4501\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4446 - val_loss: 1.4626\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4457 - val_loss: 1.4436\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4431 - val_loss: 1.4426\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4420 - val_loss: 1.4429\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4410 - val_loss: 1.4403\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4392 - val_loss: 1.4398\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4374\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4357\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4342 - val_loss: 1.4400\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4352\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4330\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4331\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4333\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.4352\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4306\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4322\n",
      "Top-2 accuracy = 0.613\n",
      "29\n",
      "robustY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5622 - val_loss: 1.5090\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4810 - val_loss: 1.4625\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4527 - val_loss: 1.4456\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4401\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4414\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4393\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4360\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4375\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4332 - val_loss: 1.4379\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4329 - val_loss: 1.4359\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4332 - val_loss: 1.4337\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4325\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4307 - val_loss: 1.4400\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4314 - val_loss: 1.4320\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4300 - val_loss: 1.4318\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4394\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4373\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4343\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4290 - val_loss: 1.4328\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4320\n",
      "Top-2 accuracy = 0.611\n",
      "0\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.6060 - val_loss: 1.6030\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6005 - val_loss: 1.5996\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5947 - val_loss: 1.5832\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5573 - val_loss: 1.5289\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5017 - val_loss: 1.4794\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4618 - val_loss: 1.4525\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4472 - val_loss: 1.4449\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4404 - val_loss: 1.4433\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4380 - val_loss: 1.4488\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4387 - val_loss: 1.4375\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4367 - val_loss: 1.4366\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4355 - val_loss: 1.4399\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4369 - val_loss: 1.4489\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4371 - val_loss: 1.4371\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4344 - val_loss: 1.4347\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4334 - val_loss: 1.4373\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4351 - val_loss: 1.4379\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4339 - val_loss: 1.4362\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4335 - val_loss: 1.4336\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4333 - val_loss: 1.4406\n",
      "Top-2 accuracy = 0.61\n",
      "1\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5615 - val_loss: 1.5289\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5046 - val_loss: 1.4850\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4623 - val_loss: 1.4471\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4390 - val_loss: 1.4366\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4337 - val_loss: 1.4407\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4324 - val_loss: 1.4493\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4349 - val_loss: 1.4334\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4309 - val_loss: 1.4322\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4297 - val_loss: 1.4330\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4292 - val_loss: 1.4323\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4288 - val_loss: 1.4320\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4285 - val_loss: 1.4324\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4307 - val_loss: 1.4383\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4297 - val_loss: 1.4319\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4287 - val_loss: 1.4321\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4276 - val_loss: 1.4309\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4278 - val_loss: 1.4325\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4282 - val_loss: 1.4309\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4284 - val_loss: 1.4305\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4270 - val_loss: 1.4311\n",
      "Top-2 accuracy = 0.613\n",
      "2\n",
      "maxabsF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5921 - val_loss: 1.5490\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4863 - val_loss: 1.4561\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4468 - val_loss: 1.4433\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4402 - val_loss: 1.4431\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4391 - val_loss: 1.4383\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4371 - val_loss: 1.4368\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4353 - val_loss: 1.4442\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4358 - val_loss: 1.4374\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4363 - val_loss: 1.4358\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4348 - val_loss: 1.4363\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4342 - val_loss: 1.4353\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4334 - val_loss: 1.4373\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4332 - val_loss: 1.4358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4356 - val_loss: 1.4355\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4324 - val_loss: 1.4346\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4335 - val_loss: 1.4373\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4319 - val_loss: 1.4392\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4318 - val_loss: 1.4350\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4321 - val_loss: 1.4368\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4325 - val_loss: 1.4351\n",
      "Top-2 accuracy = 0.615\n",
      "3\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5709 - val_loss: 1.5329\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5092 - val_loss: 1.4942\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4878 - val_loss: 1.4865\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4828 - val_loss: 1.4802\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4780 - val_loss: 1.4767\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4692 - val_loss: 1.4677\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4655 - val_loss: 1.4743\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4612 - val_loss: 1.4618\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4592 - val_loss: 1.4609\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4556 - val_loss: 1.4562\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4529 - val_loss: 1.4544\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4540 - val_loss: 1.4553\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4525 - val_loss: 1.4547\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4509 - val_loss: 1.4533\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4505 - val_loss: 1.4533\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4503 - val_loss: 1.4529\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4492 - val_loss: 1.4515\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4491 - val_loss: 1.4516\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4492 - val_loss: 1.4539\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4486 - val_loss: 1.4508\n",
      "Top-2 accuracy = 0.604\n",
      "4\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5824 - val_loss: 1.5477\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5184 - val_loss: 1.4982\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4768 - val_loss: 1.4651\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4515 - val_loss: 1.4465\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4429\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4319\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4290\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4276\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4266\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4221 - val_loss: 1.4263\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4209 - val_loss: 1.4265\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4206 - val_loss: 1.4225\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4193 - val_loss: 1.4227\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4185 - val_loss: 1.4217\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4182 - val_loss: 1.4240\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4178 - val_loss: 1.4224\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4169 - val_loss: 1.4232\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4167 - val_loss: 1.4234\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4167 - val_loss: 1.4226\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4163 - val_loss: 1.4209\n",
      "Top-2 accuracy = 0.618\n",
      "5\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5995 - val_loss: 1.5954\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5825 - val_loss: 1.5666\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5442 - val_loss: 1.5260\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5107 - val_loss: 1.4990\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4900 - val_loss: 1.4835\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4782 - val_loss: 1.4744\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4712 - val_loss: 1.4690\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4663 - val_loss: 1.4647\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4631 - val_loss: 1.4621\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4606 - val_loss: 1.4608\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4584 - val_loss: 1.4582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4565 - val_loss: 1.4569\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4551 - val_loss: 1.4553\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4540 - val_loss: 1.4546\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4524 - val_loss: 1.4529\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4519 - val_loss: 1.4536\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4510 - val_loss: 1.4523\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4502 - val_loss: 1.4514\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4493 - val_loss: 1.4521\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4495 - val_loss: 1.4499\n",
      "Top-2 accuracy = 0.602\n",
      "6\n",
      "maxabsZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5758 - val_loss: 1.5470\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5352 - val_loss: 1.5145\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4752 - val_loss: 1.4603\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4555 - val_loss: 1.4527\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4473 - val_loss: 1.4444\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4413 - val_loss: 1.4366\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4332 - val_loss: 1.4331\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4294 - val_loss: 1.4323\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4295 - val_loss: 1.4355\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4282 - val_loss: 1.4306\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4262 - val_loss: 1.4305\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4265 - val_loss: 1.4284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4251 - val_loss: 1.4323\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4246 - val_loss: 1.4314\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4255 - val_loss: 1.4287\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4251 - val_loss: 1.4276\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4254 - val_loss: 1.4288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4246 - val_loss: 1.4294\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4237 - val_loss: 1.4326\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4240 - val_loss: 1.4267\n",
      "Top-2 accuracy = 0.615\n",
      "7\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 1.5705 - val_loss: 1.5216\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4968 - val_loss: 1.4853\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5105 - val_loss: 1.5568\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5396 - val_loss: 1.5419\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5374 - val_loss: 1.5124\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5020 - val_loss: 1.5026\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4978 - val_loss: 1.4804\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5137 - val_loss: 1.5314\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5284 - val_loss: 1.5277\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5667 - val_loss: 1.5999\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5979 - val_loss: 1.5989\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5975 - val_loss: 1.5987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5974 - val_loss: 1.5989\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5975 - val_loss: 1.5990\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5974 - val_loss: 1.5989\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "8\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 1.6000 - val_loss: 1.5972\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5788 - val_loss: 1.5345\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5147 - val_loss: 1.5094\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5075 - val_loss: 1.5097\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5096 - val_loss: 1.5115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5107 - val_loss: 1.5115\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 4s 43ms/step - loss: 1.5108 - val_loss: 1.5126\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5109 - val_loss: 1.5136\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5162 - val_loss: 1.5170\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5165 - val_loss: 1.5172\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5161 - val_loss: 1.5173\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5162 - val_loss: 1.5168\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5165 - val_loss: 1.5172\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5162 - val_loss: 1.5174\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5162 - val_loss: 1.5172\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5161 - val_loss: 1.5168\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5161 - val_loss: 1.5167\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5162 - val_loss: 1.5169\n",
      "Top-2 accuracy = 0.529\n",
      "9\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5971 - val_loss: 1.5895\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5774 - val_loss: 1.5675\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5536 - val_loss: 1.5459\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5336 - val_loss: 1.5281\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5185 - val_loss: 1.5154\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5072 - val_loss: 1.5048\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4975 - val_loss: 1.4964\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4906 - val_loss: 1.4911\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4853 - val_loss: 1.4855\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4809 - val_loss: 1.4818\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4778 - val_loss: 1.4781\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4741 - val_loss: 1.4760\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4713 - val_loss: 1.4723\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4685 - val_loss: 1.4704\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4663 - val_loss: 1.4677\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4643 - val_loss: 1.4658\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4623 - val_loss: 1.4650\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4608 - val_loss: 1.4625\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4588 - val_loss: 1.4606\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4570 - val_loss: 1.4594\n",
      "Top-2 accuracy = 0.604\n",
      "10\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5862 - val_loss: 1.5481\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4857 - val_loss: 1.4428\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4359 - val_loss: 1.4417\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4309 - val_loss: 1.4338\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4300 - val_loss: 1.4353\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4300 - val_loss: 1.4309\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4273 - val_loss: 1.4375\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4271 - val_loss: 1.4343\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4278 - val_loss: 1.4322\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4258 - val_loss: 1.4295\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4397\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4259 - val_loss: 1.4320\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4298\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4297\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4260 - val_loss: 1.4332\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4243 - val_loss: 1.4319\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4244 - val_loss: 1.4367\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4299\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4241 - val_loss: 1.4326\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4241 - val_loss: 1.4293\n",
      "Top-2 accuracy = 0.614\n",
      "11\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5809 - val_loss: 1.5480\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5320 - val_loss: 1.5198\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5088 - val_loss: 1.4980\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4874 - val_loss: 1.4789\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4708 - val_loss: 1.4663\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4625 - val_loss: 1.4610\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4580 - val_loss: 1.4573\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4518 - val_loss: 1.4488\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4480 - val_loss: 1.4456\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4442 - val_loss: 1.4448\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4434 - val_loss: 1.4429\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4430 - val_loss: 1.4414\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4422 - val_loss: 1.4454\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4420 - val_loss: 1.4417\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4407 - val_loss: 1.4413\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4396 - val_loss: 1.4412\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4417 - val_loss: 1.4440\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4407 - val_loss: 1.4397\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4387 - val_loss: 1.4381\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4377 - val_loss: 1.4390\n",
      "Top-2 accuracy = 0.607\n",
      "12\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5768 - val_loss: 1.5174\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4717 - val_loss: 1.4487\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4390 - val_loss: 1.4361\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4322 - val_loss: 1.4374\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4327 - val_loss: 1.4322\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4292 - val_loss: 1.4316\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4287 - val_loss: 1.4403\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4290 - val_loss: 1.4326\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4275 - val_loss: 1.4301\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4263 - val_loss: 1.4320\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4267 - val_loss: 1.4292\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4260 - val_loss: 1.4308\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4270 - val_loss: 1.4310\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4268 - val_loss: 1.4294\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4262 - val_loss: 1.4305\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4252 - val_loss: 1.4302\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4247 - val_loss: 1.4294\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4247 - val_loss: 1.4298\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4264 - val_loss: 1.4336\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4259 - val_loss: 1.4329\n",
      "Top-2 accuracy = 0.612\n",
      "13\n",
      "minmaxA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5391 - val_loss: 1.4818\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4634 - val_loss: 1.4467\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4461 - val_loss: 1.4421\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4409 - val_loss: 1.4483\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4409 - val_loss: 1.4399\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4378 - val_loss: 1.4409\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4382 - val_loss: 1.4459\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4381 - val_loss: 1.4379\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4373 - val_loss: 1.4427\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4371 - val_loss: 1.4361\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4356 - val_loss: 1.4447\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4388 - val_loss: 1.4368\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4359 - val_loss: 1.4399\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4362 - val_loss: 1.4379\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4362 - val_loss: 1.4390\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4356 - val_loss: 1.4375\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4352 - val_loss: 1.4366\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4346 - val_loss: 1.4362\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4353 - val_loss: 1.4367\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4355 - val_loss: 1.4411\n",
      "Top-2 accuracy = 0.604\n",
      "14\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5616 - val_loss: 1.4967\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4720 - val_loss: 1.4600\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4525 - val_loss: 1.4477\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4435 - val_loss: 1.4401\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4384 - val_loss: 1.4386\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4357 - val_loss: 1.4372\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4353 - val_loss: 1.4351\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4312 - val_loss: 1.4490\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4332 - val_loss: 1.4549\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4317 - val_loss: 1.4327\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4376 - val_loss: 1.4304\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4292 - val_loss: 1.4461\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4299 - val_loss: 1.4307\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4278 - val_loss: 1.4324\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4289 - val_loss: 1.4318\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4288 - val_loss: 1.4299\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4281 - val_loss: 1.4323\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4276 - val_loss: 1.4365\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4289 - val_loss: 1.4325\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4272 - val_loss: 1.4293\n",
      "Top-2 accuracy = 0.613\n",
      "15\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5855 - val_loss: 1.5296\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4849 - val_loss: 1.4652\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4516 - val_loss: 1.4443\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4406 - val_loss: 1.4374\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4346 - val_loss: 1.4366\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4327 - val_loss: 1.4340\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4339 - val_loss: 1.4313\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4309 - val_loss: 1.4484\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4315 - val_loss: 1.4356\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4318 - val_loss: 1.4310\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4304 - val_loss: 1.4394\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4293 - val_loss: 1.4326\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4285 - val_loss: 1.4307\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4302 - val_loss: 1.4340\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4289 - val_loss: 1.4306\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4296 - val_loss: 1.4342\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4273 - val_loss: 1.4294\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4269 - val_loss: 1.4297\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4268 - val_loss: 1.4304\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4273 - val_loss: 1.4303\n",
      "Top-2 accuracy = 0.609\n",
      "16\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5919 - val_loss: 1.5658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5162 - val_loss: 1.4842\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4708 - val_loss: 1.4758\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4667 - val_loss: 1.4579\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4512 - val_loss: 1.4494\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4453 - val_loss: 1.4456\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4439 - val_loss: 1.4435\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4427 - val_loss: 1.4421\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4409 - val_loss: 1.4438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4406 - val_loss: 1.4402\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4398 - val_loss: 1.4395\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4388 - val_loss: 1.4402\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4366 - val_loss: 1.4336\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4272 - val_loss: 1.4349\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4281 - val_loss: 1.4398\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4271 - val_loss: 1.4295\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4264 - val_loss: 1.4285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4240 - val_loss: 1.4288\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4245 - val_loss: 1.4311\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4247 - val_loss: 1.4325\n",
      "Top-2 accuracy = 0.61\n",
      "17\n",
      "robustg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5577 - val_loss: 1.4927\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4791 - val_loss: 1.4708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4693 - val_loss: 1.4594\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4512 - val_loss: 1.4515\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4463 - val_loss: 1.4489\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4422 - val_loss: 1.4452\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4372 - val_loss: 1.4337\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4296 - val_loss: 1.4309\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4300 - val_loss: 1.4316\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4278 - val_loss: 1.4321\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4270 - val_loss: 1.4316\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4280 - val_loss: 1.4431\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4273 - val_loss: 1.4305\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4247 - val_loss: 1.4281\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4246 - val_loss: 1.4291\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4242 - val_loss: 1.4290\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4238 - val_loss: 1.4324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4236 - val_loss: 1.4300\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4222 - val_loss: 1.4305\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4227 - val_loss: 1.4409\n",
      "Top-2 accuracy = 0.607\n",
      "18\n",
      "minmaxT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5766 - val_loss: 1.5263\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4872 - val_loss: 1.4621\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4529 - val_loss: 1.4487\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4412 - val_loss: 1.4372\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4390 - val_loss: 1.4393\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4364 - val_loss: 1.4384\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4353 - val_loss: 1.4388\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4333 - val_loss: 1.4329\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4329 - val_loss: 1.4318\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4330 - val_loss: 1.4306\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4305\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4307 - val_loss: 1.4322\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4315 - val_loss: 1.4294\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4292 - val_loss: 1.4300\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4320\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4268 - val_loss: 1.4296\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4274\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4268\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4247 - val_loss: 1.4298\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4299\n",
      "Top-2 accuracy = 0.612\n",
      "19\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.6049 - val_loss: 1.6006\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5992 - val_loss: 1.5988\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5978 - val_loss: 1.5984\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "20\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5786 - val_loss: 1.5463\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5161 - val_loss: 1.4924\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4710 - val_loss: 1.4578\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4447\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4399\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4361 - val_loss: 1.4379\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4339 - val_loss: 1.4352\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4353\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4327\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4325\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4313\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4317\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4322\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4313\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4299\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4313\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4332\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4297\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4289\n",
      "Top-2 accuracy = 0.612\n",
      "21\n",
      "maxabsc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.6057 - val_loss: 1.6030\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6006 - val_loss: 1.6001\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5985 - val_loss: 1.5990\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5977 - val_loss: 1.5987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "22\n",
      "maxabsB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5730 - val_loss: 1.5462\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5230 - val_loss: 1.5002\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4819 - val_loss: 1.4687\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4565 - val_loss: 1.4493\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4428 - val_loss: 1.4411\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.4377\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4362\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4356\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4344\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4353\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4332\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4331\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4331\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4321\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4341\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4302 - val_loss: 1.4337\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4302 - val_loss: 1.4322\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4298 - val_loss: 1.4323\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.4319\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4295 - val_loss: 1.4330\n",
      "Top-2 accuracy = 0.613\n",
      "23\n",
      "standardized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5798 - val_loss: 1.5305\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4925 - val_loss: 1.4657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4542 - val_loss: 1.4472\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4450 - val_loss: 1.4539\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4446 - val_loss: 1.4408\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4402 - val_loss: 1.4446\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4375 - val_loss: 1.4390\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4351 - val_loss: 1.4421\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4364 - val_loss: 1.4356\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4343 - val_loss: 1.4373\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4348 - val_loss: 1.4355\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4340 - val_loss: 1.4365\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4346 - val_loss: 1.4359\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4359 - val_loss: 1.4355\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4329 - val_loss: 1.4338\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4325 - val_loss: 1.4383\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4323 - val_loss: 1.4350\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4332 - val_loss: 1.4352\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4306 - val_loss: 1.4351\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4320 - val_loss: 1.4351\n",
      "Top-2 accuracy = 0.605\n",
      "24\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5525 - val_loss: 1.5054\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4753 - val_loss: 1.4640\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4540 - val_loss: 1.4500\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4439 - val_loss: 1.4431\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4410 - val_loss: 1.4447\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4381 - val_loss: 1.4437\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4362 - val_loss: 1.4372\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4335 - val_loss: 1.4373\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4325 - val_loss: 1.4314\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4296 - val_loss: 1.4311\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4300 - val_loss: 1.4304\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4292 - val_loss: 1.4282\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4272 - val_loss: 1.4392\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4319 - val_loss: 1.4304\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4289\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4260 - val_loss: 1.4287\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4282\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4241 - val_loss: 1.4279\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4247 - val_loss: 1.4271\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4238 - val_loss: 1.4265\n",
      "Top-2 accuracy = 0.615\n",
      "25\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5857 - val_loss: 1.5282\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4953 - val_loss: 1.4702\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4595 - val_loss: 1.4538\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4517 - val_loss: 1.4541\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4490 - val_loss: 1.4510\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4478 - val_loss: 1.4476\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4464 - val_loss: 1.4569\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4475 - val_loss: 1.4466\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4470 - val_loss: 1.4469\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4462 - val_loss: 1.4486\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4461 - val_loss: 1.4478\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4462 - val_loss: 1.4456\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4458 - val_loss: 1.4518\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4453 - val_loss: 1.4448\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4463 - val_loss: 1.4452\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4471 - val_loss: 1.4466\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4535 - val_loss: 1.4466\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4453 - val_loss: 1.4450\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4458 - val_loss: 1.4442\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4446 - val_loss: 1.4468\n",
      "Top-2 accuracy = 0.6\n",
      "26\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5785 - val_loss: 1.5282\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4908 - val_loss: 1.4712\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4590 - val_loss: 1.4593\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4501 - val_loss: 1.4505\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4464 - val_loss: 1.4473\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4408 - val_loss: 1.4415\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4380 - val_loss: 1.4406\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4347 - val_loss: 1.4395\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4341 - val_loss: 1.4370\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4328 - val_loss: 1.4347\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4314 - val_loss: 1.4357\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4304 - val_loss: 1.4343\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4296 - val_loss: 1.4343\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4294 - val_loss: 1.4334\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4294 - val_loss: 1.4359\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4288 - val_loss: 1.4320\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4274 - val_loss: 1.4320\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4279 - val_loss: 1.4314\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4320\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4280 - val_loss: 1.4313\n",
      "Top-2 accuracy = 0.61\n",
      "27\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5542 - val_loss: 1.5088\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4825 - val_loss: 1.4736\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4610 - val_loss: 1.4530\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4429 - val_loss: 1.4475\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4400 - val_loss: 1.4395\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4355 - val_loss: 1.4399\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4361 - val_loss: 1.4434\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4353 - val_loss: 1.4405\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4332 - val_loss: 1.4358\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4325 - val_loss: 1.4401\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4317 - val_loss: 1.4367\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4340 - val_loss: 1.4405\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4317 - val_loss: 1.4483\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4343 - val_loss: 1.4385\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4325 - val_loss: 1.4365\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4332 - val_loss: 1.4369\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4316 - val_loss: 1.4354\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4307 - val_loss: 1.4362\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4311 - val_loss: 1.4496\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4346 - val_loss: 1.4355\n",
      "Top-2 accuracy = 0.61\n",
      "28\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5903 - val_loss: 1.5583\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5265 - val_loss: 1.5140\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4888 - val_loss: 1.4788\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4707 - val_loss: 1.4701\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4618 - val_loss: 1.4682\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4569 - val_loss: 1.4548\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4536 - val_loss: 1.4519\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4513 - val_loss: 1.4510\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4497 - val_loss: 1.4494\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4487 - val_loss: 1.4545\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4485 - val_loss: 1.4490\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4469 - val_loss: 1.4498\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4468 - val_loss: 1.4488\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4474 - val_loss: 1.4491\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4463 - val_loss: 1.4459\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4452 - val_loss: 1.4459\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4457 - val_loss: 1.4454\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4465 - val_loss: 1.4456\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4449 - val_loss: 1.4488\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4453 - val_loss: 1.4450\n",
      "Top-2 accuracy = 0.608\n",
      "29\n",
      "maxabsW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5663 - val_loss: 1.5101\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4675 - val_loss: 1.4454\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4406 - val_loss: 1.4414\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4371 - val_loss: 1.4401\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4357 - val_loss: 1.4328\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4307 - val_loss: 1.4452\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4318 - val_loss: 1.4488\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4319 - val_loss: 1.4302\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4301 - val_loss: 1.4312\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4289 - val_loss: 1.4337\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4295 - val_loss: 1.4329\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4295 - val_loss: 1.4298\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4270 - val_loss: 1.4291\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4296 - val_loss: 1.4282\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4262 - val_loss: 1.4279\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4265 - val_loss: 1.4351\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4273 - val_loss: 1.4338\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4276 - val_loss: 1.4323\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4276 - val_loss: 1.4304\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4264 - val_loss: 1.4431\n",
      "Top-2 accuracy = 0.607\n",
      "0\n",
      "normalizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.6007 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5975 - val_loss: 1.5985\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5988\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5966 - val_loss: 1.5987\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "1\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5803 - val_loss: 1.5347\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5000 - val_loss: 1.4792\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4682 - val_loss: 1.4625\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4560 - val_loss: 1.4543\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4496 - val_loss: 1.4492\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4475\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4414 - val_loss: 1.4423\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4398 - val_loss: 1.4594\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4415 - val_loss: 1.4426\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4411 - val_loss: 1.4394\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4423\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4373 - val_loss: 1.4373\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4371 - val_loss: 1.4384\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4377 - val_loss: 1.4416\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4376 - val_loss: 1.4366\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4364 - val_loss: 1.4386\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4361 - val_loss: 1.4401\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4356 - val_loss: 1.4481\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4366 - val_loss: 1.4370\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4349 - val_loss: 1.4356\n",
      "Top-2 accuracy = 0.61\n",
      "2\n",
      "standardizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5911 - val_loss: 1.5553\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5134 - val_loss: 1.4883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4821 - val_loss: 1.4736\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4695 - val_loss: 1.4679\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4653 - val_loss: 1.4673\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4639 - val_loss: 1.4654\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4627 - val_loss: 1.4634\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4563 - val_loss: 1.4583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4526 - val_loss: 1.4525\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4508 - val_loss: 1.4518\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4494 - val_loss: 1.4507\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4494 - val_loss: 1.4528\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4442 - val_loss: 1.4438\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4407 - val_loss: 1.4481\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4390 - val_loss: 1.4551\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4429 - val_loss: 1.4403\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4384 - val_loss: 1.4399\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4375 - val_loss: 1.4385\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4367 - val_loss: 1.4544\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4386 - val_loss: 1.4392\n",
      "Top-2 accuracy = 0.607\n",
      "3\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.6056 - val_loss: 1.6029\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6007 - val_loss: 1.6001\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5985 - val_loss: 1.5990\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5977 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Top-2 accuracy = 0.456\n",
      "4\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5835 - val_loss: 1.5374\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5218 - val_loss: 1.4818\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4711 - val_loss: 1.4621\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4621 - val_loss: 1.4600\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4540 - val_loss: 1.4505\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4471 - val_loss: 1.4467\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4453 - val_loss: 1.4448\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4468 - val_loss: 1.4447\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4436 - val_loss: 1.4479\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4428 - val_loss: 1.4443\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4433 - val_loss: 1.4452\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4421 - val_loss: 1.4442\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4421 - val_loss: 1.4452\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4420 - val_loss: 1.4434\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4398 - val_loss: 1.4529\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4377 - val_loss: 1.4357\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4337 - val_loss: 1.4376\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4313 - val_loss: 1.4358\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4301 - val_loss: 1.4308\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4312 - val_loss: 1.4328\n",
      "Top-2 accuracy = 0.608\n",
      "5\n",
      "standardizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5715 - val_loss: 1.5168\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4754 - val_loss: 1.4559\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4430 - val_loss: 1.4384\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4315 - val_loss: 1.4353\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4276 - val_loss: 1.4341\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4281 - val_loss: 1.4331\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4253 - val_loss: 1.4295\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4253 - val_loss: 1.4323\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4270 - val_loss: 1.4385\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4235 - val_loss: 1.4279\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4231 - val_loss: 1.4332\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4224 - val_loss: 1.4412\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4229 - val_loss: 1.4341\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4255 - val_loss: 1.4287\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4246 - val_loss: 1.4381\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4227 - val_loss: 1.4300\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4229 - val_loss: 1.4308\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4235 - val_loss: 1.4384\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4228 - val_loss: 1.4280\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4223 - val_loss: 1.4281\n",
      "Top-2 accuracy = 0.616\n",
      "6\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5704 - val_loss: 1.5250\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4908 - val_loss: 1.4752\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4616 - val_loss: 1.4590\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4544 - val_loss: 1.4565\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4502 - val_loss: 1.4498\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4489 - val_loss: 1.4497\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4476 - val_loss: 1.4471\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4469 - val_loss: 1.4424\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4390 - val_loss: 1.4359\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4341 - val_loss: 1.4414\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4352 - val_loss: 1.4364\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4325 - val_loss: 1.4344\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4320 - val_loss: 1.4340\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4309 - val_loss: 1.4335\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4315 - val_loss: 1.4324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4328 - val_loss: 1.4365\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4310 - val_loss: 1.4330\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4316 - val_loss: 1.4334\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4294 - val_loss: 1.4333\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4307 - val_loss: 1.4483\n",
      "Top-2 accuracy = 0.606\n",
      "7\n",
      "maxabsH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6028 - val_loss: 1.5955\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5859 - val_loss: 1.5730\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5470 - val_loss: 1.5221\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5015 - val_loss: 1.4861\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4730 - val_loss: 1.4658\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4583 - val_loss: 1.4559\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4509 - val_loss: 1.4506\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4473 - val_loss: 1.4468\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4443 - val_loss: 1.4445\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4432 - val_loss: 1.4433\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4424 - val_loss: 1.4459\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4423\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4418\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4410 - val_loss: 1.4429\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4410 - val_loss: 1.4417\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4412 - val_loss: 1.4428\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4409 - val_loss: 1.4412\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4403 - val_loss: 1.4419\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4403 - val_loss: 1.4415\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4403 - val_loss: 1.4420\n",
      "Top-2 accuracy = 0.608\n",
      "8\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5480 - val_loss: 1.4834\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4608 - val_loss: 1.4465\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4438 - val_loss: 1.4433\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4376 - val_loss: 1.4377\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4348 - val_loss: 1.4352\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4331\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4314 - val_loss: 1.4327\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4333\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4322\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4286 - val_loss: 1.4304\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4313\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4302\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4302\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4308\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4290\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4284\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4292\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4284\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4272\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4296\n",
      "Top-2 accuracy = 0.613\n",
      "9\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5767 - val_loss: 1.5186\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5051 - val_loss: 1.4846\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4734 - val_loss: 1.4681\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4626 - val_loss: 1.4555\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4558 - val_loss: 1.4641\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4521 - val_loss: 1.4444\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4459 - val_loss: 1.4449\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4452 - val_loss: 1.4460\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4449 - val_loss: 1.4509\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4445 - val_loss: 1.4440\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4472 - val_loss: 1.4423\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4436 - val_loss: 1.4461\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4420 - val_loss: 1.4403\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4411 - val_loss: 1.4412\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4419 - val_loss: 1.4406\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4405 - val_loss: 1.4403\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4409 - val_loss: 1.4427\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4410 - val_loss: 1.4480\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4414 - val_loss: 1.4445\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4421 - val_loss: 1.4419\n",
      "Top-2 accuracy = 0.605\n",
      "10\n",
      "standardizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5751 - val_loss: 1.5304\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4859 - val_loss: 1.4652\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4509 - val_loss: 1.4495\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4392 - val_loss: 1.4407\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4359 - val_loss: 1.4449\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4339 - val_loss: 1.4356\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4315 - val_loss: 1.4332\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4311 - val_loss: 1.4341\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4297 - val_loss: 1.4313\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4303 - val_loss: 1.4350\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4297 - val_loss: 1.4308\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4288 - val_loss: 1.4306\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4288 - val_loss: 1.4305\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4280 - val_loss: 1.4308\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4286 - val_loss: 1.4306\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4272 - val_loss: 1.4347\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4306 - val_loss: 1.4343\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4273 - val_loss: 1.4294\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4270 - val_loss: 1.4288\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4274 - val_loss: 1.4291\n",
      "Top-2 accuracy = 0.611\n",
      "11\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5845 - val_loss: 1.5498\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5088 - val_loss: 1.4753\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4679 - val_loss: 1.4620\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4558 - val_loss: 1.5040\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4517 - val_loss: 1.4492\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4442 - val_loss: 1.4405\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4370 - val_loss: 1.4390\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4367 - val_loss: 1.4492\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4383 - val_loss: 1.4366\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4363 - val_loss: 1.4363\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4335 - val_loss: 1.4401\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4341 - val_loss: 1.4350\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4332 - val_loss: 1.4375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4349 - val_loss: 1.4376\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4331 - val_loss: 1.4388\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4358 - val_loss: 1.4395\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4315 - val_loss: 1.4362\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4331 - val_loss: 1.4334\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4319 - val_loss: 1.4340\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4312 - val_loss: 1.4332\n",
      "Top-2 accuracy = 0.608\n",
      "12\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5813 - val_loss: 1.5493\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5186 - val_loss: 1.4919\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4765 - val_loss: 1.4673\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4596 - val_loss: 1.4524\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4512 - val_loss: 1.4503\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4497 - val_loss: 1.4552\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4487 - val_loss: 1.4505\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4466 - val_loss: 1.4457\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4457 - val_loss: 1.4462\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4451 - val_loss: 1.4558\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4463 - val_loss: 1.4447\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4445 - val_loss: 1.4453\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4449 - val_loss: 1.4504\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4441 - val_loss: 1.4441\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4435 - val_loss: 1.4625\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4453 - val_loss: 1.4464\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4453 - val_loss: 1.4443\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4430 - val_loss: 1.4452\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4434 - val_loss: 1.4440\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4433 - val_loss: 1.4475\n",
      "Top-2 accuracy = 0.599\n",
      "13\n",
      "normalizeG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5460 - val_loss: 1.4693\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4549 - val_loss: 1.4629\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4480\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4418 - val_loss: 1.4386\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 1.4387 - val_loss: 1.4388\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4353\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4351 - val_loss: 1.4426\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4342 - val_loss: 1.4352\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4334 - val_loss: 1.4353\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4330 - val_loss: 1.4336\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4350\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4350\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4324\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4317\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4359\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4452\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4365\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4413\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4293\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4283 - val_loss: 1.4310\n",
      "Top-2 accuracy = 0.614\n",
      "14\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5895 - val_loss: 1.5689\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5431 - val_loss: 1.5222\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5104 - val_loss: 1.5035\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5030 - val_loss: 1.5028\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5034 - val_loss: 1.5010\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5082 - val_loss: 1.5131\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5115 - val_loss: 1.5143\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5120 - val_loss: 1.5105\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5107 - val_loss: 1.5121\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5116 - val_loss: 1.5120\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5106 - val_loss: 1.5032\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5087 - val_loss: 1.5275\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5259 - val_loss: 1.5269\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5256 - val_loss: 1.5269\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5253 - val_loss: 1.5269\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5251 - val_loss: 1.5275\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5254 - val_loss: 1.5270\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5252 - val_loss: 1.5265\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5224 - val_loss: 1.5190\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5190 - val_loss: 1.5231\n",
      "Top-2 accuracy = 0.542\n",
      "15\n",
      "minmaxP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 1.5873 - val_loss: 1.5540\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5528 - val_loss: 1.5290\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5236 - val_loss: 1.5216\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5245 - val_loss: 1.5423\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5284 - val_loss: 1.5286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5321 - val_loss: 1.5282\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5320 - val_loss: 1.5291\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5343 - val_loss: 1.5320\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5333 - val_loss: 1.5284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5323 - val_loss: 1.5341\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5375 - val_loss: 1.5342\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5373 - val_loss: 1.5344\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5299 - val_loss: 1.5233\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5503 - val_loss: 1.5904\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5876 - val_loss: 1.5900\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5875 - val_loss: 1.5898\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5875 - val_loss: 1.5898\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5875 - val_loss: 1.5898\n",
      "Top-2 accuracy = 0.482\n",
      "16\n",
      "minmaxG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.6011 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Top-2 accuracy = 0.456\n",
      "17\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5909 - val_loss: 1.5666\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5234 - val_loss: 1.4764\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4621 - val_loss: 1.4550\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4494 - val_loss: 1.4446\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4393\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4346\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4333\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4318\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4319\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4308\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4323\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4304\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4314 - val_loss: 1.4308\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4323\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4335\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4289\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4287 - val_loss: 1.4289\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4363\n",
      "Top-2 accuracy = 0.608\n",
      "18\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5568 - val_loss: 1.4872\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4622 - val_loss: 1.4504\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4425 - val_loss: 1.4654\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4481 - val_loss: 1.4359\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4347 - val_loss: 1.4362\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4326 - val_loss: 1.4330\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4331 - val_loss: 1.4390\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4335 - val_loss: 1.4314\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4318 - val_loss: 1.4348\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4325 - val_loss: 1.4413\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4332 - val_loss: 1.4338\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4320 - val_loss: 1.4452\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4344 - val_loss: 1.4358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4309 - val_loss: 1.4300\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4293 - val_loss: 1.4400\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4312 - val_loss: 1.4337\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4284 - val_loss: 1.4356\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4306 - val_loss: 1.4303\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4289 - val_loss: 1.4325\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4275 - val_loss: 1.4336\n",
      "Top-2 accuracy = 0.612\n",
      "19\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6053 - val_loss: 1.6012\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5953 - val_loss: 1.5909\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5822 - val_loss: 1.5766\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5633 - val_loss: 1.5546\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5358 - val_loss: 1.5263\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5096 - val_loss: 1.5050\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4910 - val_loss: 1.4874\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4770 - val_loss: 1.4759\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4681 - val_loss: 1.4677\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4619 - val_loss: 1.4627\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4572 - val_loss: 1.4587\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4546 - val_loss: 1.4561\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4526 - val_loss: 1.4545\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4512 - val_loss: 1.4531\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4507 - val_loss: 1.4522\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4501 - val_loss: 1.4520\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4493 - val_loss: 1.4513\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4491 - val_loss: 1.4507\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4485 - val_loss: 1.4508\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4486 - val_loss: 1.4506\n",
      "Top-2 accuracy = 0.604\n",
      "20\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5868 - val_loss: 1.5443\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5008 - val_loss: 1.4885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4801 - val_loss: 1.4722\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5156 - val_loss: 1.5743\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5644 - val_loss: 1.5598\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5640 - val_loss: 1.5645\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5718 - val_loss: 1.5931\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5932 - val_loss: 1.5944\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5955 - val_loss: 1.5985\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5978 - val_loss: 1.5989\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5977 - val_loss: 1.5988\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5976 - val_loss: 1.5988\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5976 - val_loss: 1.5988\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5975 - val_loss: 1.5988\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5976 - val_loss: 1.5989\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5976 - val_loss: 1.5986\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5977 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "21\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5988 - val_loss: 1.5988\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5983\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5942 - val_loss: 1.5897\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5778 - val_loss: 1.5722\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5760 - val_loss: 1.5738\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5665 - val_loss: 1.5503\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5577 - val_loss: 1.5525\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5593 - val_loss: 1.5575\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5530 - val_loss: 1.5476\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5559 - val_loss: 1.5568\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5607 - val_loss: 1.5536\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5388 - val_loss: 1.5288\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5325 - val_loss: 1.5381\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5152 - val_loss: 1.5115\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5494 - val_loss: 1.5453\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5472 - val_loss: 1.5399\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5390 - val_loss: 1.5339\n",
      "Top-2 accuracy = 0.558\n",
      "22\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.6001 - val_loss: 1.5989\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5975 - val_loss: 1.5987\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5975 - val_loss: 1.5985\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.5985\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5975 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "23\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5706 - val_loss: 1.5145\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4913 - val_loss: 1.4785\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4676 - val_loss: 1.4550\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4529 - val_loss: 1.4585\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4420 - val_loss: 1.4383\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4361 - val_loss: 1.4422\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4342 - val_loss: 1.4640\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4379 - val_loss: 1.4323\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4313 - val_loss: 1.4351\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4320 - val_loss: 1.4316\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4298 - val_loss: 1.4314\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4300 - val_loss: 1.4355\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4296 - val_loss: 1.4375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4305 - val_loss: 1.4351\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4301 - val_loss: 1.4305\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4300 - val_loss: 1.4446\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4304 - val_loss: 1.4315\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4284 - val_loss: 1.4587\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4323 - val_loss: 1.4318\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4303 - val_loss: 1.4309\n",
      "Top-2 accuracy = 0.611\n",
      "24\n",
      "normalizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6055 - val_loss: 1.5998\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5919 - val_loss: 1.5787\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5568 - val_loss: 1.5323\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5212 - val_loss: 1.5095\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5040 - val_loss: 1.4957\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4932 - val_loss: 1.4856\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4845 - val_loss: 1.4788\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4783 - val_loss: 1.4738\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4740 - val_loss: 1.4693\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4696 - val_loss: 1.4662\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4665 - val_loss: 1.4628\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4635 - val_loss: 1.4619\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4614 - val_loss: 1.4588\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4588 - val_loss: 1.4568\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4570 - val_loss: 1.4555\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4551 - val_loss: 1.4543\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4535 - val_loss: 1.4522\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4519 - val_loss: 1.4513\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4503 - val_loss: 1.4494\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4493 - val_loss: 1.4484\n",
      "Top-2 accuracy = 0.612\n",
      "25\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 1.5744 - val_loss: 1.5168\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5106 - val_loss: 1.5123\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5096 - val_loss: 1.5113\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5093 - val_loss: 1.5111\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5093 - val_loss: 1.5107\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5098 - val_loss: 1.5110\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5080 - val_loss: 1.5072\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5061 - val_loss: 1.5071\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5062 - val_loss: 1.5069\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5057 - val_loss: 1.5066\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5062 - val_loss: 1.5062\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5046 - val_loss: 1.5067\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5049 - val_loss: 1.5065\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5048 - val_loss: 1.5064\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5048 - val_loss: 1.5062\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5047 - val_loss: 1.5063\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5050 - val_loss: 1.5064\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5047 - val_loss: 1.5063\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5047 - val_loss: 1.5065\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5047 - val_loss: 1.5061\n",
      "Top-2 accuracy = 0.556\n",
      "26\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.6019 - val_loss: 1.6003\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5982 - val_loss: 1.5989\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5975 - val_loss: 1.5987\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5974 - val_loss: 1.5986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5985\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5987\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5973 - val_loss: 1.5986\n",
      "Top-2 accuracy = 0.456\n",
      "27\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 20ms/step - loss: 1.5579 - val_loss: 1.5143\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5041 - val_loss: 1.4957\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4921 - val_loss: 1.4928\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4909 - val_loss: 1.4924\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4911 - val_loss: 1.4928\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4911 - val_loss: 1.4925\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4913 - val_loss: 1.4931\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4910 - val_loss: 1.4931\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4912 - val_loss: 1.4931\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4909 - val_loss: 1.4930\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4908 - val_loss: 1.4938\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4910 - val_loss: 1.4930\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4911 - val_loss: 1.4931\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4910 - val_loss: 1.4932\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4914 - val_loss: 1.4936\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4909 - val_loss: 1.4929\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4908 - val_loss: 1.4926\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4907 - val_loss: 1.4934\n",
      "Top-2 accuracy = 0.569\n",
      "28\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5964 - val_loss: 1.5768\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5561 - val_loss: 1.5365\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5281 - val_loss: 1.5156\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5054 - val_loss: 1.4934\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4881 - val_loss: 1.4749\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4718 - val_loss: 1.4684\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4639 - val_loss: 1.4604\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4593 - val_loss: 1.4693\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4566 - val_loss: 1.4581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4516 - val_loss: 1.4555\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4474 - val_loss: 1.4461\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4427 - val_loss: 1.4432\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4414 - val_loss: 1.4482\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4414 - val_loss: 1.4426\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4380 - val_loss: 1.4431\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4412 - val_loss: 1.4414\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4388 - val_loss: 1.4372\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4371 - val_loss: 1.4381\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4415 - val_loss: 1.4369\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4363 - val_loss: 1.4416\n",
      "Top-2 accuracy = 0.605\n",
      "29\n",
      "standardizei|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5667 - val_loss: 1.5316\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5342 - val_loss: 1.5193\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4965 - val_loss: 1.4921\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4869 - val_loss: 1.4904\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4847 - val_loss: 1.4849\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4796 - val_loss: 1.4813\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4809 - val_loss: 1.4824\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4818 - val_loss: 1.4817\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4822 - val_loss: 1.4817\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4799 - val_loss: 1.4788\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4760 - val_loss: 1.4750\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4738 - val_loss: 1.4671\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4730 - val_loss: 1.4727\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4715 - val_loss: 1.4711\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4636 - val_loss: 1.4600\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4570 - val_loss: 1.4513\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4534 - val_loss: 1.4527\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4523 - val_loss: 1.4557\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4513 - val_loss: 1.4485\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4491 - val_loss: 1.4475\n",
      "Top-2 accuracy = 0.608\n"
     ]
    }
   ],
   "source": [
    "top2 = []\n",
    "\n",
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"accuracy\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [MulticlassDL(n_classes=5, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20)],\n",
    "    \"post_train_hooks\": [top2_hook],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"eclipse-5class\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        MulticlassDL(n_classes=5, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.34738014970573106\n",
      "Top-2 Accuracy: 0.6181646763042112\n"
     ]
    }
   ],
   "source": [
    "interp = DODGEInterpreter(files=['./eclipse-5class.txt'], max_by=0, \n",
    "                          metrics=['accuracy'])\n",
    "results = interp.interpret()['eclipse-5class.txt']\n",
    "print('Top-1 Accuracy:', np.median(results['accuracy']))\n",
    "print('Top-2 Accuracy:', np.median(np.amax(np.array(top2).reshape(10,30), axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = np.where(data.y_train < 1, 0, np.where(data.y_train < 2, 1, np.where(data.y_train < 3, 2, np.where(data.y_train < 6, 3, np.where(data.y_train < 11, 4, np.where(data.y_train < 21, 5, 6))))))\n",
    "data.y_test = np.where(data.y_test < 1, 0, np.where(data.y_test < 2, 1, np.where(data.y_test < 3, 2, np.where(data.y_test < 6, 3, np.where(data.y_test < 11, 4, np.where(data.y_test < 21, 5, 6))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y_train = to_categorical(data.y_train, num_classes=7)\n",
    "data.y_test = to_categorical(data.y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162a17a90>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162a172b0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15bdd1160>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x159f041f0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1540dd400>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152eba2b0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15bdd14f0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x175a79a00>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x175a791f0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14eac67f0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17ccb3a90>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f489d0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f48430>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f48c10>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f483d0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f48f10>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152f48b20>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x168d00af0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17735b100>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x172642a30>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1629e6160>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1629e62e0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1629e6910>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1629e6040>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1629e6190>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1540d6e80>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1701f3af0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1701f3f10>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1701f3940>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1701f3700>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1701f3100>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1701f3250>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1701f39d0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x152479340>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x16f2c57c0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1631c6d90>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1550960a0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x155096af0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b28a5b0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x186848dc0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1632633a0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x161b94940>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x158f6a100>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162ba0a00>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162ba0ca0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162ba0220>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162ba0130>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162ba0280>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162ba0460>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17b81a610>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x16326cd60>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4691 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9246 - val_loss: 1.9125\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9090 - val_loss: 1.9043\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9011 - val_loss: 1.8938\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8869 - val_loss: 1.8783\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8745 - val_loss: 1.8691\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8657 - val_loss: 1.8608\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8584 - val_loss: 1.8541\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8512 - val_loss: 1.8470\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8439 - val_loss: 1.8417\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8377 - val_loss: 1.8351\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8326 - val_loss: 1.8309\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8278 - val_loss: 1.8266\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8242 - val_loss: 1.8223\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8197 - val_loss: 1.8188\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8163 - val_loss: 1.8149\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8118 - val_loss: 1.8127\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8082 - val_loss: 1.8087\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8053 - val_loss: 1.8056\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8028 - val_loss: 1.8024\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8004 - val_loss: 1.8000\n",
      "Top-2 accuracy = 0.449\n",
      "1\n",
      "maxabsO|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4695 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9166 - val_loss: 1.8916\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8761 - val_loss: 1.8552\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8442 - val_loss: 1.8349\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8260 - val_loss: 1.8156\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8088 - val_loss: 1.8002\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7919\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.7828\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7839 - val_loss: 1.7796\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7795 - val_loss: 1.7757\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7769 - val_loss: 1.7723\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7738 - val_loss: 1.7729\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7706 - val_loss: 1.7662\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7642\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7669 - val_loss: 1.7666\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7657 - val_loss: 1.7628\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7634 - val_loss: 1.7657\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7625 - val_loss: 1.7585\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7608 - val_loss: 1.7594\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7597 - val_loss: 1.7564\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7569 - val_loss: 1.7573\n",
      "Top-2 accuracy = 0.478\n",
      "2\n",
      "maxabsC|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4701 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9290 - val_loss: 1.9201\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9168 - val_loss: 1.9100\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9086 - val_loss: 1.9022\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9017 - val_loss: 1.8957\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8942 - val_loss: 1.8874\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8871 - val_loss: 1.8804\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8800 - val_loss: 1.8734\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8730 - val_loss: 1.8665\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8661 - val_loss: 1.8602\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8594 - val_loss: 1.8539\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8531 - val_loss: 1.8475\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8471 - val_loss: 1.8416\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8417 - val_loss: 1.8365\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8370 - val_loss: 1.8323\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8327 - val_loss: 1.8278\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8287 - val_loss: 1.8241\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8251 - val_loss: 1.8212\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8214 - val_loss: 1.8174\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8184 - val_loss: 1.8145\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8156 - val_loss: 1.8121\n",
      "Top-2 accuracy = 0.457\n",
      "3\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4706 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9244 - val_loss: 1.8925\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8756 - val_loss: 1.8600\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8525 - val_loss: 1.8426\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8350 - val_loss: 1.8260\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8202 - val_loss: 1.8146\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8102 - val_loss: 1.8068\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8039 - val_loss: 1.7986\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7988 - val_loss: 1.7950\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7951 - val_loss: 1.7912\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7911 - val_loss: 1.7891\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7859 - val_loss: 1.7840\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7837 - val_loss: 1.7804\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7798\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7787 - val_loss: 1.7759\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7769 - val_loss: 1.7741\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7719\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7725 - val_loss: 1.7775\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7711 - val_loss: 1.7728\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7701 - val_loss: 1.7691\n",
      "Top-2 accuracy = 0.469\n",
      "4\n",
      "minmaxI|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4712 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9192 - val_loss: 1.8876\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8723 - val_loss: 1.8554\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8459 - val_loss: 1.8342\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8262 - val_loss: 1.8178\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8105 - val_loss: 1.8039\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7982 - val_loss: 1.7924\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7901 - val_loss: 1.7841\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7852 - val_loss: 1.7792\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7814 - val_loss: 1.7756\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7782 - val_loss: 1.7821\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7759 - val_loss: 1.7711\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7739 - val_loss: 1.7702\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7720 - val_loss: 1.7722\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7711 - val_loss: 1.7686\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7687 - val_loss: 1.7666\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7680 - val_loss: 1.7705\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7676 - val_loss: 1.7683\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7657 - val_loss: 1.7626\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7642 - val_loss: 1.7623\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7639 - val_loss: 1.7594\n",
      "Top-2 accuracy = 0.478\n",
      "5\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4717 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9351 - val_loss: 1.9215\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9162 - val_loss: 1.9119\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9125 - val_loss: 1.9117\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9111\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9108 - val_loss: 1.9074\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9009 - val_loss: 1.8846\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8798 - val_loss: 1.8679\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8647 - val_loss: 1.8553\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8524 - val_loss: 1.8477\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8441 - val_loss: 1.8408\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8380 - val_loss: 1.8353\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8332 - val_loss: 1.8303\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8297 - val_loss: 1.8275\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8265 - val_loss: 1.8261\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8242 - val_loss: 1.8226\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8224 - val_loss: 1.8201\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8206 - val_loss: 1.8200\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8191 - val_loss: 1.8160\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8177 - val_loss: 1.8141\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8167 - val_loss: 1.8164\n",
      "Top-2 accuracy = 0.454\n",
      "6\n",
      "minmaxs|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4724 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9280 - val_loss: 1.9048\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8820 - val_loss: 1.8557\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8405 - val_loss: 1.8287\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8236 - val_loss: 1.8174\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8130 - val_loss: 1.8131\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8035 - val_loss: 1.7945\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7951 - val_loss: 1.8012\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7896 - val_loss: 1.7853\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7866 - val_loss: 1.7829\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7793\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7819 - val_loss: 1.7772\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7781 - val_loss: 1.7743\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7770 - val_loss: 1.7729\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7764 - val_loss: 1.7726\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7714\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7726 - val_loss: 1.7680\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7689\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7709 - val_loss: 1.7669\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7721 - val_loss: 1.7702\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7701 - val_loss: 1.7697\n",
      "Top-2 accuracy = 0.476\n",
      "7\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4731 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9120 - val_loss: 1.8641\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8379 - val_loss: 1.8135\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8021 - val_loss: 1.7892\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7807\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7827 - val_loss: 1.7760\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7785 - val_loss: 1.7737\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7702\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7712 - val_loss: 1.7664\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7705 - val_loss: 1.7653\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7661 - val_loss: 1.7631\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7615\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7614 - val_loss: 1.7594\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7604 - val_loss: 1.7588\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7559\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7554\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7557 - val_loss: 1.7544\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7546 - val_loss: 1.7546\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7535 - val_loss: 1.7566\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7523 - val_loss: 1.7518\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7513 - val_loss: 1.7513\n",
      "Top-2 accuracy = 0.485\n",
      "8\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4736 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9404 - val_loss: 1.9313\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9277 - val_loss: 1.9221\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9200 - val_loss: 1.9134\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9112 - val_loss: 1.9031\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9013 - val_loss: 1.8907\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8890 - val_loss: 1.8762\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8761 - val_loss: 1.8646\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8643 - val_loss: 1.8549\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8547 - val_loss: 1.8476\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8476 - val_loss: 1.8412\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8420 - val_loss: 1.8365\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8374 - val_loss: 1.8323\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8337 - val_loss: 1.8294\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8306 - val_loss: 1.8258\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8282 - val_loss: 1.8233\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8259 - val_loss: 1.8216\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8242 - val_loss: 1.8205\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8222 - val_loss: 1.8180\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8203 - val_loss: 1.8153\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8186 - val_loss: 1.8149\n",
      "Top-2 accuracy = 0.456\n",
      "9\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4742 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9131 - val_loss: 1.8772\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8487 - val_loss: 1.8220\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8078 - val_loss: 1.7937\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7909 - val_loss: 1.7832\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7848 - val_loss: 1.7788\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7808 - val_loss: 1.7771\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7786 - val_loss: 1.7753\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7766 - val_loss: 1.7732\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7752 - val_loss: 1.7714\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7735 - val_loss: 1.7695\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7723 - val_loss: 1.7694\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7694\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7668\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7690 - val_loss: 1.7659\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7683 - val_loss: 1.7653\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7673 - val_loss: 1.7646\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7632\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7652 - val_loss: 1.7634\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7644 - val_loss: 1.7627\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7638 - val_loss: 1.7611\n",
      "Top-2 accuracy = 0.484\n",
      "10\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4745 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9023 - val_loss: 1.8660\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8386 - val_loss: 1.8171\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8075 - val_loss: 1.7951\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7932 - val_loss: 1.7858\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7866 - val_loss: 1.7809\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7825 - val_loss: 1.7776\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7792 - val_loss: 1.7749\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7767 - val_loss: 1.7721\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7744 - val_loss: 1.7703\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7722 - val_loss: 1.7703\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7707 - val_loss: 1.7675\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7697 - val_loss: 1.7662\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7681 - val_loss: 1.7654\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7671 - val_loss: 1.7648\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7660 - val_loss: 1.7630\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7650 - val_loss: 1.7621\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7616\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7628 - val_loss: 1.7610\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7621 - val_loss: 1.7603\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7611 - val_loss: 1.7590\n",
      "Top-2 accuracy = 0.488\n",
      "11\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4748 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9129 - val_loss: 1.8722\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8299 - val_loss: 1.7988\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7909 - val_loss: 1.7792\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7770 - val_loss: 1.7710\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7700 - val_loss: 1.7667\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7657 - val_loss: 1.7629\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7626 - val_loss: 1.7614\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7597 - val_loss: 1.7588\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7579 - val_loss: 1.7573\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7562 - val_loss: 1.7549\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7548 - val_loss: 1.7560\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7538 - val_loss: 1.7540\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7517 - val_loss: 1.7521\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7510 - val_loss: 1.7542\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7494 - val_loss: 1.7516\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7487 - val_loss: 1.7504\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7477 - val_loss: 1.7515\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7470 - val_loss: 1.7496\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7458 - val_loss: 1.7488\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7446 - val_loss: 1.7477\n",
      "Top-2 accuracy = 0.488\n",
      "12\n",
      "standardizeG|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4753 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9418 - val_loss: 1.9277\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9226 - val_loss: 1.9167\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9140 - val_loss: 1.9099\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9051 - val_loss: 1.8916\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8646 - val_loss: 1.8276\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8133 - val_loss: 1.8028\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7962 - val_loss: 1.7912\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7890 - val_loss: 1.7860\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7850 - val_loss: 1.7835\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7825 - val_loss: 1.7803\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7803 - val_loss: 1.7792\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7786 - val_loss: 1.7770\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7777 - val_loss: 1.7760\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7763 - val_loss: 1.7754\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7754 - val_loss: 1.7741\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7746 - val_loss: 1.7736\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7735 - val_loss: 1.7731\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7733 - val_loss: 1.7721\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7724 - val_loss: 1.7718\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7719 - val_loss: 1.7721\n",
      "Top-2 accuracy = 0.475\n",
      "13\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4758 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 681281134264320.0000 - val_loss: 193744968089600.0000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 119704161091584.0000 - val_loss: 80981021163520.0000\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 64770468216832.0000 - val_loss: 49846606102528.0000\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 38500720181248.0000 - val_loss: 28468429455360.0000\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 22176952483840.0000 - val_loss: 16866519023616.0000\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 13281291927552.0000 - val_loss: 10611662520320.0000\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 9481767354368.0000 - val_loss: 7877768511488.0000\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 7025642176512.0000 - val_loss: 6216363278336.0000\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5235405750272.0000 - val_loss: 4492043485184.0000\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4197539643392.0000 - val_loss: 3567008088064.0000\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3641524355072.0000 - val_loss: 3281334304768.0000\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3083163664384.0000 - val_loss: 2126206992384.0000\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2474405789696.0000 - val_loss: 3364204314624.0000\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2602727374848.0000 - val_loss: 2263459561472.0000\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2084822843392.0000 - val_loss: 2039254614016.0000\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1748815577088.0000 - val_loss: 1315277897728.0000\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1545825157120.0000 - val_loss: 1176101847040.0000\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1410688090112.0000 - val_loss: 2187185881088.0000\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1659382792192.0000 - val_loss: 1977487851520.0000\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1569280491520.0000 - val_loss: 1738860134400.0000\n",
      "Top-2 accuracy = 0.413\n",
      "14\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4762 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9232 - val_loss: 1.8777\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8408 - val_loss: 1.8194\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8067 - val_loss: 1.7986\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7958 - val_loss: 1.7929\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7927\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7886 - val_loss: 1.7870\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7868 - val_loss: 1.7852\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7848\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7830 - val_loss: 1.7833\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7805\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 1.7787\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7783 - val_loss: 1.7776\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7772 - val_loss: 1.7823\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7767\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7747 - val_loss: 1.7742\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7732 - val_loss: 1.7724\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7718 - val_loss: 1.7721\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7712 - val_loss: 1.7714\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7697 - val_loss: 1.7709\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7687\n",
      "Top-2 accuracy = 0.473\n",
      "15\n",
      "robustI|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4769 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 6220984877056.0000 - val_loss: 1.9076\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 4885820928.0000 - val_loss: 1.8824\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8686 - val_loss: 1.8600\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 688941568.0000 - val_loss: 1.8409\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 787184192.0000 - val_loss: 1.8287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8260 - val_loss: 1.8200\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8190 - val_loss: 1.8137\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8137 - val_loss: 1.8090\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8101 - val_loss: 1.8060\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8077 - val_loss: 1.8040\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8058 - val_loss: 1.8020\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8043 - val_loss: 1.8014\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8035 - val_loss: 1.8006\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8026 - val_loss: 1.8004\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 62397050880.0000 - val_loss: 1.7993\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8015 - val_loss: 1.7986\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8009 - val_loss: 1.7983\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 300770240.0000 - val_loss: 1.7982\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8000 - val_loss: 1.7977\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7996 - val_loss: 1.7971\n",
      "Top-2 accuracy = 0.446\n",
      "16\n",
      "minmaxh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9066 - val_loss: 1.8633\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8173 - val_loss: 1.7924\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7898 - val_loss: 1.7824\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7862 - val_loss: 1.7846\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7852 - val_loss: 1.7828\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7809 - val_loss: 1.7771\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7809 - val_loss: 1.7758\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7802 - val_loss: 1.7771\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7753\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7785 - val_loss: 1.7748\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7776 - val_loss: 1.7803\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7762 - val_loss: 1.7734\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7753 - val_loss: 1.7725\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7731\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 1.7727\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7739 - val_loss: 1.7760\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7854\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7750 - val_loss: 1.7716\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7729 - val_loss: 1.7737\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7728 - val_loss: 1.7739\n",
      "Top-2 accuracy = 0.469\n",
      "17\n",
      "minmaxz|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4782 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9348 - val_loss: 1.9245\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.8994\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8771 - val_loss: 1.8616\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8444 - val_loss: 1.8397\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8288 - val_loss: 1.8265\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8191 - val_loss: 1.8192\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8128 - val_loss: 1.8129\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8093 - val_loss: 1.8077\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8058 - val_loss: 1.8049\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8033 - val_loss: 1.8044\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8018 - val_loss: 1.8021\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8007 - val_loss: 1.8003\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7997 - val_loss: 1.7995\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7992 - val_loss: 1.7977\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7984 - val_loss: 1.7984\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7978 - val_loss: 1.7967\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7970 - val_loss: 1.7956\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7979 - val_loss: 1.7966\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7963 - val_loss: 1.7948\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7965 - val_loss: 1.7981\n",
      "Top-2 accuracy = 0.464\n",
      "18\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9332 - val_loss: 1.9042\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8853 - val_loss: 1.8623\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8522 - val_loss: 1.8435\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8397 - val_loss: 1.8377\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8369 - val_loss: 1.8371\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8364 - val_loss: 1.8378\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8363 - val_loss: 1.8369\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8362 - val_loss: 1.8364\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8361 - val_loss: 1.8368\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8360 - val_loss: 1.8368\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8360 - val_loss: 1.8371\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8359 - val_loss: 1.8369\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8360 - val_loss: 1.8370\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8358 - val_loss: 1.8366\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8360 - val_loss: 1.8363\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8357 - val_loss: 1.8366\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8358 - val_loss: 1.8362\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8360 - val_loss: 1.8365\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8359 - val_loss: 1.8366\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8359 - val_loss: 1.8375\n",
      "Top-2 accuracy = 0.451\n",
      "19\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8977 - val_loss: 1.8433\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8194 - val_loss: 1.8051\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7978 - val_loss: 1.7943\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7899 - val_loss: 1.7887\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7868 - val_loss: 1.7850\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7840 - val_loss: 1.7824\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7803\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7802 - val_loss: 1.7787\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7776\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7773 - val_loss: 1.7785\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7764 - val_loss: 1.7767\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7755 - val_loss: 1.7752\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7750\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7733 - val_loss: 1.7770\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7722 - val_loss: 1.7732\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7715 - val_loss: 1.7720\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7718\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7708 - val_loss: 1.7703\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7696\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7696\n",
      "Top-2 accuracy = 0.475\n",
      "20\n",
      "normalizee|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4796 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9264 - val_loss: 1.9142\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9059 - val_loss: 1.8873\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8562 - val_loss: 1.8414\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8304 - val_loss: 1.8258\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8205 - val_loss: 1.8176\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8160 - val_loss: 1.8131\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8114 - val_loss: 1.8047\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8034 - val_loss: 1.7985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7997 - val_loss: 1.7963\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7973 - val_loss: 1.7923\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7939 - val_loss: 1.7895\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7916 - val_loss: 1.7882\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7904 - val_loss: 1.7876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7895 - val_loss: 1.7863\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7880 - val_loss: 1.7854\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7864 - val_loss: 1.7840\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7837\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7826\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7845 - val_loss: 1.7819\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7828 - val_loss: 1.7817\n",
      "Top-2 accuracy = 0.472\n",
      "21\n",
      "robustY|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4802 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9344 - val_loss: 1.9231\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9167 - val_loss: 1.9112\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9042 - val_loss: 1.8968\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8857 - val_loss: 1.8786\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8680 - val_loss: 1.8633\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8538 - val_loss: 1.8501\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8423 - val_loss: 1.8397\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8330 - val_loss: 1.8315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8262 - val_loss: 1.8244\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8209 - val_loss: 1.8197\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8173 - val_loss: 1.8156\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8151 - val_loss: 1.8132\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8137 - val_loss: 1.8121\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8112 - val_loss: 1.8051\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8024 - val_loss: 1.7989\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7995 - val_loss: 1.7970\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7982 - val_loss: 1.7952\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7967 - val_loss: 1.7947\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7965 - val_loss: 1.7934\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7954 - val_loss: 1.7929\n",
      "Top-2 accuracy = 0.466\n",
      "22\n",
      "minmaxR|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4807 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9285 - val_loss: 1.8922\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8597 - val_loss: 1.8268\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8160 - val_loss: 1.8060\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8059 - val_loss: 1.8010\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8012 - val_loss: 1.8010\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7982 - val_loss: 1.8021\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7968 - val_loss: 1.7951\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7953 - val_loss: 1.7953\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7953 - val_loss: 1.7928\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7931 - val_loss: 1.7910\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7922 - val_loss: 1.7901\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7919 - val_loss: 1.7923\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7907 - val_loss: 1.7890\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7908 - val_loss: 1.7874\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7900 - val_loss: 1.7875\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7888 - val_loss: 1.7866\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7879 - val_loss: 1.7867\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7843\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7870 - val_loss: 1.7841\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7856\n",
      "Top-2 accuracy = 0.468\n",
      "23\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9385 - val_loss: 1.9316\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9279 - val_loss: 1.9233\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9215 - val_loss: 1.9184\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9176 - val_loss: 1.9154\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9152 - val_loss: 1.9137\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9138 - val_loss: 1.9127\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9130 - val_loss: 1.9122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9125 - val_loss: 1.9117\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9116\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "24\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9243 - val_loss: 1.9087\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8995 - val_loss: 1.8847\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8790 - val_loss: 1.8673\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8652 - val_loss: 1.8561\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8553 - val_loss: 1.8483\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8479 - val_loss: 1.8428\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8420 - val_loss: 1.8378\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8372 - val_loss: 1.8336\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8332 - val_loss: 1.8301\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8301 - val_loss: 1.8272\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8272 - val_loss: 1.8241\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8247 - val_loss: 1.8228\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8228 - val_loss: 1.8205\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8209 - val_loss: 1.8183\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8195 - val_loss: 1.8170\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8175 - val_loss: 1.8147\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8157 - val_loss: 1.8134\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8137 - val_loss: 1.8110\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8119 - val_loss: 1.8089\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8102 - val_loss: 1.8075\n",
      "Top-2 accuracy = 0.463\n",
      "25\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4824 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8948 - val_loss: 1.8468\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8212 - val_loss: 1.8059\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8020 - val_loss: 1.7944\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7954 - val_loss: 1.7895\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7918 - val_loss: 1.7871\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7896 - val_loss: 1.7854\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7864 - val_loss: 1.7824\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7843 - val_loss: 1.7804\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7823 - val_loss: 1.7830\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7819 - val_loss: 1.7819\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7799 - val_loss: 1.7777\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7767\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7769 - val_loss: 1.7751\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7761 - val_loss: 1.7730\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 1.7728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7745 - val_loss: 1.7755\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7737 - val_loss: 1.7732\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7726 - val_loss: 1.7726\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7718 - val_loss: 1.7724\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7712 - val_loss: 1.7699\n",
      "Top-2 accuracy = 0.479\n",
      "26\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4830 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9026 - val_loss: 1.8729\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8432 - val_loss: 1.8246\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8157 - val_loss: 1.8069\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8033 - val_loss: 1.7984\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7970 - val_loss: 1.7930\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7929 - val_loss: 1.7895\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7907 - val_loss: 1.7865\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7886 - val_loss: 1.7851\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7870 - val_loss: 1.7836\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7854 - val_loss: 1.7844\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7799\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7831 - val_loss: 1.7803\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7822 - val_loss: 1.7797\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7777\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7804 - val_loss: 1.7786\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7795 - val_loss: 1.7764\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7785 - val_loss: 1.7756\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7778 - val_loss: 1.7760\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7776 - val_loss: 1.7745\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7764 - val_loss: 1.7741\n",
      "Top-2 accuracy = 0.479\n",
      "27\n",
      "minmaxg|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4834 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9302 - val_loss: 1.9083\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8936 - val_loss: 1.8699\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8514 - val_loss: 1.8355\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8238 - val_loss: 1.8170\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8129 - val_loss: 1.8164\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8085 - val_loss: 1.8107\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8059 - val_loss: 1.8035\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8028 - val_loss: 1.7994\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7999 - val_loss: 1.7992\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7981 - val_loss: 1.7978\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7968\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7953 - val_loss: 1.7944\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7930 - val_loss: 1.7927\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7913 - val_loss: 1.7896\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7913 - val_loss: 1.7910\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7893 - val_loss: 1.7889\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7895 - val_loss: 1.7869\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7882 - val_loss: 1.7858\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7875 - val_loss: 1.7861\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7865 - val_loss: 1.7884\n",
      "Top-2 accuracy = 0.465\n",
      "28\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4841 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9182 - val_loss: 1.9064\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8888 - val_loss: 1.8576\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8328 - val_loss: 1.8159\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8123 - val_loss: 1.8062\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8056 - val_loss: 1.8011\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8034 - val_loss: 1.8014\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8005 - val_loss: 1.7958\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7982 - val_loss: 1.7953\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7980 - val_loss: 1.7937\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7962 - val_loss: 1.7937\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7943 - val_loss: 1.7938\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7938 - val_loss: 1.7919\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7932 - val_loss: 1.7900\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7890\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7912 - val_loss: 1.7905\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7907 - val_loss: 1.7887\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7889\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7900 - val_loss: 1.7880\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7904 - val_loss: 1.7867\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7888 - val_loss: 1.7867\n",
      "Top-2 accuracy = 0.462\n",
      "29\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4848 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 3.5691 - val_loss: 2.1677\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9956 - val_loss: 1.9005\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8722 - val_loss: 1.8555\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8433 - val_loss: 1.8353\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8300 - val_loss: 1.8265\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8224 - val_loss: 1.8185\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8170 - val_loss: 1.8126\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8128 - val_loss: 1.8098\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8098 - val_loss: 1.8066\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8077 - val_loss: 1.8048\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8049 - val_loss: 1.8020\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8026 - val_loss: 1.8009\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8010 - val_loss: 1.7979\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7984 - val_loss: 1.7969\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7976 - val_loss: 1.7987\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7952 - val_loss: 1.7928\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7938 - val_loss: 1.7943\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7927 - val_loss: 1.7916\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7920 - val_loss: 1.7936\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7933 - val_loss: 1.7912\n",
      "Top-2 accuracy = 0.467\n",
      "0\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4851 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9131 - val_loss: 1.8535\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8256 - val_loss: 1.8101\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8031 - val_loss: 1.7980\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7951 - val_loss: 1.7945\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7909 - val_loss: 1.7905\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7873 - val_loss: 1.7894\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7854 - val_loss: 1.7846\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7832 - val_loss: 1.7850\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7814 - val_loss: 1.7824\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7803\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7785 - val_loss: 1.7784\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7767 - val_loss: 1.7768\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7752 - val_loss: 1.7763\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7749\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7735\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7721\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7704 - val_loss: 1.7717\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7700 - val_loss: 1.7716\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7699\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7676 - val_loss: 1.7688\n",
      "Top-2 accuracy = 0.477\n",
      "1\n",
      "maxabsY|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4856 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8764 - val_loss: 1.8439\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8219 - val_loss: 1.8099\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8040 - val_loss: 1.7998\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7942\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7880\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7881 - val_loss: 1.7869\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7865 - val_loss: 1.7841\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7850 - val_loss: 1.7836\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7833 - val_loss: 1.7810\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7823 - val_loss: 1.7811\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7809 - val_loss: 1.7807\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 1.7773\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7789 - val_loss: 1.7763\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7781 - val_loss: 1.7762\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7767 - val_loss: 1.7748\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7790\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7751\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7742 - val_loss: 1.7758\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.7745\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7732 - val_loss: 1.7716\n",
      "Top-2 accuracy = 0.473\n",
      "2\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8798 - val_loss: 1.8417\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8152 - val_loss: 1.8117\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8050 - val_loss: 1.8107\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7997 - val_loss: 1.7998\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7960 - val_loss: 1.8076\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7947 - val_loss: 1.7960\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7896 - val_loss: 1.7907\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7882 - val_loss: 1.7912\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7867 - val_loss: 1.7889\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7842 - val_loss: 1.7876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 1.7810\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7817 - val_loss: 1.7814\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7785 - val_loss: 1.7802\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7788 - val_loss: 1.7763\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7766 - val_loss: 1.7765\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7753 - val_loss: 1.7763\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7748 - val_loss: 1.7760\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7734 - val_loss: 1.7753\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7737 - val_loss: 1.7769\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7719 - val_loss: 1.7734\n",
      "Top-2 accuracy = 0.474\n",
      "3\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9385 - val_loss: 1.9314\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9275 - val_loss: 1.9230\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9213 - val_loss: 1.9182\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9173 - val_loss: 1.9153\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9150 - val_loss: 1.9136\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9136 - val_loss: 1.9127\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9129 - val_loss: 1.9122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9125 - val_loss: 1.9118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9123 - val_loss: 1.9117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9116\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Top-2 accuracy = 0.382\n",
      "4\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9386 - val_loss: 1.9315\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9279 - val_loss: 1.9231\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9214 - val_loss: 1.9182\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9175 - val_loss: 1.9154\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9151 - val_loss: 1.9137\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9137 - val_loss: 1.9127\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9129 - val_loss: 1.9122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9126 - val_loss: 1.9120\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9123 - val_loss: 1.9117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9112\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "5\n",
      "normalizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8945 - val_loss: 1.8160\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8035 - val_loss: 1.7951\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7941 - val_loss: 1.7909\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7914 - val_loss: 1.7890\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7900 - val_loss: 1.7874\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7884 - val_loss: 1.7861\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7861 - val_loss: 1.7906\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7840\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7850\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7835 - val_loss: 1.7817\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7822 - val_loss: 1.7815\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7824\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7817 - val_loss: 1.7778\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7793 - val_loss: 1.7839\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7793 - val_loss: 1.7794\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7771 - val_loss: 1.7784\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7783 - val_loss: 1.7774\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7747\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7751 - val_loss: 1.7735\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7736\n",
      "Top-2 accuracy = 0.472\n",
      "6\n",
      "robustY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9219 - val_loss: 1.9082\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8887 - val_loss: 1.8718\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8451 - val_loss: 1.8298\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8195 - val_loss: 1.8198\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8088 - val_loss: 1.8035\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8012 - val_loss: 1.7988\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7879 - val_loss: 1.7838\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7834 - val_loss: 1.7818\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7813 - val_loss: 1.7806\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7800 - val_loss: 1.7809\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7789 - val_loss: 1.7821\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7775 - val_loss: 1.7781\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7764 - val_loss: 1.7775\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7757 - val_loss: 1.7782\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7756 - val_loss: 1.7861\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7750 - val_loss: 1.7830\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7751 - val_loss: 1.7761\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7744 - val_loss: 1.7779\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7738 - val_loss: 1.7767\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7769\n",
      "Top-2 accuracy = 0.47\n",
      "7\n",
      "maxabsg|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4893 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9078 - val_loss: 1.8702\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8395 - val_loss: 1.8143\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8065 - val_loss: 1.7978\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7975 - val_loss: 1.7941\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7939 - val_loss: 1.7902\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7918 - val_loss: 1.7886\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7894 - val_loss: 1.7858\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7878 - val_loss: 1.7843\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7865 - val_loss: 1.7837\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7853 - val_loss: 1.7817\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7841 - val_loss: 1.7807\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7832 - val_loss: 1.7804\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7823 - val_loss: 1.7803\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7815 - val_loss: 1.7781\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7805 - val_loss: 1.7776\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7797 - val_loss: 1.7776\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7769\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7785 - val_loss: 1.7760\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7774 - val_loss: 1.7753\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7755\n",
      "Top-2 accuracy = 0.474\n",
      "8\n",
      "normalizei|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8947 - val_loss: 1.8512\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8242 - val_loss: 1.8031\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7916 - val_loss: 1.7839\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7803 - val_loss: 1.7897\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7768 - val_loss: 1.7768\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7756 - val_loss: 1.7743\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7725 - val_loss: 1.7823\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7715 - val_loss: 1.7716\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7692 - val_loss: 1.7666\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7698 - val_loss: 1.7675\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7691 - val_loss: 1.7693\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7676 - val_loss: 1.7703\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7680 - val_loss: 1.7671\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7669 - val_loss: 1.7774\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7683 - val_loss: 1.7686\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7662 - val_loss: 1.7683\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7662 - val_loss: 1.7619\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7657 - val_loss: 1.7614\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7646 - val_loss: 1.7625\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7664 - val_loss: 1.7631\n",
      "Top-2 accuracy = 0.476\n",
      "9\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4904 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9137 - val_loss: 1.8769\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8439 - val_loss: 1.8215\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8085 - val_loss: 1.7998\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7959 - val_loss: 1.7927\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7903 - val_loss: 1.7871\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7865 - val_loss: 1.7830\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7816\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7820 - val_loss: 1.7795\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7801 - val_loss: 1.7779\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7784 - val_loss: 1.7766\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7762\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7757 - val_loss: 1.7747\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7736\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7737 - val_loss: 1.7729\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7726\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7714 - val_loss: 1.7710\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7704 - val_loss: 1.7701\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7700 - val_loss: 1.7688\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7685 - val_loss: 1.7676\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7681 - val_loss: 1.7681\n",
      "Top-2 accuracy = 0.473\n",
      "10\n",
      "standardizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9290 - val_loss: 1.9151\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9023 - val_loss: 1.8856\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8645 - val_loss: 1.8535\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8350 - val_loss: 1.8284\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8158 - val_loss: 1.8131\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8042 - val_loss: 1.8040\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7970 - val_loss: 1.7982\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7923 - val_loss: 1.7929\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7885 - val_loss: 1.7970\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7863 - val_loss: 1.7865\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7833 - val_loss: 1.7844\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7815\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7803\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7790 - val_loss: 1.7796\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7784 - val_loss: 1.7803\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7780 - val_loss: 1.7785\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7796\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7771 - val_loss: 1.7784\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7765 - val_loss: 1.7790\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7762 - val_loss: 1.7812\n",
      "Top-2 accuracy = 0.47\n",
      "11\n",
      "robustA|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4916 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.3100 - val_loss: 1.9891\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9459 - val_loss: 1.9219\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9105 - val_loss: 1.9053\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8952 - val_loss: 1.8912\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8818 - val_loss: 1.8786\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8701 - val_loss: 1.8669\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 81s 981ms/step - loss: 1.8589 - val_loss: 1.8559\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8491 - val_loss: 1.8462\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8396 - val_loss: 1.8366\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8311 - val_loss: 1.8277\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8233 - val_loss: 1.8208\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8179 - val_loss: 1.8161\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8142 - val_loss: 1.8126\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8117 - val_loss: 1.8101\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8099 - val_loss: 1.8082\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8086 - val_loss: 1.8072\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8073 - val_loss: 1.8058\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8063 - val_loss: 1.8052\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8052 - val_loss: 1.8041\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8043 - val_loss: 1.8034\n",
      "Top-2 accuracy = 0.452\n",
      "12\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4920 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9175 - val_loss: 1.8927\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8729 - val_loss: 1.8441\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8260 - val_loss: 1.8145\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8062 - val_loss: 1.7990\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7989 - val_loss: 1.7933\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7953 - val_loss: 1.7907\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7921 - val_loss: 1.7883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7903 - val_loss: 1.7887\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7893 - val_loss: 1.7853\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7876 - val_loss: 1.7869\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7865 - val_loss: 1.7844\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7858 - val_loss: 1.7818\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7842 - val_loss: 1.7830\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7832 - val_loss: 1.7806\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7824 - val_loss: 1.7814\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7811 - val_loss: 1.7782\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7801 - val_loss: 1.7773\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7795 - val_loss: 1.7784\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7787 - val_loss: 1.7758\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7783 - val_loss: 1.7747\n",
      "Top-2 accuracy = 0.472\n",
      "13\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9147 - val_loss: 1.8793\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8436 - val_loss: 1.8190\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8034 - val_loss: 1.7925\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7896 - val_loss: 1.7861\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7853 - val_loss: 1.7827\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7831 - val_loss: 1.7820\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7819 - val_loss: 1.7820\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7814 - val_loss: 1.7795\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 1.7783\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7802 - val_loss: 1.7786\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7794 - val_loss: 1.7773\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7787 - val_loss: 1.7767\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7759\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7787 - val_loss: 1.7776\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7769 - val_loss: 1.7742\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7761 - val_loss: 1.7739\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7753 - val_loss: 1.7748\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7746\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7720\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7737 - val_loss: 1.7718\n",
      "Top-2 accuracy = 0.477\n",
      "14\n",
      "robustq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.8892\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8783 - val_loss: 1.8665\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8633 - val_loss: 1.8557\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8570 - val_loss: 1.8519\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8549 - val_loss: 1.8508\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8544 - val_loss: 1.8503\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8540 - val_loss: 1.8507\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8539 - val_loss: 1.8503\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8537 - val_loss: 1.8504\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8536 - val_loss: 1.8501\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8536 - val_loss: 1.8499\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8536 - val_loss: 1.8504\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8536 - val_loss: 1.8505\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8535 - val_loss: 1.8499\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8535 - val_loss: 1.8502\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8536 - val_loss: 1.8505\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8536 - val_loss: 1.8500\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8535 - val_loss: 1.8500\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8535 - val_loss: 1.8502\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8535 - val_loss: 1.8507\n",
      "Top-2 accuracy = 0.429\n",
      "15\n",
      "standardizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9112 - val_loss: 1.8624\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8355 - val_loss: 1.8092\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8064 - val_loss: 1.7980\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7889 - val_loss: 1.7833\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7817 - val_loss: 1.7782\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7788 - val_loss: 1.7777\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7779 - val_loss: 1.7786\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7758 - val_loss: 1.7748\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7743 - val_loss: 1.7750\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7745 - val_loss: 1.7744\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7732 - val_loss: 1.7717\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7720 - val_loss: 1.7750\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7721\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7715 - val_loss: 1.7710\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7709 - val_loss: 1.7696\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7710 - val_loss: 1.7717\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7705 - val_loss: 1.7706\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7699 - val_loss: 1.7734\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7696 - val_loss: 1.7707\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7679 - val_loss: 1.7678\n",
      "Top-2 accuracy = 0.472\n",
      "16\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9177 - val_loss: 1.9016\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8709 - val_loss: 1.8404\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8190 - val_loss: 1.8037\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7916 - val_loss: 1.7859\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7843 - val_loss: 1.7860\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7818 - val_loss: 1.7791\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7798 - val_loss: 1.7767\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7792 - val_loss: 1.7763\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7777 - val_loss: 1.7752\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7763 - val_loss: 1.7747\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7754 - val_loss: 1.7728\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7741 - val_loss: 1.7723\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7736 - val_loss: 1.7713\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7734 - val_loss: 1.7705\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7720 - val_loss: 1.7719\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7717 - val_loss: 1.7722\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7711 - val_loss: 1.7684\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7710 - val_loss: 1.7682\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7710 - val_loss: 1.7698\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7688 - val_loss: 1.7675\n",
      "Top-2 accuracy = 0.475\n",
      "17\n",
      "maxabsr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.9364 - val_loss: 1.9280\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9221 - val_loss: 1.9181\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9152 - val_loss: 1.9138\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9129 - val_loss: 1.9124\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9119\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9118\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Top-2 accuracy = 0.382\n",
      "18\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8781 - val_loss: 1.8219\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7998 - val_loss: 1.7853\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7787 - val_loss: 1.7779\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7738 - val_loss: 1.7723\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7709 - val_loss: 1.7709\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7694\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7695 - val_loss: 1.7704\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7690 - val_loss: 1.7711\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7679 - val_loss: 1.7677\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7680 - val_loss: 1.7681\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 1.7674\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7656 - val_loss: 1.7661\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7650 - val_loss: 1.7699\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7680 - val_loss: 1.7653\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7655 - val_loss: 1.7661\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7651\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7656 - val_loss: 1.7657\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7640 - val_loss: 1.7662\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7718\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7631 - val_loss: 1.7701\n",
      "Top-2 accuracy = 0.473\n",
      "19\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9349 - val_loss: 1.9228\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9190 - val_loss: 1.9121\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9060\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8867 - val_loss: 1.8630\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8434 - val_loss: 1.8285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8155 - val_loss: 1.8095\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8023 - val_loss: 1.7998\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7956 - val_loss: 1.7954\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7918\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7903 - val_loss: 1.7899\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7887\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7883 - val_loss: 1.7885\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7879 - val_loss: 1.7875\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7872 - val_loss: 1.7893\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7868 - val_loss: 1.7878\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7868 - val_loss: 1.7870\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7860 - val_loss: 1.7867\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7860 - val_loss: 1.7868\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7859 - val_loss: 1.7867\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7870\n",
      "Top-2 accuracy = 0.468\n",
      "20\n",
      "robusty|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4959 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9203 - val_loss: 1.8985\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8900 - val_loss: 1.8804\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8721 - val_loss: 1.8652\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8573 - val_loss: 1.8516\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8443 - val_loss: 1.8402\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8334 - val_loss: 1.8291\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8235 - val_loss: 1.8212\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8145 - val_loss: 1.8120\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8074 - val_loss: 1.8082\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8033 - val_loss: 1.8031\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8006 - val_loss: 1.8004\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7978 - val_loss: 1.7982\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7958 - val_loss: 1.7974\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7945 - val_loss: 1.7951\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7932 - val_loss: 1.7940\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7921 - val_loss: 1.7928\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7913 - val_loss: 1.7926\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7906 - val_loss: 1.7935\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7903 - val_loss: 1.7912\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7898 - val_loss: 1.7910\n",
      "Top-2 accuracy = 0.467\n",
      "21\n",
      "normalizeB|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4965 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9100 - val_loss: 1.8543\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8307 - val_loss: 1.8122\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8044 - val_loss: 1.7963\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7935 - val_loss: 1.7924\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7898 - val_loss: 1.7906\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7794\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7809\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7810 - val_loss: 1.7747\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7771 - val_loss: 1.7756\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7759 - val_loss: 1.7744\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 1.7725\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7735 - val_loss: 1.7725\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7722 - val_loss: 1.7713\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7709 - val_loss: 1.7690\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7705 - val_loss: 1.7717\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7694 - val_loss: 1.7668\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7683 - val_loss: 1.7688\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7699\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7665 - val_loss: 1.7687\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7653 - val_loss: 1.7657\n",
      "Top-2 accuracy = 0.477\n",
      "22\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4972 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9435 - val_loss: 1.9217\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9157 - val_loss: 1.9046\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8981 - val_loss: 1.8874\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8779 - val_loss: 1.8655\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8552 - val_loss: 1.8438\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8383 - val_loss: 1.8325\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8289 - val_loss: 1.8299\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8234 - val_loss: 1.8217\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8188 - val_loss: 1.8176\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8157 - val_loss: 1.8151\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8134 - val_loss: 1.8133\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8113 - val_loss: 1.8111\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8097 - val_loss: 1.8091\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8085 - val_loss: 1.8093\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8071 - val_loss: 1.8064\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8058 - val_loss: 1.8050\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8048 - val_loss: 1.8074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8043 - val_loss: 1.8049\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8034 - val_loss: 1.8023\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8027 - val_loss: 1.8023\n",
      "Top-2 accuracy = 0.459\n",
      "23\n",
      "normalizeu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4975 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9261 - val_loss: 1.9168\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9129 - val_loss: 1.9114\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9095 - val_loss: 1.9087\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9051 - val_loss: 1.9022\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8915 - val_loss: 1.8805\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8657 - val_loss: 1.8581\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8469 - val_loss: 1.8421\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8343 - val_loss: 1.8319\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8255 - val_loss: 1.8232\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8194 - val_loss: 1.8189\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8152 - val_loss: 1.8160\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8123 - val_loss: 1.8107\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8105 - val_loss: 1.8097\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8084 - val_loss: 1.8072\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8069 - val_loss: 1.8068\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8063 - val_loss: 1.8044\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8055 - val_loss: 1.8031\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8047 - val_loss: 1.8032\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8039 - val_loss: 1.8024\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8034 - val_loss: 1.8020\n",
      "Top-2 accuracy = 0.458\n",
      "24\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_4981 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9271 - val_loss: 1.9170\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.9058 - val_loss: 1.8929\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8720 - val_loss: 1.8591\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8442 - val_loss: 1.8391\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8291 - val_loss: 1.8258\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8206 - val_loss: 1.8192\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8147 - val_loss: 1.8113\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8099 - val_loss: 1.8061\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8069 - val_loss: 1.8045\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8047 - val_loss: 1.8013\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8030 - val_loss: 1.8021\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8013 - val_loss: 1.7974\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7998 - val_loss: 1.7972\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7984 - val_loss: 1.7942\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7975 - val_loss: 1.7938\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7915\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7960 - val_loss: 1.7914\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7947 - val_loss: 1.7904\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7952 - val_loss: 1.7895\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7936 - val_loss: 1.7896\n",
      "Top-2 accuracy = 0.467\n",
      "25\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8792 - val_loss: 1.8176\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8029 - val_loss: 1.7967\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7919 - val_loss: 1.7856\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7861 - val_loss: 1.7813\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7824 - val_loss: 1.7879\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7790 - val_loss: 1.7767\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7766 - val_loss: 1.7801\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7745 - val_loss: 1.7702\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7718 - val_loss: 1.7702\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7716 - val_loss: 1.7687\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7709\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7659\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7669\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7667 - val_loss: 1.7672\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7655\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7655 - val_loss: 1.7677\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7654 - val_loss: 1.7651\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7648 - val_loss: 1.7643\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7634 - val_loss: 1.7629\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7659 - val_loss: 1.7633\n",
      "Top-2 accuracy = 0.474\n",
      "26\n",
      "minmaxK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9186 - val_loss: 1.9119\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9125 - val_loss: 1.9110\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9124 - val_loss: 1.9110\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9124 - val_loss: 1.9118\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9119\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9108\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9121\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9111\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9117\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9119\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9117\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9117\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9110\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-2 accuracy = 0.382\n",
      "27\n",
      "maxabsZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9304 - val_loss: 1.9084\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8708 - val_loss: 1.8509\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8235 - val_loss: 1.8162\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8048 - val_loss: 1.7998\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7974 - val_loss: 1.7942\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7948 - val_loss: 1.7911\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7909 - val_loss: 1.7907\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7906 - val_loss: 1.7873\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7899 - val_loss: 1.7887\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.7857\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7877 - val_loss: 1.7848\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7861 - val_loss: 1.7879\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7852 - val_loss: 1.7838\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7845 - val_loss: 1.7820\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7859 - val_loss: 1.7835\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7833 - val_loss: 1.7839\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7828 - val_loss: 1.7916\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7848 - val_loss: 1.7805\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7813\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7811 - val_loss: 1.7790\n",
      "Top-2 accuracy = 0.47\n",
      "28\n",
      "robustB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9303 - val_loss: 1.9047\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8953 - val_loss: 1.8748\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8611 - val_loss: 1.8317\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8197 - val_loss: 1.8074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7996 - val_loss: 1.7926\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7916 - val_loss: 1.7896\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.7849\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7870 - val_loss: 1.7843\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7849 - val_loss: 1.7826\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7835 - val_loss: 1.7822\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7829 - val_loss: 1.7810\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7816 - val_loss: 1.7793\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7785\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7785 - val_loss: 1.7807\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7775\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7769 - val_loss: 1.7760\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7754\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7753 - val_loss: 1.7767\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7751\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7750\n",
      "Top-2 accuracy = 0.472\n",
      "29\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9081 - val_loss: 1.8805\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8556 - val_loss: 1.8482\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8311 - val_loss: 1.8264\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8161 - val_loss: 1.8136\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8065 - val_loss: 1.8036\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7994 - val_loss: 1.7989\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7933 - val_loss: 1.7907\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7895 - val_loss: 1.7882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7866 - val_loss: 1.7831\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7845 - val_loss: 1.7819\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7807\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7799\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7805 - val_loss: 1.7788\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7801 - val_loss: 1.7794\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7803\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7766\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7778 - val_loss: 1.7763\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7781 - val_loss: 1.7782\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7770 - val_loss: 1.7768\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7771 - val_loss: 1.7787\n",
      "Top-2 accuracy = 0.475\n",
      "0\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8905 - val_loss: 1.8275\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8070 - val_loss: 1.7945\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7896 - val_loss: 1.7884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7833 - val_loss: 1.7816\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7809 - val_loss: 1.7796\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7795 - val_loss: 1.7785\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7781 - val_loss: 1.7761\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 1.7760\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7754 - val_loss: 1.7763\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7742 - val_loss: 1.7753\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7738 - val_loss: 1.7751\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7723 - val_loss: 1.7720\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7775\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7710 - val_loss: 1.7725\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7725\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7695 - val_loss: 1.7703\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7696 - val_loss: 1.7708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7694\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7674 - val_loss: 1.7660\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7685 - val_loss: 1.7687\n",
      "Top-2 accuracy = 0.473\n",
      "1\n",
      "minmaxU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9222 - val_loss: 1.9143\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9124 - val_loss: 1.9074\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8852 - val_loss: 1.8592\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8382 - val_loss: 1.8261\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8160 - val_loss: 1.8161\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8060 - val_loss: 1.7997\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8013 - val_loss: 1.8184\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8011 - val_loss: 1.8008\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7995 - val_loss: 1.7947\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7939 - val_loss: 1.7963\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7958 - val_loss: 1.7904\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7934 - val_loss: 1.7972\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7930 - val_loss: 1.8233\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8099 - val_loss: 1.7897\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7908 - val_loss: 1.7896\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7906 - val_loss: 1.7947\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7895 - val_loss: 1.7883\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7892 - val_loss: 1.8029\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7892 - val_loss: 1.7850\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7893 - val_loss: 1.7855\n",
      "Top-2 accuracy = 0.465\n",
      "2\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5029 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9233 - val_loss: 1.9077\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9051 - val_loss: 1.8939\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8824 - val_loss: 1.8632\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8508 - val_loss: 1.8380\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8332 - val_loss: 1.8300\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8258 - val_loss: 1.8225\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8210 - val_loss: 1.8181\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8174 - val_loss: 1.8147\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8142 - val_loss: 1.8112\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8116 - val_loss: 1.8099\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8090 - val_loss: 1.8070\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8065 - val_loss: 1.8037\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8045 - val_loss: 1.8017\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8026 - val_loss: 1.8004\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8008 - val_loss: 1.7996\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7995 - val_loss: 1.7982\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7978 - val_loss: 1.7972\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7962 - val_loss: 1.7937\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7952 - val_loss: 1.7950\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7945 - val_loss: 1.7925\n",
      "Top-2 accuracy = 0.463\n",
      "3\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9240 - val_loss: 1.9147\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9131 - val_loss: 1.9107\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9061 - val_loss: 1.8978\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8814 - val_loss: 1.8664\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8522 - val_loss: 1.8412\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8329 - val_loss: 1.8316\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8252 - val_loss: 1.8195\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8184 - val_loss: 1.8174\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8139 - val_loss: 1.8145\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8133 - val_loss: 1.8140\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8103 - val_loss: 1.8083\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8091 - val_loss: 1.8079\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8081 - val_loss: 1.8063\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8098 - val_loss: 1.8056\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8063 - val_loss: 1.8049\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8058 - val_loss: 1.8077\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8054 - val_loss: 1.8047\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8055 - val_loss: 1.8036\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8051 - val_loss: 1.8030\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8039 - val_loss: 1.8029\n",
      "Top-2 accuracy = 0.452\n",
      "4\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5040 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9239 - val_loss: 1.8857\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8607 - val_loss: 1.8432\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8319 - val_loss: 1.8241\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8189 - val_loss: 1.8140\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8116 - val_loss: 1.8077\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8067 - val_loss: 1.8036\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8027 - val_loss: 1.7997\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7996 - val_loss: 1.7969\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7969 - val_loss: 1.7945\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7950 - val_loss: 1.7927\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7931 - val_loss: 1.7911\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7917 - val_loss: 1.7897\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7905 - val_loss: 1.7884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7894 - val_loss: 1.7874\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7887 - val_loss: 1.7866\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7875 - val_loss: 1.7853\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7868 - val_loss: 1.7850\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7859 - val_loss: 1.7841\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7853 - val_loss: 1.7844\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7846 - val_loss: 1.7832\n",
      "Top-2 accuracy = 0.47\n",
      "5\n",
      "minmaxo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9134 - val_loss: 1.8584\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8281 - val_loss: 1.8105\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8043 - val_loss: 1.8019\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7980 - val_loss: 1.7985\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7944 - val_loss: 1.7972\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7933 - val_loss: 1.7908\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7912 - val_loss: 1.7925\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7908 - val_loss: 1.7960\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7979\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7893 - val_loss: 1.7875\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7885 - val_loss: 1.7865\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7878 - val_loss: 1.7844\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7852 - val_loss: 1.7873\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7875 - val_loss: 1.7864\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7849 - val_loss: 1.7834\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7843 - val_loss: 1.7852\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7830 - val_loss: 1.7834\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7831 - val_loss: 1.7828\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7811 - val_loss: 1.7809\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7815\n",
      "Top-2 accuracy = 0.467\n",
      "6\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9317 - val_loss: 1.9012\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8622 - val_loss: 1.8220\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8128 - val_loss: 1.7992\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7963 - val_loss: 1.7910\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7899 - val_loss: 1.7871\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7853 - val_loss: 1.7843\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7829 - val_loss: 1.7822\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7823\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7805 - val_loss: 1.7830\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7790 - val_loss: 1.7792\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7788\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7773 - val_loss: 1.7810\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7772 - val_loss: 1.7784\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7761 - val_loss: 1.7821\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7760 - val_loss: 1.7770\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7756\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7749 - val_loss: 1.7762\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7742 - val_loss: 1.7741\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7736 - val_loss: 1.7739\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7731 - val_loss: 1.7736\n",
      "Top-2 accuracy = 0.472\n",
      "7\n",
      "standardizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9362 - val_loss: 1.9268\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9216 - val_loss: 1.9165\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9149 - val_loss: 1.9130\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9129 - val_loss: 1.9121\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9118\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9117\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9112\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "8\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9217 - val_loss: 1.8921\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8627 - val_loss: 1.8343\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8219 - val_loss: 1.8116\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7974 - val_loss: 1.7978\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7870 - val_loss: 1.7868\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7843 - val_loss: 1.7859\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7835 - val_loss: 1.7915\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7808 - val_loss: 1.7877\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7797 - val_loss: 1.7781\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7770 - val_loss: 1.7842\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7783 - val_loss: 1.7792\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7759 - val_loss: 1.7779\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7777 - val_loss: 1.7822\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7752 - val_loss: 1.7764\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7739 - val_loss: 1.7749\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7735 - val_loss: 1.7800\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7725 - val_loss: 1.7913\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7758 - val_loss: 1.7851\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7732 - val_loss: 1.7717\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7715 - val_loss: 1.7817\n",
      "Top-2 accuracy = 0.468\n",
      "9\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9006 - val_loss: 1.8433\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8107 - val_loss: 1.7923\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7909 - val_loss: 1.7865\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7877 - val_loss: 1.7831\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7833 - val_loss: 1.7791\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7800 - val_loss: 1.7719\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7744 - val_loss: 1.7678\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 1.7716\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7698 - val_loss: 1.7667\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7698 - val_loss: 1.7665\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7687 - val_loss: 1.7651\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7664 - val_loss: 1.7655\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7660 - val_loss: 1.7664\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7669 - val_loss: 1.7645\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7657 - val_loss: 1.7630\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7641\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7648 - val_loss: 1.7648\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7653 - val_loss: 1.7637\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7638 - val_loss: 1.7629\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7644 - val_loss: 1.7625\n",
      "Top-2 accuracy = 0.476\n",
      "10\n",
      "minmaxJ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5074 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9268 - val_loss: 1.8988\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8894 - val_loss: 1.8689\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8548 - val_loss: 1.8369\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8289 - val_loss: 1.8215\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8182 - val_loss: 1.8140\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8134 - val_loss: 1.8103\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8098 - val_loss: 1.8081\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8070 - val_loss: 1.8061\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8052 - val_loss: 1.8022\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8040 - val_loss: 1.8012\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8024 - val_loss: 1.8030\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8023 - val_loss: 1.7986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8011 - val_loss: 1.8009\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8001 - val_loss: 1.8023\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7996 - val_loss: 1.7989\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7987 - val_loss: 1.7969\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7983 - val_loss: 1.7963\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7980 - val_loss: 1.7953\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7975 - val_loss: 1.7960\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7967 - val_loss: 1.7949\n",
      "Top-2 accuracy = 0.466\n",
      "11\n",
      "standardizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9197 - val_loss: 1.8845\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8419 - val_loss: 1.8174\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8070 - val_loss: 1.8028\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7921\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7858\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7835\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7845 - val_loss: 1.7824\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7831 - val_loss: 1.7830\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7800\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7807 - val_loss: 1.7785\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7796 - val_loss: 1.7774\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7789 - val_loss: 1.7795\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7781 - val_loss: 1.7803\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7768 - val_loss: 1.7754\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7762 - val_loss: 1.7742\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7733\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7747 - val_loss: 1.7754\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7738 - val_loss: 1.7732\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7730 - val_loss: 1.7722\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7719 - val_loss: 1.7704\n",
      "Top-2 accuracy = 0.472\n",
      "12\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9289 - val_loss: 1.8959\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8536 - val_loss: 1.8223\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8074 - val_loss: 1.7938\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7834 - val_loss: 1.7835\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7788 - val_loss: 1.7789\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7767 - val_loss: 1.7772\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7746 - val_loss: 1.7733\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7723 - val_loss: 1.7726\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7715 - val_loss: 1.7747\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7700 - val_loss: 1.7729\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7681 - val_loss: 1.7722\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7688 - val_loss: 1.7678\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7677 - val_loss: 1.7688\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7671 - val_loss: 1.7709\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7669 - val_loss: 1.7674\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7667 - val_loss: 1.7657\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7656 - val_loss: 1.7651\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7662 - val_loss: 1.7662\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7665 - val_loss: 1.7665\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7672 - val_loss: 1.7667\n",
      "Top-2 accuracy = 0.476\n",
      "13\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9058 - val_loss: 1.8654\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8348 - val_loss: 1.8152\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8066 - val_loss: 1.8000\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7975 - val_loss: 1.7944\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7925 - val_loss: 1.7934\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7895 - val_loss: 1.7906\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7871 - val_loss: 1.7863\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7856\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7839\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7829 - val_loss: 1.7827\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7814 - val_loss: 1.7806\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7800 - val_loss: 1.7812\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7792 - val_loss: 1.7788\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7781 - val_loss: 1.7774\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7783 - val_loss: 1.7766\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7767 - val_loss: 1.7757\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7759 - val_loss: 1.7749\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7755 - val_loss: 1.7780\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7742\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7740 - val_loss: 1.7742\n",
      "Top-2 accuracy = 0.472\n",
      "14\n",
      "normalizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9022 - val_loss: 1.8397\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8143 - val_loss: 1.7980\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7928 - val_loss: 1.7868\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7832 - val_loss: 1.7845\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7833 - val_loss: 1.7779\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7768 - val_loss: 1.7738\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7762 - val_loss: 1.7763\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7754 - val_loss: 1.7725\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7759 - val_loss: 1.7759\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7812 - val_loss: 1.7765\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7738 - val_loss: 1.7717\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7711 - val_loss: 1.7684\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7699 - val_loss: 1.7681\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7679 - val_loss: 1.7714\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7670 - val_loss: 1.7667\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7750 - val_loss: 1.7689\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7656 - val_loss: 1.7703\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7652 - val_loss: 1.7789\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7659 - val_loss: 1.7683\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7632 - val_loss: 1.7652\n",
      "Top-2 accuracy = 0.474\n",
      "15\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9343 - val_loss: 1.9218\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8991 - val_loss: 1.8784\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8525 - val_loss: 1.8459\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8301 - val_loss: 1.8307\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8193 - val_loss: 1.8215\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8131 - val_loss: 1.8160\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8096 - val_loss: 1.8128\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8072 - val_loss: 1.8105\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8058 - val_loss: 1.8087\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8046 - val_loss: 1.8075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8037 - val_loss: 1.8069\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8034 - val_loss: 1.8061\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8028 - val_loss: 1.8056\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8023 - val_loss: 1.8044\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8022 - val_loss: 1.8043\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8017 - val_loss: 1.8035\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8016 - val_loss: 1.8031\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8011 - val_loss: 1.8030\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8009 - val_loss: 1.8033\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8008 - val_loss: 1.8023\n",
      "Top-2 accuracy = 0.453\n",
      "16\n",
      "normalizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9154 - val_loss: 1.8837\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8391 - val_loss: 1.8173\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8056 - val_loss: 1.7959\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.7895\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7841 - val_loss: 1.7828\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7804 - val_loss: 1.7811\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7790\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7765 - val_loss: 1.7813\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7752 - val_loss: 1.7773\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7738 - val_loss: 1.7765\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7725 - val_loss: 1.7838\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7734 - val_loss: 1.7746\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7710 - val_loss: 1.7744\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7755\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7706 - val_loss: 1.7764\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7701 - val_loss: 1.7716\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7710\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7684 - val_loss: 1.7698\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7681 - val_loss: 1.7690\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7698\n",
      "Top-2 accuracy = 0.471\n",
      "17\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9053 - val_loss: 1.8519\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8206 - val_loss: 1.7914\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7811 - val_loss: 1.7772\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7731 - val_loss: 1.7711\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7708 - val_loss: 1.7730\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7688 - val_loss: 1.7677\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7677 - val_loss: 1.7678\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7663 - val_loss: 1.7694\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7679 - val_loss: 1.7686\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7656 - val_loss: 1.7665\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7673 - val_loss: 1.7690\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7657 - val_loss: 1.7675\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7659 - val_loss: 1.7816\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7668 - val_loss: 1.7678\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7653 - val_loss: 1.7675\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7648 - val_loss: 1.7674\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7644 - val_loss: 1.7661\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7637 - val_loss: 1.7674\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7642 - val_loss: 1.7668\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7632 - val_loss: 1.7684\n",
      "Top-2 accuracy = 0.473\n",
      "18\n",
      "robustz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9024 - val_loss: 1.8451\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8203 - val_loss: 1.8014\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7945 - val_loss: 1.8034\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7876 - val_loss: 1.7829\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7767\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7773 - val_loss: 1.7749\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7834\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7744 - val_loss: 1.8020\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7768 - val_loss: 1.7742\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7712 - val_loss: 1.7785\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7711\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7705 - val_loss: 1.7691\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7724 - val_loss: 1.7719\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7688 - val_loss: 1.7681\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7691\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7675\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7681 - val_loss: 1.7715\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7692\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7667\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7653 - val_loss: 1.7723\n",
      "Top-2 accuracy = 0.471\n",
      "19\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5118 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9235 - val_loss: 1.8895\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8731 - val_loss: 1.8334\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8108 - val_loss: 1.7915\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7888 - val_loss: 1.7848\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7836 - val_loss: 1.7804\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7810 - val_loss: 1.7786\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7796 - val_loss: 1.7771\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7775 - val_loss: 1.7771\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7761 - val_loss: 1.7753\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7745 - val_loss: 1.7744\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7735 - val_loss: 1.7728\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7723 - val_loss: 1.7722\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7712 - val_loss: 1.7719\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7720\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7700\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7720\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7691\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7677 - val_loss: 1.7729\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7697 - val_loss: 1.7676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7666 - val_loss: 1.7675\n",
      "Top-2 accuracy = 0.476\n",
      "20\n",
      "standardizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8999 - val_loss: 1.8425\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8144 - val_loss: 1.7984\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7927 - val_loss: 1.7893\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7813\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7808 - val_loss: 1.7783\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7772 - val_loss: 1.7796\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7744\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7731 - val_loss: 1.7707\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7714 - val_loss: 1.7696\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7700 - val_loss: 1.7698\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7692\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7683 - val_loss: 1.7693\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7654\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 1.7655\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7653 - val_loss: 1.7653\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7650\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7641 - val_loss: 1.7649\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7689\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7635 - val_loss: 1.7646\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7633\n",
      "Top-2 accuracy = 0.478\n",
      "21\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9349 - val_loss: 1.9227\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9168 - val_loss: 1.9111\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9110\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9118\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9111\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Top-2 accuracy = 0.382\n",
      "22\n",
      "standardizec|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5132 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9387 - val_loss: 1.9062\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8868 - val_loss: 1.8639\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8414 - val_loss: 1.8227\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8095 - val_loss: 1.8026\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7974 - val_loss: 1.7952\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7925 - val_loss: 1.7921\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7900 - val_loss: 1.7892\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7878 - val_loss: 1.7876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7866 - val_loss: 1.7859\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7852 - val_loss: 1.7847\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7840 - val_loss: 1.7830\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7827 - val_loss: 1.7825\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7815 - val_loss: 1.7809\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7807 - val_loss: 1.7798\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7799 - val_loss: 1.7789\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7791 - val_loss: 1.7785\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7786 - val_loss: 1.7776\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7777 - val_loss: 1.7785\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7771 - val_loss: 1.7761\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7767 - val_loss: 1.7763\n",
      "Top-2 accuracy = 0.471\n",
      "23\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9140 - val_loss: 1.8784\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8533 - val_loss: 1.8428\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8266 - val_loss: 1.8235\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8136 - val_loss: 1.8105\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8073 - val_loss: 1.8041\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8037 - val_loss: 1.8010\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8013 - val_loss: 1.7994\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7983 - val_loss: 1.7942\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7939 - val_loss: 1.7915\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7898 - val_loss: 1.7887\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7876 - val_loss: 1.7868\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7870 - val_loss: 1.7873\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7846 - val_loss: 1.7852\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7833 - val_loss: 1.7832\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7793\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7816 - val_loss: 1.7814\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7832 - val_loss: 1.7813\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7810 - val_loss: 1.7781\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7804 - val_loss: 1.7814\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7799 - val_loss: 1.7769\n",
      "Top-2 accuracy = 0.467\n",
      "24\n",
      "standardizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8956 - val_loss: 1.8445\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8189 - val_loss: 1.8008\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7913 - val_loss: 1.7863\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7819 - val_loss: 1.7809\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7772 - val_loss: 1.7765\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7733 - val_loss: 1.7773\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7722 - val_loss: 1.7730\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7702\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7693 - val_loss: 1.7703\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7679 - val_loss: 1.7724\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7676 - val_loss: 1.7675\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7670 - val_loss: 1.7666\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7666 - val_loss: 1.7659\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7657 - val_loss: 1.7706\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7650 - val_loss: 1.7668\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7641 - val_loss: 1.7765\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7659 - val_loss: 1.7676\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7634 - val_loss: 1.7638\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7633 - val_loss: 1.7638\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7632\n",
      "Top-2 accuracy = 0.477\n",
      "25\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9170 - val_loss: 1.8969\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8409 - val_loss: 1.8084\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7983 - val_loss: 1.7954\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7890 - val_loss: 1.7884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7863 - val_loss: 1.7854\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7889\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7847 - val_loss: 1.7851\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7837 - val_loss: 1.7829\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7828 - val_loss: 1.7820\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7827\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7809 - val_loss: 1.7807\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7799 - val_loss: 1.7810\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7802 - val_loss: 1.7808\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7797 - val_loss: 1.7805\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7790 - val_loss: 1.7788\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7789 - val_loss: 1.7797\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7787 - val_loss: 1.7789\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7791 - val_loss: 1.7781\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7801\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7803\n",
      "Top-2 accuracy = 0.47\n",
      "26\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9369 - val_loss: 1.9235\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8726 - val_loss: 1.8349\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8122 - val_loss: 1.8085\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7998 - val_loss: 1.8018\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7954 - val_loss: 1.7976\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7944\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7908 - val_loss: 1.7924\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7913\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7885 - val_loss: 1.7895\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7877 - val_loss: 1.7889\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7871 - val_loss: 1.7872\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7858 - val_loss: 1.7860\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7851\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7843 - val_loss: 1.7845\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7834 - val_loss: 1.7845\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7826 - val_loss: 1.7834\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7826 - val_loss: 1.7842\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7821\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7811 - val_loss: 1.7834\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7826\n",
      "Top-2 accuracy = 0.469\n",
      "27\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5159 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9488 - val_loss: 1.8833\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8542 - val_loss: 1.8395\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8267 - val_loss: 1.8216\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8140 - val_loss: 1.8105\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8054 - val_loss: 1.8026\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7993 - val_loss: 1.7970\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7951 - val_loss: 1.7939\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7922 - val_loss: 1.7904\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7900 - val_loss: 1.7884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7881 - val_loss: 1.7859\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7869 - val_loss: 1.7853\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7854 - val_loss: 1.7839\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7833\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7832 - val_loss: 1.7811\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7825 - val_loss: 1.7817\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7814 - val_loss: 1.7812\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7807 - val_loss: 1.7792\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7797 - val_loss: 1.7774\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7790 - val_loss: 1.7774\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7783 - val_loss: 1.7770\n",
      "Top-2 accuracy = 0.474\n",
      "28\n",
      "normalizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9021 - val_loss: 1.8466\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8137 - val_loss: 1.7936\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7870 - val_loss: 1.7897\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7791 - val_loss: 1.7778\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7764 - val_loss: 1.7720\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7746 - val_loss: 1.7831\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7797\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 1.7709\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7719 - val_loss: 1.7731\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7702 - val_loss: 1.7746\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7711 - val_loss: 1.7688\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7691 - val_loss: 1.7666\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7665\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7675 - val_loss: 1.7701\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7675\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7661\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7665 - val_loss: 1.7745\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7685 - val_loss: 1.7651\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7685 - val_loss: 1.7644\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7654\n",
      "Top-2 accuracy = 0.474\n",
      "29\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8989 - val_loss: 1.8301\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8103 - val_loss: 1.8007\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7968 - val_loss: 1.7939\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7926 - val_loss: 1.7899\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7893 - val_loss: 1.7908\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7882 - val_loss: 1.7887\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7861 - val_loss: 1.7837\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7842 - val_loss: 1.7803\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7834 - val_loss: 1.7803\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7830 - val_loss: 1.7791\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7818 - val_loss: 1.7891\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7818 - val_loss: 1.7854\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7801 - val_loss: 1.7787\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7796 - val_loss: 1.7832\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7827 - val_loss: 1.7769\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7791 - val_loss: 1.7760\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7777 - val_loss: 1.7838\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7799 - val_loss: 1.7741\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7772 - val_loss: 1.7827\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7792 - val_loss: 1.7767\n",
      "Top-2 accuracy = 0.473\n",
      "0\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8933 - val_loss: 1.8350\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8159 - val_loss: 1.8019\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7988 - val_loss: 1.7951\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7900 - val_loss: 1.7883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7861 - val_loss: 1.7840\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7842 - val_loss: 1.7818\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7816 - val_loss: 1.7808\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7801 - val_loss: 1.7803\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7789 - val_loss: 1.7770\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7792 - val_loss: 1.7838\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7778 - val_loss: 1.7782\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7771 - val_loss: 1.7810\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7778 - val_loss: 1.7729\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7762 - val_loss: 1.7726\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7745 - val_loss: 1.7766\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7758 - val_loss: 1.7712\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7737 - val_loss: 1.7726\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7749 - val_loss: 1.7730\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7734 - val_loss: 1.7787\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7787 - val_loss: 1.7714\n",
      "Top-2 accuracy = 0.472\n",
      "1\n",
      "maxabsV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9290 - val_loss: 1.9171\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9132 - val_loss: 1.9091\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9039 - val_loss: 1.8954\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8764 - val_loss: 1.8612\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8411 - val_loss: 1.8327\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8195 - val_loss: 1.8155\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8077 - val_loss: 1.8063\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8009 - val_loss: 1.8000\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7966 - val_loss: 1.7969\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7943 - val_loss: 1.7943\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7923 - val_loss: 1.7922\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7909 - val_loss: 1.7917\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7892 - val_loss: 1.7887\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7881 - val_loss: 1.7888\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7873 - val_loss: 1.7872\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7866 - val_loss: 1.7869\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7860 - val_loss: 1.7863\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7859\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7857\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7849 - val_loss: 1.7854\n",
      "Top-2 accuracy = 0.468\n",
      "2\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9025 - val_loss: 1.8536\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8363 - val_loss: 1.8206\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8148 - val_loss: 1.8095\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8067 - val_loss: 1.8064\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8020 - val_loss: 1.7954\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7939 - val_loss: 1.8276\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7941 - val_loss: 1.7882\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7907 - val_loss: 1.7878\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7878 - val_loss: 1.7852\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7862 - val_loss: 1.7854\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7880 - val_loss: 1.7841\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7846 - val_loss: 1.7822\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7837 - val_loss: 1.7882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7835 - val_loss: 1.7854\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7842 - val_loss: 1.7796\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7797 - val_loss: 1.7789\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7792 - val_loss: 1.7782\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7769 - val_loss: 1.7776\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7757 - val_loss: 1.7840\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7757 - val_loss: 1.7766\n",
      "Top-2 accuracy = 0.468\n",
      "3\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9322 - val_loss: 1.9178\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8988 - val_loss: 1.8732\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8454 - val_loss: 1.8304\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8186 - val_loss: 1.8162\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8081 - val_loss: 1.8060\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8037 - val_loss: 1.8025\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7997 - val_loss: 1.7994\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7999 - val_loss: 1.7999\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7968 - val_loss: 1.8084\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7979 - val_loss: 1.7959\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7946 - val_loss: 1.7942\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7937 - val_loss: 1.7947\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7934 - val_loss: 1.7923\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7920 - val_loss: 1.7903\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7918 - val_loss: 1.7902\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7913 - val_loss: 1.7898\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7908 - val_loss: 1.7891\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7912 - val_loss: 1.7914\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7919 - val_loss: 1.7908\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7899 - val_loss: 1.7910\n",
      "Top-2 accuracy = 0.466\n",
      "4\n",
      "maxabsY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9139 - val_loss: 1.8824\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8525 - val_loss: 1.8356\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8189 - val_loss: 1.8131\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8034 - val_loss: 1.7999\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7967 - val_loss: 1.7957\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7925 - val_loss: 1.7906\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7915 - val_loss: 1.7958\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7897 - val_loss: 1.7896\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7890 - val_loss: 1.7896\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7891 - val_loss: 1.7872\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7882 - val_loss: 1.7869\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7883 - val_loss: 1.7862\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7873 - val_loss: 1.7873\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7885 - val_loss: 1.7864\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7888 - val_loss: 1.7858\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7879 - val_loss: 1.7869\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7871\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7886 - val_loss: 1.7890\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7879 - val_loss: 1.7854\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7870 - val_loss: 1.7854\n",
      "Top-2 accuracy = 0.468\n",
      "5\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5199 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9141 - val_loss: 1.8986\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8687 - val_loss: 1.8412\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8240 - val_loss: 1.8105\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8057 - val_loss: 1.8005\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7989 - val_loss: 1.7977\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7972 - val_loss: 1.7934\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7950 - val_loss: 1.7919\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7940 - val_loss: 1.7925\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7938 - val_loss: 1.7917\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7923 - val_loss: 1.7894\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7889\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7913 - val_loss: 1.7877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7902 - val_loss: 1.7908\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7898 - val_loss: 1.7886\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7883 - val_loss: 1.7926\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7891 - val_loss: 1.7882\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7880 - val_loss: 1.7911\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7870 - val_loss: 1.7838\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7854\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7857\n",
      "Top-2 accuracy = 0.469\n",
      "6\n",
      "normalizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9386 - val_loss: 1.9313\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9260 - val_loss: 1.9178\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9053 - val_loss: 1.8833\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8638 - val_loss: 1.8503\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8379 - val_loss: 1.8340\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8243 - val_loss: 1.8239\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8161 - val_loss: 1.8156\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8103 - val_loss: 1.8122\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8068 - val_loss: 1.8073\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8044 - val_loss: 1.8042\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8025 - val_loss: 1.8025\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8013 - val_loss: 1.8011\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8006 - val_loss: 1.8001\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7998 - val_loss: 1.8014\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7995 - val_loss: 1.7991\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7988 - val_loss: 1.7991\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7985 - val_loss: 1.7995\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7981 - val_loss: 1.7988\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7980 - val_loss: 1.7974\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7983 - val_loss: 1.7981\n",
      "Top-2 accuracy = 0.464\n",
      "7\n",
      "standardizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9050 - val_loss: 1.8426\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8176 - val_loss: 1.8052\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8007 - val_loss: 1.7936\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7937 - val_loss: 1.7883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7843\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7865 - val_loss: 1.7844\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7856 - val_loss: 1.7809\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7834 - val_loss: 1.7790\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7828 - val_loss: 1.7847\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7813 - val_loss: 1.7765\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7802 - val_loss: 1.7777\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7802 - val_loss: 1.7752\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7766\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7785 - val_loss: 1.7745\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7774 - val_loss: 1.7733\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7744\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7757 - val_loss: 1.7723\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7770 - val_loss: 1.7758\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7751 - val_loss: 1.7722\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7724\n",
      "Top-2 accuracy = 0.471\n",
      "8\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8884 - val_loss: 1.8385\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8093 - val_loss: 1.7895\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7844 - val_loss: 1.7837\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7792 - val_loss: 1.7774\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7764 - val_loss: 1.7832\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7762 - val_loss: 1.7750\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7750 - val_loss: 1.7736\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7739 - val_loss: 1.7709\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7745 - val_loss: 1.7714\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7734 - val_loss: 1.7734\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7728 - val_loss: 1.7734\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7703 - val_loss: 1.7727\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7708 - val_loss: 1.7765\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7697 - val_loss: 1.7688\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7719 - val_loss: 1.7680\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7695 - val_loss: 1.7680\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7685 - val_loss: 1.7690\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7687 - val_loss: 1.7677\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7683 - val_loss: 1.7687\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7672 - val_loss: 1.7809\n",
      "Top-2 accuracy = 0.473\n",
      "9\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9322 - val_loss: 1.9138\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8934 - val_loss: 1.8636\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8481 - val_loss: 1.8297\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8249 - val_loss: 1.8183\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8143 - val_loss: 1.8109\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8084 - val_loss: 1.8078\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8044 - val_loss: 1.8035\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8015 - val_loss: 1.8041\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8007 - val_loss: 1.7994\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7993 - val_loss: 1.7984\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7975 - val_loss: 1.7975\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7965 - val_loss: 1.7959\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7964 - val_loss: 1.7955\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7956 - val_loss: 1.7968\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7950 - val_loss: 1.7940\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7950 - val_loss: 1.7940\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7946 - val_loss: 1.7955\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7944 - val_loss: 1.7933\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7943 - val_loss: 1.8002\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7951 - val_loss: 1.7936\n",
      "Top-2 accuracy = 0.467\n",
      "10\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9084 - val_loss: 1.8478\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8233 - val_loss: 1.8100\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8044 - val_loss: 1.7971\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7941 - val_loss: 1.7895\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7902 - val_loss: 1.7866\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7857 - val_loss: 1.7830\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7813\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7801 - val_loss: 1.7773\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7762\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7767 - val_loss: 1.7737\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7719\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7760\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7711\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7722\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7708 - val_loss: 1.7715\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7710 - val_loss: 1.7724\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7702\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7699 - val_loss: 1.7697\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7692\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7716\n",
      "Top-2 accuracy = 0.47\n",
      "11\n",
      "minmaxa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9030 - val_loss: 1.8603\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8177 - val_loss: 1.8001\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7866 - val_loss: 1.7788\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7803 - val_loss: 1.7794\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7804 - val_loss: 1.7782\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7789 - val_loss: 1.7744\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7771 - val_loss: 1.7753\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7770 - val_loss: 1.7725\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7756 - val_loss: 1.7728\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7765 - val_loss: 1.7759\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7752 - val_loss: 1.7767\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7758 - val_loss: 1.7739\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7794 - val_loss: 1.7765\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7798 - val_loss: 1.7722\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7747 - val_loss: 1.7760\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7736 - val_loss: 1.7722\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7737 - val_loss: 1.7715\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.7709\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7731 - val_loss: 1.7696\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7733 - val_loss: 1.7868\n",
      "Top-2 accuracy = 0.458\n",
      "12\n",
      "maxabsB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8945 - val_loss: 1.8366\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8183 - val_loss: 1.7980\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7941 - val_loss: 1.7877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7904 - val_loss: 1.7977\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7909 - val_loss: 1.7853\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7861 - val_loss: 1.7842\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7816\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7792\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7814 - val_loss: 1.7826\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7824 - val_loss: 1.7804\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7821 - val_loss: 1.7782\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7813 - val_loss: 1.7776\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7802 - val_loss: 1.7772\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7808 - val_loss: 1.7764\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7778 - val_loss: 1.7793\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7776 - val_loss: 1.7749\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7772 - val_loss: 1.7745\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7777 - val_loss: 1.7735\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7760 - val_loss: 1.7734\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7764\n",
      "Top-2 accuracy = 0.472\n",
      "13\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9292 - val_loss: 1.9165\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8979 - val_loss: 1.8663\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8288 - val_loss: 1.8098\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8040 - val_loss: 1.8011\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8005 - val_loss: 1.7992\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7989 - val_loss: 1.7986\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7977 - val_loss: 1.7987\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7975 - val_loss: 1.7950\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7956 - val_loss: 1.7978\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7961 - val_loss: 1.7961\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7959 - val_loss: 1.7937\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7940 - val_loss: 1.7969\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7944 - val_loss: 1.7950\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7932 - val_loss: 1.8022\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7941 - val_loss: 1.7923\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7926 - val_loss: 1.7943\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7921 - val_loss: 1.7913\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7927\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7890\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7909 - val_loss: 1.7887\n",
      "Top-2 accuracy = 0.465\n",
      "14\n",
      "normalizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9111\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9115 - val_loss: 1.9043\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8752 - val_loss: 1.8553\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8276 - val_loss: 1.8065\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7996 - val_loss: 1.7956\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7963 - val_loss: 1.7919\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7941 - val_loss: 1.7990\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7932 - val_loss: 1.7928\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7910 - val_loss: 1.7877\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7883 - val_loss: 1.7834\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 1.7838\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7875 - val_loss: 1.7878\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7842 - val_loss: 1.8005\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7868 - val_loss: 1.7815\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7845 - val_loss: 1.7787\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7831 - val_loss: 1.7863\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7879 - val_loss: 1.7779\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7817 - val_loss: 1.7778\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7839 - val_loss: 1.7786\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7803 - val_loss: 1.7828\n",
      "Top-2 accuracy = 0.466\n",
      "15\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9122 - val_loss: 1.8565\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8366 - val_loss: 1.8109\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8033 - val_loss: 1.8016\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7991 - val_loss: 1.7918\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7958 - val_loss: 1.7895\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7907 - val_loss: 1.7861\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7903 - val_loss: 1.7862\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7889 - val_loss: 1.7931\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7858 - val_loss: 1.7829\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7859 - val_loss: 1.7795\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7827 - val_loss: 1.7818\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7844 - val_loss: 1.7840\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7814 - val_loss: 1.7758\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7804 - val_loss: 1.7774\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7794 - val_loss: 1.7760\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7802 - val_loss: 1.7806\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7819 - val_loss: 1.7738\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7763 - val_loss: 1.7724\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7755 - val_loss: 1.7752\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7768 - val_loss: 1.7745\n",
      "Top-2 accuracy = 0.472\n",
      "16\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9291 - val_loss: 1.9202\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9153 - val_loss: 1.9141\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9128 - val_loss: 1.9123\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9118\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9117\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Top-2 accuracy = 0.382\n",
      "17\n",
      "minmaxX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9203 - val_loss: 1.9120\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9124 - val_loss: 1.9113\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9127\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9125 - val_loss: 1.9117\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9117\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9119\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9115\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9124 - val_loss: 1.9114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9124 - val_loss: 1.9119\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9077 - val_loss: 1.9012\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9035 - val_loss: 1.9052\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9049 - val_loss: 1.9056\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9050 - val_loss: 1.9055\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9048 - val_loss: 1.9058\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9046 - val_loss: 1.9052\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9047 - val_loss: 1.9057\n",
      "Top-2 accuracy = 0.387\n",
      "18\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5273 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8833 - val_loss: 1.8271\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8060 - val_loss: 1.7957\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7888 - val_loss: 1.7839\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7828 - val_loss: 1.7807\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7787 - val_loss: 1.7772\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7738\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7742 - val_loss: 1.7712\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7716 - val_loss: 1.7719\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7700\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7691\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7671\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 1.7647\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7649\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7643 - val_loss: 1.7633\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7631 - val_loss: 1.7636\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7697\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7617\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7612 - val_loss: 1.7657\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7611 - val_loss: 1.7617\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7611\n",
      "Top-2 accuracy = 0.482\n",
      "19\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9304 - val_loss: 1.9071\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8683 - val_loss: 1.8351\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8161 - val_loss: 1.8061\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7986 - val_loss: 1.7951\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7923 - val_loss: 1.7904\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7893 - val_loss: 1.7890\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7876 - val_loss: 1.7861\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7853\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7859 - val_loss: 1.7851\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7827\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7829 - val_loss: 1.7824\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7814 - val_loss: 1.7809\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7813 - val_loss: 1.7808\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 1.7788\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7800 - val_loss: 1.7784\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7793 - val_loss: 1.7784\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7785 - val_loss: 1.7779\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7783\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7773\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7771 - val_loss: 1.7769\n",
      "Top-2 accuracy = 0.468\n",
      "20\n",
      "standardizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9125 - val_loss: 1.8687\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8401 - val_loss: 1.8211\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8155 - val_loss: 1.8097\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8091 - val_loss: 1.8078\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8043 - val_loss: 1.8055\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8015 - val_loss: 1.8033\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7993 - val_loss: 1.8012\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7983 - val_loss: 1.7985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7960 - val_loss: 1.7947\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7935 - val_loss: 1.7933\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7906 - val_loss: 1.7881\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7888 - val_loss: 1.7873\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7883 - val_loss: 1.7862\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7865 - val_loss: 1.7875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7858 - val_loss: 1.7852\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7864\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7866 - val_loss: 1.7877\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7856 - val_loss: 1.7917\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7859 - val_loss: 1.7836\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7847 - val_loss: 1.7852\n",
      "Top-2 accuracy = 0.466\n",
      "21\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9167 - val_loss: 1.9100\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9104 - val_loss: 1.9092\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9090 - val_loss: 1.9054\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9078 - val_loss: 1.9093\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9089 - val_loss: 1.9077\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9117 - val_loss: 1.9126\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9126 - val_loss: 1.9118\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9125 - val_loss: 1.9114\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9126 - val_loss: 1.9117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9126 - val_loss: 1.9108\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9124 - val_loss: 1.9118\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9124\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9124 - val_loss: 1.9125\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9123 - val_loss: 1.9117\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9109\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9117\n",
      "Top-2 accuracy = 0.382\n",
      "22\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9388 - val_loss: 1.9319\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9281 - val_loss: 1.9235\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9215 - val_loss: 1.9184\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9175 - val_loss: 1.9154\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9151 - val_loss: 1.9137\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9137 - val_loss: 1.9128\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9129 - val_loss: 1.9122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9125 - val_loss: 1.9119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9118\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9116\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Top-2 accuracy = 0.382\n",
      "23\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9278 - val_loss: 1.9162\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9077 - val_loss: 1.8909\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8626 - val_loss: 1.8427\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8215 - val_loss: 1.8172\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7967 - val_loss: 1.7949\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7895 - val_loss: 1.7875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7865 - val_loss: 1.7864\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7846 - val_loss: 1.7833\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7840 - val_loss: 1.7834\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7820 - val_loss: 1.7842\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7811 - val_loss: 1.7807\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7806\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7793 - val_loss: 1.7807\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7790 - val_loss: 1.7790\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7776 - val_loss: 1.7831\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7786 - val_loss: 1.7772\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7775 - val_loss: 1.7769\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7794 - val_loss: 1.7761\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7772 - val_loss: 1.7785\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7764 - val_loss: 1.7753\n",
      "Top-2 accuracy = 0.473\n",
      "24\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8991 - val_loss: 1.8440\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8284 - val_loss: 1.8132\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8090 - val_loss: 1.8026\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7983 - val_loss: 1.7943\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7903\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7895 - val_loss: 1.7895\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7880 - val_loss: 1.7846\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7893\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7886\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7838 - val_loss: 1.7823\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7821 - val_loss: 1.7809\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7813 - val_loss: 1.7798\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7807 - val_loss: 1.7788\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7800 - val_loss: 1.7783\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7766\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7768 - val_loss: 1.7768\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7729\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7739\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7726\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7719\n",
      "Top-2 accuracy = 0.475\n",
      "25\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9277 - val_loss: 1.9188\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9156 - val_loss: 1.9139\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9130 - val_loss: 1.9121\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Top-2 accuracy = 0.382\n",
      "26\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9144 - val_loss: 1.8978\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8918 - val_loss: 1.8867\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8835 - val_loss: 1.8816\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8807 - val_loss: 1.8790\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8790 - val_loss: 1.8779\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8774 - val_loss: 1.8791\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8766 - val_loss: 1.8778\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8760 - val_loss: 1.8757\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8751 - val_loss: 1.8750\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8746 - val_loss: 1.8747\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8737 - val_loss: 1.8738\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8731 - val_loss: 1.8736\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8737 - val_loss: 1.8725\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8729 - val_loss: 1.8717\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8723 - val_loss: 1.8721\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8720 - val_loss: 1.8730\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8718 - val_loss: 1.8730\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8712 - val_loss: 1.8716\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8716 - val_loss: 1.8715\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8711 - val_loss: 1.8717\n",
      "Top-2 accuracy = 0.429\n",
      "27\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8944 - val_loss: 1.8251\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7994 - val_loss: 1.7895\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7851 - val_loss: 1.7842\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7803 - val_loss: 1.7778\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7782 - val_loss: 1.7824\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7763 - val_loss: 1.7899\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7751 - val_loss: 1.7745\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7737 - val_loss: 1.7775\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7760 - val_loss: 1.7733\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7711 - val_loss: 1.7730\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7703 - val_loss: 1.7723\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7734 - val_loss: 1.7720\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7698 - val_loss: 1.7699\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7685 - val_loss: 1.7695\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7685 - val_loss: 1.7711\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7678 - val_loss: 1.7709\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7678 - val_loss: 1.7707\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7675 - val_loss: 1.7709\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7665 - val_loss: 1.7727\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7686 - val_loss: 1.7673\n",
      "Top-2 accuracy = 0.472\n",
      "28\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9134 - val_loss: 1.8853\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8459 - val_loss: 1.8076\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7975 - val_loss: 1.7902\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7854 - val_loss: 1.7831\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7811 - val_loss: 1.7814\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7771\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7767 - val_loss: 1.7776\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7754 - val_loss: 1.7860\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7819\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7759\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7729\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7726 - val_loss: 1.7747\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7718 - val_loss: 1.7723\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7716\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7709 - val_loss: 1.7706\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7712 - val_loss: 1.7720\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7704 - val_loss: 1.7695\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7712 - val_loss: 1.7734\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7699 - val_loss: 1.7699\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7694 - val_loss: 1.7684\n",
      "Top-2 accuracy = 0.473\n",
      "29\n",
      "maxabsT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9276 - val_loss: 1.9192\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9046 - val_loss: 1.8974\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8836 - val_loss: 1.8779\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8642 - val_loss: 1.8584\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8447 - val_loss: 1.8390\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8288 - val_loss: 1.8246\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8160 - val_loss: 1.8148\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8073 - val_loss: 1.8061\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8010 - val_loss: 1.8000\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7981\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7933 - val_loss: 1.7961\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7911 - val_loss: 1.7921\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7893 - val_loss: 1.7886\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7882 - val_loss: 1.7887\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7869 - val_loss: 1.7868\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7868 - val_loss: 1.7865\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7862 - val_loss: 1.7856\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7860 - val_loss: 1.7858\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7878 - val_loss: 1.7872\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7847 - val_loss: 1.7893\n",
      "Top-2 accuracy = 0.467\n",
      "0\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9388 - val_loss: 1.9303\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9243 - val_loss: 1.9197\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9150 - val_loss: 1.9098\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8861 - val_loss: 1.8568\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8345 - val_loss: 1.8255\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8119 - val_loss: 1.8074\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7991 - val_loss: 1.7971\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7938 - val_loss: 1.7933\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7924\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7907 - val_loss: 1.7894\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7913\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7894 - val_loss: 1.7902\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7895 - val_loss: 1.7889\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7885 - val_loss: 1.7890\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7888 - val_loss: 1.7925\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7886 - val_loss: 1.7883\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7884 - val_loss: 1.7880\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7878 - val_loss: 1.7884\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7873 - val_loss: 1.7880\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7871 - val_loss: 1.7902\n",
      "Top-2 accuracy = 0.466\n",
      "1\n",
      "minmaxP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8719 - val_loss: 1.8443\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8257 - val_loss: 1.8266\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8084 - val_loss: 1.8063\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7961 - val_loss: 1.7950\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.7908\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7839 - val_loss: 1.7832\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7812 - val_loss: 1.7795\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7787 - val_loss: 1.7770\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7768 - val_loss: 1.7775\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7772 - val_loss: 1.7853\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7761 - val_loss: 1.7769\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7749 - val_loss: 1.7758\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7755 - val_loss: 1.7760\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7745 - val_loss: 1.7740\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7727\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7737 - val_loss: 1.7736\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7768\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7757 - val_loss: 1.7722\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7731 - val_loss: 1.7726\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7731 - val_loss: 1.7727\n",
      "Top-2 accuracy = 0.472\n",
      "2\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9380 - val_loss: 1.9285\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9203 - val_loss: 1.9081\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8999 - val_loss: 1.8800\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8764 - val_loss: 1.8652\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8592 - val_loss: 1.8402\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8344 - val_loss: 1.8260\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8221 - val_loss: 1.8185\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8152 - val_loss: 1.8111\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8092 - val_loss: 1.8072\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8063 - val_loss: 1.8053\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8032 - val_loss: 1.8077\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8040 - val_loss: 1.8026\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8007 - val_loss: 1.8033\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7998 - val_loss: 1.7994\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7988 - val_loss: 1.7986\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7982 - val_loss: 1.7992\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7998 - val_loss: 1.7980\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7979 - val_loss: 1.7977\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7976 - val_loss: 1.7976\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7971 - val_loss: 1.7963\n",
      "Top-2 accuracy = 0.461\n",
      "3\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9120 - val_loss: 1.8768\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8403 - val_loss: 1.8177\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7965 - val_loss: 1.7873\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7847 - val_loss: 1.7849\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7790 - val_loss: 1.7797\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7772 - val_loss: 1.7765\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7737 - val_loss: 1.7753\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7734 - val_loss: 1.7736\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7735 - val_loss: 1.7806\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7730 - val_loss: 1.7728\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7747 - val_loss: 1.7719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7739 - val_loss: 1.7752\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 1.7701\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7696 - val_loss: 1.7717\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7688 - val_loss: 1.7737\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7723\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7712 - val_loss: 1.7819\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7693 - val_loss: 1.7706\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7729 - val_loss: 1.7712\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7697 - val_loss: 1.7741\n",
      "Top-2 accuracy = 0.475\n",
      "4\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9245 - val_loss: 1.9116\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9110\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9097\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8939 - val_loss: 1.8648\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8433 - val_loss: 1.8313\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8328 - val_loss: 1.8309\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8312 - val_loss: 1.8328\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8281 - val_loss: 1.8366\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8323 - val_loss: 1.8308\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8270 - val_loss: 1.8279\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8253 - val_loss: 1.8285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8247 - val_loss: 1.8244\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8225 - val_loss: 1.8260\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8210 - val_loss: 1.8233\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8244 - val_loss: 1.8217\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8209 - val_loss: 1.8223\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8210 - val_loss: 1.8263\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8221 - val_loss: 1.8211\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8177 - val_loss: 1.8188\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8153 - val_loss: 1.8180\n",
      "Top-2 accuracy = 0.443\n",
      "5\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9099 - val_loss: 1.8802\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8342 - val_loss: 1.8057\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7972 - val_loss: 1.7907\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7884 - val_loss: 1.7848\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7859 - val_loss: 1.7847\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7828 - val_loss: 1.7815\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7827 - val_loss: 1.7808\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7799\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7812 - val_loss: 1.7778\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7793 - val_loss: 1.7785\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7808 - val_loss: 1.7766\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7817\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7786 - val_loss: 1.7793\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7752\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7773 - val_loss: 1.7759\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7767 - val_loss: 1.7796\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7769 - val_loss: 1.7760\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7760 - val_loss: 1.7807\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7754 - val_loss: 1.7751\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7768 - val_loss: 1.7748\n",
      "Top-2 accuracy = 0.469\n",
      "6\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8986 - val_loss: 1.8451\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8142 - val_loss: 1.7999\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7908 - val_loss: 1.7868\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7821 - val_loss: 1.7814\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7781 - val_loss: 1.7740\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7752 - val_loss: 1.7737\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7733 - val_loss: 1.7778\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7721 - val_loss: 1.7711\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7707 - val_loss: 1.7691\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7698 - val_loss: 1.7695\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7693 - val_loss: 1.7696\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7678 - val_loss: 1.7681\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7688 - val_loss: 1.7722\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7675 - val_loss: 1.7680\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7695 - val_loss: 1.7656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7657 - val_loss: 1.7687\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7655 - val_loss: 1.7667\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7646 - val_loss: 1.7667\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7648 - val_loss: 1.7667\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7652 - val_loss: 1.7710\n",
      "Top-2 accuracy = 0.474\n",
      "7\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9380 - val_loss: 1.9305\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9210 - val_loss: 1.9114\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8941 - val_loss: 1.8852\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8693 - val_loss: 1.8673\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8554 - val_loss: 1.8549\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8445 - val_loss: 1.8451\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8352 - val_loss: 1.8353\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8267 - val_loss: 1.8256\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8192 - val_loss: 1.8197\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8134 - val_loss: 1.8159\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8094 - val_loss: 1.8092\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8054 - val_loss: 1.8076\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8027 - val_loss: 1.8041\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8012 - val_loss: 1.8048\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7995 - val_loss: 1.8007\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7980 - val_loss: 1.8001\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7969 - val_loss: 1.7992\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7968\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7953 - val_loss: 1.7966\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7945 - val_loss: 1.7949\n",
      "Top-2 accuracy = 0.464\n",
      "8\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9295 - val_loss: 1.9148\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8963 - val_loss: 1.8832\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8673 - val_loss: 1.8614\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8486 - val_loss: 1.8455\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8342 - val_loss: 1.8319\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8223 - val_loss: 1.8218\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8130 - val_loss: 1.8117\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8060 - val_loss: 1.8052\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8020 - val_loss: 1.8022\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7983 - val_loss: 1.7974\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7954 - val_loss: 1.7953\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7939 - val_loss: 1.7929\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7934\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7902\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7909 - val_loss: 1.7890\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7910 - val_loss: 1.7903\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7895 - val_loss: 1.7901\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.7873\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7885 - val_loss: 1.7866\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7882 - val_loss: 1.7883\n",
      "Top-2 accuracy = 0.466\n",
      "9\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9124 - val_loss: 1.8601\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8554 - val_loss: 1.8458\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8426 - val_loss: 1.8403\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8372 - val_loss: 1.8371\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8332 - val_loss: 1.8325\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8311 - val_loss: 1.8305\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8306 - val_loss: 1.8286\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8274 - val_loss: 1.8314\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8260 - val_loss: 1.8348\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8267 - val_loss: 1.8259\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8229 - val_loss: 1.8244\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8235 - val_loss: 1.8236\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8207 - val_loss: 1.8202\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8191 - val_loss: 1.8227\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8196 - val_loss: 1.8232\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8162 - val_loss: 1.8254\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8167 - val_loss: 1.8139\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7990 - val_loss: 1.7823\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7735 - val_loss: 1.7821\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7719 - val_loss: 1.7754\n",
      "Top-2 accuracy = 0.476\n",
      "10\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9387 - val_loss: 1.9308\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9269 - val_loss: 1.9190\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9175 - val_loss: 1.9114\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9094 - val_loss: 1.8823\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8828 - val_loss: 1.8634\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8596 - val_loss: 1.8399\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8374 - val_loss: 1.8276\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8240 - val_loss: 1.8141\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8143 - val_loss: 1.8091\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8074 - val_loss: 1.7992\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7987 - val_loss: 1.7953\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7942 - val_loss: 1.7974\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7931 - val_loss: 1.7885\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7884 - val_loss: 1.7893\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7881 - val_loss: 1.7849\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 1.8062\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7916 - val_loss: 1.7839\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7850 - val_loss: 1.7845\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7835 - val_loss: 1.7888\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7853 - val_loss: 1.7813\n",
      "Top-2 accuracy = 0.47\n",
      "11\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9151 - val_loss: 1.8857\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8485 - val_loss: 1.8157\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8070 - val_loss: 1.8003\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7981 - val_loss: 1.7978\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7949 - val_loss: 1.7915\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7920 - val_loss: 1.7901\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7906 - val_loss: 1.7878\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7892 - val_loss: 1.7864\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7883 - val_loss: 1.7863\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7879 - val_loss: 1.7843\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7862\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7860 - val_loss: 1.7829\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7849 - val_loss: 1.7839\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7812\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7837 - val_loss: 1.7835\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7836 - val_loss: 1.7815\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7826 - val_loss: 1.7800\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7820 - val_loss: 1.7788\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7819 - val_loss: 1.7783\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7808 - val_loss: 1.7779\n",
      "Top-2 accuracy = 0.472\n",
      "12\n",
      "minmaxI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9238 - val_loss: 1.8798\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8382 - val_loss: 1.8121\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8027 - val_loss: 1.7974\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7940 - val_loss: 1.7912\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7906 - val_loss: 1.8001\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7888 - val_loss: 1.7879\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7864 - val_loss: 1.7874\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7850 - val_loss: 1.7867\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7850 - val_loss: 1.7848\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7841 - val_loss: 1.7830\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7826\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7816 - val_loss: 1.7866\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7807 - val_loss: 1.7803\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7809 - val_loss: 1.7897\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7819 - val_loss: 1.7834\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7793 - val_loss: 1.7791\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7781 - val_loss: 1.7798\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7787 - val_loss: 1.7769\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7781 - val_loss: 1.7774\n",
      "Top-2 accuracy = 0.47\n",
      "13\n",
      "robustI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9068 - val_loss: 1.8655\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8237 - val_loss: 1.7966\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7863 - val_loss: 1.7807\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7781 - val_loss: 1.7773\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7761 - val_loss: 1.7762\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7743 - val_loss: 1.7739\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.7737\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7722 - val_loss: 1.7732\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7717 - val_loss: 1.7760\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 1.7699\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7713 - val_loss: 1.7717\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7702 - val_loss: 1.7700\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7697 - val_loss: 1.7687\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7697 - val_loss: 1.7698\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7691 - val_loss: 1.7681\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7690 - val_loss: 1.7667\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7682 - val_loss: 1.7702\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7716 - val_loss: 1.7686\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7686 - val_loss: 1.7688\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7675 - val_loss: 1.7684\n",
      "Top-2 accuracy = 0.473\n",
      "14\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9171 - val_loss: 1.8722\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8250 - val_loss: 1.8029\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8009 - val_loss: 1.7950\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7959 - val_loss: 1.7978\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7928 - val_loss: 1.7876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7881 - val_loss: 1.7841\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7849 - val_loss: 1.7791\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7819 - val_loss: 1.7768\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7797 - val_loss: 1.7929\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 1.7745\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7771 - val_loss: 1.7728\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7754 - val_loss: 1.7737\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7747 - val_loss: 1.7714\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7753 - val_loss: 1.7703\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7732 - val_loss: 1.7706\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7729 - val_loss: 1.7802\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7690\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7710\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7685\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7706 - val_loss: 1.7687\n",
      "Top-2 accuracy = 0.471\n",
      "15\n",
      "robustc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9185 - val_loss: 1.8779\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8512 - val_loss: 1.8229\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8149 - val_loss: 1.8043\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7998 - val_loss: 1.7904\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7918 - val_loss: 1.7896\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7891 - val_loss: 1.7888\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7883 - val_loss: 1.7868\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7851 - val_loss: 1.7839\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7856 - val_loss: 1.7865\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7860 - val_loss: 1.8006\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7844 - val_loss: 1.7888\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7816 - val_loss: 1.7802\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7810 - val_loss: 1.7815\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7812 - val_loss: 1.7780\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7800 - val_loss: 1.7770\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7811 - val_loss: 1.7820\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7781 - val_loss: 1.7775\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7782 - val_loss: 1.7882\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7812 - val_loss: 1.7774\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7781 - val_loss: 1.7780\n",
      "Top-2 accuracy = 0.469\n",
      "16\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9209 - val_loss: 1.8971\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8642 - val_loss: 1.8303\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8093 - val_loss: 1.7948\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7901 - val_loss: 1.7845\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7843 - val_loss: 1.7826\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7807 - val_loss: 1.7781\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7774\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7760 - val_loss: 1.7759\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7738\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7731\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7732 - val_loss: 1.7718\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7725 - val_loss: 1.7713\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7723 - val_loss: 1.7708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7745\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7718 - val_loss: 1.7692\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7705 - val_loss: 1.7685\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7700 - val_loss: 1.7693\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7699 - val_loss: 1.7686\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7695 - val_loss: 1.7682\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7678\n",
      "Top-2 accuracy = 0.473\n",
      "17\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9300 - val_loss: 1.9216\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9162 - val_loss: 1.9141\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9126 - val_loss: 1.9118\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9115\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9116\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9117\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9117\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "18\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9201 - val_loss: 1.9051\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8961 - val_loss: 1.8877\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8872 - val_loss: 1.8841\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8854 - val_loss: 1.8843\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8756 - val_loss: 1.8736\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8724 - val_loss: 1.8719\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8693 - val_loss: 1.8688\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8657 - val_loss: 1.8685\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8641 - val_loss: 1.8630\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8583 - val_loss: 1.8553\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8573 - val_loss: 1.8553\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8551 - val_loss: 1.8532\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8551 - val_loss: 1.8536\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8546 - val_loss: 1.8520\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8561 - val_loss: 1.8776\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8593 - val_loss: 1.8540\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8538 - val_loss: 1.8539\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8531 - val_loss: 1.8547\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8549 - val_loss: 1.8534\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8529 - val_loss: 1.8521\n",
      "Top-2 accuracy = 0.448\n",
      "19\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9339 - val_loss: 1.9199\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9040 - val_loss: 1.8855\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8739 - val_loss: 1.8704\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8664 - val_loss: 1.8623\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8568 - val_loss: 1.8609\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8517 - val_loss: 1.8590\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8479 - val_loss: 1.8574\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8465 - val_loss: 1.8446\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8460 - val_loss: 1.8474\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8426 - val_loss: 1.8490\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8440 - val_loss: 1.8434\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8426 - val_loss: 1.8416\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8414 - val_loss: 1.8444\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8412 - val_loss: 1.8662\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8637 - val_loss: 1.8360\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8378 - val_loss: 1.8343\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8289 - val_loss: 1.8332\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8320 - val_loss: 1.8442\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8304 - val_loss: 1.8318\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8222 - val_loss: 1.8274\n",
      "Top-2 accuracy = 0.438\n",
      "20\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9386 - val_loss: 1.9234\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8966 - val_loss: 1.8558\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8296 - val_loss: 1.8147\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8057 - val_loss: 1.8060\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7990 - val_loss: 1.7975\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7956 - val_loss: 1.7982\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7937 - val_loss: 1.7962\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7916 - val_loss: 1.7915\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7903 - val_loss: 1.7909\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7891 - val_loss: 1.7896\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7894 - val_loss: 1.7880\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7873 - val_loss: 1.7873\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7864 - val_loss: 1.7852\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7858 - val_loss: 1.7884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7843\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7846 - val_loss: 1.7843\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7842 - val_loss: 1.7831\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7831 - val_loss: 1.7837\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7833 - val_loss: 1.7828\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7820 - val_loss: 1.7811\n",
      "Top-2 accuracy = 0.466\n",
      "21\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9231 - val_loss: 1.9105\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8886 - val_loss: 1.8744\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8655 - val_loss: 1.8617\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8526 - val_loss: 1.8497\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8444 - val_loss: 1.8345\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8262 - val_loss: 1.8255\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8244 - val_loss: 1.8416\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8248 - val_loss: 1.8468\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8261 - val_loss: 1.8360\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8207 - val_loss: 1.8274\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8171 - val_loss: 1.8265\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8244 - val_loss: 1.8205\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8178 - val_loss: 1.8248\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8161 - val_loss: 1.8204\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8192 - val_loss: 1.8196\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8143 - val_loss: 1.8137\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8126 - val_loss: 1.8140\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8169 - val_loss: 1.9556\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8277 - val_loss: 1.8181\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8114 - val_loss: 1.8154\n",
      "Top-2 accuracy = 0.455\n",
      "22\n",
      "maxabsZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9224 - val_loss: 1.9056\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9030 - val_loss: 1.8904\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8788 - val_loss: 1.8639\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8547 - val_loss: 1.8421\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8352 - val_loss: 1.8732\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8515 - val_loss: 1.8449\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8268 - val_loss: 1.8410\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8227 - val_loss: 1.8281\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8213 - val_loss: 1.8246\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8216 - val_loss: 1.8246\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8194 - val_loss: 1.8269\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8202 - val_loss: 1.8234\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8204 - val_loss: 1.8372\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8193 - val_loss: 1.8200\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8172 - val_loss: 1.8263\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8174 - val_loss: 1.8199\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8162 - val_loss: 1.8854\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8257 - val_loss: 1.8272\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8170 - val_loss: 1.8231\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8181 - val_loss: 1.8374\n",
      "Top-2 accuracy = 0.436\n",
      "23\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9364 - val_loss: 1.9251\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9108 - val_loss: 1.8988\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8907 - val_loss: 1.8859\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8827 - val_loss: 1.8792\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8789 - val_loss: 1.8766\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8770 - val_loss: 1.8742\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8756 - val_loss: 1.8731\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8749 - val_loss: 1.8721\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8745 - val_loss: 1.8717\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8739 - val_loss: 1.8714\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8733 - val_loss: 1.8707\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8732 - val_loss: 1.8698\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8726 - val_loss: 1.8708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8722 - val_loss: 1.8682\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8614 - val_loss: 1.8435\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8190 - val_loss: 1.8109\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8068 - val_loss: 1.8045\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8035 - val_loss: 1.8014\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7994 - val_loss: 1.7990\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7977 - val_loss: 1.7974\n",
      "Top-2 accuracy = 0.467\n",
      "24\n",
      "normalizeG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9203 - val_loss: 1.8859\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8815 - val_loss: 1.8760\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8754 - val_loss: 1.8700\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8688 - val_loss: 1.8545\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8551 - val_loss: 1.8537\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8181 - val_loss: 1.8085\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7976 - val_loss: 1.7989\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7941 - val_loss: 1.7896\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7870 - val_loss: 1.7867\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7854 - val_loss: 1.7837\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7847 - val_loss: 1.7857\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7822 - val_loss: 1.7824\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7803 - val_loss: 1.7819\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7800 - val_loss: 1.7796\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7788 - val_loss: 1.7847\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7791 - val_loss: 1.7786\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7781 - val_loss: 1.7769\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7775 - val_loss: 1.7796\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7788 - val_loss: 1.7767\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7771 - val_loss: 1.7786\n",
      "Top-2 accuracy = 0.472\n",
      "25\n",
      "robustA|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5468 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1682 - val_loss: 1.9178\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8818 - val_loss: 1.8482\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8394 - val_loss: 1.8282\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8206 - val_loss: 1.8136\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8087 - val_loss: 1.8054\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8028 - val_loss: 1.8000\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7985 - val_loss: 1.7954\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7955 - val_loss: 1.7930\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7929 - val_loss: 1.7913\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7909 - val_loss: 1.7886\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7889 - val_loss: 1.7864\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7873 - val_loss: 1.7860\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7858 - val_loss: 1.7850\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7848 - val_loss: 1.7830\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7837 - val_loss: 1.7826\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7822 - val_loss: 1.7820\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7807\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7806 - val_loss: 1.7798\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7797 - val_loss: 1.7793\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7792 - val_loss: 1.7789\n",
      "Top-2 accuracy = 0.469\n",
      "26\n",
      "minmaxU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9248 - val_loss: 1.9111\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9128 - val_loss: 1.9109\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9113 - val_loss: 1.9087\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8724 - val_loss: 1.8377\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8287 - val_loss: 1.8184\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8173 - val_loss: 1.8186\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8118 - val_loss: 1.8100\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8063 - val_loss: 1.8047\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8028 - val_loss: 1.7987\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8008 - val_loss: 1.8044\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7986 - val_loss: 1.7960\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7992 - val_loss: 1.8029\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7970 - val_loss: 1.7952\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7970 - val_loss: 1.7956\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7959 - val_loss: 1.7917\n",
      "Top-2 accuracy = 0.46\n",
      "27\n",
      "maxabsG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9100 - val_loss: 1.8497\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8352 - val_loss: 1.8148\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8093 - val_loss: 1.8048\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8011 - val_loss: 1.7972\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7951 - val_loss: 1.8096\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7953 - val_loss: 1.7954\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7908 - val_loss: 1.7989\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7888 - val_loss: 1.7905\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7888 - val_loss: 1.7904\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7871 - val_loss: 1.7917\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7862\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7850 - val_loss: 1.7872\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7848 - val_loss: 1.7870\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7875 - val_loss: 1.7845\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7836 - val_loss: 1.7901\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7834 - val_loss: 1.7838\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7832 - val_loss: 1.7951\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7939 - val_loss: 1.7851\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7823 - val_loss: 1.7830\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7841\n",
      "Top-2 accuracy = 0.469\n",
      "28\n",
      "standardizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9095 - val_loss: 1.8791\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.8499 - val_loss: 1.8272\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8127 - val_loss: 1.8030\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7941\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7909 - val_loss: 1.7903\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7886 - val_loss: 1.7883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7863 - val_loss: 1.7855\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7848 - val_loss: 1.7853\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7841 - val_loss: 1.7844\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7833 - val_loss: 1.7853\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7824 - val_loss: 1.7807\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7814 - val_loss: 1.7829\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7808 - val_loss: 1.7810\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7805 - val_loss: 1.7809\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7803\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7794 - val_loss: 1.7792\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7794 - val_loss: 1.7798\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7795 - val_loss: 1.7800\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7786 - val_loss: 1.7786\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7780\n",
      "Top-2 accuracy = 0.47\n",
      "29\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9007 - val_loss: 1.8556\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8255 - val_loss: 1.8058\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7999 - val_loss: 1.7927\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7878 - val_loss: 1.7906\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7819 - val_loss: 1.7816\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7783 - val_loss: 1.7765\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7761 - val_loss: 1.7750\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7744\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7733 - val_loss: 1.7759\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7724 - val_loss: 1.7733\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7712 - val_loss: 1.7707\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7708 - val_loss: 1.7707\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7703 - val_loss: 1.7687\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7694 - val_loss: 1.7688\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7685 - val_loss: 1.7675\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7677 - val_loss: 1.7692\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7671 - val_loss: 1.7702\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7676 - val_loss: 1.7677\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7671\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7672 - val_loss: 1.7662\n",
      "Top-2 accuracy = 0.471\n",
      "0\n",
      "normalizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9383 - val_loss: 1.9266\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9181 - val_loss: 1.9012\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8863 - val_loss: 1.8638\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8559 - val_loss: 1.8428\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8369 - val_loss: 1.8290\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8243 - val_loss: 1.8197\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8145 - val_loss: 1.8125\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8078 - val_loss: 1.8081\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8031 - val_loss: 1.8046\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7991 - val_loss: 1.7992\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7960 - val_loss: 1.7975\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7944 - val_loss: 1.7949\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7921 - val_loss: 1.7964\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7924\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7899 - val_loss: 1.7903\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7888 - val_loss: 1.7914\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7880 - val_loss: 1.7896\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7877 - val_loss: 1.7882\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7869 - val_loss: 1.7886\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7869 - val_loss: 1.7905\n",
      "Top-2 accuracy = 0.465\n",
      "1\n",
      "robustw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8989 - val_loss: 1.8347\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8143 - val_loss: 1.8022\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7916 - val_loss: 1.7889\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7808 - val_loss: 1.7822\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7775 - val_loss: 1.7760\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7749 - val_loss: 1.7742\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7746 - val_loss: 1.7717\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7728\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7716 - val_loss: 1.7702\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7700 - val_loss: 1.7691\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7680\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7697 - val_loss: 1.7677\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7677 - val_loss: 1.7678\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7669 - val_loss: 1.7705\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7679 - val_loss: 1.7670\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7675 - val_loss: 1.7662\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7699 - val_loss: 1.7670\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7667 - val_loss: 1.7686\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 1.7656\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7653 - val_loss: 1.7721\n",
      "Top-2 accuracy = 0.472\n",
      "2\n",
      "maxabsf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9216 - val_loss: 1.8771\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8354 - val_loss: 1.8078\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8009 - val_loss: 1.7968\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7937 - val_loss: 1.7909\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7903 - val_loss: 1.7880\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7873 - val_loss: 1.7848\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7840\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7843 - val_loss: 1.7826\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7832 - val_loss: 1.7800\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7822 - val_loss: 1.7801\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7813 - val_loss: 1.7792\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7799 - val_loss: 1.7784\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7797 - val_loss: 1.7779\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7786 - val_loss: 1.7811\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7777 - val_loss: 1.7769\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7765 - val_loss: 1.7780\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7762 - val_loss: 1.7756\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7761 - val_loss: 1.7744\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7754 - val_loss: 1.7740\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7746 - val_loss: 1.7735\n",
      "Top-2 accuracy = 0.47\n",
      "3\n",
      "maxabsm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9264 - val_loss: 1.9128\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9123 - val_loss: 1.9113\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9115 - val_loss: 1.9105\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9079 - val_loss: 1.9051\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8892 - val_loss: 1.8571\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8305 - val_loss: 1.8157\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8055 - val_loss: 1.7956\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7950 - val_loss: 1.7888\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7891 - val_loss: 1.7857\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7871 - val_loss: 1.7831\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7858 - val_loss: 1.7828\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7811\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7841 - val_loss: 1.7805\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7826 - val_loss: 1.7792\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7816 - val_loss: 1.7782\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7813 - val_loss: 1.7790\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7806 - val_loss: 1.7777\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7810 - val_loss: 1.7777\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7797 - val_loss: 1.7759\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7799 - val_loss: 1.7764\n",
      "Top-2 accuracy = 0.471\n",
      "4\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9181 - val_loss: 1.8918\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8667 - val_loss: 1.8470\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8428 - val_loss: 1.8410\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8397 - val_loss: 1.8392\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8379 - val_loss: 1.8371\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8321 - val_loss: 1.8298\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8268 - val_loss: 1.8299\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8223 - val_loss: 1.8374\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8205 - val_loss: 1.8191\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8182 - val_loss: 1.8166\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8165 - val_loss: 1.8165\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8172 - val_loss: 1.8175\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8162 - val_loss: 1.8148\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8149 - val_loss: 1.8211\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8251 - val_loss: 1.8156\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8148 - val_loss: 1.8148\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8135 - val_loss: 1.8175\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8128 - val_loss: 1.8199\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8268 - val_loss: 1.8169\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8141 - val_loss: 1.8137\n",
      "Top-2 accuracy = 0.435\n",
      "5\n",
      "normalizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9045 - val_loss: 1.8847\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8762 - val_loss: 1.8595\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8360 - val_loss: 1.8188\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8115 - val_loss: 1.8027\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8025 - val_loss: 1.7973\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7970 - val_loss: 1.8019\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7965 - val_loss: 1.7917\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7904 - val_loss: 1.7817\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7896 - val_loss: 1.7881\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7931 - val_loss: 1.8052\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7875 - val_loss: 1.7893\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7848 - val_loss: 1.7812\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7863 - val_loss: 1.7860\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7846 - val_loss: 1.7864\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7823 - val_loss: 1.7787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7829 - val_loss: 1.7771\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7824 - val_loss: 1.7768\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7811 - val_loss: 1.7866\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7859 - val_loss: 1.7815\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7798 - val_loss: 1.7806\n",
      "Top-2 accuracy = 0.467\n",
      "6\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9299 - val_loss: 1.9082\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8803 - val_loss: 1.8629\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8536 - val_loss: 1.8501\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8391 - val_loss: 1.8375\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8323 - val_loss: 1.8298\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8244 - val_loss: 1.8178\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8179 - val_loss: 1.8167\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8137 - val_loss: 1.8141\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8113 - val_loss: 1.8070\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8058 - val_loss: 1.8001\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8046 - val_loss: 1.8008\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8007 - val_loss: 1.8016\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8008 - val_loss: 1.7982\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7981 - val_loss: 1.7959\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7978 - val_loss: 1.7983\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7960 - val_loss: 1.7961\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7947 - val_loss: 1.7948\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7961 - val_loss: 1.7935\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7955 - val_loss: 1.7923\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7932 - val_loss: 1.7918\n",
      "Top-2 accuracy = 0.463\n",
      "7\n",
      "maxabsV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9175 - val_loss: 1.8801\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8462 - val_loss: 1.8164\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8040 - val_loss: 1.7932\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7920 - val_loss: 1.7856\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7879 - val_loss: 1.7854\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7847 - val_loss: 1.7844\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7882 - val_loss: 1.7807\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7819 - val_loss: 1.7797\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7809 - val_loss: 1.7798\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7787 - val_loss: 1.7806\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7785 - val_loss: 1.7792\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7779 - val_loss: 1.7803\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7761 - val_loss: 1.7836\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7769 - val_loss: 1.7765\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7759 - val_loss: 1.7790\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7741 - val_loss: 1.7830\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7758 - val_loss: 1.7756\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7736 - val_loss: 1.7784\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7737 - val_loss: 1.7766\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7729 - val_loss: 1.7781\n",
      "Top-2 accuracy = 0.47\n",
      "8\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9086 - val_loss: 1.8874\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8546 - val_loss: 1.8460\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8227 - val_loss: 1.8217\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8066 - val_loss: 1.8050\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7999 - val_loss: 1.7999\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7944 - val_loss: 1.7893\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7835 - val_loss: 1.7810\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7793 - val_loss: 1.7802\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7787 - val_loss: 1.7800\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7780 - val_loss: 1.7785\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7765 - val_loss: 1.7759\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7756 - val_loss: 1.7774\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7754 - val_loss: 1.7767\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7748 - val_loss: 1.7759\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7746 - val_loss: 1.7761\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7766 - val_loss: 1.7755\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7730 - val_loss: 1.7726\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7721 - val_loss: 1.7729\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7821\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7727 - val_loss: 1.7733\n",
      "Top-2 accuracy = 0.472\n",
      "9\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9114 - val_loss: 1.8774\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8394 - val_loss: 1.8266\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8064 - val_loss: 1.7983\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7891 - val_loss: 1.7908\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7860 - val_loss: 1.7840\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7847 - val_loss: 1.7830\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7850 - val_loss: 1.7870\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7811 - val_loss: 1.7879\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7796 - val_loss: 1.7808\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7803 - val_loss: 1.7774\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7776 - val_loss: 1.7772\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7773 - val_loss: 1.7786\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7771 - val_loss: 1.7791\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7758 - val_loss: 1.7921\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7769 - val_loss: 1.7748\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7751 - val_loss: 1.7757\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7745 - val_loss: 1.7768\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7785 - val_loss: 1.7729\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7731 - val_loss: 1.7817\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7758 - val_loss: 1.7741\n",
      "Top-2 accuracy = 0.472\n",
      "10\n",
      "robusty|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5546 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9182 - val_loss: 1.8997\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8814 - val_loss: 1.8607\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8456 - val_loss: 1.8311\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8220 - val_loss: 1.8111\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8083 - val_loss: 1.8015\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7993 - val_loss: 1.7968\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7944 - val_loss: 1.7917\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7917 - val_loss: 1.7875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7898 - val_loss: 1.7853\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7878 - val_loss: 1.7847\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7867 - val_loss: 1.7852\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7863 - val_loss: 1.7820\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7846 - val_loss: 1.7807\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7836 - val_loss: 1.7817\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7811\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7820 - val_loss: 1.7772\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7805 - val_loss: 1.7774\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7796 - val_loss: 1.7755\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7790 - val_loss: 1.7771\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7747\n",
      "Top-2 accuracy = 0.471\n",
      "11\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8870 - val_loss: 1.8281\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7949 - val_loss: 1.7852\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7792 - val_loss: 1.7781\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7779 - val_loss: 1.7802\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7743 - val_loss: 1.7748\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7728 - val_loss: 1.7843\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7739 - val_loss: 1.7802\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7751 - val_loss: 1.7704\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7718 - val_loss: 1.7726\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7719 - val_loss: 1.7707\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7706 - val_loss: 1.7700\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7700 - val_loss: 1.7771\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7731 - val_loss: 1.7727\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7704 - val_loss: 1.7689\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7697 - val_loss: 1.7792\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7702 - val_loss: 1.7686\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7690 - val_loss: 1.7735\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7693 - val_loss: 1.7700\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7704 - val_loss: 1.7669\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7683 - val_loss: 1.7692\n",
      "Top-2 accuracy = 0.472\n",
      "12\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9062 - val_loss: 1.8677\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8379 - val_loss: 1.8218\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8106 - val_loss: 1.8015\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7965 - val_loss: 1.7898\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7878 - val_loss: 1.7831\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7828 - val_loss: 1.7800\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7798 - val_loss: 1.7790\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7785 - val_loss: 1.7764\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7774 - val_loss: 1.7757\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7761 - val_loss: 1.7737\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7751 - val_loss: 1.7738\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.7728\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7738 - val_loss: 1.7712\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7709\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7730 - val_loss: 1.7785\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7690\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7709 - val_loss: 1.7689\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7709 - val_loss: 1.7677\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7696 - val_loss: 1.7676\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7673\n",
      "Top-2 accuracy = 0.475\n",
      "13\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9236 - val_loss: 1.8869\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8443 - val_loss: 1.8045\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7934 - val_loss: 1.7858\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7827 - val_loss: 1.7806\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7790 - val_loss: 1.7791\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7778 - val_loss: 1.7852\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7764 - val_loss: 1.7753\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7738 - val_loss: 1.7751\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7737\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7716 - val_loss: 1.7719\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7721 - val_loss: 1.7705\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7714\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7690 - val_loss: 1.7749\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7690\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7685 - val_loss: 1.7721\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7696\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7685\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7675 - val_loss: 1.7680\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7679 - val_loss: 1.7682\n",
      "Top-2 accuracy = 0.471\n",
      "14\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5566 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9361 - val_loss: 1.9246\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9173 - val_loss: 1.9133\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9073 - val_loss: 1.9041\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8952 - val_loss: 1.8899\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8775 - val_loss: 1.8703\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8571 - val_loss: 1.8515\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8403 - val_loss: 1.8379\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8299 - val_loss: 1.8287\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8228 - val_loss: 1.8235\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8181 - val_loss: 1.8197\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8148 - val_loss: 1.8144\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8118 - val_loss: 1.8109\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8092 - val_loss: 1.8105\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8080 - val_loss: 1.8074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8058 - val_loss: 1.8055\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8045 - val_loss: 1.8034\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8031 - val_loss: 1.8028\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8032 - val_loss: 1.8029\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8018 - val_loss: 1.8001\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8010 - val_loss: 1.7998\n",
      "Top-2 accuracy = 0.457\n",
      "15\n",
      "standardized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9215 - val_loss: 1.9032\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8882 - val_loss: 1.8691\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8567 - val_loss: 1.8450\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8373 - val_loss: 1.8319\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8229 - val_loss: 1.8214\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8135 - val_loss: 1.8128\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8069 - val_loss: 1.8060\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8012 - val_loss: 1.8015\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7977 - val_loss: 1.7993\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7948 - val_loss: 1.7965\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7932 - val_loss: 1.7944\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7914 - val_loss: 1.7930\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7902 - val_loss: 1.7923\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7891 - val_loss: 1.7911\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7879 - val_loss: 1.7900\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7875 - val_loss: 1.7889\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7877 - val_loss: 1.7883\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7862 - val_loss: 1.7875\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7858 - val_loss: 1.7875\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7851 - val_loss: 1.7870\n",
      "Top-2 accuracy = 0.465\n",
      "16\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9094 - val_loss: 1.8592\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8308 - val_loss: 1.8081\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8033 - val_loss: 1.7960\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7948 - val_loss: 1.7925\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7908 - val_loss: 1.7882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7881 - val_loss: 1.7849\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7852 - val_loss: 1.7822\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7831 - val_loss: 1.7828\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7782\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7807 - val_loss: 1.7770\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7795 - val_loss: 1.7763\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7784 - val_loss: 1.7749\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7776 - val_loss: 1.7752\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7772 - val_loss: 1.7750\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7764 - val_loss: 1.7732\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7760 - val_loss: 1.7740\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7763 - val_loss: 1.7729\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7757 - val_loss: 1.7721\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7742 - val_loss: 1.7708\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7745 - val_loss: 1.7716\n",
      "Top-2 accuracy = 0.473\n",
      "17\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9059 - val_loss: 1.8788\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8515 - val_loss: 1.8405\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8232 - val_loss: 1.8212\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8105 - val_loss: 1.8104\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8028 - val_loss: 1.8029\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7980 - val_loss: 1.7980\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7939 - val_loss: 1.7950\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7916 - val_loss: 1.7927\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7904\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7882 - val_loss: 1.7899\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7877 - val_loss: 1.7878\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7864 - val_loss: 1.7875\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7885\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7849 - val_loss: 1.7854\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7867\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7847 - val_loss: 1.7867\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7846 - val_loss: 1.7859\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7849 - val_loss: 1.7847\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7838 - val_loss: 1.7848\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7830 - val_loss: 1.7838\n",
      "Top-2 accuracy = 0.471\n",
      "18\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8964 - val_loss: 1.8557\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8229 - val_loss: 1.8034\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7938 - val_loss: 1.7866\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7865 - val_loss: 1.7812\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7814 - val_loss: 1.7771\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7814 - val_loss: 1.7786\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7778 - val_loss: 1.7781\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7772 - val_loss: 1.7750\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7769 - val_loss: 1.7743\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7759 - val_loss: 1.7733\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7751 - val_loss: 1.7798\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7744 - val_loss: 1.7729\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7753 - val_loss: 1.7735\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7733 - val_loss: 1.7731\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7733 - val_loss: 1.7711\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7721 - val_loss: 1.7720\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7717 - val_loss: 1.7720\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7734 - val_loss: 1.7756\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7729 - val_loss: 1.7704\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7709 - val_loss: 1.7721\n",
      "Top-2 accuracy = 0.472\n",
      "19\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9053\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8773 - val_loss: 1.8414\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8288 - val_loss: 1.8112\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8088 - val_loss: 1.8030\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8020 - val_loss: 1.8003\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7986 - val_loss: 1.7978\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7959 - val_loss: 1.7949\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7943 - val_loss: 1.7939\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7901\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7907 - val_loss: 1.7887\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7894 - val_loss: 1.7879\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7885 - val_loss: 1.7871\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7872 - val_loss: 1.7853\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7865 - val_loss: 1.7843\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7856 - val_loss: 1.7840\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7848 - val_loss: 1.7825\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7843 - val_loss: 1.7819\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7837 - val_loss: 1.7816\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7831 - val_loss: 1.7812\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7829 - val_loss: 1.7812\n",
      "Top-2 accuracy = 0.465\n",
      "20\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9475 - val_loss: 1.9328\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9286 - val_loss: 1.9239\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9210 - val_loss: 1.9149\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8982 - val_loss: 1.8604\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8325 - val_loss: 1.8102\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8033 - val_loss: 1.7983\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7950 - val_loss: 1.7912\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7902 - val_loss: 1.7869\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7861 - val_loss: 1.7842\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7831\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7830 - val_loss: 1.7818\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7823 - val_loss: 1.7814\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7814 - val_loss: 1.7817\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7816\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7804 - val_loss: 1.7815\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7800 - val_loss: 1.7787\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7795 - val_loss: 1.7791\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7795 - val_loss: 1.7782\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7793 - val_loss: 1.7782\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7779\n",
      "Top-2 accuracy = 0.469\n",
      "21\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9228 - val_loss: 1.8764\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8447 - val_loss: 1.8289\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8171 - val_loss: 1.8054\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7976 - val_loss: 1.7934\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7841 - val_loss: 1.7778\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7792 - val_loss: 1.7978\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7834 - val_loss: 1.7762\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7753 - val_loss: 1.7750\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7748 - val_loss: 1.7770\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7752 - val_loss: 1.7745\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7749 - val_loss: 1.7728\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7739 - val_loss: 1.7742\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7720 - val_loss: 1.7710\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7716 - val_loss: 1.7734\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7718 - val_loss: 1.7690\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7705 - val_loss: 1.7714\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7711 - val_loss: 1.7725\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7722 - val_loss: 1.7758\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7718 - val_loss: 1.7707\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7734 - val_loss: 1.7751\n",
      "Top-2 accuracy = 0.47\n",
      "22\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5602 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9215 - val_loss: 1.8879\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8478 - val_loss: 1.8212\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8103 - val_loss: 1.8054\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8019 - val_loss: 1.7993\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7989 - val_loss: 1.7975\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7976 - val_loss: 1.7988\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7960 - val_loss: 1.7933\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7949 - val_loss: 1.7928\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7942 - val_loss: 1.7969\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7931 - val_loss: 1.7897\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7929 - val_loss: 1.7896\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7908\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7924 - val_loss: 1.7883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7901 - val_loss: 1.7929\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7894 - val_loss: 1.7864\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7880 - val_loss: 1.7856\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7878 - val_loss: 1.7842\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7869 - val_loss: 1.7858\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7863 - val_loss: 1.7829\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7849 - val_loss: 1.7858\n",
      "Top-2 accuracy = 0.466\n",
      "23\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8794 - val_loss: 1.8227\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 1.8037 - val_loss: 1.7878\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7865 - val_loss: 1.7919\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7810 - val_loss: 1.7783\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7756 - val_loss: 1.7864\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7763 - val_loss: 1.7723\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7733 - val_loss: 1.7714\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7727 - val_loss: 1.7683\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7708 - val_loss: 1.7725\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7731 - val_loss: 1.7684\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7698 - val_loss: 1.7980\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7719 - val_loss: 1.7677\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7700 - val_loss: 1.7696\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7712 - val_loss: 1.7738\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7699 - val_loss: 1.7859\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7685 - val_loss: 1.7734\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7686 - val_loss: 1.7790\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7680 - val_loss: 1.7666\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7668 - val_loss: 1.7652\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7677 - val_loss: 1.7678\n",
      "Top-2 accuracy = 0.472\n",
      "24\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5613 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 17699144990720.0000 - val_loss: 2204812443648.0000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1253906055168.0000 - val_loss: 925703667712.0000\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 947050840064.0000 - val_loss: 1272180768768.0000\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 914313510912.0000 - val_loss: 805541511168.0000\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 753467326464.0000 - val_loss: 749988544512.0000\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 791413391360.0000 - val_loss: 748129353728.0000\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 661886992384.0000 - val_loss: 1340147892224.0000\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 592075161600.0000 - val_loss: 370431098880.0000\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 680288518144.0000 - val_loss: 782472118272.0000\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 656374497280.0000 - val_loss: 438844391424.0000\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 641194655744.0000 - val_loss: 673850130432.0000\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 578530181120.0000 - val_loss: 457972350976.0000\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 478492033024.0000 - val_loss: 498937495552.0000\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 525370523648.0000 - val_loss: 1109491712000.0000\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 720066707456.0000 - val_loss: 463259828224.0000\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 454563332096.0000 - val_loss: 470790045696.0000\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 510142644224.0000 - val_loss: 340601896960.0000\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 386698379264.0000 - val_loss: 526267547648.0000\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 467147685888.0000 - val_loss: 318009737216.0000\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 422649823232.0000 - val_loss: 554169466880.0000\n",
      "Top-2 accuracy = 0.359\n",
      "25\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9386 - val_loss: 1.9316\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9277 - val_loss: 1.9230\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9212 - val_loss: 1.9181\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9173 - val_loss: 1.9152\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9151 - val_loss: 1.9135\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9137 - val_loss: 1.9126\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9129 - val_loss: 1.9120\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9125 - val_loss: 1.9118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9116\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9112\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "26\n",
      "robustq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9107 - val_loss: 1.8898\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8928 - val_loss: 1.8936\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8911 - val_loss: 1.8891\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8894 - val_loss: 1.8874\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8883 - val_loss: 1.8877\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8845 - val_loss: 1.8830\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8738 - val_loss: 1.8644\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8549 - val_loss: 1.8564\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8426 - val_loss: 1.8323\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8175 - val_loss: 1.8154\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8125 - val_loss: 1.8124\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8065 - val_loss: 1.8076\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8026 - val_loss: 1.8015\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8014 - val_loss: 1.7952\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7937 - val_loss: 1.7910\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7898 - val_loss: 1.7911\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7872 - val_loss: 1.7864\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7866 - val_loss: 1.7836\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7842 - val_loss: 1.7881\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7834 - val_loss: 1.7828\n",
      "Top-2 accuracy = 0.468\n",
      "27\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9123 - val_loss: 1.8632\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8225 - val_loss: 1.7965\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7884 - val_loss: 1.7812\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7797 - val_loss: 1.7772\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7766 - val_loss: 1.7734\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7746 - val_loss: 1.7738\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.7716\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7731 - val_loss: 1.7707\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7716 - val_loss: 1.7699\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7717 - val_loss: 1.7700\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7706 - val_loss: 1.7711\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7699 - val_loss: 1.7804\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7697 - val_loss: 1.7690\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7692 - val_loss: 1.7699\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7691 - val_loss: 1.7680\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7677 - val_loss: 1.7667\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7674 - val_loss: 1.7685\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7678 - val_loss: 1.7696\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7675 - val_loss: 1.7683\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7683 - val_loss: 1.7686\n",
      "Top-2 accuracy = 0.476\n",
      "28\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9260 - val_loss: 1.9169\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9146 - val_loss: 1.9139\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9130 - val_loss: 1.9125\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9123 - val_loss: 1.9120\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9117\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Top-2 accuracy = 0.382\n",
      "29\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9321 - val_loss: 1.9149\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9131 - val_loss: 1.9113\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9119\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9113\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9113\n",
      "Top-2 accuracy = 0.382\n",
      "0\n",
      "maxabsR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9288 - val_loss: 1.9181\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9137 - val_loss: 1.9128\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9124 - val_loss: 1.9119\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9097 - val_loss: 1.9052\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9061 - val_loss: 1.9067\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9004 - val_loss: 1.8925\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8861 - val_loss: 1.8821\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8802 - val_loss: 1.8773\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8654 - val_loss: 1.8644\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8642 - val_loss: 1.8942\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8928 - val_loss: 1.8930\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8957 - val_loss: 1.9111\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9112\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9120 - val_loss: 1.9116\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9119 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9119 - val_loss: 1.9112\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9120 - val_loss: 1.9109\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9118\n",
      "Top-2 accuracy = 0.382\n",
      "1\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9346 - val_loss: 1.9106\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8924 - val_loss: 1.8726\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8665 - val_loss: 1.8466\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8358 - val_loss: 1.8222\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8152 - val_loss: 1.8111\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8066 - val_loss: 1.8027\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8006 - val_loss: 1.8033\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7976 - val_loss: 1.7974\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7961 - val_loss: 1.7935\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7926 - val_loss: 1.7922\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7916 - val_loss: 1.7895\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7903 - val_loss: 1.7868\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7899 - val_loss: 1.7881\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7894 - val_loss: 1.7873\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7883 - val_loss: 1.7844\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7868 - val_loss: 1.7841\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7861 - val_loss: 1.7904\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7881 - val_loss: 1.7824\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7853 - val_loss: 1.8039\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7871 - val_loss: 1.7826\n",
      "Top-2 accuracy = 0.47\n",
      "2\n",
      "robustc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9230 - val_loss: 1.9123\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9081 - val_loss: 1.9047\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9019 - val_loss: 1.9011\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9009 - val_loss: 1.9010\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8994 - val_loss: 1.8980\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8973 - val_loss: 1.8954\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8933 - val_loss: 1.8925\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8996 - val_loss: 1.9016\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9005 - val_loss: 1.9001\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9005 - val_loss: 1.9004\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9006 - val_loss: 1.9001\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9004 - val_loss: 1.9006\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9004 - val_loss: 1.9006\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9004 - val_loss: 1.9004\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9004 - val_loss: 1.9008\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9004 - val_loss: 1.9001\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9005 - val_loss: 1.9003\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9004 - val_loss: 1.9000\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9004 - val_loss: 1.9002\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9006 - val_loss: 1.9005\n",
      "Top-2 accuracy = 0.398\n",
      "3\n",
      "normalizeq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9139 - val_loss: 1.8904\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8720 - val_loss: 1.8649\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8528 - val_loss: 1.8545\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8437 - val_loss: 1.8438\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8399 - val_loss: 1.8422\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8362 - val_loss: 1.8374\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8340 - val_loss: 1.8353\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8326 - val_loss: 1.8349\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8316 - val_loss: 1.8340\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8244 - val_loss: 1.7931\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7850 - val_loss: 1.7818\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7823 - val_loss: 1.7809\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7818 - val_loss: 1.7816\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7820 - val_loss: 1.7828\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7794 - val_loss: 1.7734\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7768 - val_loss: 1.7814\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7775 - val_loss: 1.7775\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7796 - val_loss: 1.7784\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7750 - val_loss: 1.7751\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7745 - val_loss: 1.7792\n",
      "Top-2 accuracy = 0.468\n",
      "4\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9259 - val_loss: 1.8852\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8490 - val_loss: 1.8140\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8026 - val_loss: 1.7957\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7900 - val_loss: 1.7864\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7843 - val_loss: 1.7815\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7818 - val_loss: 1.7813\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7808 - val_loss: 1.7788\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7798 - val_loss: 1.7763\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7763 - val_loss: 1.7760\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7775 - val_loss: 1.7742\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7753 - val_loss: 1.7741\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7761 - val_loss: 1.7734\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7740 - val_loss: 1.7785\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7742 - val_loss: 1.7799\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7735 - val_loss: 1.7760\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7729 - val_loss: 1.7749\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7726 - val_loss: 1.7697\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7708 - val_loss: 1.7838\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7717 - val_loss: 1.7688\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7696 - val_loss: 1.7682\n",
      "Top-2 accuracy = 0.474\n",
      "5\n",
      "minmaxP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9380 - val_loss: 1.9290\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8983 - val_loss: 1.8629\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8387 - val_loss: 1.8330\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8178 - val_loss: 1.8196\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8066 - val_loss: 1.8102\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7999 - val_loss: 1.7968\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7932 - val_loss: 1.7930\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7913 - val_loss: 1.7918\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7901 - val_loss: 1.7900\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7901 - val_loss: 1.7896\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7894 - val_loss: 1.7926\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7890 - val_loss: 1.7888\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7879 - val_loss: 1.7894\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7880 - val_loss: 1.7875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7879\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7890\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7865 - val_loss: 1.7858\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7856 - val_loss: 1.7908\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7854 - val_loss: 1.7922\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7881 - val_loss: 1.7871\n",
      "Top-2 accuracy = 0.463\n",
      "6\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9348 - val_loss: 1.9230\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9177 - val_loss: 1.9122\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9125 - val_loss: 1.9109\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "7\n",
      "minmaxT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9353 - val_loss: 1.9215\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.8961\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8952 - val_loss: 1.8835\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8808 - val_loss: 1.8684\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8680 - val_loss: 1.8587\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8597 - val_loss: 1.8511\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8498 - val_loss: 1.8473\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8435 - val_loss: 1.8406\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8384 - val_loss: 1.8341\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8330 - val_loss: 1.8342\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8300 - val_loss: 1.8259\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8266 - val_loss: 1.8254\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8228 - val_loss: 1.8209\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8196 - val_loss: 1.8159\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8168 - val_loss: 1.8123\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8145 - val_loss: 1.8152\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8130 - val_loss: 1.8090\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8112 - val_loss: 1.8083\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8099 - val_loss: 1.8066\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8081 - val_loss: 1.8098\n",
      "Top-2 accuracy = 0.457\n",
      "8\n",
      "minmaxI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9091 - val_loss: 1.8804\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8467 - val_loss: 1.8204\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8067 - val_loss: 1.7989\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7949 - val_loss: 1.7910\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7910 - val_loss: 1.7897\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.7943\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7887 - val_loss: 1.7857\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7871 - val_loss: 1.7840\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7852 - val_loss: 1.7868\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7858 - val_loss: 1.7835\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7840 - val_loss: 1.7833\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7835 - val_loss: 1.7809\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7828 - val_loss: 1.7811\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7842 - val_loss: 1.7858\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7828 - val_loss: 1.7807\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7821 - val_loss: 1.7811\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7820 - val_loss: 1.7818\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7835 - val_loss: 1.7824\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7835 - val_loss: 1.7792\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7810\n",
      "Top-2 accuracy = 0.469\n",
      "9\n",
      "normalizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9375 - val_loss: 1.9281\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9157 - val_loss: 1.8945\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8704 - val_loss: 1.8490\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8291 - val_loss: 1.8178\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8112 - val_loss: 1.8085\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8047 - val_loss: 1.8038\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8016 - val_loss: 1.8012\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8002 - val_loss: 1.7972\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7989 - val_loss: 1.7979\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7980 - val_loss: 1.7963\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7973 - val_loss: 1.7946\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7968 - val_loss: 1.7941\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7949\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7960 - val_loss: 1.7941\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7955 - val_loss: 1.7935\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7958 - val_loss: 1.7940\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7947 - val_loss: 1.7924\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7946 - val_loss: 1.7926\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7943 - val_loss: 1.7938\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7947 - val_loss: 1.7923\n",
      "Top-2 accuracy = 0.463\n",
      "10\n",
      "maxabso|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9114 - val_loss: 1.8771\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8450 - val_loss: 1.8023\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7925 - val_loss: 1.7780\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7787 - val_loss: 1.7787\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7763 - val_loss: 1.7709\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7713 - val_loss: 1.7821\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7758 - val_loss: 1.7721\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7705 - val_loss: 1.7671\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7692 - val_loss: 1.7692\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7712 - val_loss: 1.7692\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7695 - val_loss: 1.7653\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7676 - val_loss: 1.7753\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7681 - val_loss: 1.7679\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7660 - val_loss: 1.7659\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7688 - val_loss: 1.7748\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7660 - val_loss: 1.7660\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7663 - val_loss: 1.7652\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7670 - val_loss: 1.7686\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7669 - val_loss: 1.7682\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7654 - val_loss: 1.7674\n",
      "Top-2 accuracy = 0.468\n",
      "11\n",
      "standardizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9155 - val_loss: 1.8974\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8601 - val_loss: 1.8235\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8137 - val_loss: 1.8012\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7959 - val_loss: 1.7888\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7901 - val_loss: 1.7893\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7870 - val_loss: 1.7805\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7825 - val_loss: 1.7810\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7821 - val_loss: 1.7769\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7780 - val_loss: 1.7760\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7757 - val_loss: 1.7811\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7760 - val_loss: 1.7729\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7748 - val_loss: 1.7719\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7737 - val_loss: 1.7710\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7730 - val_loss: 1.7729\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7732 - val_loss: 1.7706\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7741 - val_loss: 1.7701\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7722 - val_loss: 1.7699\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7711 - val_loss: 1.7690\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7711 - val_loss: 1.7699\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7701 - val_loss: 1.7714\n",
      "Top-2 accuracy = 0.475\n",
      "12\n",
      "minmaxA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8887 - val_loss: 1.8321\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8084 - val_loss: 1.7955\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7975 - val_loss: 1.7923\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7958 - val_loss: 1.7924\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7940 - val_loss: 1.7888\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7926 - val_loss: 1.7933\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7912 - val_loss: 1.7853\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7912 - val_loss: 1.7869\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7910 - val_loss: 1.7850\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7898 - val_loss: 1.7850\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7911 - val_loss: 1.7857\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7885 - val_loss: 1.7849\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7880 - val_loss: 1.7870\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7906 - val_loss: 1.7827\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7875 - val_loss: 1.7822\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7870 - val_loss: 1.7876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7874 - val_loss: 1.7831\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7860 - val_loss: 1.7823\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7848 - val_loss: 1.7818\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7840 - val_loss: 1.7832\n",
      "Top-2 accuracy = 0.47\n",
      "13\n",
      "maxabsg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9123 - val_loss: 1.8651\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8382 - val_loss: 1.8204\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8054 - val_loss: 1.7940\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7902 - val_loss: 1.7838\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7841 - val_loss: 1.7811\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7835 - val_loss: 1.7822\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7815 - val_loss: 1.7769\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7796 - val_loss: 1.7763\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7778 - val_loss: 1.7773\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7763 - val_loss: 1.7744\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7768 - val_loss: 1.7750\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7752 - val_loss: 1.7736\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7754 - val_loss: 1.7789\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7753 - val_loss: 1.7756\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7740 - val_loss: 1.7724\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7742 - val_loss: 1.7735\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7751 - val_loss: 1.7725\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7733 - val_loss: 1.7709\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7726 - val_loss: 1.7714\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7726 - val_loss: 1.7701\n",
      "Top-2 accuracy = 0.474\n",
      "14\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9203 - val_loss: 1.8811\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8500 - val_loss: 1.8209\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8134 - val_loss: 1.8019\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8001 - val_loss: 1.7993\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7964 - val_loss: 1.7924\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7947 - val_loss: 1.7900\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7899\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7916 - val_loss: 1.7933\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7921 - val_loss: 1.7877\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7892 - val_loss: 1.7867\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7886 - val_loss: 1.7871\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7877 - val_loss: 1.7877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7869 - val_loss: 1.7851\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7861 - val_loss: 1.7843\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7864 - val_loss: 1.7869\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7846\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7861 - val_loss: 1.7836\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7852 - val_loss: 1.7865\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7891\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7863 - val_loss: 1.7841\n",
      "Top-2 accuracy = 0.466\n",
      "15\n",
      "robustd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9038 - val_loss: 1.8650\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8339 - val_loss: 1.8206\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8047 - val_loss: 1.7999\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7946 - val_loss: 1.7946\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7905 - val_loss: 1.7917\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7884 - val_loss: 1.7888\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7866 - val_loss: 1.7865\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7854 - val_loss: 1.7893\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7838 - val_loss: 1.7832\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7821\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7804\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7800 - val_loss: 1.7796\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7789 - val_loss: 1.7790\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7755\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7760 - val_loss: 1.7784\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7747 - val_loss: 1.7733\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7742 - val_loss: 1.7760\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7728 - val_loss: 1.7706\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7722 - val_loss: 1.7699\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7713 - val_loss: 1.7693\n",
      "Top-2 accuracy = 0.473\n",
      "16\n",
      "standardizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9336 - val_loss: 1.9279\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9204 - val_loss: 1.9194\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9155 - val_loss: 1.9154\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9135 - val_loss: 1.9135\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9126 - val_loss: 1.9125\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9123 - val_loss: 1.9124\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9119\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Top-2 accuracy = 0.382\n",
      "17\n",
      "minmaxY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9263 - val_loss: 1.9165\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9132 - val_loss: 1.9121\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9125 - val_loss: 1.9117\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9111\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9120\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9124 - val_loss: 1.9115\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9112\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9124 - val_loss: 1.9117\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9117\n",
      "Top-2 accuracy = 0.382\n",
      "18\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9259 - val_loss: 1.9139\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8869 - val_loss: 1.8514\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8397 - val_loss: 1.8302\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8240 - val_loss: 1.8197\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8127 - val_loss: 1.8086\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8032 - val_loss: 1.7942\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7920 - val_loss: 1.7848\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7846 - val_loss: 1.7829\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7802 - val_loss: 1.7774\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7781 - val_loss: 1.7769\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7749 - val_loss: 1.7749\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7738 - val_loss: 1.7713\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7720 - val_loss: 1.7720\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7721 - val_loss: 1.7713\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7704 - val_loss: 1.7701\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7704 - val_loss: 1.7706\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7703 - val_loss: 1.7702\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7693 - val_loss: 1.7700\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7694 - val_loss: 1.7688\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7693 - val_loss: 1.7698\n",
      "Top-2 accuracy = 0.476\n",
      "19\n",
      "standardizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8993 - val_loss: 1.8467\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8190 - val_loss: 1.8042\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7929 - val_loss: 1.7884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7850 - val_loss: 1.7817\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7804 - val_loss: 1.7804\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7783 - val_loss: 1.7780\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7769 - val_loss: 1.7786\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7753 - val_loss: 1.7797\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7733 - val_loss: 1.7726\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7722 - val_loss: 1.7726\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7721 - val_loss: 1.7714\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7721 - val_loss: 1.7705\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7703\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7688 - val_loss: 1.7716\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7685 - val_loss: 1.7700\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7675 - val_loss: 1.7680\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7673 - val_loss: 1.7677\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7671 - val_loss: 1.7677\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7680 - val_loss: 1.7722\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7665 - val_loss: 1.7654\n",
      "Top-2 accuracy = 0.474\n",
      "20\n",
      "robustz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.9299 - val_loss: 1.9162\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9131 - val_loss: 1.9116\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9122 - val_loss: 1.9111\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9121 - val_loss: 1.9123\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9123 - val_loss: 1.9115\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9119\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9111\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9119\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9118\n",
      "Top-2 accuracy = 0.382\n",
      "21\n",
      "minmaxR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9337 - val_loss: 1.9224\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9155 - val_loss: 1.9138\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9125 - val_loss: 1.9118\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9124 - val_loss: 1.9113\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9117\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9117 - val_loss: 1.9116\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9111 - val_loss: 1.9120\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9111\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9122\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9125 - val_loss: 1.9118\n",
      "Top-2 accuracy = 0.382\n",
      "22\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9323 - val_loss: 1.9084\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8821 - val_loss: 1.8493\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8346 - val_loss: 1.8171\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8110 - val_loss: 1.8031\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8002 - val_loss: 1.8051\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7969 - val_loss: 1.7942\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7933 - val_loss: 1.8046\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7930 - val_loss: 1.7911\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7929 - val_loss: 1.7989\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7933 - val_loss: 1.7981\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7930 - val_loss: 1.7953\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7912 - val_loss: 1.7895\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7910 - val_loss: 1.7910\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7900 - val_loss: 1.7876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7896 - val_loss: 1.7874\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7900 - val_loss: 1.7881\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7886 - val_loss: 1.7907\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7894 - val_loss: 1.7881\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7905 - val_loss: 1.7871\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7887 - val_loss: 1.7963\n",
      "Top-2 accuracy = 0.461\n",
      "23\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8922 - val_loss: 1.8283\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8022 - val_loss: 1.7911\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7847 - val_loss: 1.7827\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7798 - val_loss: 1.7772\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7786 - val_loss: 1.7773\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7754 - val_loss: 1.7749\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7739 - val_loss: 1.7720\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7722 - val_loss: 1.7729\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7720\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7750 - val_loss: 1.7724\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7708 - val_loss: 1.7712\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7703 - val_loss: 1.7748\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7697 - val_loss: 1.7716\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7754 - val_loss: 1.7718\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7696 - val_loss: 1.7696\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7684 - val_loss: 1.7676\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7673 - val_loss: 1.7740\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7692 - val_loss: 1.7699\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7669 - val_loss: 1.7693\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7669 - val_loss: 1.7672\n",
      "Top-2 accuracy = 0.473\n",
      "24\n",
      "minmaxp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9385 - val_loss: 1.9314\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9276 - val_loss: 1.9230\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9213 - val_loss: 1.9181\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9174 - val_loss: 1.9153\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9150 - val_loss: 1.9136\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9137 - val_loss: 1.9127\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9129 - val_loss: 1.9122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9125 - val_loss: 1.9118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9123 - val_loss: 1.9117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "25\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8914 - val_loss: 1.8381\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8033 - val_loss: 1.7835\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7778 - val_loss: 1.7732\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7732 - val_loss: 1.7725\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7702 - val_loss: 1.7714\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7696 - val_loss: 1.7760\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7700 - val_loss: 1.7674\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7674 - val_loss: 1.7682\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7686 - val_loss: 1.7706\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7672 - val_loss: 1.7657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7684 - val_loss: 1.7685\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7662 - val_loss: 1.7661\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7645 - val_loss: 1.7752\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7666 - val_loss: 1.7662\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7762\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7645 - val_loss: 1.7635\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7634 - val_loss: 1.7638\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7622 - val_loss: 1.7656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7642 - val_loss: 1.7637\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7633 - val_loss: 1.7638\n",
      "Top-2 accuracy = 0.476\n",
      "26\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9223 - val_loss: 1.8861\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8678 - val_loss: 1.8619\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8583 - val_loss: 1.9066\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8519 - val_loss: 1.8441\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8475 - val_loss: 1.8503\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8492 - val_loss: 1.8438\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8483 - val_loss: 1.8469\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8469 - val_loss: 1.8419\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8442 - val_loss: 1.8428\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8435 - val_loss: 1.8429\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8436 - val_loss: 1.8434\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8437 - val_loss: 1.8435\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8516 - val_loss: 1.8564\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8537 - val_loss: 1.8535\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8467 - val_loss: 1.8460\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8455 - val_loss: 1.8446\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8466 - val_loss: 1.8448\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8481 - val_loss: 1.8470\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8488 - val_loss: 1.8525\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8479 - val_loss: 1.8473\n",
      "Top-2 accuracy = 0.443\n",
      "27\n",
      "minmaxt|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5785 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9385 - val_loss: 1.9306\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9262 - val_loss: 1.9199\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9176 - val_loss: 1.9135\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9135 - val_loss: 1.9114\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9124 - val_loss: 1.9111\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Top-2 accuracy = 0.382\n",
      "28\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9314 - val_loss: 1.9137\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9127 - val_loss: 1.9119\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9123 - val_loss: 1.9118\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9124 - val_loss: 1.9119\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9123 - val_loss: 1.9110\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9118\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9123 - val_loss: 1.9115\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9112\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9122 - val_loss: 1.9111\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9124 - val_loss: 1.9114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9121 - val_loss: 1.9125\n",
      "Top-2 accuracy = 0.382\n",
      "29\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9366 - val_loss: 1.9279\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9221 - val_loss: 1.9176\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9155 - val_loss: 1.9140\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9131 - val_loss: 1.9125\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9124 - val_loss: 1.9120\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9118\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9117\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9116\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9112\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "0\n",
      "standardizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.9255 - val_loss: 1.9115\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9125 - val_loss: 1.9111\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9124 - val_loss: 1.9119\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9121\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9122 - val_loss: 1.9119\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9111\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9123 - val_loss: 1.9122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9113\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9118\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9124 - val_loss: 1.9120\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9115\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9119\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9123 - val_loss: 1.9118\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9123 - val_loss: 1.9119\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "1\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8792 - val_loss: 1.8156\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7943 - val_loss: 1.7824\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7796 - val_loss: 1.7757\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7747 - val_loss: 1.7804\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7717 - val_loss: 1.7718\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7708 - val_loss: 1.7706\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7691 - val_loss: 1.7694\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7688 - val_loss: 1.7713\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7688 - val_loss: 1.7660\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7667 - val_loss: 1.7797\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7687 - val_loss: 1.7677\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7665 - val_loss: 1.7666\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7663 - val_loss: 1.7639\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7657 - val_loss: 1.7828\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7657 - val_loss: 1.7656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7643 - val_loss: 1.7635\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7716 - val_loss: 1.7630\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7651 - val_loss: 1.7655\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7623 - val_loss: 1.7628\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7651 - val_loss: 1.7615\n",
      "Top-2 accuracy = 0.476\n",
      "2\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9055 - val_loss: 1.8426\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8135 - val_loss: 1.7938\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7878 - val_loss: 1.7796\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7803 - val_loss: 1.7767\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7800 - val_loss: 1.7759\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7767 - val_loss: 1.7763\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7765 - val_loss: 1.7749\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7779 - val_loss: 1.7781\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7738 - val_loss: 1.7718\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7735 - val_loss: 1.7795\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7725 - val_loss: 1.7710\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7718 - val_loss: 1.7747\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7731 - val_loss: 1.7757\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7720 - val_loss: 1.7722\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7698 - val_loss: 1.7706\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7709 - val_loss: 1.7684\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7695 - val_loss: 1.7690\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7685 - val_loss: 1.7734\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7709 - val_loss: 1.7683\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7675 - val_loss: 1.7693\n",
      "Top-2 accuracy = 0.472\n",
      "3\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9344 - val_loss: 1.9230\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9203 - val_loss: 1.9142\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9148 - val_loss: 1.9116\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9128 - val_loss: 1.9111\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "4\n",
      "normalizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.8875 - val_loss: 1.8372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8150 - val_loss: 1.7993\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7924 - val_loss: 1.8151\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7861 - val_loss: 1.7857\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7846 - val_loss: 1.7904\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7829 - val_loss: 1.7841\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7811 - val_loss: 1.7794\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7801 - val_loss: 1.7797\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7786 - val_loss: 1.7756\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7773 - val_loss: 1.7785\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7768 - val_loss: 1.7952\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7789 - val_loss: 1.7736\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7757 - val_loss: 1.7786\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7915 - val_loss: 1.7855\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7830 - val_loss: 1.7814\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7768 - val_loss: 1.7822\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7742 - val_loss: 1.7807\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7747 - val_loss: 1.7737\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7733 - val_loss: 1.7695\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7722 - val_loss: 1.7773\n",
      "Top-2 accuracy = 0.475\n",
      "5\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.8985 - val_loss: 1.8424\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8160 - val_loss: 1.7980\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7944 - val_loss: 1.7949\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.7922 - val_loss: 1.7903\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.7849 - val_loss: 1.7856\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.7821 - val_loss: 1.7818\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7788 - val_loss: 1.7796\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7786 - val_loss: 1.7779\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7769 - val_loss: 1.7779\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7763 - val_loss: 1.7747\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7745 - val_loss: 1.7794\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7737 - val_loss: 1.7731\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7742 - val_loss: 1.7729\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7753 - val_loss: 1.7793\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7730 - val_loss: 1.7729\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7737 - val_loss: 1.7712\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7748 - val_loss: 1.7727\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7718 - val_loss: 1.7743\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7705 - val_loss: 1.7726\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7689 - val_loss: 1.7724\n",
      "Top-2 accuracy = 0.473\n",
      "6\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9218 - val_loss: 1.9130\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9124 - val_loss: 1.9115\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9111\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8974 - val_loss: 1.8477\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8245 - val_loss: 1.8120\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8029 - val_loss: 1.7960\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7939 - val_loss: 1.7938\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7909 - val_loss: 1.7871\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7867 - val_loss: 1.7838\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7845 - val_loss: 1.7826\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7846 - val_loss: 1.7827\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7829 - val_loss: 1.7796\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7826 - val_loss: 1.7804\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7808 - val_loss: 1.7839\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7801 - val_loss: 1.7801\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7793 - val_loss: 1.7837\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7802 - val_loss: 1.7950\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7810 - val_loss: 1.7794\n",
      "Top-2 accuracy = 0.467\n",
      "7\n",
      "minmaxh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9412 - val_loss: 1.9300\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9203 - val_loss: 1.9033\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8646 - val_loss: 1.8545\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8410 - val_loss: 1.8380\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8223 - val_loss: 1.8165\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8089 - val_loss: 1.8082\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8018 - val_loss: 1.8043\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7983 - val_loss: 1.8057\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7960 - val_loss: 1.7965\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7947 - val_loss: 1.7968\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7925 - val_loss: 1.7925\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7913 - val_loss: 1.8020\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7928 - val_loss: 1.7909\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7908 - val_loss: 1.7915\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7952\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7904 - val_loss: 1.7939\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7908 - val_loss: 1.7886\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7904 - val_loss: 1.7933\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7899 - val_loss: 1.7907\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7891 - val_loss: 1.7886\n",
      "Top-2 accuracy = 0.466\n",
      "8\n",
      "robustA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9251 - val_loss: 1.9139\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9070 - val_loss: 1.9036\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8930 - val_loss: 1.8676\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8440 - val_loss: 1.8275\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8175 - val_loss: 1.8157\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8092 - val_loss: 1.8074\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8035 - val_loss: 1.8027\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7988 - val_loss: 1.7983\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7963 - val_loss: 1.7965\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7937 - val_loss: 1.8010\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7933 - val_loss: 1.7986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7921 - val_loss: 1.7939\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7918 - val_loss: 1.7924\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7902 - val_loss: 1.7932\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7901 - val_loss: 1.7928\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7895 - val_loss: 1.7898\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7864 - val_loss: 1.7929\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7856 - val_loss: 1.7888\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 1.7893\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7843 - val_loss: 1.7849\n",
      "Top-2 accuracy = 0.464\n",
      "9\n",
      "standardizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9276 - val_loss: 1.8960\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8873 - val_loss: 1.8774\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8796 - val_loss: 1.8771\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8796 - val_loss: 1.8789\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8819 - val_loss: 1.8810\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8829 - val_loss: 1.8809\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8827 - val_loss: 1.8811\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8829 - val_loss: 1.8811\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8827 - val_loss: 1.8813\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8827 - val_loss: 1.8812\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8827 - val_loss: 1.8809\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8827 - val_loss: 1.8811\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8826 - val_loss: 1.8818\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8827 - val_loss: 1.8809\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8828 - val_loss: 1.8816\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8827 - val_loss: 1.8811\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8827 - val_loss: 1.8812\n",
      "Top-2 accuracy = 0.425\n",
      "10\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.9231 - val_loss: 1.9116\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9124 - val_loss: 1.9121\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9110\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9124 - val_loss: 1.9115\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9122\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9123\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9128 - val_loss: 1.9112\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9122 - val_loss: 1.9117\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9124 - val_loss: 1.9114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9124 - val_loss: 1.9118\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9122 - val_loss: 1.9118\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9122 - val_loss: 1.9118\n",
      "Top-2 accuracy = 0.382\n",
      "11\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9018 - val_loss: 1.8333\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8089 - val_loss: 1.7948\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7906\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.7854\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7859 - val_loss: 1.7846\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7852 - val_loss: 1.7825\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7838 - val_loss: 1.7818\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7820 - val_loss: 1.7901\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7784\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7768\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7828\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7816 - val_loss: 1.7788\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7787 - val_loss: 1.7757\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7775 - val_loss: 1.7779\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7768 - val_loss: 1.7730\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7760 - val_loss: 1.7749\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7778 - val_loss: 1.7717\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7725\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7755 - val_loss: 1.7717\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7757 - val_loss: 1.7719\n",
      "Top-2 accuracy = 0.474\n",
      "12\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.8759 - val_loss: 1.8112\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.7930 - val_loss: 1.7831\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7808 - val_loss: 1.7773\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7763 - val_loss: 1.7924\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7774 - val_loss: 1.7759\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7752 - val_loss: 1.7718\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7730 - val_loss: 1.7748\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7761 - val_loss: 1.7748\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7737 - val_loss: 1.7708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7712 - val_loss: 1.7738\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7716 - val_loss: 1.7685\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7694 - val_loss: 1.7719\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7706 - val_loss: 1.7803\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7683 - val_loss: 1.7686\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7708 - val_loss: 1.7699\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7734 - val_loss: 1.7775\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7745 - val_loss: 1.7742\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7700 - val_loss: 1.7695\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7686 - val_loss: 1.7713\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7675 - val_loss: 1.7688\n",
      "Top-2 accuracy = 0.472\n",
      "13\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9278 - val_loss: 1.9003\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8633 - val_loss: 1.8223\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8101 - val_loss: 1.8002\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7995 - val_loss: 1.7988\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7954 - val_loss: 1.7932\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7935 - val_loss: 1.7930\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7922 - val_loss: 1.7923\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7921 - val_loss: 1.8007\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7921 - val_loss: 1.7900\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7913 - val_loss: 1.7900\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7896\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7914 - val_loss: 1.7898\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7908 - val_loss: 1.7900\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7909 - val_loss: 1.7887\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7909 - val_loss: 1.7888\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7911 - val_loss: 1.7888\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7904 - val_loss: 1.7881\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7901 - val_loss: 1.7889\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7900 - val_loss: 1.7880\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7902 - val_loss: 1.7877\n",
      "Top-2 accuracy = 0.468\n",
      "14\n",
      "normalizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9004 - val_loss: 1.8466\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8118 - val_loss: 1.8028\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7909 - val_loss: 1.7930\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7851 - val_loss: 1.7921\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7836 - val_loss: 1.7811\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7813 - val_loss: 1.7785\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7813 - val_loss: 1.7811\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7793 - val_loss: 1.7820\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7793 - val_loss: 1.8045\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7786 - val_loss: 1.7843\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7763 - val_loss: 1.7770\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7749 - val_loss: 1.7740\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7748 - val_loss: 1.7751\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7786 - val_loss: 1.7777\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7777 - val_loss: 1.7827\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7769 - val_loss: 1.7981\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7757 - val_loss: 1.7714\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7744 - val_loss: 1.7739\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7741 - val_loss: 1.7745\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7732 - val_loss: 1.7743\n",
      "Top-2 accuracy = 0.472\n",
      "15\n",
      "maxabsZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9022 - val_loss: 1.8514\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8257 - val_loss: 1.8020\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7950 - val_loss: 1.7880\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 1.7883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7838 - val_loss: 1.7811\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7823 - val_loss: 1.7807\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7802 - val_loss: 1.7814\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7792 - val_loss: 1.7800\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7784 - val_loss: 1.7823\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7793 - val_loss: 1.7765\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7752 - val_loss: 1.7761\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7747 - val_loss: 1.7753\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7755 - val_loss: 1.7927\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7753 - val_loss: 1.7765\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7771 - val_loss: 1.7758\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7739 - val_loss: 1.7740\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7732 - val_loss: 1.7732\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7727 - val_loss: 1.7746\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7749 - val_loss: 1.7725\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7721 - val_loss: 1.7740\n",
      "Top-2 accuracy = 0.474\n",
      "16\n",
      "minmaxK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9275 - val_loss: 1.9136\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8939 - val_loss: 1.8721\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8470 - val_loss: 1.8338\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8182 - val_loss: 1.8134\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8048 - val_loss: 1.8023\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7993 - val_loss: 1.7987\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7965 - val_loss: 1.7963\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7957 - val_loss: 1.7958\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7953 - val_loss: 1.7954\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7949 - val_loss: 1.7947\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7946 - val_loss: 1.7949\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7945 - val_loss: 1.7965\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7941 - val_loss: 1.7943\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7947 - val_loss: 1.7933\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7938 - val_loss: 1.7925\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7934 - val_loss: 1.7955\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7930 - val_loss: 1.7924\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7926 - val_loss: 1.7919\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7928 - val_loss: 1.7916\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7928 - val_loss: 1.7940\n",
      "Top-2 accuracy = 0.468\n",
      "17\n",
      "normalizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.9266 - val_loss: 1.9137\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9125 - val_loss: 1.9113\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9110\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9117\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9117\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "18\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9277 - val_loss: 1.9083\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8788 - val_loss: 1.8559\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8332 - val_loss: 1.8208\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8100 - val_loss: 1.8068\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8004 - val_loss: 1.7970\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7941 - val_loss: 1.7932\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7902 - val_loss: 1.7905\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7906 - val_loss: 1.7888\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7873 - val_loss: 1.7869\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 1.7883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7863 - val_loss: 1.7868\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7860 - val_loss: 1.7865\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7850 - val_loss: 1.7884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7854 - val_loss: 1.7856\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7837 - val_loss: 1.7849\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7831 - val_loss: 1.7856\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7828 - val_loss: 1.7840\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7828 - val_loss: 1.7866\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7822 - val_loss: 1.7911\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7828 - val_loss: 1.7853\n",
      "Top-2 accuracy = 0.468\n",
      "19\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9162 - val_loss: 1.8642\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8281 - val_loss: 1.8051\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7979 - val_loss: 1.7925\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7903 - val_loss: 1.7883\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7874 - val_loss: 1.7847\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7859\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7846 - val_loss: 1.7844\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7848 - val_loss: 1.7835\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7836 - val_loss: 1.7820\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7829 - val_loss: 1.7840\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7825 - val_loss: 1.7820\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7821\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7820 - val_loss: 1.7817\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7834 - val_loss: 1.7819\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7810\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7800 - val_loss: 1.7804\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7799 - val_loss: 1.7815\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7808\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7800 - val_loss: 1.7793\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 1.7798\n",
      "Top-2 accuracy = 0.471\n",
      "20\n",
      "maxabse|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9216 - val_loss: 1.8780\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8388 - val_loss: 1.8120\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8011 - val_loss: 1.7964\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7898 - val_loss: 1.7878\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7831 - val_loss: 1.7850\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7814 - val_loss: 1.7831\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7778 - val_loss: 1.7790\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7764 - val_loss: 1.7763\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7745 - val_loss: 1.7763\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7736 - val_loss: 1.7744\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7729 - val_loss: 1.7751\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7743 - val_loss: 1.7742\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7707 - val_loss: 1.7718\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7714 - val_loss: 1.7728\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7704 - val_loss: 1.7723\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7701 - val_loss: 1.7713\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7696 - val_loss: 1.7887\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7706 - val_loss: 1.7707\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7687 - val_loss: 1.7768\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7701 - val_loss: 1.7681\n",
      "Top-2 accuracy = 0.476\n",
      "21\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9128 - val_loss: 1.8793\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8496 - val_loss: 1.8207\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8104 - val_loss: 1.8008\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7971 - val_loss: 1.7924\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7914 - val_loss: 1.7896\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7890 - val_loss: 1.7872\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7873 - val_loss: 1.7860\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7857\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7846 - val_loss: 1.7873\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7843 - val_loss: 1.7837\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7838 - val_loss: 1.7845\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7836 - val_loss: 1.7883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7833 - val_loss: 1.7828\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7830 - val_loss: 1.7829\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7827 - val_loss: 1.7823\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7823 - val_loss: 1.7816\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7818 - val_loss: 1.7818\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7816 - val_loss: 1.7815\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7821\n",
      "Top-2 accuracy = 0.468\n",
      "22\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9376 - val_loss: 1.9300\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9202 - val_loss: 1.9111\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9053 - val_loss: 1.9047\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9030 - val_loss: 1.9036\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9027 - val_loss: 1.9032\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9025 - val_loss: 1.9030\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9023 - val_loss: 1.9033\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9023 - val_loss: 1.9034\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9023 - val_loss: 1.9036\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9022 - val_loss: 1.9037\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9022 - val_loss: 1.9027\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9022 - val_loss: 1.9028\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9022 - val_loss: 1.9034\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9021 - val_loss: 1.9040\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9020 - val_loss: 1.9031\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9022 - val_loss: 1.9030\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9021 - val_loss: 1.9029\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9022 - val_loss: 1.9029\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9023 - val_loss: 1.9031\n",
      "Top-2 accuracy = 0.406\n",
      "23\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5927 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8862 - val_loss: 1.8538\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8286 - val_loss: 1.8146\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8068 - val_loss: 1.8012\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7977 - val_loss: 1.7939\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7922 - val_loss: 1.7889\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7885 - val_loss: 1.7867\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7855 - val_loss: 1.7825\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7827 - val_loss: 1.7815\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7813 - val_loss: 1.7791\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7794 - val_loss: 1.7771\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7783 - val_loss: 1.7768\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7769 - val_loss: 1.7740\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7761 - val_loss: 1.7737\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7745\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7733 - val_loss: 1.7718\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7718 - val_loss: 1.7723\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7712 - val_loss: 1.7687\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7704 - val_loss: 1.7689\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7687\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7688 - val_loss: 1.7683\n",
      "Top-2 accuracy = 0.475\n",
      "24\n",
      "standardized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9173 - val_loss: 1.8680\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8315 - val_loss: 1.8137\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7996 - val_loss: 1.7899\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7860 - val_loss: 1.7808\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7795 - val_loss: 1.7746\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7774 - val_loss: 1.7714\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.7715\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7731 - val_loss: 1.7685\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7727 - val_loss: 1.7676\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7737 - val_loss: 1.7674\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7734 - val_loss: 1.7695\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7702 - val_loss: 1.7674\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7694 - val_loss: 1.7652\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7686 - val_loss: 1.7650\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7683 - val_loss: 1.7639\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7671 - val_loss: 1.7632\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7668 - val_loss: 1.7632\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7676 - val_loss: 1.7653\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7660 - val_loss: 1.7654\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7673 - val_loss: 1.7644\n",
      "Top-2 accuracy = 0.473\n",
      "25\n",
      "normalizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8844 - val_loss: 1.8154\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7989 - val_loss: 1.7911\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7849 - val_loss: 1.7816\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7801 - val_loss: 1.7779\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7744\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7740 - val_loss: 1.7726\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7727 - val_loss: 1.7718\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7792\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7710 - val_loss: 1.7722\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7706\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7700\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7804\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7685 - val_loss: 1.7689\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7663\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7659 - val_loss: 1.7663\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7656 - val_loss: 1.7676\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7659 - val_loss: 1.7649\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7670\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7639\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7635 - val_loss: 1.7645\n",
      "Top-2 accuracy = 0.477\n",
      "26\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9386 - val_loss: 1.9305\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9265 - val_loss: 1.9198\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9186 - val_loss: 1.9136\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9146 - val_loss: 1.9113\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9125 - val_loss: 1.9097\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9087 - val_loss: 1.9003\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8877 - val_loss: 1.8687\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8547 - val_loss: 1.8300\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8176 - val_loss: 1.8075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7994 - val_loss: 1.7946\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7921 - val_loss: 1.7916\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7902 - val_loss: 1.7891\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7879 - val_loss: 1.7874\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7866 - val_loss: 1.7867\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7858 - val_loss: 1.7895\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7853\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7850 - val_loss: 1.7851\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7845 - val_loss: 1.7848\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7843 - val_loss: 1.7883\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7848 - val_loss: 1.7852\n",
      "Top-2 accuracy = 0.47\n",
      "27\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9065 - val_loss: 1.8553\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8261 - val_loss: 1.8100\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7968 - val_loss: 1.7879\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7860 - val_loss: 1.7835\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7821 - val_loss: 1.7823\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7788 - val_loss: 1.7766\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7770 - val_loss: 1.7751\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7755 - val_loss: 1.7765\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7752 - val_loss: 1.7770\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7749 - val_loss: 1.7742\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7728 - val_loss: 1.7782\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7733 - val_loss: 1.7731\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.7749\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7722 - val_loss: 1.7750\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 1.7715\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 1.7719\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7721\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7698 - val_loss: 1.7706\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7689 - val_loss: 1.7790\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7692 - val_loss: 1.7722\n",
      "Top-2 accuracy = 0.474\n",
      "28\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9128 - val_loss: 1.8809\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8495 - val_loss: 1.8206\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8066 - val_loss: 1.7963\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7925 - val_loss: 1.7895\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7874 - val_loss: 1.7864\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7844 - val_loss: 1.7842\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7821 - val_loss: 1.7810\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7799 - val_loss: 1.7815\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7787 - val_loss: 1.7794\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7777 - val_loss: 1.7782\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7773 - val_loss: 1.7770\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7770 - val_loss: 1.7759\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7756 - val_loss: 1.7759\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7779 - val_loss: 1.7753\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7751 - val_loss: 1.7742\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7747 - val_loss: 1.7739\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7738 - val_loss: 1.7772\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7744 - val_loss: 1.7739\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7737 - val_loss: 1.7732\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7733 - val_loss: 1.7757\n",
      "Top-2 accuracy = 0.472\n",
      "29\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8927 - val_loss: 1.8334\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8127 - val_loss: 1.7989\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7942 - val_loss: 1.7888\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7878 - val_loss: 1.7870\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7844 - val_loss: 1.7814\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7820 - val_loss: 1.7790\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7804 - val_loss: 1.7775\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7793 - val_loss: 1.7772\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7775 - val_loss: 1.7780\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7774 - val_loss: 1.7742\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7767 - val_loss: 1.7730\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7752 - val_loss: 1.7742\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7739 - val_loss: 1.7727\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7727 - val_loss: 1.7705\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7725 - val_loss: 1.7721\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7707 - val_loss: 1.7715\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7712 - val_loss: 1.7687\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7709 - val_loss: 1.7675\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7687 - val_loss: 1.7701\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7682 - val_loss: 1.7677\n",
      "Top-2 accuracy = 0.473\n",
      "0\n",
      "maxabsa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9292 - val_loss: 1.9136\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9135 - val_loss: 1.9113\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9113\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9117\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9118\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9111\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9118\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9108\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9123 - val_loss: 1.9113\n",
      "Top-2 accuracy = 0.382\n",
      "1\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.9001 - val_loss: 1.8516\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8407 - val_loss: 1.8280\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8233 - val_loss: 1.8197\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8233 - val_loss: 1.8261\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8396 - val_loss: 1.8476\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8508 - val_loss: 1.8529\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8312 - val_loss: 1.8252\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8315 - val_loss: 1.8196\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8214 - val_loss: 1.8249\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8233 - val_loss: 1.8220\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8234 - val_loss: 1.8238\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8604 - val_loss: 1.8633\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8638 - val_loss: 1.8626\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8639 - val_loss: 1.8616\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8525 - val_loss: 1.8279\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8238 - val_loss: 1.8231\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8238 - val_loss: 1.8237\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8234 - val_loss: 1.8246\n",
      "Top-2 accuracy = 0.457\n",
      "2\n",
      "minmaxb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8984 - val_loss: 1.8520\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8361 - val_loss: 1.8266\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8085 - val_loss: 1.7941\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7960 - val_loss: 1.7954\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7968 - val_loss: 1.7852\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7872 - val_loss: 1.7802\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7851 - val_loss: 1.7797\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7818 - val_loss: 1.7813\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7806 - val_loss: 1.7729\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7770 - val_loss: 1.7774\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7771 - val_loss: 1.7691\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7721 - val_loss: 1.7691\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7737 - val_loss: 1.7698\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7718 - val_loss: 1.7703\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7703 - val_loss: 1.7675\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7701 - val_loss: 1.7672\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7727 - val_loss: 1.7749\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7696 - val_loss: 1.7722\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7700 - val_loss: 1.7640\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7679 - val_loss: 1.7633\n",
      "Top-2 accuracy = 0.474\n",
      "3\n",
      "normalizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8813 - val_loss: 1.8267\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8194 - val_loss: 1.8064\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8018 - val_loss: 1.8016\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7949 - val_loss: 1.7944\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7846 - val_loss: 1.7825\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7835 - val_loss: 1.8007\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7874 - val_loss: 1.7803\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7794 - val_loss: 1.7782\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7794 - val_loss: 1.7812\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7773 - val_loss: 1.7756\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7770 - val_loss: 1.7779\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7764 - val_loss: 1.7766\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7769 - val_loss: 1.7819\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7884 - val_loss: 1.7781\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7766 - val_loss: 1.7771\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7762 - val_loss: 1.7771\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7749 - val_loss: 1.7773\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7751 - val_loss: 1.7797\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7754 - val_loss: 1.7730\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7729 - val_loss: 1.7741\n",
      "Top-2 accuracy = 0.472\n",
      "4\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.9307 - val_loss: 1.9149\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9143 - val_loss: 1.9114\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9124 - val_loss: 1.9112\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9120 - val_loss: 1.9120\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Top-2 accuracy = 0.382\n",
      "5\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9237 - val_loss: 1.9054\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9011 - val_loss: 1.8831\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8741 - val_loss: 1.8508\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8307 - val_loss: 1.8086\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7973 - val_loss: 1.7909\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7891 - val_loss: 1.7867\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7844 - val_loss: 1.7842\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7828 - val_loss: 1.7841\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7829 - val_loss: 1.7842\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7824 - val_loss: 1.7879\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7822 - val_loss: 1.7828\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7847 - val_loss: 1.7886\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7820 - val_loss: 1.7838\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7809 - val_loss: 1.7833\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7810 - val_loss: 1.7826\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7804 - val_loss: 1.7819\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7805 - val_loss: 1.7822\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7801 - val_loss: 1.7806\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7810 - val_loss: 1.7859\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7801 - val_loss: 1.7808\n",
      "Top-2 accuracy = 0.47\n",
      "6\n",
      "robustK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9119 - val_loss: 1.8769\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8577 - val_loss: 1.8345\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8238 - val_loss: 1.8138\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8063 - val_loss: 1.8062\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7984 - val_loss: 1.7939\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7930 - val_loss: 1.7901\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7886 - val_loss: 1.7869\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7875 - val_loss: 1.7868\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7859 - val_loss: 1.7864\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7844 - val_loss: 1.7860\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7851 - val_loss: 1.7894\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7842 - val_loss: 1.7842\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7835 - val_loss: 1.7849\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7832 - val_loss: 1.7851\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7822 - val_loss: 1.7832\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7832 - val_loss: 1.7837\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7826 - val_loss: 1.7829\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7820 - val_loss: 1.7914\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7824 - val_loss: 1.7834\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7818 - val_loss: 1.7873\n",
      "Top-2 accuracy = 0.47\n",
      "7\n",
      "normalizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9323 - val_loss: 1.9104\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8744 - val_loss: 1.8372\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8205 - val_loss: 1.8095\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8015 - val_loss: 1.7977\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7931 - val_loss: 1.7942\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7891 - val_loss: 1.7938\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7866 - val_loss: 1.7898\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7859 - val_loss: 1.7880\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7846 - val_loss: 1.7866\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7848 - val_loss: 1.7887\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7850 - val_loss: 1.7858\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7833 - val_loss: 1.7871\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7831 - val_loss: 1.7845\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7831 - val_loss: 1.7869\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7825 - val_loss: 1.7839\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7819 - val_loss: 1.7839\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7833 - val_loss: 1.7829\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7815 - val_loss: 1.7839\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7805 - val_loss: 1.7844\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7808 - val_loss: 1.7832\n",
      "Top-2 accuracy = 0.467\n",
      "8\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9390 - val_loss: 1.9319\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9281 - val_loss: 1.9234\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9216 - val_loss: 1.9183\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9175 - val_loss: 1.9152\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9152 - val_loss: 1.9137\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9139 - val_loss: 1.9128\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9130 - val_loss: 1.9122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9125 - val_loss: 1.9119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Top-2 accuracy = 0.382\n",
      "9\n",
      "minmaxg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9079 - val_loss: 1.8671\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8361 - val_loss: 1.8018\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7930 - val_loss: 1.7816\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7815 - val_loss: 1.7796\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7790 - val_loss: 1.7829\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7799 - val_loss: 1.7761\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7757 - val_loss: 1.7755\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.7712\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7739 - val_loss: 1.7713\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7723 - val_loss: 1.7698\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7721 - val_loss: 1.7719\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7712\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7712 - val_loss: 1.7724\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 1.7738\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7719 - val_loss: 1.7778\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7718 - val_loss: 1.7680\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7701 - val_loss: 1.7695\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7695 - val_loss: 1.7725\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7710\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7672\n",
      "Top-2 accuracy = 0.474\n",
      "10\n",
      "normalizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8933 - val_loss: 1.8678\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8400 - val_loss: 1.8190\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8044 - val_loss: 1.7948\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7940 - val_loss: 1.7871\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.7859\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7869 - val_loss: 1.7840\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7859 - val_loss: 1.7830\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7872 - val_loss: 1.8004\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7850 - val_loss: 1.7813\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7837 - val_loss: 1.7798\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7801\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7831 - val_loss: 1.7793\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7818 - val_loss: 1.7783\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7811 - val_loss: 1.7782\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7820 - val_loss: 1.7788\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7847\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7810 - val_loss: 1.7795\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7814 - val_loss: 1.7783\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 1.7781\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7804 - val_loss: 1.7822\n",
      "Top-2 accuracy = 0.469\n",
      "11\n",
      "normalizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9354 - val_loss: 1.9206\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9150 - val_loss: 1.9115\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.9111\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9110\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9119\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Top-2 accuracy = 0.382\n",
      "12\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9266 - val_loss: 1.8937\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8512 - val_loss: 1.8208\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8126 - val_loss: 1.8033\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8047 - val_loss: 1.8035\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8032 - val_loss: 1.8282\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8025 - val_loss: 1.8027\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7990 - val_loss: 1.7988\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7984 - val_loss: 1.7982\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7964 - val_loss: 1.7985\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7975 - val_loss: 1.7953\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7949\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7940 - val_loss: 1.7955\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7938 - val_loss: 1.7980\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7929 - val_loss: 1.7920\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.8091\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7933 - val_loss: 1.8004\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7918 - val_loss: 1.7916\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7919 - val_loss: 1.8060\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7894\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7903 - val_loss: 1.7933\n",
      "Top-2 accuracy = 0.464\n",
      "13\n",
      "standardizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9300 - val_loss: 1.9118\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9030 - val_loss: 1.8980\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8957 - val_loss: 1.8951\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8935 - val_loss: 1.8939\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8936 - val_loss: 1.8940\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8935 - val_loss: 1.8933\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8935 - val_loss: 1.8934\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8937 - val_loss: 1.8942\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8936 - val_loss: 1.8944\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8939 - val_loss: 1.8945\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8931 - val_loss: 1.8862\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8877 - val_loss: 1.8875\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8873 - val_loss: 1.8864\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8870 - val_loss: 1.8865\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8871 - val_loss: 1.8867\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8870 - val_loss: 1.8861\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8871 - val_loss: 1.8865\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8870 - val_loss: 1.8862\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8871 - val_loss: 1.8862\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8870 - val_loss: 1.8863\n",
      "Top-2 accuracy = 0.418\n",
      "14\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8783 - val_loss: 1.8229\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7921 - val_loss: 1.7807\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7766 - val_loss: 1.7767\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7742 - val_loss: 1.7722\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7705 - val_loss: 1.7745\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7713 - val_loss: 1.7695\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7672 - val_loss: 1.7678\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7670 - val_loss: 1.7646\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7658 - val_loss: 1.7701\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7659 - val_loss: 1.7702\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7660 - val_loss: 1.7641\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7650 - val_loss: 1.7643\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7649 - val_loss: 1.7717\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7650 - val_loss: 1.7743\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7653 - val_loss: 1.7633\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7632 - val_loss: 1.7647\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7621 - val_loss: 1.7662\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7637 - val_loss: 1.7641\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7619 - val_loss: 1.7671\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7659 - val_loss: 1.7614\n",
      "Top-2 accuracy = 0.477\n",
      "15\n",
      "minmaxn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.8914 - val_loss: 1.8397\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8205 - val_loss: 1.8071\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7964 - val_loss: 1.7936\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7946 - val_loss: 1.7924\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7907 - val_loss: 1.7846\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7860 - val_loss: 1.7838\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7822 - val_loss: 1.7818\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7837 - val_loss: 1.7802\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7802 - val_loss: 1.7754\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7799 - val_loss: 1.7823\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7776 - val_loss: 1.7712\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7749 - val_loss: 1.7756\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7742 - val_loss: 1.7707\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7746 - val_loss: 1.7773\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7754 - val_loss: 1.7715\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7770 - val_loss: 1.7836\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7774 - val_loss: 1.7703\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7740 - val_loss: 1.7744\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7728 - val_loss: 1.7685\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7716 - val_loss: 1.7679\n",
      "Top-2 accuracy = 0.473\n",
      "16\n",
      "robustV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9247 - val_loss: 1.9135\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9117 - val_loss: 1.9082\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9087 - val_loss: 1.9070\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9076 - val_loss: 1.9071\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9071 - val_loss: 1.9064\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9072 - val_loss: 1.9063\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9070 - val_loss: 1.9065\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9069 - val_loss: 1.9068\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9069 - val_loss: 1.9073\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9069 - val_loss: 1.9076\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9070 - val_loss: 1.9064\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9070 - val_loss: 1.9071\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9068 - val_loss: 1.9068\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9069 - val_loss: 1.9070\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9069 - val_loss: 1.9062\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9068 - val_loss: 1.9070\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9068 - val_loss: 1.9063\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9068 - val_loss: 1.9070\n",
      "Top-2 accuracy = 0.392\n",
      "17\n",
      "maxabsF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9100 - val_loss: 1.8505\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8230 - val_loss: 1.8023\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7967 - val_loss: 1.7895\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7913 - val_loss: 1.7831\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7848 - val_loss: 1.7829\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7839 - val_loss: 1.7796\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7821 - val_loss: 1.7815\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7804 - val_loss: 1.7836\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7798 - val_loss: 1.7774\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7785 - val_loss: 1.7794\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7778 - val_loss: 1.7774\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7775 - val_loss: 1.7745\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7748 - val_loss: 1.7762\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7754 - val_loss: 1.7743\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7759 - val_loss: 1.7747\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7740 - val_loss: 1.7753\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7734 - val_loss: 1.7745\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7726\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7732 - val_loss: 1.7721\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7753 - val_loss: 1.7738\n",
      "Top-2 accuracy = 0.472\n",
      "18\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8843 - val_loss: 1.8368\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8127 - val_loss: 1.7935\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7894 - val_loss: 1.7804\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7791 - val_loss: 1.7726\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7731 - val_loss: 1.7682\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7704 - val_loss: 1.7772\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7702 - val_loss: 1.7642\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7679 - val_loss: 1.7661\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7653 - val_loss: 1.7669\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7645 - val_loss: 1.7660\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7632 - val_loss: 1.7706\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7638 - val_loss: 1.7740\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7636 - val_loss: 1.7646\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7618 - val_loss: 1.7610\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7619 - val_loss: 1.7619\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7622 - val_loss: 1.7642\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7619 - val_loss: 1.7585\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7623 - val_loss: 1.7584\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7606 - val_loss: 1.7623\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7605 - val_loss: 1.7642\n",
      "Top-2 accuracy = 0.48\n",
      "19\n",
      "maxabsR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9232 - val_loss: 1.8849\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8591 - val_loss: 1.8282\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8152 - val_loss: 1.7995\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7983 - val_loss: 1.7930\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7946 - val_loss: 1.7905\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7906 - val_loss: 1.7854\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7888 - val_loss: 1.7851\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7898 - val_loss: 1.7878\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7889 - val_loss: 1.7849\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7848 - val_loss: 1.7845\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7831 - val_loss: 1.7810\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7824 - val_loss: 1.7785\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7819 - val_loss: 1.7800\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7790 - val_loss: 1.7774\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7791 - val_loss: 1.7776\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7781 - val_loss: 1.7764\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7774 - val_loss: 1.7882\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7775 - val_loss: 1.7806\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7791 - val_loss: 1.7794\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7761 - val_loss: 1.7767\n",
      "Top-2 accuracy = 0.469\n",
      "20\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9062 - val_loss: 1.8671\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8429 - val_loss: 1.8268\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8076 - val_loss: 1.7924\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.7894 - val_loss: 1.7859\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7831 - val_loss: 1.7850\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7838 - val_loss: 1.7925\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.7802 - val_loss: 1.7782\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.7774 - val_loss: 1.7836\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.7771 - val_loss: 1.7774\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7762 - val_loss: 1.7767\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7764 - val_loss: 1.7754\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.7737 - val_loss: 1.7739\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7730 - val_loss: 1.7760\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.7734 - val_loss: 1.7740\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7720 - val_loss: 1.7731\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.7711 - val_loss: 1.7719\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7706 - val_loss: 1.7746\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.7705 - val_loss: 1.7725\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.7697 - val_loss: 1.7701\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.7702 - val_loss: 1.7788\n",
      "Top-2 accuracy = 0.468\n",
      "21\n",
      "standardizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9061 - val_loss: 1.8780\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8446 - val_loss: 1.8247\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8140 - val_loss: 1.8053\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7956 - val_loss: 1.7893\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7872 - val_loss: 1.7961\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7827 - val_loss: 1.7799\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7786 - val_loss: 1.7839\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7767 - val_loss: 1.7763\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7743 - val_loss: 1.7748\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7730 - val_loss: 1.7741\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7724 - val_loss: 1.7712\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7714 - val_loss: 1.7720\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7719 - val_loss: 1.7728\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7701 - val_loss: 1.7708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7695 - val_loss: 1.7708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7686 - val_loss: 1.7699\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7688 - val_loss: 1.7703\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7686 - val_loss: 1.7707\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7685 - val_loss: 1.7702\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7715 - val_loss: 1.7755\n",
      "Top-2 accuracy = 0.475\n",
      "22\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8996 - val_loss: 1.8723\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8502 - val_loss: 1.8264\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8138 - val_loss: 1.8041\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8019 - val_loss: 1.7951\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7946 - val_loss: 1.7916\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7903 - val_loss: 1.7878\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7883 - val_loss: 1.7864\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7861 - val_loss: 1.7868\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7847 - val_loss: 1.7838\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7846 - val_loss: 1.7820\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7828 - val_loss: 1.7827\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7832 - val_loss: 1.7829\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7810 - val_loss: 1.7802\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7808 - val_loss: 1.7798\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7804 - val_loss: 1.7790\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7808 - val_loss: 1.7799\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7795 - val_loss: 1.7787\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7791 - val_loss: 1.7780\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7797 - val_loss: 1.7789\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7798 - val_loss: 1.7777\n",
      "Top-2 accuracy = 0.471\n",
      "23\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9291 - val_loss: 1.9206\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9140 - val_loss: 1.9081\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8827 - val_loss: 1.8513\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8307 - val_loss: 1.8176\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8084 - val_loss: 1.8025\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8006 - val_loss: 1.7985\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7969 - val_loss: 1.7941\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7948 - val_loss: 1.7987\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7970 - val_loss: 1.7926\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7928 - val_loss: 1.7905\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7925 - val_loss: 1.7898\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7923 - val_loss: 1.7894\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7914 - val_loss: 1.7952\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7935 - val_loss: 1.7881\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7905 - val_loss: 1.7922\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7901 - val_loss: 1.7871\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7906 - val_loss: 1.7865\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7910 - val_loss: 1.7937\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7900 - val_loss: 1.7911\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7895 - val_loss: 1.7958\n",
      "Top-2 accuracy = 0.469\n",
      "24\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9048 - val_loss: 1.8357\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8131 - val_loss: 1.7947\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7914 - val_loss: 1.7859\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7865 - val_loss: 1.7847\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7830 - val_loss: 1.7875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7836 - val_loss: 1.7810\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7816 - val_loss: 1.7776\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7777 - val_loss: 1.7859\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7783 - val_loss: 1.7749\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7811 - val_loss: 1.7805\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7790 - val_loss: 1.7800\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7756 - val_loss: 1.7798\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7750 - val_loss: 1.7728\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7737 - val_loss: 1.7767\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7736 - val_loss: 1.7741\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7720 - val_loss: 1.7697\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7727 - val_loss: 1.7731\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7712 - val_loss: 1.7683\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7702 - val_loss: 1.7707\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7707 - val_loss: 1.7684\n",
      "Top-2 accuracy = 0.47\n",
      "25\n",
      "normalizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9354 - val_loss: 1.9211\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9047 - val_loss: 1.8809\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8774 - val_loss: 1.8643\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8627 - val_loss: 1.8507\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8512 - val_loss: 1.8374\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8283 - val_loss: 1.8177\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8101 - val_loss: 1.8141\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8035 - val_loss: 1.7993\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7949 - val_loss: 1.7965\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7939 - val_loss: 1.7961\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7923 - val_loss: 1.7918\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7904 - val_loss: 1.7922\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7887 - val_loss: 1.7894\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7891 - val_loss: 1.7898\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7875 - val_loss: 1.7902\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7868 - val_loss: 1.7897\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7868 - val_loss: 1.7878\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7857 - val_loss: 1.7888\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7873 - val_loss: 1.7876\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7854 - val_loss: 1.7873\n",
      "Top-2 accuracy = 0.469\n",
      "26\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 1.8930 - val_loss: 1.8403\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.8159 - val_loss: 1.8111\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8128 - val_loss: 1.8094\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8100 - val_loss: 1.8069\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8089 - val_loss: 1.8073\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8086 - val_loss: 1.8066\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8090 - val_loss: 1.8066\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8082 - val_loss: 1.8083\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8116 - val_loss: 1.8130\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8113 - val_loss: 1.8131\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8114 - val_loss: 1.8133\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8108 - val_loss: 1.8126\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8104 - val_loss: 1.8126\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8107 - val_loss: 1.8130\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8108 - val_loss: 1.8125\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8107 - val_loss: 1.8135\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8108 - val_loss: 1.8130\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8109 - val_loss: 1.8128\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8126 - val_loss: 1.8134\n",
      "Top-2 accuracy = 0.462\n",
      "27\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9217 - val_loss: 1.8847\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8647 - val_loss: 1.8316\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8164 - val_loss: 1.8020\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7988 - val_loss: 1.7917\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7910 - val_loss: 1.7860\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7875 - val_loss: 1.7825\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7848 - val_loss: 1.7819\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7837 - val_loss: 1.7794\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7825 - val_loss: 1.7797\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7816 - val_loss: 1.7792\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7816 - val_loss: 1.7772\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7807 - val_loss: 1.7771\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7793 - val_loss: 1.7813\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7790 - val_loss: 1.7799\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7785 - val_loss: 1.7756\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7781 - val_loss: 1.7785\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7784 - val_loss: 1.7816\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7776 - val_loss: 1.7743\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7749 - val_loss: 1.7734\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7748 - val_loss: 1.7730\n",
      "Top-2 accuracy = 0.469\n",
      "28\n",
      "robustk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8901 - val_loss: 1.8333\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8072 - val_loss: 1.7861\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7806 - val_loss: 1.7733\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7728 - val_loss: 1.7772\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7692 - val_loss: 1.7652\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7716 - val_loss: 1.7656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7659 - val_loss: 1.7644\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7652 - val_loss: 1.7659\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7672 - val_loss: 1.7695\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7644 - val_loss: 1.7647\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7638 - val_loss: 1.7650\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7651 - val_loss: 1.7726\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7652 - val_loss: 1.7672\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7631 - val_loss: 1.7648\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7618 - val_loss: 1.7606\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7622 - val_loss: 1.7609\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7608 - val_loss: 1.7610\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7618 - val_loss: 1.7631\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7603 - val_loss: 1.7615\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7606 - val_loss: 1.7604\n",
      "Top-2 accuracy = 0.475\n",
      "29\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9380 - val_loss: 1.9293\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9200\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9191 - val_loss: 1.9156\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9152 - val_loss: 1.9132\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9134 - val_loss: 1.9121\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9126 - val_loss: 1.9119\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "0\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9385 - val_loss: 1.9314\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9277 - val_loss: 1.9230\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9212 - val_loss: 1.9181\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9174 - val_loss: 1.9153\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9151 - val_loss: 1.9137\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9137 - val_loss: 1.9127\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9129 - val_loss: 1.9122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9125 - val_loss: 1.9119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9123 - val_loss: 1.9117\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9113\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9112\n",
      "Top-2 accuracy = 0.382\n",
      "1\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.9209 - val_loss: 1.9047\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8995 - val_loss: 1.8994\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8971 - val_loss: 1.8955\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8954 - val_loss: 1.8939\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8948 - val_loss: 1.8932\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8954 - val_loss: 1.8926\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8956 - val_loss: 1.8929\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8954 - val_loss: 1.8932\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8953 - val_loss: 1.8926\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8953 - val_loss: 1.8926\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8953 - val_loss: 1.8941\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8953 - val_loss: 1.8930\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8952 - val_loss: 1.8930\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8953 - val_loss: 1.8923\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8951 - val_loss: 1.8927\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8952 - val_loss: 1.8925\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8953 - val_loss: 1.8921\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8952 - val_loss: 1.8923\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8953 - val_loss: 1.8922\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8953 - val_loss: 1.8936\n",
      "Top-2 accuracy = 0.405\n",
      "2\n",
      "maxabse|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8874 - val_loss: 1.8238\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8170 - val_loss: 1.8026\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7905 - val_loss: 1.7802\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7759 - val_loss: 1.7727\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7707 - val_loss: 1.7771\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7691 - val_loss: 1.7680\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7658 - val_loss: 1.7669\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7662 - val_loss: 1.7712\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7660 - val_loss: 1.7647\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7634 - val_loss: 1.7680\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7654 - val_loss: 1.7653\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.7624 - val_loss: 1.7629\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.7623 - val_loss: 1.7610\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7622 - val_loss: 1.7839\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7630 - val_loss: 1.7625\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7615 - val_loss: 1.7637\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7620 - val_loss: 1.7636\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.7614 - val_loss: 1.7706\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.7634 - val_loss: 1.7600\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.7597 - val_loss: 1.7701\n",
      "Top-2 accuracy = 0.476\n",
      "3\n",
      "robustm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.9161 - val_loss: 1.8915\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8755 - val_loss: 1.8514\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8456 - val_loss: 1.8390\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8374 - val_loss: 1.8348\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8500 - val_loss: 1.8549\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8569 - val_loss: 1.8403\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8392 - val_loss: 1.8389\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8398 - val_loss: 1.8432\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8438 - val_loss: 1.8438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8434 - val_loss: 1.8423\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8432 - val_loss: 1.8436\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8433 - val_loss: 1.8428\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8432 - val_loss: 1.8422\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8433 - val_loss: 1.8430\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8431 - val_loss: 1.8418\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8432 - val_loss: 1.8425\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8432 - val_loss: 1.8428\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8432 - val_loss: 1.8424\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8431 - val_loss: 1.8427\n",
      "Top-2 accuracy = 0.453\n",
      "4\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9357 - val_loss: 1.9266\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9163 - val_loss: 1.9112\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8978 - val_loss: 1.8925\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8889 - val_loss: 1.8908\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8875 - val_loss: 1.8899\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8872 - val_loss: 1.8901\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8872 - val_loss: 1.8907\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8871 - val_loss: 1.8892\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8867 - val_loss: 1.8881\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8862 - val_loss: 1.8887\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8865 - val_loss: 1.9002\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8960 - val_loss: 1.8976\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8958 - val_loss: 1.8977\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8960 - val_loss: 1.8974\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8962 - val_loss: 1.8969\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8963 - val_loss: 1.8973\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8962 - val_loss: 1.8968\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8980 - val_loss: 1.8989\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9000 - val_loss: 1.9069\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9040 - val_loss: 1.9046\n",
      "Top-2 accuracy = 0.388\n",
      "5\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9126 - val_loss: 1.8735\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8483 - val_loss: 1.8130\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7946 - val_loss: 1.7879\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7800 - val_loss: 1.7796\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7744 - val_loss: 1.7776\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7719 - val_loss: 1.7722\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7696 - val_loss: 1.7709\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7672 - val_loss: 1.7711\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7658 - val_loss: 1.7682\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7657 - val_loss: 1.7665\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7649 - val_loss: 1.7690\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7635 - val_loss: 1.7658\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7633 - val_loss: 1.7646\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7634 - val_loss: 1.7640\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7648\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7619 - val_loss: 1.7634\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7638 - val_loss: 1.7658\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7614\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7611 - val_loss: 1.7630\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7607 - val_loss: 1.7622\n",
      "Top-2 accuracy = 0.477\n",
      "6\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.9327 - val_loss: 1.9277\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9051 - val_loss: 1.8998\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8761 - val_loss: 1.8686\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8689 - val_loss: 1.8812\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8808 - val_loss: 1.8807\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8796 - val_loss: 1.8786\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8794 - val_loss: 1.8782\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8948 - val_loss: 1.9112\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9111\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9111\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9125 - val_loss: 1.9111\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9123\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9124 - val_loss: 1.9111\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9123 - val_loss: 1.9107\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9125 - val_loss: 1.9112\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9111\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Top-2 accuracy = 0.382\n",
      "7\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.9308 - val_loss: 1.9182\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9078 - val_loss: 1.9022\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8998 - val_loss: 1.8957\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8963 - val_loss: 1.8940\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8952 - val_loss: 1.8938\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8950 - val_loss: 1.8935\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8952 - val_loss: 1.8938\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.8951 - val_loss: 1.8932\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8951 - val_loss: 1.8938\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8951 - val_loss: 1.8935\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8951 - val_loss: 1.8938\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8950 - val_loss: 1.8933\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.8952 - val_loss: 1.8932\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.8950 - val_loss: 1.8941\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.8951 - val_loss: 1.8937\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8950 - val_loss: 1.8944\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8951 - val_loss: 1.8941\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8950 - val_loss: 1.8934\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8949 - val_loss: 1.8940\n",
      "Top-2 accuracy = 0.404\n",
      "8\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.9099 - val_loss: 1.8632\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8390 - val_loss: 1.8197\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8124 - val_loss: 1.8060\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8071 - val_loss: 1.8027\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8007 - val_loss: 1.7991\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7957 - val_loss: 1.7899\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7966 - val_loss: 1.7914\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7931 - val_loss: 1.7882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7891 - val_loss: 1.7873\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7867 - val_loss: 1.7934\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7898 - val_loss: 1.7918\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7888 - val_loss: 1.7927\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7866 - val_loss: 1.7836\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7835 - val_loss: 1.7864\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7836 - val_loss: 1.7817\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7811 - val_loss: 1.7830\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7825 - val_loss: 1.7849\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7831 - val_loss: 1.7852\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7813 - val_loss: 1.7823\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7803 - val_loss: 1.7819\n",
      "Top-2 accuracy = 0.469\n",
      "9\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8918 - val_loss: 1.8564\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8295 - val_loss: 1.8131\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8019 - val_loss: 1.7942\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7927 - val_loss: 1.7900\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7902 - val_loss: 1.7861\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7880 - val_loss: 1.7839\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7874 - val_loss: 1.7834\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7866 - val_loss: 1.7821\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7852 - val_loss: 1.7818\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7845 - val_loss: 1.7824\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7840 - val_loss: 1.7811\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7797\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7821 - val_loss: 1.7788\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7818 - val_loss: 1.7798\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7795\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7782\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7790 - val_loss: 1.7762\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7785 - val_loss: 1.7771\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7754\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7775 - val_loss: 1.7752\n",
      "Top-2 accuracy = 0.469\n",
      "10\n",
      "robustd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9362 - val_loss: 1.9227\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8944 - val_loss: 1.8595\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8450 - val_loss: 1.8437\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8351 - val_loss: 1.8441\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8044 - val_loss: 1.7952\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7923 - val_loss: 1.7968\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7894 - val_loss: 1.7900\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7871 - val_loss: 1.7881\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7860 - val_loss: 1.7852\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7838 - val_loss: 1.7841\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7834 - val_loss: 1.7846\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7819 - val_loss: 1.7855\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7820 - val_loss: 1.7817\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7812 - val_loss: 1.7876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7808 - val_loss: 1.7872\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7801 - val_loss: 1.7798\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7796 - val_loss: 1.7810\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7780 - val_loss: 1.7781\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7774 - val_loss: 1.7769\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7772 - val_loss: 1.7788\n",
      "Top-2 accuracy = 0.471\n",
      "11\n",
      "standardizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9239 - val_loss: 1.9044\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8985 - val_loss: 1.8804\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8752 - val_loss: 1.8498\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8461 - val_loss: 1.8279\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8283 - val_loss: 1.8152\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8166 - val_loss: 1.8063\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8086 - val_loss: 1.8013\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8037 - val_loss: 1.7969\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7994 - val_loss: 1.7947\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7967 - val_loss: 1.7919\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7939 - val_loss: 1.7897\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7896\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7900 - val_loss: 1.7894\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7890 - val_loss: 1.7868\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7878 - val_loss: 1.7854\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7866 - val_loss: 1.7851\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7860 - val_loss: 1.7846\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7856 - val_loss: 1.7841\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7845 - val_loss: 1.7837\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7840 - val_loss: 1.7831\n",
      "Top-2 accuracy = 0.47\n",
      "12\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9414 - val_loss: 1.9290\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9232 - val_loss: 1.9176\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9106 - val_loss: 1.8942\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8619 - val_loss: 1.8324\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8138 - val_loss: 1.8016\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7953 - val_loss: 1.7914\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7901 - val_loss: 1.7868\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7866 - val_loss: 1.7919\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 1.7848\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7845 - val_loss: 1.7834\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7828 - val_loss: 1.7812\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7820 - val_loss: 1.7803\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7813 - val_loss: 1.7800\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7811 - val_loss: 1.7802\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7804 - val_loss: 1.7861\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7802 - val_loss: 1.7815\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7792 - val_loss: 1.7788\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7782 - val_loss: 1.7770\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7784 - val_loss: 1.7768\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7789 - val_loss: 1.7770\n",
      "Top-2 accuracy = 0.473\n",
      "13\n",
      "normalizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9202 - val_loss: 1.9118\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9110 - val_loss: 1.9049\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8791 - val_loss: 1.8556\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8301 - val_loss: 1.8070\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7899 - val_loss: 1.7802\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7780 - val_loss: 1.7779\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7749 - val_loss: 1.7738\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7779 - val_loss: 1.7805\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7732 - val_loss: 1.7679\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7702 - val_loss: 1.7658\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7681 - val_loss: 1.7656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7659 - val_loss: 1.7649\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7606\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7644 - val_loss: 1.7650\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7634 - val_loss: 1.7598\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7648 - val_loss: 1.7576\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7633 - val_loss: 1.7582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7611 - val_loss: 1.7580\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7612 - val_loss: 1.7587\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7624 - val_loss: 1.7629\n",
      "Top-2 accuracy = 0.476\n",
      "14\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.9214 - val_loss: 1.8830\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8386 - val_loss: 1.8076\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7954 - val_loss: 1.7887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7863 - val_loss: 1.7840\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7818 - val_loss: 1.7857\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7793 - val_loss: 1.7826\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7776 - val_loss: 1.7785\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7771 - val_loss: 1.7878\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7752 - val_loss: 1.7765\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7726 - val_loss: 1.7737\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7739 - val_loss: 1.7807\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7728 - val_loss: 1.7748\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7711 - val_loss: 1.7733\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7709 - val_loss: 1.7745\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7714 - val_loss: 1.7729\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7697 - val_loss: 1.7755\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7702 - val_loss: 1.7703\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7705 - val_loss: 1.7719\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7690 - val_loss: 1.7829\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7697 - val_loss: 1.7730\n",
      "Top-2 accuracy = 0.474\n",
      "15\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9167 - val_loss: 1.8938\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8730 - val_loss: 1.8495\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8214 - val_loss: 1.7964\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7882 - val_loss: 1.7851\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7805 - val_loss: 1.7818\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7809 - val_loss: 1.7800\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7777 - val_loss: 1.7853\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7785 - val_loss: 1.7751\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7765 - val_loss: 1.7781\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7755 - val_loss: 1.7735\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7747 - val_loss: 1.7735\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7750 - val_loss: 1.7721\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7741 - val_loss: 1.7734\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7733 - val_loss: 1.7723\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7728 - val_loss: 1.7705\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7718 - val_loss: 1.7688\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7710 - val_loss: 1.7686\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7739 - val_loss: 1.7710\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7710 - val_loss: 1.7698\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7701 - val_loss: 1.7778\n",
      "Top-2 accuracy = 0.471\n",
      "16\n",
      "minmaxY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8871 - val_loss: 1.8271\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7994 - val_loss: 1.7863\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7839 - val_loss: 1.7820\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7806 - val_loss: 1.7772\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7765 - val_loss: 1.7727\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7732 - val_loss: 1.7722\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7738 - val_loss: 1.7716\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7729 - val_loss: 1.7700\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7714 - val_loss: 1.7754\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7717 - val_loss: 1.7719\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7717 - val_loss: 1.7705\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7691 - val_loss: 1.7676\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7696 - val_loss: 1.7712\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7699 - val_loss: 1.7683\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7716 - val_loss: 1.7660\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7674 - val_loss: 1.7681\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7682 - val_loss: 1.7703\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7672 - val_loss: 1.7643\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7668 - val_loss: 1.7703\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7678 - val_loss: 1.7652\n",
      "Top-2 accuracy = 0.472\n",
      "17\n",
      "minmaxA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 1.9099 - val_loss: 1.8747\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8615 - val_loss: 1.8301\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8637 - val_loss: 1.9001\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8893 - val_loss: 1.8996\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9000 - val_loss: 1.8998\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9011 - val_loss: 1.9015\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9012 - val_loss: 1.9010\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9015 - val_loss: 1.9010\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9009 - val_loss: 1.9016\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9011 - val_loss: 1.9012\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9009 - val_loss: 1.8998\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9008 - val_loss: 1.9005\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9008 - val_loss: 1.9003\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9008 - val_loss: 1.9022\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9009 - val_loss: 1.9026\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9009 - val_loss: 1.8996\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9009 - val_loss: 1.9009\n",
      "Top-2 accuracy = 0.396\n",
      "18\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9400 - val_loss: 1.9318\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9273 - val_loss: 1.9226\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9169 - val_loss: 1.8971\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8449 - val_loss: 1.8117\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8020 - val_loss: 1.7943\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7892 - val_loss: 1.7854\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7853 - val_loss: 1.7836\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 1.7850\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7837 - val_loss: 1.7832\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7833 - val_loss: 1.7808\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7835 - val_loss: 1.7815\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7834 - val_loss: 1.7798\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7816 - val_loss: 1.7893\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7820 - val_loss: 1.7789\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7813 - val_loss: 1.7789\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7824 - val_loss: 1.7856\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7840 - val_loss: 1.7783\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7803 - val_loss: 1.7814\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7807 - val_loss: 1.7785\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7802 - val_loss: 1.7784\n",
      "Top-2 accuracy = 0.472\n",
      "19\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9200 - val_loss: 1.8876\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8852 - val_loss: 1.8811\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8702 - val_loss: 1.8275\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8215 - val_loss: 1.8153\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8068 - val_loss: 1.7984\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7937 - val_loss: 1.7889\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7863 - val_loss: 1.7836\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7812 - val_loss: 1.7809\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7823 - val_loss: 1.7789\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7776 - val_loss: 1.7807\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7766 - val_loss: 1.7765\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7766 - val_loss: 1.7825\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7758 - val_loss: 1.7752\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7746 - val_loss: 1.7754\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7743 - val_loss: 1.7753\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7736 - val_loss: 1.7758\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7735 - val_loss: 1.7731\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7727 - val_loss: 1.7736\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7724 - val_loss: 1.7760\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7714 - val_loss: 1.7724\n",
      "Top-2 accuracy = 0.474\n",
      "20\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.9254 - val_loss: 1.9044\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8944 - val_loss: 1.8880\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8875 - val_loss: 1.8856\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8869 - val_loss: 1.8846\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8867 - val_loss: 1.8853\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8863 - val_loss: 1.8847\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8850 - val_loss: 1.8794\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8790 - val_loss: 1.8808\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8791 - val_loss: 1.8797\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8795 - val_loss: 1.8790\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8794 - val_loss: 1.8793\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8794 - val_loss: 1.8796\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8793 - val_loss: 1.8798\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8794 - val_loss: 1.8796\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8792 - val_loss: 1.8797\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8793 - val_loss: 1.8795\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8795 - val_loss: 1.8797\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8792 - val_loss: 1.8795\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8793 - val_loss: 1.8798\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8793 - val_loss: 1.8790\n",
      "Top-2 accuracy = 0.424\n",
      "21\n",
      "minmaxF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 1.9173 - val_loss: 1.8801\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8727 - val_loss: 1.8470\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8365 - val_loss: 1.8171\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8166 - val_loss: 1.8043\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7983 - val_loss: 1.7867\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7838 - val_loss: 1.7840\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7790 - val_loss: 1.7750\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7772 - val_loss: 1.7776\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7749 - val_loss: 1.7739\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7730 - val_loss: 1.7710\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7716 - val_loss: 1.7691\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7719 - val_loss: 1.7697\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7703 - val_loss: 1.7690\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7707 - val_loss: 1.7754\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7688 - val_loss: 1.7713\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7719 - val_loss: 1.7699\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7700 - val_loss: 1.7692\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7687 - val_loss: 1.7713\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7699 - val_loss: 1.7713\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7691 - val_loss: 1.7674\n",
      "Top-2 accuracy = 0.474\n",
      "22\n",
      "maxabsD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9233 - val_loss: 1.9032\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8822 - val_loss: 1.8687\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8489 - val_loss: 1.8371\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8262 - val_loss: 1.8189\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8146 - val_loss: 1.8099\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8084 - val_loss: 1.8053\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8042 - val_loss: 1.8023\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8018 - val_loss: 1.8000\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8004 - val_loss: 1.7989\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7992 - val_loss: 1.7981\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7997 - val_loss: 1.7982\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7981 - val_loss: 1.7975\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7975 - val_loss: 1.7991\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7974 - val_loss: 1.7963\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7970 - val_loss: 1.7959\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7968 - val_loss: 1.7968\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7964 - val_loss: 1.7952\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7962 - val_loss: 1.7949\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7959 - val_loss: 1.7943\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7961 - val_loss: 1.7960\n",
      "Top-2 accuracy = 0.465\n",
      "23\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9231 - val_loss: 1.8764\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8402 - val_loss: 1.8087\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7996 - val_loss: 1.8031\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7852 - val_loss: 1.7830\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7794 - val_loss: 1.7778\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7772 - val_loss: 1.7758\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7771 - val_loss: 1.7743\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7748 - val_loss: 1.7764\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7741 - val_loss: 1.7736\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7710 - val_loss: 1.7766\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7719 - val_loss: 1.7690\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7692 - val_loss: 1.7726\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7690 - val_loss: 1.7763\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7686 - val_loss: 1.7681\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7689 - val_loss: 1.7667\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7674 - val_loss: 1.7669\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7681 - val_loss: 1.7761\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7678 - val_loss: 1.7677\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7668 - val_loss: 1.7681\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7672 - val_loss: 1.7823\n",
      "Top-2 accuracy = 0.471\n",
      "24\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 1.9285 - val_loss: 1.9122\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9123 - val_loss: 1.9112\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9122 - val_loss: 1.9120\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9122 - val_loss: 1.9111\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9122 - val_loss: 1.9118\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9124 - val_loss: 1.9111\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9122 - val_loss: 1.9119\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9124 - val_loss: 1.9114\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9123 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9123 - val_loss: 1.9118\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9109\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9122 - val_loss: 1.9118\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9113\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9121 - val_loss: 1.9109\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9123 - val_loss: 1.9114\n",
      "Top-2 accuracy = 0.382\n",
      "25\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9381 - val_loss: 1.9309\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9239 - val_loss: 1.9188\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9147 - val_loss: 1.9137\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9126 - val_loss: 1.9122\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 1.9115\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9118\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Top-2 accuracy = 0.382\n",
      "26\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9336 - val_loss: 1.9190\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8968 - val_loss: 1.8760\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8558 - val_loss: 1.8429\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8276 - val_loss: 1.8227\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8118 - val_loss: 1.8088\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8020 - val_loss: 1.8019\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7981 - val_loss: 1.7950\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7930 - val_loss: 1.7909\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7911 - val_loss: 1.7885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7887 - val_loss: 1.7877\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7880 - val_loss: 1.7885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7874 - val_loss: 1.7879\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7871 - val_loss: 1.7851\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7868 - val_loss: 1.7867\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7867 - val_loss: 1.7850\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7867 - val_loss: 1.7841\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 1.7858\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7859 - val_loss: 1.7859\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7853 - val_loss: 1.7869\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7853 - val_loss: 1.7832\n",
      "Top-2 accuracy = 0.472\n",
      "27\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8995 - val_loss: 1.8620\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8415 - val_loss: 1.8497\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8215 - val_loss: 1.8155\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8027 - val_loss: 1.7945\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7982 - val_loss: 1.7972\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7955 - val_loss: 1.7920\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7929 - val_loss: 1.7907\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7908 - val_loss: 1.7893\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7880 - val_loss: 1.7840\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7846 - val_loss: 1.7827\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7832 - val_loss: 1.7810\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7810 - val_loss: 1.7837\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7809 - val_loss: 1.7772\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7790 - val_loss: 1.7756\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7795 - val_loss: 1.7764\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7788 - val_loss: 1.7762\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7764 - val_loss: 1.7756\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7762 - val_loss: 1.7762\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7758 - val_loss: 1.7759\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7756 - val_loss: 1.7743\n",
      "Top-2 accuracy = 0.469\n",
      "28\n",
      "normalizee|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9191 - val_loss: 1.8924\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8576 - val_loss: 1.8411\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8259 - val_loss: 1.8199\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8112 - val_loss: 1.8076\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8034 - val_loss: 1.8042\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7996 - val_loss: 1.8014\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7973 - val_loss: 1.7993\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7953 - val_loss: 1.7945\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7937 - val_loss: 1.7951\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7930 - val_loss: 1.7914\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7908\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7910 - val_loss: 1.7900\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7908 - val_loss: 1.7899\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7903 - val_loss: 1.7890\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7896 - val_loss: 1.7894\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7916\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7895\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7888 - val_loss: 1.7880\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7887 - val_loss: 1.7879\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7886 - val_loss: 1.7878\n",
      "Top-2 accuracy = 0.466\n",
      "29\n",
      "normalizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9314 - val_loss: 1.9217\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9166 - val_loss: 1.9149\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9129 - val_loss: 1.9122\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9114\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9116\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9113\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9112\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9115\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9112\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9115\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9122 - val_loss: 1.9113\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9121 - val_loss: 1.9116\n",
      "Top-2 accuracy = 0.382\n"
     ]
    }
   ],
   "source": [
    "top2 = []\n",
    "\n",
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"accuracy\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [MulticlassDL(n_classes=7, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20)],\n",
    "    \"post_train_hooks\": [top2_hook],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"eclipse-7class\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        MulticlassDL(n_classes=7, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.3049540026284212\n",
      "Top-2 Accuracy: 0.4772013027826981\n"
     ]
    }
   ],
   "source": [
    "interp = DODGEInterpreter(files=['./eclipse-7class.txt'], max_by=0, \n",
    "                          metrics=['accuracy'])\n",
    "results = interp.interpret()['eclipse-7class.txt']\n",
    "print('Top-1 Accuracy:', np.median(results['accuracy']))\n",
    "print('Top-2 Accuracy:', np.median(np.amax(np.array(top2).reshape(10,30), axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = np.where(data.y_train < 1, 0, np.where(data.y_train < 2, 1, np.where(data.y_train < 3, 2, np.where(data.y_train < 4, 3, np.where(data.y_train < 6, 4, np.where(data.y_train < 8, 5, np.where(data.y_train < 11, 6, np.where(data.y_train < 21, 7, 8))))))))\n",
    "data.y_test = np.where(data.y_test < 1, 0, np.where(data.y_test < 2, 1, np.where(data.y_test < 3, 2, np.where(data.y_test < 4, 3, np.where(data.y_test < 6, 4, np.where(data.y_test < 8, 5, np.where(data.y_test < 11, 6, np.where(data.y_test < 21, 7, 8))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y_train = to_categorical(data.y_train, num_classes=9)\n",
    "data.y_test = to_categorical(data.y_test, num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x157787970>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15e4a4610>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1867cd760>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b27de50>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15ab7d760>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17c363430>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1867cd940>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x153d25c70>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14f3f3670>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x151d3b0d0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17702a970>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x151d3bfd0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x151d3b670>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x151d3bcd0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x151d3b7c0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x151d3bf70>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x151d3be20>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14d2a9490>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1529a4700>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1529a4eb0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1529a4880>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1529a4310>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1529a4400>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1529a42b0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1529a47c0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x156c124c0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15ab5b970>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15ab5b460>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15ab5bd60>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b28af40>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14f3ee190>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x177333f40>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x16c95d4c0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x16c95d7f0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x16c95dd30>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x163434a90>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x163434220>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x163434670>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1634342e0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1634344f0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x163434940>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x163434520>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x163434970>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x16df45610>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15b176190>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1529964f0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1806e74f0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1811c9af0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1811c99d0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1811c9490>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1811c9e20>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardizen|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6270 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1566 - val_loss: 2.0904\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0462 - val_loss: 2.0102\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9892 - val_loss: 1.9796\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9679 - val_loss: 1.9662\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9569 - val_loss: 1.9577\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9493 - val_loss: 1.9512\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9437 - val_loss: 1.9460\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9397 - val_loss: 1.9434\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9368 - val_loss: 1.9402\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9345 - val_loss: 1.9385\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9325 - val_loss: 1.9371\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9313 - val_loss: 1.9361\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9300 - val_loss: 1.9358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9294 - val_loss: 1.9347\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9282 - val_loss: 1.9337\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9271 - val_loss: 1.9338\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9264 - val_loss: 1.9333\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9258 - val_loss: 1.9323\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9252 - val_loss: 1.9316\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9247 - val_loss: 1.9309\n",
      "Top-2 accuracy = 0.49\n",
      "1\n",
      "normalizeq|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6275 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1515 - val_loss: 2.0913\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0293 - val_loss: 1.9845\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9729 - val_loss: 1.9667\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9589 - val_loss: 1.9574\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9518 - val_loss: 1.9517\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9459 - val_loss: 1.9464\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9425 - val_loss: 1.9435\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9401 - val_loss: 1.9421\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9380 - val_loss: 1.9393\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9369 - val_loss: 1.9389\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9357 - val_loss: 1.9362\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9345 - val_loss: 1.9371\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9342 - val_loss: 1.9351\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9325 - val_loss: 1.9339\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9315 - val_loss: 1.9337\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9308 - val_loss: 1.9343\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9302 - val_loss: 1.9319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9291 - val_loss: 1.9327\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9294 - val_loss: 1.9318\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9288 - val_loss: 1.9313\n",
      "Top-2 accuracy = 0.49\n",
      "2\n",
      "minmaxf|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6280 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1337 - val_loss: 2.1143\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1052 - val_loss: 2.0947\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0857 - val_loss: 2.0735\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0627 - val_loss: 2.0492\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0399 - val_loss: 2.0285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0216 - val_loss: 2.0134\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0083 - val_loss: 2.0023\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9991 - val_loss: 1.9953\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9928 - val_loss: 1.9903\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9880 - val_loss: 1.9869\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9846 - val_loss: 1.9846\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9821 - val_loss: 1.9825\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9799 - val_loss: 1.9807\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9780 - val_loss: 1.9794\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9767 - val_loss: 1.9781\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9750 - val_loss: 1.9770\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9737 - val_loss: 1.9757\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9724 - val_loss: 1.9742\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9710 - val_loss: 1.9731\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9698 - val_loss: 1.9718\n",
      "Top-2 accuracy = 0.477\n",
      "3\n",
      "maxabsN|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6283 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1440 - val_loss: 2.0920\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0555 - val_loss: 2.0281\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0137 - val_loss: 2.0046\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9904\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9837 - val_loss: 1.9831\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9752 - val_loss: 1.9734\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9688 - val_loss: 1.9707\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9641 - val_loss: 1.9630\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9586 - val_loss: 1.9607\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9551 - val_loss: 1.9541\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9498 - val_loss: 1.9521\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9460 - val_loss: 1.9492\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9414 - val_loss: 1.9416\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9381 - val_loss: 1.9406\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9364 - val_loss: 1.9370\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9337 - val_loss: 1.9369\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9331 - val_loss: 1.9335\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9313 - val_loss: 1.9347\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9305 - val_loss: 1.9354\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9299 - val_loss: 1.9314\n",
      "Top-2 accuracy = 0.493\n",
      "4\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6289 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1715 - val_loss: 2.1279\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1146 - val_loss: 2.1027\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0932 - val_loss: 2.0836\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0745 - val_loss: 2.0527\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0451 - val_loss: 2.0359\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0185 - val_loss: 2.0033\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9959 - val_loss: 1.9915\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9879 - val_loss: 1.9850\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9808 - val_loss: 1.9804\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9760 - val_loss: 1.9753\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9716 - val_loss: 1.9724\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9682 - val_loss: 1.9698\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9645 - val_loss: 1.9664\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9614 - val_loss: 1.9631\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9581 - val_loss: 1.9619\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9544 - val_loss: 1.9569\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9512 - val_loss: 1.9528\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9485 - val_loss: 1.9502\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9457 - val_loss: 1.9494\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9441 - val_loss: 1.9476\n",
      "Top-2 accuracy = 0.486\n",
      "5\n",
      "minmaxT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1597 - val_loss: 2.0928\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0315 - val_loss: 1.9994\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9830 - val_loss: 1.9749\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9654 - val_loss: 1.9642\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9582 - val_loss: 1.9580\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9537 - val_loss: 1.9554\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9519 - val_loss: 1.9539\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9502 - val_loss: 1.9531\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9498 - val_loss: 1.9537\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9493 - val_loss: 1.9507\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9483 - val_loss: 1.9501\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9479 - val_loss: 1.9492\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9469 - val_loss: 1.9491\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9462 - val_loss: 1.9481\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9456 - val_loss: 1.9471\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9453 - val_loss: 1.9464\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9454 - val_loss: 1.9466\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9452 - val_loss: 1.9484\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9440 - val_loss: 1.9456\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9436 - val_loss: 1.9478\n",
      "Top-2 accuracy = 0.486\n",
      "6\n",
      "standardizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1130 - val_loss: 2.0255\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9955 - val_loss: 1.9790\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9678 - val_loss: 1.9621\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9525 - val_loss: 1.9516\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9441 - val_loss: 1.9449\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9382 - val_loss: 1.9389\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9341 - val_loss: 1.9381\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9313 - val_loss: 1.9329\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9274 - val_loss: 1.9301\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9264 - val_loss: 1.9292\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9247 - val_loss: 1.9277\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9229 - val_loss: 1.9277\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9227 - val_loss: 1.9288\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9218 - val_loss: 1.9274\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9220 - val_loss: 1.9271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9209 - val_loss: 1.9269\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9196 - val_loss: 1.9276\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9199 - val_loss: 1.9272\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9195 - val_loss: 1.9298\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9202 - val_loss: 1.9260\n",
      "Top-2 accuracy = 0.493\n",
      "7\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6305 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1711 - val_loss: 2.1174\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0260 - val_loss: 1.9712\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9602 - val_loss: 1.9598\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9507 - val_loss: 1.9498\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9458 - val_loss: 1.9524\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9439 - val_loss: 1.9454\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9419 - val_loss: 1.9431\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9403 - val_loss: 1.9426\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9389 - val_loss: 1.9412\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9382 - val_loss: 1.9416\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9423\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9361 - val_loss: 1.9369\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9344 - val_loss: 1.9359\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9336 - val_loss: 1.9349\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9321 - val_loss: 1.9358\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9320 - val_loss: 1.9338\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9302 - val_loss: 1.9340\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9300 - val_loss: 1.9321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9287 - val_loss: 1.9332\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9283 - val_loss: 1.9306\n",
      "Top-2 accuracy = 0.49\n",
      "8\n",
      "normalizeH|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6312 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1157 - val_loss: 2.0480\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9951 - val_loss: 1.9683\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9577 - val_loss: 1.9534\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9468 - val_loss: 1.9480\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9410 - val_loss: 1.9395\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9357 - val_loss: 1.9354\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9335 - val_loss: 1.9338\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9310 - val_loss: 1.9302\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9289 - val_loss: 1.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9279 - val_loss: 1.9290\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9264 - val_loss: 1.9278\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9249 - val_loss: 1.9257\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9246 - val_loss: 1.9255\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9230 - val_loss: 1.9252\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9221 - val_loss: 1.9263\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9222 - val_loss: 1.9243\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9208 - val_loss: 1.9255\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9209 - val_loss: 1.9248\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9210 - val_loss: 1.9241\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9208 - val_loss: 1.9241\n",
      "Top-2 accuracy = 0.494\n",
      "9\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6319 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1295 - val_loss: 2.1000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0702 - val_loss: 2.0237\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9945 - val_loss: 1.9782\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9689 - val_loss: 1.9712\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9602 - val_loss: 1.9594\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9530 - val_loss: 1.9599\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9488 - val_loss: 1.9490\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9432 - val_loss: 1.9458\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9411 - val_loss: 1.9423\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9372 - val_loss: 1.9400\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9359 - val_loss: 1.9367\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9338 - val_loss: 1.9351\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9331 - val_loss: 1.9348\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9321 - val_loss: 1.9335\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9306 - val_loss: 1.9378\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9314 - val_loss: 1.9326\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9297 - val_loss: 1.9316\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9288 - val_loss: 1.9307\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9280 - val_loss: 1.9315\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9278 - val_loss: 1.9305\n",
      "Top-2 accuracy = 0.491\n",
      "10\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6324 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.3576 - val_loss: 2.1329\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.0921\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0777 - val_loss: 2.0678\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0555 - val_loss: 2.0503\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0365 - val_loss: 2.0314\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0179 - val_loss: 2.0157\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0025 - val_loss: 2.0024\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9933 - val_loss: 1.9981\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9838 - val_loss: 1.9879\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9788 - val_loss: 1.9834\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9755 - val_loss: 1.9802\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9712 - val_loss: 1.9763\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9679 - val_loss: 1.9752\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9650 - val_loss: 1.9742\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9651 - val_loss: 1.9701\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9605 - val_loss: 1.9673\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9580 - val_loss: 1.9642\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9561 - val_loss: 1.9640\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9554 - val_loss: 1.9638\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9541 - val_loss: 1.9592\n",
      "Top-2 accuracy = 0.48\n",
      "11\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1246 - val_loss: 2.0132\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9729 - val_loss: 1.9657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9552 - val_loss: 1.9506\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9450 - val_loss: 1.9466\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9434 - val_loss: 1.9512\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9406 - val_loss: 1.9403\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9376 - val_loss: 1.9392\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9374 - val_loss: 1.9387\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9359 - val_loss: 1.9381\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9349 - val_loss: 1.9400\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9358 - val_loss: 1.9371\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9371 - val_loss: 1.9360\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9343 - val_loss: 1.9397\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9335 - val_loss: 1.9362\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9329 - val_loss: 1.9381\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9330 - val_loss: 1.9349\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9316 - val_loss: 1.9422\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9342 - val_loss: 1.9384\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9323 - val_loss: 1.9382\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9345 - val_loss: 1.9356\n",
      "Top-2 accuracy = 0.486\n",
      "12\n",
      "minmaxg|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6337 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1396 - val_loss: 2.0800\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0584 - val_loss: 2.0318\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0170 - val_loss: 1.9985\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9929 - val_loss: 1.9853\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9826 - val_loss: 1.9782\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9762 - val_loss: 1.9737\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9722 - val_loss: 1.9700\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9688 - val_loss: 1.9680\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9658 - val_loss: 1.9668\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9635 - val_loss: 1.9623\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9606 - val_loss: 1.9605\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9586 - val_loss: 1.9588\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9565 - val_loss: 1.9561\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9543 - val_loss: 1.9542\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9526 - val_loss: 1.9526\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9512 - val_loss: 1.9506\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9485 - val_loss: 1.9503\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9465 - val_loss: 1.9473\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9445 - val_loss: 1.9460\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9433 - val_loss: 1.9450\n",
      "Top-2 accuracy = 0.487\n",
      "13\n",
      "standardizeq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1453 - val_loss: 2.0975\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0614 - val_loss: 2.0290\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0039 - val_loss: 1.9842\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9710 - val_loss: 1.9634\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9570 - val_loss: 1.9565\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9508 - val_loss: 1.9504\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9481 - val_loss: 1.9484\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9460 - val_loss: 1.9458\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9431 - val_loss: 1.9447\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9422 - val_loss: 1.9431\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9413 - val_loss: 1.9438\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9405 - val_loss: 1.9425\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9398 - val_loss: 1.9418\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9393 - val_loss: 1.9407\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9395 - val_loss: 1.9406\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9382 - val_loss: 1.9409\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9401\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9374 - val_loss: 1.9407\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9372 - val_loss: 1.9397\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9367 - val_loss: 1.9386\n",
      "Top-2 accuracy = 0.485\n",
      "14\n",
      "standardizec|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6345 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1988 - val_loss: 2.1012\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0590 - val_loss: 2.0258\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0125 - val_loss: 2.0008\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9925 - val_loss: 1.9874\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9798 - val_loss: 1.9781\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9702 - val_loss: 1.9697\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9619 - val_loss: 1.9627\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9545 - val_loss: 1.9552\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9481 - val_loss: 1.9503\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9435 - val_loss: 1.9474\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9400 - val_loss: 1.9436\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9372 - val_loss: 1.9414\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9351 - val_loss: 1.9396\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9336 - val_loss: 1.9379\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9320 - val_loss: 1.9373\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9307 - val_loss: 1.9359\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9355\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9290 - val_loss: 1.9344\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9284 - val_loss: 1.9340\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9279 - val_loss: 1.9335\n",
      "Top-2 accuracy = 0.491\n",
      "15\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1771 - val_loss: 2.1484\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0918 - val_loss: 2.0188\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9866 - val_loss: 1.9687\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9588 - val_loss: 1.9565\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9515 - val_loss: 1.9519\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9495 - val_loss: 1.9496\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9454 - val_loss: 1.9520\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9426 - val_loss: 1.9450\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9394 - val_loss: 1.9483\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9427\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9390 - val_loss: 1.9383\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9361 - val_loss: 1.9378\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9351 - val_loss: 1.9391\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9344 - val_loss: 1.9383\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9338 - val_loss: 1.9381\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9335 - val_loss: 1.9365\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9337 - val_loss: 1.9472\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9353 - val_loss: 1.9356\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9342 - val_loss: 1.9383\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9326 - val_loss: 1.9431\n",
      "Top-2 accuracy = 0.482\n",
      "16\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6353 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1315 - val_loss: 2.0303\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9925 - val_loss: 1.9768\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9650 - val_loss: 1.9634\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9536 - val_loss: 1.9505\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9443 - val_loss: 1.9436\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9391 - val_loss: 1.9412\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9352 - val_loss: 1.9366\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9325 - val_loss: 1.9336\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9313 - val_loss: 1.9343\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9294 - val_loss: 1.9319\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9273 - val_loss: 1.9309\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9258 - val_loss: 1.9312\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9257 - val_loss: 1.9275\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9243 - val_loss: 1.9274\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9244 - val_loss: 1.9263\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9229 - val_loss: 1.9266\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9223 - val_loss: 1.9260\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9219 - val_loss: 1.9262\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9214 - val_loss: 1.9256\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9212 - val_loss: 1.9266\n",
      "Top-2 accuracy = 0.494\n",
      "17\n",
      "maxabsr|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6359 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1429 - val_loss: 2.0658\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0245 - val_loss: 1.9925\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9810 - val_loss: 1.9718\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9651 - val_loss: 1.9615\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9543 - val_loss: 1.9541\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9463 - val_loss: 1.9458\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9391 - val_loss: 1.9406\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9348 - val_loss: 1.9369\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9324 - val_loss: 1.9352\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9310 - val_loss: 1.9330\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9320\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9284 - val_loss: 1.9314\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9276 - val_loss: 1.9304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9264 - val_loss: 1.9313\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9250 - val_loss: 1.9292\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9245 - val_loss: 1.9283\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9242 - val_loss: 1.9293\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9239 - val_loss: 1.9268\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9227 - val_loss: 1.9270\n",
      "Top-2 accuracy = 0.493\n",
      "18\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6364 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1724 - val_loss: 2.1520\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1368 - val_loss: 2.1210\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1094 - val_loss: 2.0941\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0813 - val_loss: 2.0654\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0537 - val_loss: 2.0395\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0295 - val_loss: 2.0181\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0112 - val_loss: 2.0048\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9990 - val_loss: 1.9947\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9912 - val_loss: 1.9893\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9860 - val_loss: 1.9859\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9824 - val_loss: 1.9830\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9797 - val_loss: 1.9811\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9776 - val_loss: 1.9792\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9757 - val_loss: 1.9773\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9739 - val_loss: 1.9759\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9724 - val_loss: 1.9742\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9707 - val_loss: 1.9728\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9696 - val_loss: 1.9714\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9681 - val_loss: 1.9700\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9669 - val_loss: 1.9690\n",
      "Top-2 accuracy = 0.478\n",
      "19\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6367 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1740 - val_loss: 2.1366\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1229 - val_loss: 2.1118\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1123 - val_loss: 2.1081\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1072\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1090 - val_loss: 2.1066\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1086 - val_loss: 2.1061\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1079 - val_loss: 2.1056\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1068 - val_loss: 2.1041\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1051 - val_loss: 2.1022\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1017 - val_loss: 2.0973\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0951 - val_loss: 2.0889\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0835 - val_loss: 2.0752\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0688 - val_loss: 2.0603\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0539 - val_loss: 2.0457\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0392 - val_loss: 2.0323\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0250 - val_loss: 2.0214\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0130 - val_loss: 2.0093\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0034 - val_loss: 2.0022\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9969 - val_loss: 1.9966\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9915 - val_loss: 1.9938\n",
      "Top-2 accuracy = 0.477\n",
      "20\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6374 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1251 - val_loss: 2.0804\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0412 - val_loss: 2.0047\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9910 - val_loss: 1.9807\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9722 - val_loss: 1.9686\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9610 - val_loss: 1.9608\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9541 - val_loss: 1.9551\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9472 - val_loss: 1.9521\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9444 - val_loss: 1.9472\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9413 - val_loss: 1.9433\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9424\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9347 - val_loss: 1.9378\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9326 - val_loss: 1.9397\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9318 - val_loss: 1.9406\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9312 - val_loss: 1.9331\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9283 - val_loss: 1.9313\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9275 - val_loss: 1.9342\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9282 - val_loss: 1.9328\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9266 - val_loss: 1.9351\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9279 - val_loss: 1.9356\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9270 - val_loss: 1.9293\n",
      "Top-2 accuracy = 0.493\n",
      "21\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1672 - val_loss: 2.1178\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0587 - val_loss: 2.0000\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9751 - val_loss: 1.9677\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9580 - val_loss: 1.9554\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9521 - val_loss: 1.9536\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9523 - val_loss: 1.9550\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9490 - val_loss: 1.9487\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9474 - val_loss: 1.9509\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9473 - val_loss: 1.9468\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9468 - val_loss: 1.9469\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9459 - val_loss: 1.9471\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9458 - val_loss: 1.9484\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9464 - val_loss: 1.9466\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9463 - val_loss: 1.9465\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9458 - val_loss: 1.9456\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9452 - val_loss: 1.9461\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9452 - val_loss: 1.9458\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9451 - val_loss: 1.9462\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9459 - val_loss: 1.9464\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9443 - val_loss: 1.9447\n",
      "Top-2 accuracy = 0.488\n",
      "22\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6387 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1569 - val_loss: 2.1131\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1042 - val_loss: 2.0881\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0717 - val_loss: 2.0437\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0207 - val_loss: 1.9996\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9892 - val_loss: 1.9830\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9767 - val_loss: 1.9786\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9700 - val_loss: 1.9707\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9664 - val_loss: 1.9662\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9622 - val_loss: 1.9644\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9599 - val_loss: 1.9612\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9573 - val_loss: 1.9602\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9561 - val_loss: 1.9570\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9530 - val_loss: 1.9560\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9515 - val_loss: 1.9543\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9502 - val_loss: 1.9532\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9499 - val_loss: 1.9551\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9488 - val_loss: 1.9513\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9477 - val_loss: 1.9510\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9467 - val_loss: 1.9503\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9460 - val_loss: 1.9484\n",
      "Top-2 accuracy = 0.486\n",
      "23\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1481 - val_loss: 2.0930\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0593 - val_loss: 2.0330\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0157 - val_loss: 2.0057\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9878 - val_loss: 1.9800\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9669 - val_loss: 1.9636\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9553 - val_loss: 1.9559\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9496 - val_loss: 1.9552\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9478 - val_loss: 1.9486\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9449 - val_loss: 1.9473\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9433 - val_loss: 1.9444\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9423 - val_loss: 1.9458\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9444 - val_loss: 1.9433\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9415 - val_loss: 1.9426\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9407 - val_loss: 1.9420\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9398 - val_loss: 1.9428\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9399 - val_loss: 1.9404\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9397 - val_loss: 1.9396\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9409 - val_loss: 1.9399\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9384 - val_loss: 1.9404\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9382 - val_loss: 1.9393\n",
      "Top-2 accuracy = 0.484\n",
      "24\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6397 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1334 - val_loss: 2.0793\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0378 - val_loss: 2.0002\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9795 - val_loss: 1.9697\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9586 - val_loss: 1.9558\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9485 - val_loss: 1.9496\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9435 - val_loss: 1.9460\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9386 - val_loss: 1.9411\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9350 - val_loss: 1.9391\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9323 - val_loss: 1.9348\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9303 - val_loss: 1.9338\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9292 - val_loss: 1.9336\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9276 - val_loss: 1.9343\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9269 - val_loss: 1.9313\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9324\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9252 - val_loss: 1.9307\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9246 - val_loss: 1.9281\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9235 - val_loss: 1.9281\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9232 - val_loss: 1.9279\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9219 - val_loss: 1.9267\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9221 - val_loss: 1.9269\n",
      "Top-2 accuracy = 0.492\n",
      "25\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6404 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1255\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1017 - val_loss: 2.0709\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0509 - val_loss: 2.0269\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0185 - val_loss: 2.0048\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0011 - val_loss: 1.9933\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9916 - val_loss: 1.9869\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9856 - val_loss: 1.9826\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9816 - val_loss: 1.9793\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9783 - val_loss: 1.9765\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9755 - val_loss: 1.9745\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9730 - val_loss: 1.9719\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9707 - val_loss: 1.9701\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9688 - val_loss: 1.9679\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9671 - val_loss: 1.9663\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9650 - val_loss: 1.9648\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9633 - val_loss: 1.9629\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9614 - val_loss: 1.9617\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9598 - val_loss: 1.9603\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9583 - val_loss: 1.9587\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9567 - val_loss: 1.9579\n",
      "Top-2 accuracy = 0.484\n",
      "26\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6407 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1642 - val_loss: 2.1451\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1308 - val_loss: 2.1162\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1060 - val_loss: 2.0902\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0664 - val_loss: 2.0396\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0228 - val_loss: 2.0092\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9967 - val_loss: 1.9900\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9805 - val_loss: 1.9782\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9704 - val_loss: 1.9703\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9635 - val_loss: 1.9654\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9585 - val_loss: 1.9609\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9548 - val_loss: 1.9579\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9517 - val_loss: 1.9551\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9491 - val_loss: 1.9523\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9469 - val_loss: 1.9504\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9452 - val_loss: 1.9486\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9434 - val_loss: 1.9471\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9421 - val_loss: 1.9448\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9405 - val_loss: 1.9432\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9389 - val_loss: 1.9421\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9406\n",
      "Top-2 accuracy = 0.49\n",
      "27\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6412 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1193 - val_loss: 2.0540\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0229 - val_loss: 1.9971\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9824 - val_loss: 1.9737\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9611 - val_loss: 1.9586\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9471 - val_loss: 1.9504\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9392 - val_loss: 1.9410\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9335 - val_loss: 1.9383\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9303 - val_loss: 1.9354\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9275 - val_loss: 1.9341\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9264 - val_loss: 1.9303\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9253 - val_loss: 1.9302\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9241 - val_loss: 1.9280\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9229 - val_loss: 1.9288\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9218 - val_loss: 1.9270\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9211 - val_loss: 1.9274\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9212 - val_loss: 1.9256\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9211 - val_loss: 1.9267\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9204 - val_loss: 1.9257\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9190 - val_loss: 1.9251\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9196 - val_loss: 1.9250\n",
      "Top-2 accuracy = 0.492\n",
      "28\n",
      "normalizeL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6419 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1438 - val_loss: 2.0497\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0107 - val_loss: 1.9844\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9734 - val_loss: 1.9655\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9574 - val_loss: 1.9537\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9477 - val_loss: 1.9463\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9423 - val_loss: 1.9422\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9383 - val_loss: 1.9400\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9354 - val_loss: 1.9371\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9337 - val_loss: 1.9352\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9318 - val_loss: 1.9348\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9304 - val_loss: 1.9343\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9295 - val_loss: 1.9339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9283 - val_loss: 1.9319\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9275 - val_loss: 1.9316\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9265 - val_loss: 1.9323\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9263 - val_loss: 1.9340\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9300\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9249 - val_loss: 1.9300\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9243 - val_loss: 1.9310\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9240 - val_loss: 1.9300\n",
      "Top-2 accuracy = 0.494\n",
      "29\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1175 - val_loss: 2.0416\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0081 - val_loss: 1.9876\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9768 - val_loss: 1.9707\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9647 - val_loss: 1.9627\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9559 - val_loss: 1.9576\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9526 - val_loss: 1.9545\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9474 - val_loss: 1.9450\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9438 - val_loss: 1.9443\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9428 - val_loss: 1.9428\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9402 - val_loss: 1.9419\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9400 - val_loss: 1.9432\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9375 - val_loss: 1.9379\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9356 - val_loss: 1.9391\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9363 - val_loss: 1.9387\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9350 - val_loss: 1.9362\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9335 - val_loss: 1.9359\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9334 - val_loss: 1.9387\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9325 - val_loss: 1.9353\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9313 - val_loss: 1.9358\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9309 - val_loss: 1.9340\n",
      "Top-2 accuracy = 0.485\n",
      "0\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6433 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1443 - val_loss: 2.0599\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0204 - val_loss: 1.9970\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9837 - val_loss: 1.9790\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9690 - val_loss: 1.9670\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9585 - val_loss: 1.9581\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9505 - val_loss: 1.9510\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9435 - val_loss: 1.9449\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9417\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9374 - val_loss: 1.9413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9357 - val_loss: 1.9386\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9340 - val_loss: 1.9369\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9342 - val_loss: 1.9360\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9319 - val_loss: 1.9347\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9308 - val_loss: 1.9346\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9310 - val_loss: 1.9328\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9294 - val_loss: 1.9334\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9292 - val_loss: 1.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9291 - val_loss: 1.9323\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9280 - val_loss: 1.9309\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9272 - val_loss: 1.9322\n",
      "Top-2 accuracy = 0.493\n",
      "1\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6439 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1863 - val_loss: 2.1232\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1027 - val_loss: 2.0838\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0708 - val_loss: 2.0566\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0424 - val_loss: 2.0293\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0159 - val_loss: 2.0079\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9997 - val_loss: 1.9964\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9899 - val_loss: 1.9884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9825 - val_loss: 1.9820\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9765 - val_loss: 1.9773\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9713 - val_loss: 1.9723\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9666 - val_loss: 1.9675\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9626 - val_loss: 1.9636\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9590 - val_loss: 1.9593\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9552 - val_loss: 1.9555\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9523 - val_loss: 1.9526\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9488 - val_loss: 1.9489\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9455 - val_loss: 1.9461\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9430 - val_loss: 1.9441\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9414 - val_loss: 1.9420\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9393 - val_loss: 1.9410\n",
      "Top-2 accuracy = 0.485\n",
      "2\n",
      "maxabsH|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6442 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1161 - val_loss: 2.0441\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0142 - val_loss: 1.9913\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9797 - val_loss: 1.9718\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9632 - val_loss: 1.9590\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9526 - val_loss: 1.9502\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9448 - val_loss: 1.9438\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9394 - val_loss: 1.9396\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9358 - val_loss: 1.9356\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9327 - val_loss: 1.9346\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9310 - val_loss: 1.9338\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9290 - val_loss: 1.9309\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9276 - val_loss: 1.9303\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9268 - val_loss: 1.9306\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9264 - val_loss: 1.9292\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9254 - val_loss: 1.9305\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9248 - val_loss: 1.9287\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9237 - val_loss: 1.9281\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9230 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9221 - val_loss: 1.9276\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9224 - val_loss: 1.9272\n",
      "Top-2 accuracy = 0.493\n",
      "3\n",
      "robustv|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6446 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1431 - val_loss: 2.0479\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0270 - val_loss: 2.0105\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0011 - val_loss: 1.9940\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9865 - val_loss: 1.9824\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9760 - val_loss: 1.9732\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9669 - val_loss: 1.9655\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9591 - val_loss: 1.9581\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9534 - val_loss: 1.9518\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9477 - val_loss: 1.9471\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9437 - val_loss: 1.9450\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9405 - val_loss: 1.9410\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9371 - val_loss: 1.9382\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9343 - val_loss: 1.9356\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9317 - val_loss: 1.9334\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9295 - val_loss: 1.9327\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9280 - val_loss: 1.9311\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9264 - val_loss: 1.9296\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9255 - val_loss: 1.9296\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9246 - val_loss: 1.9281\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9238 - val_loss: 1.9279\n",
      "Top-2 accuracy = 0.489\n",
      "4\n",
      "maxabsF|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6450 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1292 - val_loss: 2.0345\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0073 - val_loss: 1.9917\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9811 - val_loss: 1.9753\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9656 - val_loss: 1.9628\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9541 - val_loss: 1.9542\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9460 - val_loss: 1.9467\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9395 - val_loss: 1.9424\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9356 - val_loss: 1.9372\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9325 - val_loss: 1.9354\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9306 - val_loss: 1.9339\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9294 - val_loss: 1.9336\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9283 - val_loss: 1.9308\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9271 - val_loss: 1.9307\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9269 - val_loss: 1.9310\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9262 - val_loss: 1.9298\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9253 - val_loss: 1.9292\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9249 - val_loss: 1.9286\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9248 - val_loss: 1.9291\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9238 - val_loss: 1.9297\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9241 - val_loss: 1.9281\n",
      "Top-2 accuracy = 0.493\n",
      "5\n",
      "standardized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1165 - val_loss: 2.0448\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9981 - val_loss: 1.9650\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9524 - val_loss: 1.9485\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9417 - val_loss: 1.9440\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9371 - val_loss: 1.9374\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9332 - val_loss: 1.9344\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9301 - val_loss: 1.9337\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9276 - val_loss: 1.9300\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9270 - val_loss: 1.9280\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9260 - val_loss: 1.9276\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9242 - val_loss: 1.9265\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9243 - val_loss: 1.9292\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9233 - val_loss: 1.9261\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9232 - val_loss: 1.9269\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9227 - val_loss: 1.9262\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9219 - val_loss: 1.9248\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9214 - val_loss: 1.9251\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9212 - val_loss: 1.9248\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9212 - val_loss: 1.9252\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9200 - val_loss: 1.9248\n",
      "Top-2 accuracy = 0.492\n",
      "6\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1522 - val_loss: 2.0984\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0291 - val_loss: 1.9604\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9438 - val_loss: 1.9464\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9366 - val_loss: 1.9416\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9346 - val_loss: 1.9414\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9331 - val_loss: 1.9383\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9333 - val_loss: 1.9424\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9342 - val_loss: 1.9361\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9310 - val_loss: 1.9346\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9310 - val_loss: 1.9346\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9308 - val_loss: 1.9340\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9310 - val_loss: 1.9346\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9302 - val_loss: 1.9349\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9293 - val_loss: 1.9355\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9301 - val_loss: 1.9338\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9290 - val_loss: 1.9368\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9295 - val_loss: 1.9353\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9284 - val_loss: 1.9342\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9286 - val_loss: 1.9346\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9277 - val_loss: 1.9355\n",
      "Top-2 accuracy = 0.485\n",
      "7\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1157 - val_loss: 2.0357\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9926 - val_loss: 1.9721\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9610 - val_loss: 1.9580\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9523 - val_loss: 1.9534\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9510 - val_loss: 1.9503\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9477 - val_loss: 1.9538\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9470 - val_loss: 1.9474\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9454 - val_loss: 1.9483\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9460 - val_loss: 1.9486\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9441 - val_loss: 1.9458\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9440 - val_loss: 1.9469\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9427 - val_loss: 1.9497\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9434 - val_loss: 1.9450\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9422 - val_loss: 1.9439\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9416 - val_loss: 1.9439\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9426 - val_loss: 1.9439\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9422 - val_loss: 1.9455\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9412 - val_loss: 1.9431\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9407 - val_loss: 1.9463\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9429 - val_loss: 1.9430\n",
      "Top-2 accuracy = 0.486\n",
      "8\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1263 - val_loss: 2.0639\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0267 - val_loss: 1.9872\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9700 - val_loss: 1.9625\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9548 - val_loss: 1.9545\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9483 - val_loss: 1.9477\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9430 - val_loss: 1.9415\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9387 - val_loss: 1.9404\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9364 - val_loss: 1.9351\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9340 - val_loss: 1.9350\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9316 - val_loss: 1.9324\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9310\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9278 - val_loss: 1.9304\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9273 - val_loss: 1.9312\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9260 - val_loss: 1.9294\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9253 - val_loss: 1.9282\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9251 - val_loss: 1.9298\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9244 - val_loss: 1.9276\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9234 - val_loss: 1.9276\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9230 - val_loss: 1.9282\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9237 - val_loss: 1.9282\n",
      "Top-2 accuracy = 0.491\n",
      "9\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6476 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1290 - val_loss: 2.0595\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0288 - val_loss: 2.0003\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9808\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9734 - val_loss: 1.9695\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9621 - val_loss: 1.9586\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9529 - val_loss: 1.9493\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9444 - val_loss: 1.9436\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9392\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9359 - val_loss: 1.9368\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9336 - val_loss: 1.9341\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9312 - val_loss: 1.9327\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9304 - val_loss: 1.9321\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9290 - val_loss: 1.9316\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9273 - val_loss: 1.9290\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9260 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9250 - val_loss: 1.9293\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9244 - val_loss: 1.9287\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9235 - val_loss: 1.9275\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9231 - val_loss: 1.9277\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9227 - val_loss: 1.9269\n",
      "Top-2 accuracy = 0.492\n",
      "10\n",
      "standardizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1293 - val_loss: 2.0404\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9930 - val_loss: 1.9736\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9599 - val_loss: 1.9574\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9479 - val_loss: 1.9491\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9429 - val_loss: 1.9471\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9397 - val_loss: 1.9432\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9379 - val_loss: 1.9436\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9402\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9354 - val_loss: 1.9390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9343 - val_loss: 1.9381\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9332 - val_loss: 1.9390\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9321 - val_loss: 1.9360\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9318 - val_loss: 1.9356\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9295 - val_loss: 1.9374\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9301 - val_loss: 1.9333\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9280 - val_loss: 1.9319\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9274 - val_loss: 1.9332\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9266 - val_loss: 1.9320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9267 - val_loss: 1.9300\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9270 - val_loss: 1.9314\n",
      "Top-2 accuracy = 0.492\n",
      "11\n",
      "maxabsa|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6487 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1583 - val_loss: 2.1075\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0577 - val_loss: 2.0164\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0022 - val_loss: 1.9935\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9863 - val_loss: 1.9836\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9770 - val_loss: 1.9756\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9696 - val_loss: 1.9697\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9631 - val_loss: 1.9636\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9564 - val_loss: 1.9566\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9507 - val_loss: 1.9529\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9472 - val_loss: 1.9494\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9445 - val_loss: 1.9470\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9434 - val_loss: 1.9457\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9424 - val_loss: 1.9444\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9410 - val_loss: 1.9443\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9404 - val_loss: 1.9437\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9399 - val_loss: 1.9423\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9389 - val_loss: 1.9417\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9385 - val_loss: 1.9418\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9378 - val_loss: 1.9407\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9374 - val_loss: 1.9410\n",
      "Top-2 accuracy = 0.485\n",
      "12\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6494 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1571 - val_loss: 2.1069\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0831 - val_loss: 2.0577\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0402 - val_loss: 2.0216\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0082 - val_loss: 1.9982\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9873 - val_loss: 1.9809\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9719 - val_loss: 1.9692\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9611 - val_loss: 1.9616\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9538 - val_loss: 1.9574\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9491 - val_loss: 1.9514\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9448 - val_loss: 1.9469\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9420 - val_loss: 1.9450\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9401 - val_loss: 1.9420\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9405\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9364 - val_loss: 1.9393\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9349 - val_loss: 1.9383\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9341 - val_loss: 1.9389\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9339 - val_loss: 1.9380\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9330 - val_loss: 1.9370\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9322 - val_loss: 1.9360\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9314 - val_loss: 1.9358\n",
      "Top-2 accuracy = 0.49\n",
      "13\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6500 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.0767\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0212 - val_loss: 1.9916\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9759 - val_loss: 1.9695\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9607 - val_loss: 1.9573\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9508 - val_loss: 1.9495\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9439 - val_loss: 1.9434\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9389 - val_loss: 1.9400\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9353 - val_loss: 1.9359\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9331 - val_loss: 1.9352\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9310 - val_loss: 1.9332\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9293 - val_loss: 1.9323\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9290 - val_loss: 1.9311\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9276 - val_loss: 1.9304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9267 - val_loss: 1.9305\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9262 - val_loss: 1.9288\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9261 - val_loss: 1.9298\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9250 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9243 - val_loss: 1.9289\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9243 - val_loss: 1.9278\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9238 - val_loss: 1.9273\n",
      "Top-2 accuracy = 0.492\n",
      "14\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6505 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1721 - val_loss: 2.1365\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1131 - val_loss: 2.0902\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0678 - val_loss: 2.0398\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0214 - val_loss: 2.0055\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9947 - val_loss: 1.9860\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9775 - val_loss: 1.9741\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9664 - val_loss: 1.9653\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9596 - val_loss: 1.9600\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9546 - val_loss: 1.9557\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9511 - val_loss: 1.9526\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9484 - val_loss: 1.9508\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9467 - val_loss: 1.9484\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9449 - val_loss: 1.9487\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9451 - val_loss: 1.9462\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9425 - val_loss: 1.9448\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9420 - val_loss: 1.9435\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9419 - val_loss: 1.9431\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9406 - val_loss: 1.9441\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9400 - val_loss: 1.9415\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9393 - val_loss: 1.9415\n",
      "Top-2 accuracy = 0.484\n",
      "15\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6511 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1785 - val_loss: 2.1607\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1457 - val_loss: 2.1331\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1216 - val_loss: 2.1105\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1024 - val_loss: 2.0932\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0877 - val_loss: 2.0799\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0762 - val_loss: 2.0699\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0668 - val_loss: 2.0607\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0575 - val_loss: 2.0523\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0490 - val_loss: 2.0444\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0409 - val_loss: 2.0373\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0339 - val_loss: 2.0306\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0276 - val_loss: 2.0250\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0220 - val_loss: 2.0205\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0175 - val_loss: 2.0161\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0131 - val_loss: 2.0127\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0098 - val_loss: 2.0094\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0068 - val_loss: 2.0069\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0044 - val_loss: 2.0047\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0025 - val_loss: 2.0026\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0005 - val_loss: 2.0011\n",
      "Top-2 accuracy = 0.464\n",
      "16\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1431 - val_loss: 2.1099\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1032\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0708 - val_loss: 2.0158\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9967 - val_loss: 1.9649\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9604 - val_loss: 1.9537\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9513 - val_loss: 1.9503\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9489 - val_loss: 1.9587\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9463 - val_loss: 1.9531\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9451 - val_loss: 1.9428\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9436 - val_loss: 1.9466\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9442 - val_loss: 1.9446\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9411 - val_loss: 1.9468\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9403 - val_loss: 1.9483\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9404 - val_loss: 1.9392\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9402 - val_loss: 1.9438\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9396 - val_loss: 1.9448\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9404 - val_loss: 1.9397\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9375 - val_loss: 1.9447\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9378 - val_loss: 1.9503\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9431 - val_loss: 1.9417\n",
      "Top-2 accuracy = 0.48\n",
      "17\n",
      "robustK|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6522 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.4294 - val_loss: 2.1956\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1501 - val_loss: 2.1110\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0920 - val_loss: 2.0701\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0578 - val_loss: 2.0434\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0327 - val_loss: 2.0222\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0148 - val_loss: 2.0090\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0031 - val_loss: 1.9995\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9946 - val_loss: 1.9938\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9883 - val_loss: 1.9889\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9832 - val_loss: 1.9849\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9778 - val_loss: 1.9787\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9732 - val_loss: 1.9759\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9703 - val_loss: 1.9719\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9667 - val_loss: 1.9696\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9645 - val_loss: 1.9669\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9626 - val_loss: 1.9657\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9602 - val_loss: 1.9636\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9584 - val_loss: 1.9616\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9571 - val_loss: 1.9604\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9558 - val_loss: 1.9593\n",
      "Top-2 accuracy = 0.476\n",
      "18\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1812 - val_loss: 2.1393\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1067 - val_loss: 2.0770\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0584 - val_loss: 2.0407\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0254 - val_loss: 2.0130\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0029 - val_loss: 1.9975\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9881\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9817 - val_loss: 1.9805\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9753 - val_loss: 1.9761\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9702 - val_loss: 1.9706\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9655 - val_loss: 1.9668\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9618 - val_loss: 1.9640\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9590 - val_loss: 1.9608\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9562 - val_loss: 1.9585\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9539 - val_loss: 1.9564\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9517 - val_loss: 1.9546\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9501 - val_loss: 1.9531\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9484 - val_loss: 1.9518\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9470 - val_loss: 1.9502\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9457 - val_loss: 1.9494\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9447 - val_loss: 1.9479\n",
      "Top-2 accuracy = 0.485\n",
      "19\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1326 - val_loss: 2.0310\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9870 - val_loss: 1.9639\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9531 - val_loss: 1.9481\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9426 - val_loss: 1.9416\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9380 - val_loss: 1.9384\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9371 - val_loss: 1.9383\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9354 - val_loss: 1.9452\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9364 - val_loss: 1.9388\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.9370\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9384\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9310 - val_loss: 1.9335\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9316 - val_loss: 1.9334\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9316 - val_loss: 1.9354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9302 - val_loss: 1.9325\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9298 - val_loss: 1.9336\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9294 - val_loss: 1.9369\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9299 - val_loss: 1.9350\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9290 - val_loss: 1.9321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9292 - val_loss: 1.9326\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9285 - val_loss: 1.9324\n",
      "Top-2 accuracy = 0.484\n",
      "20\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1846 - val_loss: 2.1724\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1633 - val_loss: 2.1540\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1472 - val_loss: 2.1401\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1354 - val_loss: 2.1300\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1269 - val_loss: 2.1228\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1210 - val_loss: 2.1177\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1168 - val_loss: 2.1141\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1141 - val_loss: 2.1118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1123 - val_loss: 2.1102\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1112 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1106 - val_loss: 2.1087\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1100 - val_loss: 2.1080\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "21\n",
      "normalizeM|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6539 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1451 - val_loss: 2.1094\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0967 - val_loss: 2.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0320 - val_loss: 1.9978\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9834 - val_loss: 1.9722\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9634 - val_loss: 1.9582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9525 - val_loss: 1.9499\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9447 - val_loss: 1.9440\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9406 - val_loss: 1.9429\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9372\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9345 - val_loss: 1.9357\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9331 - val_loss: 1.9336\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9316 - val_loss: 1.9320\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9300 - val_loss: 1.9319\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9293 - val_loss: 1.9302\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9281 - val_loss: 1.9297\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9272 - val_loss: 1.9289\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9268 - val_loss: 1.9288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9251 - val_loss: 1.9270\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9242 - val_loss: 1.9276\n",
      "Top-2 accuracy = 0.491\n",
      "22\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1571 - val_loss: 2.1162\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1124 - val_loss: 2.1079\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1101 - val_loss: 2.1075\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1061\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1036 - val_loss: 2.0861\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0295 - val_loss: 1.9965\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9807 - val_loss: 1.9771\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9604 - val_loss: 1.9745\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9512 - val_loss: 1.9506\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9433 - val_loss: 1.9469\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9409 - val_loss: 1.9504\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9402 - val_loss: 1.9418\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9388 - val_loss: 1.9440\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9383 - val_loss: 1.9416\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9361 - val_loss: 1.9419\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9362 - val_loss: 1.9392\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9344 - val_loss: 1.9440\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9363 - val_loss: 1.9393\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9350 - val_loss: 1.9372\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9337 - val_loss: 1.9437\n",
      "Top-2 accuracy = 0.477\n",
      "23\n",
      "normalizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1845 - val_loss: 2.1724\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1630 - val_loss: 2.1539\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1473 - val_loss: 2.1404\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1357 - val_loss: 2.1303\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1271 - val_loss: 2.1228\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1211 - val_loss: 2.1178\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1170 - val_loss: 2.1142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1143 - val_loss: 2.1119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1125 - val_loss: 2.1103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "24\n",
      "robustF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1504 - val_loss: 2.0953\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0377 - val_loss: 1.9968\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9754 - val_loss: 1.9688\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9591 - val_loss: 1.9601\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9527 - val_loss: 1.9541\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9482 - val_loss: 1.9524\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9448 - val_loss: 1.9480\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9426 - val_loss: 1.9483\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9417 - val_loss: 1.9468\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9404 - val_loss: 1.9453\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9385 - val_loss: 1.9440\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9390 - val_loss: 1.9430\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9371 - val_loss: 1.9418\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9363 - val_loss: 1.9413\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9355 - val_loss: 1.9395\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9353 - val_loss: 1.9400\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9340 - val_loss: 1.9388\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9330 - val_loss: 1.9377\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9322 - val_loss: 1.9398\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9370\n",
      "Top-2 accuracy = 0.488\n",
      "25\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6562 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.4978 - val_loss: 2.3229\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.2548 - val_loss: 2.2071\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1801 - val_loss: 2.1582\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1419 - val_loss: 2.1260\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1124 - val_loss: 2.1000\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0893 - val_loss: 2.0800\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0724 - val_loss: 2.0666\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0605 - val_loss: 2.0557\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0503 - val_loss: 2.0465\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0411 - val_loss: 2.0382\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0337 - val_loss: 2.0318\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0277 - val_loss: 2.0268\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0230 - val_loss: 2.0224\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0186 - val_loss: 2.0184\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0149 - val_loss: 2.0152\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0116 - val_loss: 2.0124\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0088 - val_loss: 2.0098\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0064 - val_loss: 2.0077\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0040 - val_loss: 2.0053\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0020 - val_loss: 2.0033\n",
      "Top-2 accuracy = 0.465\n",
      "26\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1797 - val_loss: 2.1582\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1339 - val_loss: 2.1097\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0897 - val_loss: 2.0659\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0535 - val_loss: 2.0433\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 104s 1s/step - loss: 2.0336 - val_loss: 2.0254\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0169 - val_loss: 2.0107\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0048 - val_loss: 2.0020\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9959 - val_loss: 1.9971\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9894 - val_loss: 1.9910\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9849 - val_loss: 1.9872\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9808 - val_loss: 1.9838\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9792 - val_loss: 1.9809\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9758 - val_loss: 1.9787\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9730 - val_loss: 1.9759\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9724 - val_loss: 1.9760\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9692 - val_loss: 1.9738\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9672 - val_loss: 1.9701\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9662 - val_loss: 1.9699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9643 - val_loss: 1.9667\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9639 - val_loss: 1.9665\n",
      "Top-2 accuracy = 0.481\n",
      "27\n",
      "robustV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1623 - val_loss: 2.1242\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0986 - val_loss: 2.0705\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0564 - val_loss: 2.0355\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0275 - val_loss: 2.0148\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0097 - val_loss: 2.0009\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9959 - val_loss: 1.9909\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9867 - val_loss: 1.9846\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9798 - val_loss: 1.9781\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9741 - val_loss: 1.9736\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9703 - val_loss: 1.9719\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9665 - val_loss: 1.9661\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9640 - val_loss: 1.9630\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9614 - val_loss: 1.9620\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9602 - val_loss: 1.9612\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9579 - val_loss: 1.9586\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9574 - val_loss: 1.9591\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9565 - val_loss: 1.9583\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9550 - val_loss: 1.9561\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9539 - val_loss: 1.9557\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9535 - val_loss: 1.9547\n",
      "Top-2 accuracy = 0.483\n",
      "28\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1756 - val_loss: 2.1473\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1153 - val_loss: 2.0833\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0641 - val_loss: 2.0405\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0189 - val_loss: 2.0020\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9886 - val_loss: 1.9810\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9761 - val_loss: 1.9740\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9710 - val_loss: 1.9691\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9676 - val_loss: 1.9670\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9648 - val_loss: 1.9643\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9641 - val_loss: 1.9669\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9625 - val_loss: 1.9603\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9594 - val_loss: 1.9590\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9586 - val_loss: 1.9577\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9572 - val_loss: 1.9628\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9569 - val_loss: 1.9556\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9554 - val_loss: 1.9550\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9546 - val_loss: 1.9542\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9545 - val_loss: 1.9537\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9531 - val_loss: 1.9524\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9524 - val_loss: 1.9528\n",
      "Top-2 accuracy = 0.479\n",
      "29\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1462 - val_loss: 2.1096\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1104 - val_loss: 2.1067\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1064 - val_loss: 2.0944\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0460 - val_loss: 1.9905\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9834 - val_loss: 1.9864\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9757 - val_loss: 1.9703\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9713 - val_loss: 1.9736\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9685 - val_loss: 1.9667\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9643 - val_loss: 1.9633\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9627 - val_loss: 1.9651\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9603 - val_loss: 1.9827\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9596 - val_loss: 1.9583\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9565 - val_loss: 1.9553\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9552 - val_loss: 1.9521\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9534 - val_loss: 1.9555\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9523 - val_loss: 1.9607\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9527 - val_loss: 1.9475\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9485 - val_loss: 1.9662\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9516 - val_loss: 1.9850\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9737 - val_loss: 1.9525\n",
      "Top-2 accuracy = 0.479\n",
      "0\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1565 - val_loss: 2.1194\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0993 - val_loss: 2.0818\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0676 - val_loss: 2.0529\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0375 - val_loss: 2.0262\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0132 - val_loss: 2.0159\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9990 - val_loss: 1.9920\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9876 - val_loss: 1.9976\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9820 - val_loss: 1.9943\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9753 - val_loss: 1.9762\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9721 - val_loss: 1.9987\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9702 - val_loss: 1.9698\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9671 - val_loss: 1.9756\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9678 - val_loss: 1.9725\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9635 - val_loss: 1.9668\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9611 - val_loss: 1.9638\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9598 - val_loss: 1.9648\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9585 - val_loss: 1.9713\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9590 - val_loss: 1.9585\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9563 - val_loss: 1.9588\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9581 - val_loss: 1.9632\n",
      "Top-2 accuracy = 0.477\n",
      "1\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6590 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1847 - val_loss: 2.1609\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1424 - val_loss: 2.1234\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1091 - val_loss: 2.0916\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0727 - val_loss: 2.0503\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0263 - val_loss: 2.0083\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9960 - val_loss: 1.9900\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9840 - val_loss: 1.9815\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9776 - val_loss: 1.9768\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9734 - val_loss: 1.9728\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9701 - val_loss: 1.9704\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9675 - val_loss: 1.9676\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9655 - val_loss: 1.9659\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9631 - val_loss: 1.9635\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9612 - val_loss: 1.9615\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9596 - val_loss: 1.9604\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9579 - val_loss: 1.9585\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9566 - val_loss: 1.9569\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9549 - val_loss: 1.9555\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9538 - val_loss: 1.9535\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9513 - val_loss: 1.9524\n",
      "Top-2 accuracy = 0.481\n",
      "2\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1400 - val_loss: 2.0815\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0501 - val_loss: 2.0242\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0049 - val_loss: 1.9855\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9772 - val_loss: 1.9687\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9666 - val_loss: 1.9619\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9596 - val_loss: 1.9532\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9530 - val_loss: 1.9487\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9496 - val_loss: 1.9466\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9481 - val_loss: 1.9458\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9451 - val_loss: 1.9433\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9434 - val_loss: 1.9425\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9428 - val_loss: 1.9406\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9410 - val_loss: 1.9397\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9403 - val_loss: 1.9397\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9392 - val_loss: 1.9398\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9385 - val_loss: 1.9386\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9382\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9369 - val_loss: 1.9388\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9371 - val_loss: 1.9369\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9354 - val_loss: 1.9374\n",
      "Top-2 accuracy = 0.489\n",
      "3\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1676 - val_loss: 2.1361\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1078 - val_loss: 2.0831\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0621 - val_loss: 2.0405\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0254 - val_loss: 2.0115\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0034 - val_loss: 1.9961\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9910 - val_loss: 1.9872\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9839 - val_loss: 1.9819\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9793 - val_loss: 1.9781\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9760 - val_loss: 1.9759\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9739 - val_loss: 1.9731\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9715 - val_loss: 1.9714\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9697 - val_loss: 1.9699\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9679 - val_loss: 1.9688\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9664 - val_loss: 1.9667\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9649 - val_loss: 1.9656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9635 - val_loss: 1.9643\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9620 - val_loss: 1.9628\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9607 - val_loss: 1.9614\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9597 - val_loss: 1.9607\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9583 - val_loss: 1.9596\n",
      "Top-2 accuracy = 0.476\n",
      "4\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1057 - val_loss: 2.0042\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9770 - val_loss: 1.9619\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9549 - val_loss: 1.9498\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9476 - val_loss: 1.9448\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9439 - val_loss: 1.9434\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9434 - val_loss: 1.9427\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9412 - val_loss: 1.9411\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9389\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9362 - val_loss: 1.9375\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9357 - val_loss: 1.9376\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9356 - val_loss: 1.9356\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9341 - val_loss: 1.9410\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9331 - val_loss: 1.9390\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9334 - val_loss: 1.9367\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9319 - val_loss: 1.9376\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9301 - val_loss: 1.9340\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9296 - val_loss: 1.9459\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9316 - val_loss: 1.9345\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9279 - val_loss: 1.9319\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9278 - val_loss: 1.9340\n",
      "Top-2 accuracy = 0.491\n",
      "5\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1223 - val_loss: 2.0865\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0518 - val_loss: 2.0119\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9808 - val_loss: 1.9628\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9548 - val_loss: 1.9530\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9471 - val_loss: 1.9487\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9443 - val_loss: 1.9456\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9412 - val_loss: 1.9432\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9392 - val_loss: 1.9462\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9380 - val_loss: 1.9417\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9365 - val_loss: 1.9412\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9359 - val_loss: 1.9411\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9361 - val_loss: 1.9390\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9348 - val_loss: 1.9393\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9341 - val_loss: 1.9381\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9345 - val_loss: 1.9359\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9329 - val_loss: 1.9400\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9340 - val_loss: 1.9352\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9326 - val_loss: 1.9375\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9318 - val_loss: 1.9355\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9328 - val_loss: 1.9350\n",
      "Top-2 accuracy = 0.484\n",
      "6\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1428 - val_loss: 2.0839\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0385 - val_loss: 2.0053\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9832 - val_loss: 1.9681\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9617 - val_loss: 1.9586\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9523 - val_loss: 1.9492\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9472 - val_loss: 1.9462\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9441 - val_loss: 1.9443\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9422 - val_loss: 1.9422\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9401 - val_loss: 1.9433\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9399 - val_loss: 1.9406\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9380 - val_loss: 1.9391\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9385 - val_loss: 1.9385\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9366 - val_loss: 1.9416\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9360 - val_loss: 1.9382\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9357 - val_loss: 1.9391\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9347 - val_loss: 1.9368\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9340 - val_loss: 1.9427\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9339 - val_loss: 1.9355\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9329 - val_loss: 1.9355\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9338 - val_loss: 1.9362\n",
      "Top-2 accuracy = 0.482\n",
      "7\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6619 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1660 - val_loss: 2.1231\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1062 - val_loss: 2.0901\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0795 - val_loss: 2.0568\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0384 - val_loss: 2.0140\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0018 - val_loss: 1.9906\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9838 - val_loss: 1.9798\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9751 - val_loss: 1.9733\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9689 - val_loss: 1.9703\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9652 - val_loss: 1.9646\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9609 - val_loss: 1.9612\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9574 - val_loss: 1.9590\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9546 - val_loss: 1.9561\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9522 - val_loss: 1.9528\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9495 - val_loss: 1.9512\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9470 - val_loss: 1.9485\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9449 - val_loss: 1.9466\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9433 - val_loss: 1.9449\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9416 - val_loss: 1.9439\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9403 - val_loss: 1.9421\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9395 - val_loss: 1.9410\n",
      "Top-2 accuracy = 0.488\n",
      "8\n",
      "maxabsM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1600 - val_loss: 2.1265\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1007 - val_loss: 2.0748\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0385 - val_loss: 2.0021\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9834 - val_loss: 1.9730\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9653 - val_loss: 1.9630\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9573 - val_loss: 1.9574\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9525 - val_loss: 1.9528\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9492 - val_loss: 1.9528\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9472 - val_loss: 1.9495\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9455 - val_loss: 1.9490\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9439 - val_loss: 1.9463\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9430 - val_loss: 1.9457\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9419 - val_loss: 1.9443\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9412 - val_loss: 1.9439\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9405 - val_loss: 1.9430\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9395 - val_loss: 1.9431\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9390 - val_loss: 1.9419\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9425\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9416\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9375 - val_loss: 1.9398\n",
      "Top-2 accuracy = 0.484\n",
      "9\n",
      "maxabsc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1566 - val_loss: 2.0884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0441 - val_loss: 1.9974\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9671 - val_loss: 1.9586\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9461 - val_loss: 1.9426\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9412 - val_loss: 1.9424\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9393 - val_loss: 1.9375\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9358 - val_loss: 1.9359\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.9368\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9351 - val_loss: 1.9370\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9333 - val_loss: 1.9331\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9315 - val_loss: 1.9367\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9312 - val_loss: 1.9333\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9301 - val_loss: 1.9331\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9294 - val_loss: 1.9334\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9284 - val_loss: 1.9356\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9295 - val_loss: 1.9347\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9286 - val_loss: 1.9423\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9306 - val_loss: 1.9338\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9280 - val_loss: 1.9331\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9281 - val_loss: 1.9322\n",
      "Top-2 accuracy = 0.486\n",
      "10\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 21ms/step - loss: 2.1482 - val_loss: 2.0780\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0169 - val_loss: 1.9819\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9609 - val_loss: 1.9574\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9441 - val_loss: 1.9478\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9387 - val_loss: 1.9423\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9346 - val_loss: 1.9416\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9324 - val_loss: 1.9417\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9322 - val_loss: 1.9381\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9308 - val_loss: 1.9374\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9299 - val_loss: 1.9404\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9308 - val_loss: 1.9367\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9295 - val_loss: 1.9357\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9276 - val_loss: 1.9384\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9283 - val_loss: 1.9405\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9273 - val_loss: 1.9348\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9277 - val_loss: 1.9337\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9271 - val_loss: 1.9371\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9263 - val_loss: 1.9390\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9265 - val_loss: 1.9372\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9265 - val_loss: 1.9354\n",
      "Top-2 accuracy = 0.485\n",
      "11\n",
      "maxabsf|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6639 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1225 - val_loss: 2.0764\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0526 - val_loss: 2.0269\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0102 - val_loss: 1.9953\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9857 - val_loss: 1.9818\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9756 - val_loss: 1.9758\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9704 - val_loss: 1.9722\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9667 - val_loss: 1.9688\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9631 - val_loss: 1.9658\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9600 - val_loss: 1.9622\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9568 - val_loss: 1.9596\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9540 - val_loss: 1.9565\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9510 - val_loss: 1.9546\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9486 - val_loss: 1.9513\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9463 - val_loss: 1.9491\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9440 - val_loss: 1.9472\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9419 - val_loss: 1.9447\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9401 - val_loss: 1.9428\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9384 - val_loss: 1.9415\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9369 - val_loss: 1.9396\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9352 - val_loss: 1.9382\n",
      "Top-2 accuracy = 0.49\n",
      "12\n",
      "minmaxJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1156 - val_loss: 2.0465\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0148 - val_loss: 1.9943\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9827 - val_loss: 1.9748\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9710 - val_loss: 1.9666\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9629 - val_loss: 1.9613\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9584 - val_loss: 1.9565\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9536 - val_loss: 1.9538\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9511 - val_loss: 1.9533\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9504 - val_loss: 1.9497\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9474 - val_loss: 1.9483\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9457 - val_loss: 1.9494\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9461 - val_loss: 1.9456\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9437 - val_loss: 1.9439\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9425 - val_loss: 1.9443\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9435 - val_loss: 1.9441\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9419 - val_loss: 1.9437\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9414 - val_loss: 1.9446\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9405 - val_loss: 1.9488\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9405 - val_loss: 1.9416\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9386 - val_loss: 1.9408\n",
      "Top-2 accuracy = 0.486\n",
      "13\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1028 - val_loss: 2.0416\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0131 - val_loss: 1.9848\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9692 - val_loss: 1.9566\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9507 - val_loss: 1.9504\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9448 - val_loss: 1.9434\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9399 - val_loss: 1.9439\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9384 - val_loss: 1.9403\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9354 - val_loss: 1.9388\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9336 - val_loss: 1.9380\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9327 - val_loss: 1.9395\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9316 - val_loss: 1.9389\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9306 - val_loss: 1.9347\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9291 - val_loss: 1.9341\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9283 - val_loss: 1.9345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9278 - val_loss: 1.9331\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9264 - val_loss: 1.9324\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9269 - val_loss: 1.9313\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9244 - val_loss: 1.9315\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9244 - val_loss: 1.9310\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9224 - val_loss: 1.9327\n",
      "Top-2 accuracy = 0.491\n",
      "14\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0992 - val_loss: 2.0159\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9787 - val_loss: 1.9605\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9508 - val_loss: 1.9524\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9444 - val_loss: 1.9479\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9395 - val_loss: 1.9417\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9356 - val_loss: 1.9399\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9336 - val_loss: 1.9395\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9321 - val_loss: 1.9395\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9328 - val_loss: 1.9372\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9300 - val_loss: 1.9357\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9289 - val_loss: 1.9357\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9282 - val_loss: 1.9356\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9281 - val_loss: 1.9359\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9279 - val_loss: 1.9348\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9265 - val_loss: 1.9343\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9264 - val_loss: 1.9342\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9250 - val_loss: 1.9335\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9248 - val_loss: 1.9338\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9235 - val_loss: 1.9312\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9229 - val_loss: 1.9304\n",
      "Top-2 accuracy = 0.492\n",
      "15\n",
      "standardizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1676 - val_loss: 2.1346\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1008 - val_loss: 2.0593\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0301 - val_loss: 2.0068\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9865\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9760 - val_loss: 1.9760\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9682 - val_loss: 1.9689\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9632 - val_loss: 1.9645\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9599 - val_loss: 1.9617\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9569 - val_loss: 1.9588\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9547 - val_loss: 1.9570\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9528 - val_loss: 1.9557\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9518 - val_loss: 1.9537\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9501 - val_loss: 1.9526\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9491 - val_loss: 1.9517\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9489 - val_loss: 1.9506\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9474 - val_loss: 1.9500\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9465 - val_loss: 1.9497\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9457 - val_loss: 1.9487\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9451 - val_loss: 1.9473\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9443 - val_loss: 1.9466\n",
      "Top-2 accuracy = 0.482\n",
      "16\n",
      "robustB|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6659 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 2.2483 - val_loss: 2.1194\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0803 - val_loss: 2.0479\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0284 - val_loss: 2.0097\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9976 - val_loss: 1.9870\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9777 - val_loss: 1.9750\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9666 - val_loss: 1.9677\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9590 - val_loss: 1.9630\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9542 - val_loss: 1.9581\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9498 - val_loss: 1.9545\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9461 - val_loss: 1.9521\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9433 - val_loss: 1.9483\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9408 - val_loss: 1.9472\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9373 - val_loss: 1.9435\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9343 - val_loss: 1.9410\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9323 - val_loss: 1.9394\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9306 - val_loss: 1.9386\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9294 - val_loss: 1.9378\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9284 - val_loss: 1.9361\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9270 - val_loss: 1.9367\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9265 - val_loss: 1.9353\n",
      "Top-2 accuracy = 0.489\n",
      "17\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6662 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1322 - val_loss: 2.0835\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0554 - val_loss: 2.0223\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0093 - val_loss: 1.9925\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9859 - val_loss: 1.9791\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9741 - val_loss: 1.9708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9664 - val_loss: 1.9637\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9605 - val_loss: 1.9587\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9561 - val_loss: 1.9549\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9525 - val_loss: 1.9515\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9496 - val_loss: 1.9490\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9468 - val_loss: 1.9464\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9447 - val_loss: 1.9445\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9418 - val_loss: 1.9431\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9401 - val_loss: 1.9414\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9383 - val_loss: 1.9394\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9368 - val_loss: 1.9385\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9353 - val_loss: 1.9373\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9344 - val_loss: 1.9363\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9332 - val_loss: 1.9353\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9322 - val_loss: 1.9346\n",
      "Top-2 accuracy = 0.489\n",
      "18\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1616 - val_loss: 2.1170\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0517 - val_loss: 1.9955\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9626 - val_loss: 1.9523\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9438 - val_loss: 1.9514\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9398 - val_loss: 1.9443\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9443\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9361 - val_loss: 1.9400\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9344 - val_loss: 1.9402\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9347 - val_loss: 1.9385\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9336 - val_loss: 1.9459\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9350 - val_loss: 1.9399\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9322 - val_loss: 1.9380\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9325 - val_loss: 1.9373\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9326 - val_loss: 1.9379\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9323 - val_loss: 1.9384\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9321 - val_loss: 1.9369\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9301 - val_loss: 1.9366\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9299 - val_loss: 1.9408\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9329 - val_loss: 1.9364\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9304 - val_loss: 1.9371\n",
      "Top-2 accuracy = 0.484\n",
      "19\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1520 - val_loss: 2.1000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0623 - val_loss: 2.0112\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9844 - val_loss: 1.9679\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9612 - val_loss: 1.9573\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9549 - val_loss: 1.9520\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9517 - val_loss: 1.9502\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9496 - val_loss: 1.9469\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9469 - val_loss: 1.9450\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9457 - val_loss: 1.9427\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9438 - val_loss: 1.9417\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9431 - val_loss: 1.9414\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9420 - val_loss: 1.9421\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9421 - val_loss: 1.9398\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9408 - val_loss: 1.9387\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9397 - val_loss: 1.9383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9391 - val_loss: 1.9386\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9390 - val_loss: 1.9374\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9384 - val_loss: 1.9397\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9377\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9375 - val_loss: 1.9369\n",
      "Top-2 accuracy = 0.486\n",
      "20\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6674 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1432 - val_loss: 2.0856\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0531 - val_loss: 2.0291\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0177 - val_loss: 2.0079\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0001 - val_loss: 1.9910\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9837 - val_loss: 1.9778\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9740 - val_loss: 1.9707\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9674 - val_loss: 1.9660\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9639 - val_loss: 1.9635\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9604 - val_loss: 1.9612\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9575 - val_loss: 1.9577\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9546 - val_loss: 1.9558\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9522 - val_loss: 1.9542\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9491 - val_loss: 1.9510\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9466 - val_loss: 1.9477\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9445 - val_loss: 1.9466\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9426 - val_loss: 1.9436\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9409 - val_loss: 1.9414\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9394 - val_loss: 1.9401\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9382 - val_loss: 1.9392\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9379 - val_loss: 1.9378\n",
      "Top-2 accuracy = 0.488\n",
      "21\n",
      "normalizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1431 - val_loss: 2.0538\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0065 - val_loss: 1.9846\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9707 - val_loss: 1.9658\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9565 - val_loss: 1.9557\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9492 - val_loss: 1.9496\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9443 - val_loss: 1.9458\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9424 - val_loss: 1.9429\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9393 - val_loss: 1.9411\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9382 - val_loss: 1.9409\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9372 - val_loss: 1.9462\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9369 - val_loss: 1.9426\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9363 - val_loss: 1.9386\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9357 - val_loss: 1.9391\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9354 - val_loss: 1.9378\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9338 - val_loss: 1.9364\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9345 - val_loss: 1.9361\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9337 - val_loss: 1.9357\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9325 - val_loss: 1.9364\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9330 - val_loss: 1.9356\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9336 - val_loss: 1.9384\n",
      "Top-2 accuracy = 0.484\n",
      "22\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1615 - val_loss: 2.1093\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0699 - val_loss: 2.0343\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0092 - val_loss: 1.9908\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9758 - val_loss: 1.9700\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9616 - val_loss: 1.9582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9539 - val_loss: 1.9552\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9500 - val_loss: 1.9514\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9470 - val_loss: 1.9506\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9439 - val_loss: 1.9446\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9420 - val_loss: 1.9424\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9393 - val_loss: 1.9456\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9395 - val_loss: 1.9400\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9364 - val_loss: 1.9395\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9356 - val_loss: 1.9401\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9349 - val_loss: 1.9388\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9336 - val_loss: 1.9392\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9337 - val_loss: 1.9364\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9315 - val_loss: 1.9359\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9313 - val_loss: 1.9361\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9301 - val_loss: 1.9370\n",
      "Top-2 accuracy = 0.488\n",
      "23\n",
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6693 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.2141 - val_loss: 2.1723\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1481 - val_loss: 2.1302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1165 - val_loss: 2.1082\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1008 - val_loss: 2.0963\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0903 - val_loss: 2.0849\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0777 - val_loss: 2.0700\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0623 - val_loss: 2.0534\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0454 - val_loss: 2.0378\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0302 - val_loss: 2.0248\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0176 - val_loss: 2.0136\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0061 - val_loss: 2.0042\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9967 - val_loss: 1.9967\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9891 - val_loss: 1.9899\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9820 - val_loss: 1.9837\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9758 - val_loss: 1.9783\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9713 - val_loss: 1.9741\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9677 - val_loss: 1.9704\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9644 - val_loss: 1.9674\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9615 - val_loss: 1.9651\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9590 - val_loss: 1.9623\n",
      "Top-2 accuracy = 0.48\n",
      "24\n",
      "robustN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1519 - val_loss: 2.1177\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1121 - val_loss: 2.1070\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1048 - val_loss: 2.0961\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0718 - val_loss: 2.0367\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0079 - val_loss: 1.9880\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9757 - val_loss: 1.9710\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9640 - val_loss: 1.9625\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9576 - val_loss: 1.9573\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9533 - val_loss: 1.9534\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9506 - val_loss: 1.9509\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9483 - val_loss: 1.9489\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9465 - val_loss: 1.9474\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9452 - val_loss: 1.9463\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9445 - val_loss: 1.9456\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9429 - val_loss: 1.9446\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9421 - val_loss: 1.9444\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9415 - val_loss: 1.9433\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9412 - val_loss: 1.9425\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9402 - val_loss: 1.9423\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9400 - val_loss: 1.9420\n",
      "Top-2 accuracy = 0.484\n",
      "25\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6700 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.2409 - val_loss: 2.1738\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1417 - val_loss: 2.1078\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0807 - val_loss: 2.0483\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0328 - val_loss: 2.0165\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0094 - val_loss: 2.0004\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9956 - val_loss: 1.9897\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9856 - val_loss: 1.9821\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9781 - val_loss: 1.9760\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9719 - val_loss: 1.9710\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9671 - val_loss: 1.9667\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9632 - val_loss: 1.9646\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9602 - val_loss: 1.9610\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9569 - val_loss: 1.9591\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9546 - val_loss: 1.9566\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9524 - val_loss: 1.9548\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9500 - val_loss: 1.9530\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9481 - val_loss: 1.9518\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9464 - val_loss: 1.9495\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9446 - val_loss: 1.9478\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9431 - val_loss: 1.9465\n",
      "Top-2 accuracy = 0.485\n",
      "26\n",
      "robustX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1032 - val_loss: 2.0103\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9739 - val_loss: 1.9554\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9447 - val_loss: 1.9428\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9389\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9353 - val_loss: 1.9380\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9337 - val_loss: 1.9367\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9321 - val_loss: 1.9361\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9311 - val_loss: 1.9339\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9303 - val_loss: 1.9350\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9317 - val_loss: 1.9384\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9289 - val_loss: 1.9356\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9337\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9284 - val_loss: 1.9334\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9271 - val_loss: 1.9326\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9265 - val_loss: 1.9324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9261 - val_loss: 1.9360\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9252 - val_loss: 1.9318\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9322\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9348\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9259 - val_loss: 1.9314\n",
      "Top-2 accuracy = 0.486\n",
      "27\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1548 - val_loss: 2.1111\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1084 - val_loss: 2.0977\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0493 - val_loss: 1.9919\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9713 - val_loss: 1.9599\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9539 - val_loss: 1.9495\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9471 - val_loss: 1.9448\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9456 - val_loss: 1.9439\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9432 - val_loss: 1.9447\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9428 - val_loss: 1.9407\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9425 - val_loss: 1.9438\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9401 - val_loss: 1.9399\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9400 - val_loss: 1.9405\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9394 - val_loss: 1.9393\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9394 - val_loss: 1.9432\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9387 - val_loss: 1.9395\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9394 - val_loss: 1.9470\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9385 - val_loss: 1.9377\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9382\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9382 - val_loss: 1.9375\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9361 - val_loss: 1.9378\n",
      "Top-2 accuracy = 0.485\n",
      "28\n",
      "minmaxZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1501 - val_loss: 2.0861\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0558 - val_loss: 2.0341\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0157 - val_loss: 2.0022\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9872\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9807 - val_loss: 1.9786\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9755 - val_loss: 1.9750\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9724 - val_loss: 1.9718\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9720 - val_loss: 1.9690\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9647 - val_loss: 1.9609\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9582 - val_loss: 1.9564\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9546 - val_loss: 1.9567\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9525 - val_loss: 1.9516\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9516 - val_loss: 1.9502\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9483 - val_loss: 1.9534\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9496 - val_loss: 1.9487\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9473 - val_loss: 1.9472\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9461 - val_loss: 1.9456\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9457 - val_loss: 1.9449\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9451 - val_loss: 1.9453\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9451 - val_loss: 1.9436\n",
      "Top-2 accuracy = 0.481\n",
      "29\n",
      "robustj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.0921 - val_loss: 1.9935\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9606 - val_loss: 1.9480\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9403 - val_loss: 1.9511\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9372 - val_loss: 1.9435\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9359 - val_loss: 1.9390\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9351 - val_loss: 1.9393\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9329 - val_loss: 1.9350\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9306 - val_loss: 1.9354\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9330 - val_loss: 1.9481\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9321 - val_loss: 1.9347\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9295 - val_loss: 1.9362\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9291 - val_loss: 1.9333\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9279 - val_loss: 1.9383\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9297 - val_loss: 1.9335\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9286 - val_loss: 1.9338\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9288 - val_loss: 1.9384\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9270 - val_loss: 1.9383\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9289 - val_loss: 1.9337\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9269 - val_loss: 1.9343\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9263 - val_loss: 1.9322\n",
      "Top-2 accuracy = 0.486\n",
      "0\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1345 - val_loss: 2.0672\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0174 - val_loss: 1.9794\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9624 - val_loss: 1.9563\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9492 - val_loss: 1.9483\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9435 - val_loss: 1.9442\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9402 - val_loss: 1.9422\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9407\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9368 - val_loss: 1.9389\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9355 - val_loss: 1.9377\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9340 - val_loss: 1.9379\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9331 - val_loss: 1.9373\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9321 - val_loss: 1.9362\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9320 - val_loss: 1.9357\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9312 - val_loss: 1.9345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9300 - val_loss: 1.9338\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9312 - val_loss: 1.9346\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9288 - val_loss: 1.9378\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9290 - val_loss: 1.9338\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9296 - val_loss: 1.9342\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9281 - val_loss: 1.9330\n",
      "Top-2 accuracy = 0.488\n",
      "1\n",
      "maxabsv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1315 - val_loss: 2.0500\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0162 - val_loss: 1.9945\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9806 - val_loss: 1.9691\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9600 - val_loss: 1.9547\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9501 - val_loss: 1.9495\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9464 - val_loss: 1.9446\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9420 - val_loss: 1.9411\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9399 - val_loss: 1.9392\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9377 - val_loss: 1.9391\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9374 - val_loss: 1.9384\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9356 - val_loss: 1.9501\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9356 - val_loss: 1.9437\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9338 - val_loss: 1.9358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9330 - val_loss: 1.9360\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9314 - val_loss: 1.9357\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9310 - val_loss: 1.9366\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9312 - val_loss: 1.9340\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9315 - val_loss: 1.9405\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9319 - val_loss: 1.9348\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9294 - val_loss: 1.9340\n",
      "Top-2 accuracy = 0.484\n",
      "2\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1598 - val_loss: 2.0977\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0736 - val_loss: 2.0548\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0386 - val_loss: 2.0146\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9935 - val_loss: 1.9741\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9651 - val_loss: 1.9618\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9544 - val_loss: 1.9541\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9481 - val_loss: 1.9491\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9431 - val_loss: 1.9463\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9410 - val_loss: 1.9425\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9382 - val_loss: 1.9422\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9386 - val_loss: 1.9396\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9398\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9353 - val_loss: 1.9382\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9350 - val_loss: 1.9398\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9345 - val_loss: 1.9365\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9334 - val_loss: 1.9356\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9323 - val_loss: 1.9354\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9326 - val_loss: 1.9361\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9327 - val_loss: 1.9368\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9315 - val_loss: 1.9354\n",
      "Top-2 accuracy = 0.486\n",
      "3\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1522 - val_loss: 2.0887\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0312 - val_loss: 1.9941\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9766 - val_loss: 1.9662\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9547 - val_loss: 1.9548\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9455 - val_loss: 1.9470\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9412 - val_loss: 1.9434\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9386 - val_loss: 1.9416\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9389\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9343 - val_loss: 1.9383\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9334 - val_loss: 1.9373\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9324 - val_loss: 1.9354\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9311 - val_loss: 1.9360\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9306 - val_loss: 1.9352\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9305 - val_loss: 1.9347\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9295 - val_loss: 1.9336\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9295 - val_loss: 1.9348\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9292 - val_loss: 1.9360\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9343\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9290 - val_loss: 1.9355\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9293 - val_loss: 1.9329\n",
      "Top-2 accuracy = 0.486\n",
      "4\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1703 - val_loss: 2.1380\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1164 - val_loss: 2.1021\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0926 - val_loss: 2.0840\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0702 - val_loss: 2.0514\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0116 - val_loss: 1.9820\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9696 - val_loss: 1.9624\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9552 - val_loss: 1.9540\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9493 - val_loss: 1.9494\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9457 - val_loss: 1.9482\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9442 - val_loss: 1.9460\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9432 - val_loss: 1.9454\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9417 - val_loss: 1.9445\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9408 - val_loss: 1.9446\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9396 - val_loss: 1.9433\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9386 - val_loss: 1.9425\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9432\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9376 - val_loss: 1.9412\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9371 - val_loss: 1.9414\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9374 - val_loss: 1.9426\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9364 - val_loss: 1.9405\n",
      "Top-2 accuracy = 0.486\n",
      "5\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1600 - val_loss: 2.0951\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0400 - val_loss: 1.9901\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9593 - val_loss: 1.9491\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9382 - val_loss: 1.9378\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9356 - val_loss: 1.9370\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9334 - val_loss: 1.9446\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9352 - val_loss: 1.9356\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9321 - val_loss: 1.9347\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9316 - val_loss: 1.9346\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9319 - val_loss: 1.9374\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9333 - val_loss: 1.9344\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9301 - val_loss: 1.9373\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9315 - val_loss: 1.9332\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9304 - val_loss: 1.9389\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9308 - val_loss: 1.9324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9290 - val_loss: 1.9405\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9338 - val_loss: 1.9349\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9292 - val_loss: 1.9327\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9302 - val_loss: 1.9339\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9296 - val_loss: 1.9320\n",
      "Top-2 accuracy = 0.487\n",
      "6\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1187 - val_loss: 2.0330\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9793 - val_loss: 1.9632\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9507 - val_loss: 1.9489\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9432 - val_loss: 1.9423\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9423 - val_loss: 1.9454\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9415 - val_loss: 1.9412\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9383 - val_loss: 1.9392\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9374 - val_loss: 1.9409\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9354 - val_loss: 1.9496\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9388 - val_loss: 1.9357\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9351 - val_loss: 1.9628\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9371 - val_loss: 1.9340\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9343 - val_loss: 1.9368\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9340 - val_loss: 1.9369\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9335 - val_loss: 1.9347\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9333 - val_loss: 1.9337\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9327 - val_loss: 1.9407\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9332 - val_loss: 1.9352\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9317 - val_loss: 1.9335\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9329 - val_loss: 1.9340\n",
      "Top-2 accuracy = 0.484\n",
      "7\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1375 - val_loss: 2.1082\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1102 - val_loss: 2.1075\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1077\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1099 - val_loss: 2.1077\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1102 - val_loss: 2.1073\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1104 - val_loss: 2.1075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1101 - val_loss: 2.1073\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1099 - val_loss: 2.1073\n",
      "Top-2 accuracy = 0.384\n",
      "8\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1482 - val_loss: 2.0832\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0261 - val_loss: 1.9824\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9664 - val_loss: 1.9585\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9511 - val_loss: 1.9489\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9444 - val_loss: 1.9470\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9416 - val_loss: 1.9426\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9392 - val_loss: 1.9435\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9375 - val_loss: 1.9402\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9363 - val_loss: 1.9382\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9350 - val_loss: 1.9382\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9340 - val_loss: 1.9369\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9331 - val_loss: 1.9365\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9318 - val_loss: 1.9362\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9316 - val_loss: 1.9345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9305 - val_loss: 1.9347\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9301 - val_loss: 1.9332\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9299 - val_loss: 1.9331\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9292 - val_loss: 1.9339\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9291 - val_loss: 1.9320\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9285 - val_loss: 1.9336\n",
      "Top-2 accuracy = 0.491\n",
      "9\n",
      "robustw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1089 - val_loss: 2.0048\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9887 - val_loss: 1.9844\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9729 - val_loss: 1.9702\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9636 - val_loss: 1.9693\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9558 - val_loss: 1.9555\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9539 - val_loss: 1.9538\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9497 - val_loss: 1.9525\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9457 - val_loss: 1.9486\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9437 - val_loss: 1.9497\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9414 - val_loss: 1.9451\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9413 - val_loss: 1.9488\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9429 - val_loss: 1.9439\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9375 - val_loss: 1.9449\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9386 - val_loss: 1.9406\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9367 - val_loss: 1.9395\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9370 - val_loss: 1.9398\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9339 - val_loss: 1.9433\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9340 - val_loss: 1.9379\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9313 - val_loss: 1.9406\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9310 - val_loss: 1.9416\n",
      "Top-2 accuracy = 0.477\n",
      "10\n",
      "normalizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1321 - val_loss: 2.0348\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9894 - val_loss: 1.9622\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9535 - val_loss: 1.9505\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9421 - val_loss: 1.9416\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9373 - val_loss: 1.9390\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9353 - val_loss: 1.9398\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9336 - val_loss: 1.9368\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9327 - val_loss: 1.9441\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9336 - val_loss: 1.9365\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9301 - val_loss: 1.9343\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9316 - val_loss: 1.9342\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9304 - val_loss: 1.9346\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9300 - val_loss: 1.9386\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9341 - val_loss: 1.9337\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9292 - val_loss: 1.9344\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9294 - val_loss: 1.9381\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9287 - val_loss: 1.9325\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9283 - val_loss: 1.9349\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9267 - val_loss: 1.9317\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9275 - val_loss: 1.9343\n",
      "Top-2 accuracy = 0.487\n",
      "11\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1666 - val_loss: 2.1203\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0699 - val_loss: 2.0266\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0044 - val_loss: 1.9885\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9789 - val_loss: 1.9736\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9663 - val_loss: 1.9662\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9604 - val_loss: 1.9649\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9619 - val_loss: 1.9665\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9567 - val_loss: 1.9586\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9556 - val_loss: 1.9553\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9544 - val_loss: 1.9555\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9543 - val_loss: 1.9579\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9529 - val_loss: 1.9535\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9526 - val_loss: 1.9534\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9522 - val_loss: 1.9534\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9529 - val_loss: 1.9522\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9503 - val_loss: 1.9512\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9498 - val_loss: 1.9504\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9495 - val_loss: 1.9552\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9496 - val_loss: 1.9511\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9488 - val_loss: 1.9503\n",
      "Top-2 accuracy = 0.483\n",
      "12\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1554 - val_loss: 2.1180\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1029 - val_loss: 2.0848\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0647 - val_loss: 2.0382\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0176 - val_loss: 1.9968\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9871 - val_loss: 1.9758\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9697 - val_loss: 1.9661\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9596 - val_loss: 1.9580\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9543 - val_loss: 1.9530\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9493 - val_loss: 1.9521\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9466 - val_loss: 1.9488\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9447 - val_loss: 1.9476\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9435 - val_loss: 1.9455\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9418 - val_loss: 1.9446\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9407 - val_loss: 1.9449\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9398 - val_loss: 1.9460\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9403 - val_loss: 1.9481\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9405 - val_loss: 1.9419\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9380 - val_loss: 1.9443\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9380 - val_loss: 1.9423\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9374 - val_loss: 1.9425\n",
      "Top-2 accuracy = 0.483\n",
      "13\n",
      "normalizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1845 - val_loss: 2.1723\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1629 - val_loss: 2.1538\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1470 - val_loss: 2.1400\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1354 - val_loss: 2.1300\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1268 - val_loss: 2.1226\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1210 - val_loss: 2.1177\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1169 - val_loss: 2.1141\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1141 - val_loss: 2.1117\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1123 - val_loss: 2.1101\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1112 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1105 - val_loss: 2.1085\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1101 - val_loss: 2.1081\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1078\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Top-2 accuracy = 0.384\n",
      "14\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6796 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.2691 - val_loss: 2.1875\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1528 - val_loss: 2.1270\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1129 - val_loss: 2.0953\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0808 - val_loss: 2.0615\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0490 - val_loss: 2.0332\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0237 - val_loss: 2.0135\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0065 - val_loss: 2.0023\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9972 - val_loss: 1.9954\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9908 - val_loss: 1.9911\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9867 - val_loss: 1.9873\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9835 - val_loss: 1.9851\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9808 - val_loss: 1.9827\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9787 - val_loss: 1.9812\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9765 - val_loss: 1.9793\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9747 - val_loss: 1.9779\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9731 - val_loss: 1.9766\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9716 - val_loss: 1.9752\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9705 - val_loss: 1.9739\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9691 - val_loss: 1.9731\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9680 - val_loss: 1.9723\n",
      "Top-2 accuracy = 0.471\n",
      "15\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1403 - val_loss: 2.0911\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0621 - val_loss: 2.0157\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9845 - val_loss: 1.9700\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9550 - val_loss: 1.9563\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9423 - val_loss: 1.9537\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9386 - val_loss: 1.9398\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9357 - val_loss: 1.9381\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9342 - val_loss: 1.9358\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9328 - val_loss: 1.9355\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9323 - val_loss: 1.9355\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9323 - val_loss: 1.9370\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9318 - val_loss: 1.9359\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9308 - val_loss: 1.9389\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9308 - val_loss: 1.9335\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9318 - val_loss: 1.9387\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.9338\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9314 - val_loss: 1.9346\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9299 - val_loss: 1.9439\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9304 - val_loss: 1.9422\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9294 - val_loss: 1.9466\n",
      "Top-2 accuracy = 0.477\n",
      "16\n",
      "standardizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1200 - val_loss: 2.0490\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0099 - val_loss: 1.9859\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9708 - val_loss: 1.9664\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9570 - val_loss: 1.9578\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9504 - val_loss: 1.9558\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9442 - val_loss: 1.9512\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9421 - val_loss: 1.9465\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9385 - val_loss: 1.9457\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9380 - val_loss: 1.9458\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9374 - val_loss: 1.9435\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9370 - val_loss: 1.9442\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9343 - val_loss: 1.9419\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9346 - val_loss: 1.9389\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.9390\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9330 - val_loss: 1.9439\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9321 - val_loss: 1.9400\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9313 - val_loss: 1.9430\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9330 - val_loss: 1.9378\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9312 - val_loss: 1.9372\n",
      "Top-2 accuracy = 0.48\n",
      "17\n",
      "minmaxt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1695 - val_loss: 2.1383\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1109 - val_loss: 2.0779\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0479 - val_loss: 2.0170\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0003 - val_loss: 1.9878\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9813 - val_loss: 1.9799\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9724 - val_loss: 1.9699\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9673 - val_loss: 1.9650\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9628 - val_loss: 1.9612\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9602 - val_loss: 1.9591\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9579 - val_loss: 1.9575\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9563 - val_loss: 1.9561\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9547 - val_loss: 1.9546\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9537 - val_loss: 1.9536\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9519 - val_loss: 1.9526\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9519 - val_loss: 1.9517\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9514 - val_loss: 1.9534\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9508 - val_loss: 1.9501\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9495 - val_loss: 1.9510\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9487 - val_loss: 1.9492\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9488 - val_loss: 1.9505\n",
      "Top-2 accuracy = 0.478\n",
      "18\n",
      "maxabsU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1412 - val_loss: 2.1133\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1122 - val_loss: 2.1086\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1101 - val_loss: 2.1075\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1077\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1100 - val_loss: 2.1083\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1082\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1101 - val_loss: 2.1072\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1078\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1100 - val_loss: 2.1076\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1078\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1101 - val_loss: 2.1075\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1079\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Top-2 accuracy = 0.384\n",
      "19\n",
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1070 - val_loss: 2.0032\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9841 - val_loss: 1.9731\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9660 - val_loss: 1.9628\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9545 - val_loss: 1.9586\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9485 - val_loss: 1.9506\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9442 - val_loss: 1.9469\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9425 - val_loss: 1.9463\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9411 - val_loss: 1.9445\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9433\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9371 - val_loss: 1.9450\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9363 - val_loss: 1.9404\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9346 - val_loss: 1.9414\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9332 - val_loss: 1.9397\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9331 - val_loss: 1.9387\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9326 - val_loss: 1.9397\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9325 - val_loss: 1.9375\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9310 - val_loss: 1.9379\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9359\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9297 - val_loss: 1.9361\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9289 - val_loss: 1.9361\n",
      "Top-2 accuracy = 0.484\n",
      "20\n",
      "robustB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1348 - val_loss: 2.1093\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0932 - val_loss: 2.0672\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0298 - val_loss: 1.9968\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9775 - val_loss: 1.9698\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9610 - val_loss: 1.9618\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9545 - val_loss: 1.9570\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9503 - val_loss: 1.9533\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9473 - val_loss: 1.9502\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9452 - val_loss: 1.9483\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9433 - val_loss: 1.9471\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9421 - val_loss: 1.9448\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9406 - val_loss: 1.9435\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9396 - val_loss: 1.9424\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9386 - val_loss: 1.9414\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9379 - val_loss: 1.9410\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9372 - val_loss: 1.9397\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9363 - val_loss: 1.9393\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9360 - val_loss: 1.9388\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9352 - val_loss: 1.9378\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9349 - val_loss: 1.9377\n",
      "Top-2 accuracy = 0.485\n",
      "21\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1694 - val_loss: 2.1316\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0910 - val_loss: 2.0460\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0186 - val_loss: 1.9963\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9873 - val_loss: 1.9785\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9734 - val_loss: 1.9701\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9672 - val_loss: 1.9661\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9632 - val_loss: 1.9631\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9609 - val_loss: 1.9606\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9589 - val_loss: 1.9599\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9576 - val_loss: 1.9575\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9560 - val_loss: 1.9565\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9554 - val_loss: 1.9560\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9549 - val_loss: 1.9550\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9544 - val_loss: 1.9541\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9535 - val_loss: 1.9542\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9530 - val_loss: 1.9533\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9526 - val_loss: 1.9526\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9525 - val_loss: 1.9522\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9521 - val_loss: 1.9522\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9518 - val_loss: 1.9519\n",
      "Top-2 accuracy = 0.483\n",
      "22\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1218 - val_loss: 2.0399\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0048 - val_loss: 1.9843\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9757 - val_loss: 1.9704\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9646 - val_loss: 1.9614\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9578 - val_loss: 1.9559\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9537 - val_loss: 1.9537\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9502 - val_loss: 1.9487\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9463 - val_loss: 1.9455\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9435 - val_loss: 1.9429\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9409 - val_loss: 1.9445\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9401 - val_loss: 1.9413\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9405\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9358 - val_loss: 1.9403\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9340 - val_loss: 1.9414\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9334 - val_loss: 1.9371\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9326 - val_loss: 1.9379\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9319 - val_loss: 1.9353\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9301 - val_loss: 1.9370\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9300 - val_loss: 1.9350\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9292 - val_loss: 1.9338\n",
      "Top-2 accuracy = 0.486\n",
      "23\n",
      "minmaxI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1583 - val_loss: 2.1145\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0502 - val_loss: 2.0013\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9866 - val_loss: 1.9765\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9719 - val_loss: 1.9697\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9663 - val_loss: 1.9656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9633 - val_loss: 1.9636\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9622 - val_loss: 1.9676\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9608 - val_loss: 1.9605\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9590 - val_loss: 1.9599\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9574 - val_loss: 1.9638\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9576 - val_loss: 1.9583\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9558 - val_loss: 1.9576\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9534 - val_loss: 1.9542\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9520 - val_loss: 1.9544\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9515 - val_loss: 1.9523\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9508 - val_loss: 1.9518\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9495 - val_loss: 1.9534\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9508 - val_loss: 1.9495\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9483 - val_loss: 1.9488\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9471 - val_loss: 1.9482\n",
      "Top-2 accuracy = 0.48\n",
      "24\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1383 - val_loss: 2.1087\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1100 - val_loss: 2.1081\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1101 - val_loss: 2.1075\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1103 - val_loss: 2.1074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1073\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1069\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1060 - val_loss: 2.0925\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0642 - val_loss: 2.0286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0029 - val_loss: 1.9846\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9814 - val_loss: 1.9759\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9710 - val_loss: 1.9676\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9673 - val_loss: 1.9655\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9623 - val_loss: 1.9911\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9625 - val_loss: 1.9578\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9570 - val_loss: 1.9570\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9560 - val_loss: 1.9555\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9545 - val_loss: 1.9536\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9491 - val_loss: 1.9620\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9494 - val_loss: 1.9510\n",
      "Top-2 accuracy = 0.476\n",
      "25\n",
      "maxabsV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1564 - val_loss: 2.1338\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1167 - val_loss: 2.0943\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0744 - val_loss: 2.0531\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0394 - val_loss: 2.0226\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0139 - val_loss: 2.0005\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9951 - val_loss: 1.9864\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9857 - val_loss: 1.9795\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9792 - val_loss: 1.9753\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9738 - val_loss: 1.9721\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9706 - val_loss: 1.9753\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9692 - val_loss: 1.9667\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9661 - val_loss: 1.9650\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9648 - val_loss: 1.9710\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9643 - val_loss: 1.9637\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9626 - val_loss: 1.9632\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9609 - val_loss: 1.9618\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9612 - val_loss: 1.9603\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9598 - val_loss: 1.9594\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9580 - val_loss: 1.9587\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9573 - val_loss: 1.9599\n",
      "Top-2 accuracy = 0.479\n",
      "26\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1446 - val_loss: 2.0808\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.0388 - val_loss: 2.0095\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0101 - val_loss: 2.0002\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9815 - val_loss: 1.9599\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9531 - val_loss: 1.9536\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9473 - val_loss: 1.9574\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9470 - val_loss: 1.9486\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9450 - val_loss: 1.9461\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9401 - val_loss: 1.9488\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9399 - val_loss: 1.9498\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9401 - val_loss: 1.9411\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9374 - val_loss: 1.9437\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9371 - val_loss: 1.9395\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9334 - val_loss: 1.9450\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9364 - val_loss: 1.9404\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9331 - val_loss: 1.9402\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9307 - val_loss: 1.9450\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9316 - val_loss: 1.9408\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9299 - val_loss: 1.9442\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9307 - val_loss: 1.9364\n",
      "Top-2 accuracy = 0.484\n",
      "27\n",
      "standardizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1772 - val_loss: 2.1536\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1247 - val_loss: 2.0956\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0781 - val_loss: 2.0631\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0536 - val_loss: 2.0418\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0347 - val_loss: 2.0253\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0197 - val_loss: 2.0120\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0067 - val_loss: 1.9999\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9942 - val_loss: 1.9874\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9841 - val_loss: 1.9797\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9764 - val_loss: 1.9728\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9706 - val_loss: 1.9677\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9658 - val_loss: 1.9637\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9624 - val_loss: 1.9608\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9596 - val_loss: 1.9587\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9576 - val_loss: 1.9573\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9564 - val_loss: 1.9559\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9551 - val_loss: 1.9548\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9541 - val_loss: 1.9542\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9536 - val_loss: 1.9529\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9530 - val_loss: 1.9523\n",
      "Top-2 accuracy = 0.482\n",
      "28\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1846 - val_loss: 2.1725\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1632 - val_loss: 2.1540\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1472 - val_loss: 2.1403\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1356 - val_loss: 2.1301\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1271 - val_loss: 2.1228\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1211 - val_loss: 2.1177\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1170 - val_loss: 2.1142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1142 - val_loss: 2.1119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1126 - val_loss: 2.1104\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1107 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1081\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "29\n",
      "maxabsh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1101 - val_loss: 2.0214\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9927 - val_loss: 1.9721\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9622 - val_loss: 1.9538\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.9501 - val_loss: 1.9489\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9423 - val_loss: 1.9448\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9403 - val_loss: 1.9449\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9374 - val_loss: 1.9445\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9371 - val_loss: 1.9390\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9347 - val_loss: 1.9404\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9345 - val_loss: 1.9376\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9337 - val_loss: 1.9452\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9338 - val_loss: 1.9368\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9324 - val_loss: 1.9363\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9318 - val_loss: 1.9365\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9313 - val_loss: 1.9352\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9312 - val_loss: 1.9356\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9321 - val_loss: 1.9348\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9301 - val_loss: 1.9352\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9320 - val_loss: 1.9370\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9299 - val_loss: 1.9340\n",
      "Top-2 accuracy = 0.485\n",
      "0\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1618 - val_loss: 2.1169\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0735 - val_loss: 2.0166\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9887 - val_loss: 1.9764\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9662 - val_loss: 1.9638\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9580 - val_loss: 1.9585\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9540 - val_loss: 1.9563\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9512 - val_loss: 1.9534\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9491 - val_loss: 1.9552\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9482 - val_loss: 1.9498\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9461 - val_loss: 1.9508\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9457 - val_loss: 1.9487\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9446 - val_loss: 1.9487\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9433 - val_loss: 1.9460\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9431 - val_loss: 1.9449\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9415 - val_loss: 1.9440\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9413 - val_loss: 1.9463\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9410 - val_loss: 1.9430\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9397 - val_loss: 1.9424\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9391 - val_loss: 1.9426\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9387 - val_loss: 1.9416\n",
      "Top-2 accuracy = 0.483\n",
      "1\n",
      "minmaxp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1782 - val_loss: 2.1538\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1231 - val_loss: 2.0901\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0700 - val_loss: 2.0526\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0410 - val_loss: 2.0283\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0164 - val_loss: 2.0036\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9940 - val_loss: 1.9853\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9769 - val_loss: 1.9709\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9650 - val_loss: 1.9680\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9592 - val_loss: 1.9573\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9566 - val_loss: 1.9550\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9551 - val_loss: 1.9531\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9533 - val_loss: 1.9529\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9529 - val_loss: 1.9524\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9524 - val_loss: 1.9513\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9510 - val_loss: 1.9507\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9510 - val_loss: 1.9514\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9504 - val_loss: 1.9522\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9500 - val_loss: 1.9497\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9502 - val_loss: 1.9491\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9500 - val_loss: 1.9493\n",
      "Top-2 accuracy = 0.484\n",
      "2\n",
      "robustF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.0891 - val_loss: 2.0137\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9901 - val_loss: 1.9707\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9584 - val_loss: 1.9529\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9468 - val_loss: 1.9585\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9406 - val_loss: 1.9447\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9366 - val_loss: 1.9460\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9345 - val_loss: 1.9430\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9327 - val_loss: 1.9416\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9322 - val_loss: 1.9408\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9320 - val_loss: 1.9391\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9300 - val_loss: 1.9396\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9312 - val_loss: 1.9385\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9287 - val_loss: 1.9426\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9299 - val_loss: 1.9379\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9291 - val_loss: 1.9393\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9299 - val_loss: 1.9372\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9296 - val_loss: 1.9385\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9285 - val_loss: 1.9355\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9278 - val_loss: 1.9373\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9282 - val_loss: 1.9361\n",
      "Top-2 accuracy = 0.485\n",
      "3\n",
      "standardizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1050 - val_loss: 2.0151\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9760 - val_loss: 1.9596\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9483 - val_loss: 1.9477\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9410 - val_loss: 1.9430\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9362 - val_loss: 1.9418\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9347 - val_loss: 1.9387\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9330 - val_loss: 1.9387\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9319 - val_loss: 1.9365\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9309 - val_loss: 1.9358\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9305 - val_loss: 1.9361\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9296 - val_loss: 1.9352\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9296 - val_loss: 1.9358\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9281 - val_loss: 1.9341\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9279 - val_loss: 1.9339\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9275 - val_loss: 1.9382\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9332\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9266 - val_loss: 1.9337\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9260 - val_loss: 1.9321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9256 - val_loss: 1.9317\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9247 - val_loss: 1.9312\n",
      "Top-2 accuracy = 0.488\n",
      "4\n",
      "minmaxI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1572 - val_loss: 2.1252\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1165 - val_loss: 2.1086\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1073\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1073\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1078\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Top-2 accuracy = 0.384\n",
      "5\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1846 - val_loss: 2.1724\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1629 - val_loss: 2.1537\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1469 - val_loss: 2.1399\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1353 - val_loss: 2.1300\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1268 - val_loss: 2.1227\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1209 - val_loss: 2.1176\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1169 - val_loss: 2.1141\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1142 - val_loss: 2.1118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1124 - val_loss: 2.1103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1081\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "6\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1436 - val_loss: 2.0867\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0469 - val_loss: 2.0164\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0016 - val_loss: 1.9904\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9849 - val_loss: 1.9842\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9780 - val_loss: 1.9767\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9735 - val_loss: 1.9714\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9699 - val_loss: 1.9696\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9677 - val_loss: 1.9676\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9647 - val_loss: 1.9648\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9624 - val_loss: 1.9617\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9606 - val_loss: 1.9617\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9603 - val_loss: 1.9615\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9577 - val_loss: 1.9597\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9574 - val_loss: 1.9559\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9556 - val_loss: 1.9581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9560 - val_loss: 1.9549\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9546 - val_loss: 1.9540\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9543 - val_loss: 1.9552\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9546 - val_loss: 1.9571\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9539 - val_loss: 1.9770\n",
      "Top-2 accuracy = 0.459\n",
      "7\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1337 - val_loss: 2.0672\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0155 - val_loss: 1.9783\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9595 - val_loss: 1.9508\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9420 - val_loss: 1.9448\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9382 - val_loss: 1.9385\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9349 - val_loss: 1.9365\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9328 - val_loss: 1.9385\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9317 - val_loss: 1.9354\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9318 - val_loss: 1.9343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9296 - val_loss: 1.9332\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9299 - val_loss: 1.9327\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9289 - val_loss: 1.9328\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9286 - val_loss: 1.9332\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9289 - val_loss: 1.9326\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9283 - val_loss: 1.9315\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9281 - val_loss: 1.9354\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9271 - val_loss: 1.9327\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9267 - val_loss: 1.9310\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9268 - val_loss: 1.9332\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9267 - val_loss: 1.9362\n",
      "Top-2 accuracy = 0.484\n",
      "8\n",
      "normalizeV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6894 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1477 - val_loss: 2.0969\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0541 - val_loss: 2.0111\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9967 - val_loss: 1.9868\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9808 - val_loss: 1.9772\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9735 - val_loss: 1.9718\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9676 - val_loss: 1.9678\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9630 - val_loss: 1.9631\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9583 - val_loss: 1.9583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9545 - val_loss: 1.9554\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9499 - val_loss: 1.9507\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9466 - val_loss: 1.9477\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9429 - val_loss: 1.9473\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9418 - val_loss: 1.9434\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9391 - val_loss: 1.9409\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9370 - val_loss: 1.9405\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9359 - val_loss: 1.9397\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9350 - val_loss: 1.9375\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9335 - val_loss: 1.9358\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9319 - val_loss: 1.9359\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9306 - val_loss: 1.9348\n",
      "Top-2 accuracy = 0.492\n",
      "9\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1161 - val_loss: 2.0693\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0454 - val_loss: 2.0099\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9980 - val_loss: 1.9869\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9774 - val_loss: 1.9722\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9667 - val_loss: 1.9697\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9630 - val_loss: 1.9642\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9591 - val_loss: 1.9635\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9566 - val_loss: 1.9593\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9550 - val_loss: 1.9584\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9544 - val_loss: 1.9582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9526 - val_loss: 1.9581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9523 - val_loss: 1.9579\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9513 - val_loss: 1.9616\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9514 - val_loss: 1.9541\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9487 - val_loss: 1.9519\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9483 - val_loss: 1.9517\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9463 - val_loss: 1.9493\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9459 - val_loss: 1.9505\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9442 - val_loss: 1.9483\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9430 - val_loss: 1.9475\n",
      "Top-2 accuracy = 0.484\n",
      "10\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1137 - val_loss: 2.0230\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9917 - val_loss: 1.9790\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9671 - val_loss: 1.9649\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9554 - val_loss: 1.9497\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9448 - val_loss: 1.9468\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9429 - val_loss: 1.9522\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9448 - val_loss: 1.9375\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9370 - val_loss: 1.9384\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9353 - val_loss: 1.9353\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.9342\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9342 - val_loss: 1.9383\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9350 - val_loss: 1.9390\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9329 - val_loss: 1.9333\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9332\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9311 - val_loss: 1.9424\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9327 - val_loss: 1.9339\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9303 - val_loss: 1.9319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9306 - val_loss: 1.9328\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9310 - val_loss: 1.9336\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9300 - val_loss: 1.9352\n",
      "Top-2 accuracy = 0.485\n",
      "11\n",
      "minmaxJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1856 - val_loss: 2.1719\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1612 - val_loss: 2.1487\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1367 - val_loss: 2.1232\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1170 - val_loss: 2.1103\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1066\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1053 - val_loss: 2.0952\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0814 - val_loss: 2.0649\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0513 - val_loss: 2.0398\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0273 - val_loss: 2.0169\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0073 - val_loss: 2.0027\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9912\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9832 - val_loss: 1.9795\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9744 - val_loss: 1.9746\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9697 - val_loss: 1.9674\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9640 - val_loss: 1.9645\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9616 - val_loss: 1.9642\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9590 - val_loss: 1.9593\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9576 - val_loss: 1.9577\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9556 - val_loss: 1.9568\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9549 - val_loss: 1.9558\n",
      "Top-2 accuracy = 0.482\n",
      "12\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1090 - val_loss: 2.0217\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9801 - val_loss: 1.9608\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9522 - val_loss: 1.9511\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9448 - val_loss: 1.9484\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9418 - val_loss: 1.9432\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9411\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9370 - val_loss: 1.9395\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9344 - val_loss: 1.9402\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9342 - val_loss: 1.9389\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9326 - val_loss: 1.9378\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9318 - val_loss: 1.9462\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9328 - val_loss: 1.9361\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9296 - val_loss: 1.9342\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9291 - val_loss: 1.9352\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9293 - val_loss: 1.9365\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9286 - val_loss: 1.9353\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9278 - val_loss: 1.9366\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9284 - val_loss: 1.9338\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9265 - val_loss: 1.9393\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9267 - val_loss: 1.9347\n",
      "Top-2 accuracy = 0.486\n",
      "13\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1364 - val_loss: 2.1081\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1067 - val_loss: 2.0908\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0546 - val_loss: 2.0110\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9861 - val_loss: 1.9766\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9668 - val_loss: 1.9627\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9559 - val_loss: 1.9556\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9537 - val_loss: 1.9546\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9503 - val_loss: 1.9512\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9482 - val_loss: 1.9504\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9478 - val_loss: 1.9481\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9456 - val_loss: 1.9489\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9436 - val_loss: 1.9464\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9431 - val_loss: 1.9446\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9433 - val_loss: 1.9440\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9409 - val_loss: 1.9495\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9409 - val_loss: 1.9444\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9395 - val_loss: 1.9409\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9387 - val_loss: 1.9475\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9372 - val_loss: 1.9375\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9369 - val_loss: 1.9406\n",
      "Top-2 accuracy = 0.485\n",
      "14\n",
      "normalizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1032 - val_loss: 2.0213\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9857 - val_loss: 1.9657\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9518 - val_loss: 1.9486\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9398 - val_loss: 1.9431\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9352 - val_loss: 1.9379\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9336 - val_loss: 1.9374\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9307 - val_loss: 1.9392\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9306 - val_loss: 1.9341\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9292 - val_loss: 1.9333\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9283 - val_loss: 1.9378\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9271 - val_loss: 1.9351\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9270 - val_loss: 1.9331\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9269 - val_loss: 1.9335\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9272 - val_loss: 1.9326\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9260 - val_loss: 1.9333\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9252 - val_loss: 1.9346\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9249 - val_loss: 1.9316\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9247 - val_loss: 1.9320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9242 - val_loss: 1.9342\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9246 - val_loss: 1.9319\n",
      "Top-2 accuracy = 0.487\n",
      "15\n",
      "standardizeq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.0896 - val_loss: 1.9929\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9620 - val_loss: 1.9536\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9416 - val_loss: 1.9446\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9358 - val_loss: 1.9423\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9329 - val_loss: 1.9471\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9330 - val_loss: 1.9408\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9299 - val_loss: 1.9376\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9292 - val_loss: 1.9377\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9293 - val_loss: 1.9346\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9278 - val_loss: 1.9351\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9275 - val_loss: 1.9390\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9272 - val_loss: 1.9357\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9267 - val_loss: 1.9339\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9275 - val_loss: 1.9352\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9267 - val_loss: 1.9356\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9263 - val_loss: 1.9334\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9265 - val_loss: 1.9385\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9260 - val_loss: 1.9356\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9250 - val_loss: 1.9390\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9249 - val_loss: 1.9362\n",
      "Top-2 accuracy = 0.485\n",
      "16\n",
      "robustq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1113 - val_loss: 2.0268\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9711 - val_loss: 1.9477\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9399 - val_loss: 1.9444\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9369 - val_loss: 1.9473\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9394 - val_loss: 1.9444\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9394 - val_loss: 1.9436\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9342 - val_loss: 1.9455\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9369 - val_loss: 1.9423\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9336 - val_loss: 1.9437\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9321 - val_loss: 1.9480\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9345 - val_loss: 1.9396\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9317 - val_loss: 1.9502\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9312 - val_loss: 1.9399\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9298 - val_loss: 1.9461\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9329 - val_loss: 1.9398\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9295 - val_loss: 1.9406\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9309 - val_loss: 1.9443\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9341 - val_loss: 1.9438\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9312 - val_loss: 1.9395\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9282 - val_loss: 1.9453\n",
      "Top-2 accuracy = 0.484\n",
      "17\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1856 - val_loss: 2.1726\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1633 - val_loss: 2.1541\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1474 - val_loss: 2.1404\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1356 - val_loss: 2.1302\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1271 - val_loss: 2.1228\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1211 - val_loss: 2.1178\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1170 - val_loss: 2.1142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1143 - val_loss: 2.1119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1125 - val_loss: 2.1103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1114 - val_loss: 2.1093\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "18\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1690 - val_loss: 2.1196\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0717 - val_loss: 2.0297\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0026 - val_loss: 1.9877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9740 - val_loss: 1.9731\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9657 - val_loss: 1.9648\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9607 - val_loss: 1.9600\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9572 - val_loss: 1.9570\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9528 - val_loss: 1.9564\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9505 - val_loss: 1.9573\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9489 - val_loss: 1.9512\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9469 - val_loss: 1.9500\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9452 - val_loss: 1.9496\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9461 - val_loss: 1.9464\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9429 - val_loss: 1.9471\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9436 - val_loss: 1.9446\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9421 - val_loss: 1.9465\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9422 - val_loss: 1.9642\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9463 - val_loss: 1.9447\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9417 - val_loss: 1.9431\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9401 - val_loss: 1.9425\n",
      "Top-2 accuracy = 0.484\n",
      "19\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1290 - val_loss: 2.0162\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9753 - val_loss: 1.9581\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9452 - val_loss: 1.9450\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.9410\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9324 - val_loss: 1.9418\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9314 - val_loss: 1.9395\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9307 - val_loss: 1.9369\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9285 - val_loss: 1.9369\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9285 - val_loss: 1.9371\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9274 - val_loss: 1.9353\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9285 - val_loss: 1.9338\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9269 - val_loss: 1.9340\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9260 - val_loss: 1.9353\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9266 - val_loss: 1.9337\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9277 - val_loss: 1.9364\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9269 - val_loss: 1.9341\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9251 - val_loss: 1.9348\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9345\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9253 - val_loss: 1.9359\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9261 - val_loss: 1.9326\n",
      "Top-2 accuracy = 0.485\n",
      "20\n",
      "robustB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1516 - val_loss: 2.1033\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0860 - val_loss: 2.0495\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0340 - val_loss: 2.0176\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0042 - val_loss: 1.9895\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9824 - val_loss: 1.9710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9688 - val_loss: 1.9669\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9627 - val_loss: 1.9605\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9568 - val_loss: 1.9563\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9549 - val_loss: 1.9565\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9519 - val_loss: 1.9544\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9494 - val_loss: 1.9594\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9486 - val_loss: 1.9535\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9462 - val_loss: 1.9510\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9438 - val_loss: 1.9489\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9434 - val_loss: 1.9539\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9415 - val_loss: 1.9483\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9405 - val_loss: 1.9475\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9384 - val_loss: 1.9450\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9394 - val_loss: 1.9434\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9365 - val_loss: 1.9448\n",
      "Top-2 accuracy = 0.48\n",
      "21\n",
      "robustm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1058 - val_loss: 2.0227\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9847 - val_loss: 1.9705\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9588 - val_loss: 1.9547\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9487 - val_loss: 1.9535\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9442 - val_loss: 1.9498\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9422 - val_loss: 1.9458\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9396 - val_loss: 1.9440\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9423\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9429\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9363 - val_loss: 1.9404\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9367 - val_loss: 1.9418\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9355 - val_loss: 1.9413\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9351 - val_loss: 1.9444\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9360 - val_loss: 1.9376\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9352 - val_loss: 1.9379\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9341 - val_loss: 1.9393\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9338 - val_loss: 1.9390\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9336 - val_loss: 1.9376\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9331 - val_loss: 1.9367\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9333 - val_loss: 1.9393\n",
      "Top-2 accuracy = 0.485\n",
      "22\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1630 - val_loss: 2.1135\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0711 - val_loss: 2.0287\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0034 - val_loss: 1.9911\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9793 - val_loss: 1.9757\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9655 - val_loss: 1.9678\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9579 - val_loss: 1.9590\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9518 - val_loss: 1.9578\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9477 - val_loss: 1.9532\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9447 - val_loss: 1.9494\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9422 - val_loss: 1.9453\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9413 - val_loss: 1.9435\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9427\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9384 - val_loss: 1.9414\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9400\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9366 - val_loss: 1.9396\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9367 - val_loss: 1.9393\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9357 - val_loss: 1.9407\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9367 - val_loss: 1.9397\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9348 - val_loss: 1.9395\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9347 - val_loss: 1.9380\n",
      "Top-2 accuracy = 0.484\n",
      "23\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1814 - val_loss: 2.1602\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1454 - val_loss: 2.1337\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1255 - val_loss: 2.1199\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1167 - val_loss: 2.1134\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1127 - val_loss: 2.1104\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1110 - val_loss: 2.1090\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1103 - val_loss: 2.1083\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "24\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1549 - val_loss: 2.1159\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1119 - val_loss: 2.1075\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1073\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "25\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1799 - val_loss: 2.1596\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1402 - val_loss: 2.1210\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1073 - val_loss: 2.0895\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0701 - val_loss: 2.0469\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0225 - val_loss: 2.0038\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9783 - val_loss: 1.9684\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9556 - val_loss: 1.9524\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9477 - val_loss: 1.9478\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9442 - val_loss: 1.9454\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9444 - val_loss: 1.9468\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9422 - val_loss: 1.9482\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9420 - val_loss: 1.9460\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9405 - val_loss: 1.9441\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9401 - val_loss: 1.9426\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9408 - val_loss: 1.9429\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9402 - val_loss: 1.9427\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9392 - val_loss: 1.9422\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9393 - val_loss: 1.9417\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9381 - val_loss: 1.9407\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9455\n",
      "Top-2 accuracy = 0.48\n",
      "26\n",
      "minmaxG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1298 - val_loss: 2.0673\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0274 - val_loss: 1.9892\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9672 - val_loss: 1.9580\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9481 - val_loss: 1.9510\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9430 - val_loss: 1.9426\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9424 - val_loss: 1.9526\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9414 - val_loss: 1.9426\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9402 - val_loss: 1.9394\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9379 - val_loss: 1.9390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9370 - val_loss: 1.9387\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9364 - val_loss: 1.9436\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9386 - val_loss: 1.9606\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9384 - val_loss: 1.9360\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9352 - val_loss: 1.9368\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9342 - val_loss: 1.9387\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9340 - val_loss: 1.9370\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9337 - val_loss: 1.9353\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9327 - val_loss: 1.9388\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9350 - val_loss: 1.9352\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9330 - val_loss: 1.9349\n",
      "Top-2 accuracy = 0.484\n",
      "27\n",
      "normalizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1356 - val_loss: 2.1074\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1066\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0880 - val_loss: 2.0470\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0062 - val_loss: 1.9777\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9668 - val_loss: 1.9570\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9549 - val_loss: 1.9506\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9509 - val_loss: 1.9466\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9467 - val_loss: 1.9456\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9472 - val_loss: 1.9430\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9448 - val_loss: 1.9461\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9437 - val_loss: 1.9459\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9450 - val_loss: 1.9421\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9415 - val_loss: 1.9410\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9413 - val_loss: 1.9410\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9421 - val_loss: 1.9432\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9405 - val_loss: 1.9419\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9403 - val_loss: 1.9402\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9403 - val_loss: 1.9406\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9426\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9408 - val_loss: 1.9385\n",
      "Top-2 accuracy = 0.485\n",
      "28\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1298 - val_loss: 2.0905\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0379 - val_loss: 1.9827\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9601 - val_loss: 1.9807\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9468 - val_loss: 1.9456\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9413 - val_loss: 1.9554\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9409 - val_loss: 1.9410\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9377 - val_loss: 1.9445\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9369 - val_loss: 1.9425\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9360 - val_loss: 1.9413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9374 - val_loss: 1.9423\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9350 - val_loss: 1.9395\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9335 - val_loss: 1.9409\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9358 - val_loss: 1.9382\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9328 - val_loss: 1.9380\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9325 - val_loss: 1.9376\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9325 - val_loss: 1.9392\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9322 - val_loss: 1.9394\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9331 - val_loss: 1.9393\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9335 - val_loss: 1.9485\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9323 - val_loss: 1.9405\n",
      "Top-2 accuracy = 0.486\n",
      "29\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1581 - val_loss: 2.1064\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0761 - val_loss: 2.0475\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0092 - val_loss: 1.9879\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9764 - val_loss: 1.9695\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9629 - val_loss: 1.9627\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9545 - val_loss: 1.9564\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9477 - val_loss: 1.9481\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9426 - val_loss: 1.9491\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9402 - val_loss: 1.9434\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9463\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9380 - val_loss: 1.9581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9404 - val_loss: 1.9395\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9363 - val_loss: 1.9386\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9346 - val_loss: 1.9448\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9345 - val_loss: 1.9407\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9337 - val_loss: 1.9390\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9347 - val_loss: 1.9363\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9343 - val_loss: 1.9370\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9325 - val_loss: 1.9369\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9320 - val_loss: 1.9372\n",
      "Top-2 accuracy = 0.483\n",
      "0\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_7006 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1335 - val_loss: 2.0989\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0769 - val_loss: 2.0478\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0305 - val_loss: 2.0100\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9990 - val_loss: 1.9876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9799 - val_loss: 1.9760\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9699 - val_loss: 1.9686\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9630 - val_loss: 1.9630\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9576 - val_loss: 1.9584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9534 - val_loss: 1.9547\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9499 - val_loss: 1.9517\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9472 - val_loss: 1.9492\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9451 - val_loss: 1.9475\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9435 - val_loss: 1.9453\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9415 - val_loss: 1.9446\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9401 - val_loss: 1.9439\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9388 - val_loss: 1.9422\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9379 - val_loss: 1.9414\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9368 - val_loss: 1.9407\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9358 - val_loss: 1.9402\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9349 - val_loss: 1.9389\n",
      "Top-2 accuracy = 0.488\n",
      "1\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1546 - val_loss: 2.1044\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0560 - val_loss: 2.0158\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9921 - val_loss: 1.9758\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9677 - val_loss: 1.9606\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9553 - val_loss: 1.9524\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9487 - val_loss: 1.9487\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9451 - val_loss: 1.9460\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9427 - val_loss: 1.9446\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9421 - val_loss: 1.9438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9423 - val_loss: 1.9432\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9399 - val_loss: 1.9425\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9399 - val_loss: 1.9419\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9386 - val_loss: 1.9402\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9402\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9376 - val_loss: 1.9394\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9395\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9370 - val_loss: 1.9392\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9368 - val_loss: 1.9393\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9368 - val_loss: 1.9395\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9367 - val_loss: 1.9387\n",
      "Top-2 accuracy = 0.483\n",
      "2\n",
      "normalizeG|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_7014 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1846 - val_loss: 2.1725\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1633 - val_loss: 2.1540\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1473 - val_loss: 2.1402\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1356 - val_loss: 2.1301\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1270 - val_loss: 2.1229\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1211 - val_loss: 2.1177\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1169 - val_loss: 2.1141\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1142 - val_loss: 2.1118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1124 - val_loss: 2.1102\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1101 - val_loss: 2.1081\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "3\n",
      "standardizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1824 - val_loss: 2.1656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1442 - val_loss: 2.1202\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0964 - val_loss: 2.0766\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0636 - val_loss: 2.0525\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0441 - val_loss: 2.0362\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0303 - val_loss: 2.0244\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0191 - val_loss: 2.0144\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0097 - val_loss: 2.0060\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0019 - val_loss: 1.9989\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9952 - val_loss: 1.9932\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9882\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9854 - val_loss: 1.9843\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9816 - val_loss: 1.9812\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9785 - val_loss: 1.9785\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9758 - val_loss: 1.9766\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9737 - val_loss: 1.9752\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9721 - val_loss: 1.9728\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9702 - val_loss: 1.9716\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9688 - val_loss: 1.9706\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9676 - val_loss: 1.9693\n",
      "Top-2 accuracy = 0.482\n",
      "4\n",
      "minmaxG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1367 - val_loss: 2.0499\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0096 - val_loss: 1.9804\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9655 - val_loss: 1.9610\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9546 - val_loss: 1.9510\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9480 - val_loss: 1.9476\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9448 - val_loss: 1.9471\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9431 - val_loss: 1.9466\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9413 - val_loss: 1.9532\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9418 - val_loss: 1.9413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9387 - val_loss: 1.9414\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9380\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9376 - val_loss: 1.9383\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9381\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9361 - val_loss: 1.9362\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9358 - val_loss: 1.9366\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9358 - val_loss: 1.9449\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9360 - val_loss: 1.9356\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9359 - val_loss: 1.9436\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9352 - val_loss: 1.9371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9347 - val_loss: 1.9350\n",
      "Top-2 accuracy = 0.484\n",
      "5\n",
      "minmaxK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1731 - val_loss: 2.1463\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1284 - val_loss: 2.1139\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1126 - val_loss: 2.1084\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1101 - val_loss: 2.1076\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "6\n",
      "normalized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1769 - val_loss: 2.1532\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1347 - val_loss: 2.1170\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1019 - val_loss: 2.0832\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0715 - val_loss: 2.0575\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0457 - val_loss: 2.0394\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0276 - val_loss: 2.0208\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0110 - val_loss: 2.0046\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9969 - val_loss: 2.0124\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9959 - val_loss: 1.9857\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9810 - val_loss: 1.9767\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9746 - val_loss: 1.9712\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9694 - val_loss: 1.9745\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9672 - val_loss: 1.9740\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9634 - val_loss: 1.9614\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9609 - val_loss: 1.9625\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9649 - val_loss: 1.9650\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9577 - val_loss: 1.9606\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9584 - val_loss: 1.9690\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9575 - val_loss: 1.9682\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9585 - val_loss: 1.9561\n",
      "Top-2 accuracy = 0.481\n",
      "7\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1616 - val_loss: 2.1235\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1119 - val_loss: 2.0972\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0842 - val_loss: 2.0675\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0449 - val_loss: 2.0243\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0057 - val_loss: 1.9946\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9823 - val_loss: 1.9777\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9682 - val_loss: 1.9681\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9577 - val_loss: 1.9621\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9516 - val_loss: 1.9567\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9485 - val_loss: 1.9537\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9457 - val_loss: 1.9520\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9436 - val_loss: 1.9493\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9425 - val_loss: 1.9484\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9429 - val_loss: 1.9464\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9410 - val_loss: 1.9454\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9404 - val_loss: 1.9449\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9391 - val_loss: 1.9437\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9387 - val_loss: 1.9439\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9382 - val_loss: 1.9454\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9386 - val_loss: 1.9443\n",
      "Top-2 accuracy = 0.479\n",
      "8\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_7043 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1847 - val_loss: 2.1724\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1632 - val_loss: 2.1540\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1472 - val_loss: 2.1402\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1355 - val_loss: 2.1301\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1271 - val_loss: 2.1229\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1211 - val_loss: 2.1177\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1170 - val_loss: 2.1142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1142 - val_loss: 2.1118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1124 - val_loss: 2.1103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1107 - val_loss: 2.1087\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1103 - val_loss: 2.1083\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1100 - val_loss: 2.1080\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "9\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1083 - val_loss: 2.0233\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9874 - val_loss: 1.9712\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9551 - val_loss: 1.9536\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9456 - val_loss: 1.9615\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9415 - val_loss: 1.9478\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9417 - val_loss: 1.9418\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9365 - val_loss: 1.9396\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9349 - val_loss: 1.9396\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9338 - val_loss: 1.9390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9326 - val_loss: 1.9415\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.9508\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9327 - val_loss: 1.9360\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9311 - val_loss: 1.9493\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9357 - val_loss: 1.9368\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9295 - val_loss: 1.9343\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9306 - val_loss: 1.9427\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9300 - val_loss: 1.9384\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9304 - val_loss: 1.9355\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9317 - val_loss: 1.9347\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9298 - val_loss: 1.9345\n",
      "Top-2 accuracy = 0.486\n",
      "10\n",
      "minmaxn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1584 - val_loss: 2.1109\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0658 - val_loss: 2.0181\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9886 - val_loss: 1.9718\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9656 - val_loss: 1.9625\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9583 - val_loss: 1.9567\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9530 - val_loss: 1.9549\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9528 - val_loss: 1.9509\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9520 - val_loss: 1.9526\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9499 - val_loss: 1.9496\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9497 - val_loss: 1.9490\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9483 - val_loss: 1.9541\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9492 - val_loss: 1.9539\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9514 - val_loss: 1.9465\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9469 - val_loss: 1.9502\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9476 - val_loss: 1.9475\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9456 - val_loss: 1.9473\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9466 - val_loss: 1.9506\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9459 - val_loss: 1.9530\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9465 - val_loss: 1.9457\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9462 - val_loss: 1.9482\n",
      "Top-2 accuracy = 0.475\n",
      "11\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1010 - val_loss: 2.0186\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9831 - val_loss: 1.9562\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9445 - val_loss: 1.9436\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9406 - val_loss: 1.9407\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9374 - val_loss: 1.9397\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9359 - val_loss: 1.9378\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9350 - val_loss: 1.9401\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9356 - val_loss: 1.9354\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9345 - val_loss: 1.9348\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9335 - val_loss: 1.9349\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9321 - val_loss: 1.9354\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9324 - val_loss: 1.9352\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9315 - val_loss: 1.9385\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9342\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9305 - val_loss: 1.9358\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9312 - val_loss: 1.9330\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9300 - val_loss: 1.9356\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9316 - val_loss: 1.9346\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9322\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9294 - val_loss: 1.9347\n",
      "Top-2 accuracy = 0.484\n",
      "12\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1560 - val_loss: 2.1293\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1180 - val_loss: 2.1043\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0847 - val_loss: 2.0532\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0250 - val_loss: 2.0017\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9879 - val_loss: 1.9808\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9741 - val_loss: 1.9759\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9667 - val_loss: 1.9669\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9621 - val_loss: 1.9617\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9598 - val_loss: 1.9657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9572 - val_loss: 1.9571\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9550 - val_loss: 1.9560\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9543 - val_loss: 1.9538\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9530 - val_loss: 1.9534\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9520 - val_loss: 1.9547\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9522 - val_loss: 1.9623\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9509 - val_loss: 1.9507\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9507 - val_loss: 1.9511\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9490 - val_loss: 1.9493\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9492 - val_loss: 1.9502\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9481 - val_loss: 1.9494\n",
      "Top-2 accuracy = 0.482\n",
      "13\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1473 - val_loss: 2.1093\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1103 - val_loss: 2.1075\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1073\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1077\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1084\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1102 - val_loss: 2.1080\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1079\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1073\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1077\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1101 - val_loss: 2.1076\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1079\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1078\n",
      "Top-2 accuracy = 0.384\n",
      "14\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1724 - val_loss: 2.1253\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0642 - val_loss: 2.0095\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9791 - val_loss: 1.9676\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9595 - val_loss: 1.9542\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9480 - val_loss: 1.9455\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9436 - val_loss: 1.9438\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9404 - val_loss: 1.9415\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9401 - val_loss: 1.9405\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9382 - val_loss: 1.9397\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9371 - val_loss: 1.9405\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9357 - val_loss: 1.9373\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9360 - val_loss: 1.9385\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9368 - val_loss: 1.9402\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9361 - val_loss: 1.9358\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9344 - val_loss: 1.9360\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9349 - val_loss: 1.9373\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9350 - val_loss: 1.9393\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9365 - val_loss: 1.9379\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9344 - val_loss: 1.9353\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9333 - val_loss: 1.9365\n",
      "Top-2 accuracy = 0.482\n",
      "15\n",
      "normalizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1760 - val_loss: 2.1446\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1182 - val_loss: 2.0983\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0703 - val_loss: 2.0373\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0058 - val_loss: 1.9776\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9593 - val_loss: 1.9547\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9501 - val_loss: 1.9699\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9497 - val_loss: 1.9495\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9467 - val_loss: 1.9500\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9475 - val_loss: 1.9588\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9466 - val_loss: 1.9484\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9462 - val_loss: 1.9478\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9458 - val_loss: 1.9478\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9446 - val_loss: 1.9467\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9440 - val_loss: 1.9484\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9436 - val_loss: 1.9493\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9444 - val_loss: 1.9477\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9428 - val_loss: 1.9471\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9431 - val_loss: 1.9484\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9431 - val_loss: 1.9471\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9441 - val_loss: 1.9466\n",
      "Top-2 accuracy = 0.484\n",
      "16\n",
      "normalizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1537 - val_loss: 2.0900\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0322 - val_loss: 2.0116\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9723 - val_loss: 1.9698\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9561 - val_loss: 1.9596\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9441 - val_loss: 1.9532\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9403 - val_loss: 1.9515\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9365 - val_loss: 1.9459\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9342 - val_loss: 1.9663\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9357 - val_loss: 1.9393\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9323 - val_loss: 1.9485\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9316 - val_loss: 1.9391\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9312 - val_loss: 1.9386\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9312 - val_loss: 1.9379\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9300 - val_loss: 1.9373\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9292 - val_loss: 1.9428\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9291 - val_loss: 1.9433\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9329 - val_loss: 1.9350\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9276 - val_loss: 1.9387\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9295 - val_loss: 1.9373\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9274 - val_loss: 1.9354\n",
      "Top-2 accuracy = 0.487\n",
      "17\n",
      "normalizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1846 - val_loss: 2.1724\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1630 - val_loss: 2.1538\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1472 - val_loss: 2.1402\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1353 - val_loss: 2.1299\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1268 - val_loss: 2.1227\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1209 - val_loss: 2.1176\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1168 - val_loss: 2.1140\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1141 - val_loss: 2.1117\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1125 - val_loss: 2.1103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "18\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1320 - val_loss: 2.0496\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0086 - val_loss: 1.9836\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9735 - val_loss: 1.9699\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9597 - val_loss: 1.9535\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9511 - val_loss: 1.9495\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9468 - val_loss: 1.9494\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9439 - val_loss: 1.9492\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9417 - val_loss: 1.9434\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9385 - val_loss: 1.9413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9365 - val_loss: 1.9401\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9359 - val_loss: 1.9407\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9354 - val_loss: 1.9423\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9344 - val_loss: 1.9382\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9325 - val_loss: 1.9387\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9332 - val_loss: 1.9369\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9310 - val_loss: 1.9365\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9375\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9306 - val_loss: 1.9371\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9305 - val_loss: 1.9378\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9299 - val_loss: 1.9397\n",
      "Top-2 accuracy = 0.485\n",
      "19\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1497 - val_loss: 2.1093\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1101 - val_loss: 2.1076\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1079\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1076\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1083\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Top-2 accuracy = 0.384\n",
      "20\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1092 - val_loss: 2.0316\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0096 - val_loss: 1.9930\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9795 - val_loss: 1.9723\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9635 - val_loss: 1.9542\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9492 - val_loss: 1.9521\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9430 - val_loss: 1.9520\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9449 - val_loss: 1.9480\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9396 - val_loss: 1.9420\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9374 - val_loss: 1.9451\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9368 - val_loss: 1.9417\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9357 - val_loss: 1.9438\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9344 - val_loss: 1.9387\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9342 - val_loss: 1.9445\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9347 - val_loss: 1.9372\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9325 - val_loss: 1.9370\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9318 - val_loss: 1.9411\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9314 - val_loss: 1.9374\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9316 - val_loss: 1.9372\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9315 - val_loss: 1.9370\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9310 - val_loss: 1.9374\n",
      "Top-2 accuracy = 0.484\n",
      "21\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1122 - val_loss: 2.0358\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9926 - val_loss: 1.9628\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9495 - val_loss: 1.9441\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9397 - val_loss: 1.9391\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9344 - val_loss: 1.9361\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9319 - val_loss: 1.9366\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9331 - val_loss: 1.9343\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9305 - val_loss: 1.9333\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9301 - val_loss: 1.9342\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9293 - val_loss: 1.9329\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9285 - val_loss: 1.9347\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9286 - val_loss: 1.9327\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9279 - val_loss: 1.9364\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9285 - val_loss: 1.9322\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9276 - val_loss: 1.9324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9281 - val_loss: 1.9318\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9274 - val_loss: 1.9318\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9271 - val_loss: 1.9320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9272 - val_loss: 1.9324\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9270 - val_loss: 1.9328\n",
      "Top-2 accuracy = 0.486\n",
      "22\n",
      "maxabsf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1455 - val_loss: 2.1131\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1120 - val_loss: 2.1079\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1100 - val_loss: 2.1079\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1080\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1073\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1073\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "23\n",
      "normalizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1338 - val_loss: 2.0319\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9931 - val_loss: 1.9655\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9486 - val_loss: 1.9438\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9389 - val_loss: 1.9453\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9370 - val_loss: 1.9464\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9382 - val_loss: 1.9412\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9349 - val_loss: 1.9399\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9342 - val_loss: 1.9472\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9322 - val_loss: 1.9373\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9315 - val_loss: 1.9379\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9317 - val_loss: 1.9354\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9317 - val_loss: 1.9361\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9355\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9292 - val_loss: 1.9349\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9293 - val_loss: 1.9380\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9296 - val_loss: 1.9363\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9285 - val_loss: 1.9354\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9283 - val_loss: 1.9364\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9286 - val_loss: 1.9373\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9283 - val_loss: 1.9345\n",
      "Top-2 accuracy = 0.485\n",
      "24\n",
      "normalizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1428 - val_loss: 2.0946\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0438 - val_loss: 1.9935\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9734 - val_loss: 1.9626\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9565 - val_loss: 1.9534\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9499 - val_loss: 1.9489\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9463 - val_loss: 1.9463\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9437 - val_loss: 1.9446\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9424 - val_loss: 1.9430\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9409 - val_loss: 1.9422\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9397 - val_loss: 1.9415\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9389 - val_loss: 1.9438\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9391 - val_loss: 1.9411\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9379 - val_loss: 1.9392\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9365 - val_loss: 1.9402\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9359 - val_loss: 1.9379\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9357 - val_loss: 1.9398\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9350 - val_loss: 1.9363\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9348 - val_loss: 1.9366\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9336 - val_loss: 1.9361\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9332 - val_loss: 1.9348\n",
      "Top-2 accuracy = 0.489\n",
      "25\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1459 - val_loss: 2.1166\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0999 - val_loss: 2.0827\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0694 - val_loss: 2.0553\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0425 - val_loss: 2.0305\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0204 - val_loss: 2.0132\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0032 - val_loss: 1.9997\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9911\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9850 - val_loss: 1.9857\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9802 - val_loss: 1.9827\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9769 - val_loss: 1.9795\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9746 - val_loss: 1.9771\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9709 - val_loss: 1.9727\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9661 - val_loss: 1.9677\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9617 - val_loss: 1.9627\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9589 - val_loss: 1.9590\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9557 - val_loss: 1.9572\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9528 - val_loss: 1.9557\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9519 - val_loss: 1.9538\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9499 - val_loss: 1.9526\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9494 - val_loss: 1.9519\n",
      "Top-2 accuracy = 0.482\n",
      "26\n",
      "normalizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1694 - val_loss: 2.1333\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0911 - val_loss: 2.0436\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0113 - val_loss: 1.9878\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9710 - val_loss: 1.9636\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9560 - val_loss: 1.9628\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9514 - val_loss: 1.9524\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9497 - val_loss: 1.9523\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9487 - val_loss: 1.9586\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9490 - val_loss: 1.9498\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9467 - val_loss: 1.9499\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9462 - val_loss: 1.9472\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9448 - val_loss: 1.9471\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9442 - val_loss: 1.9462\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9430 - val_loss: 1.9449\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9414 - val_loss: 1.9504\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9414 - val_loss: 1.9418\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9403 - val_loss: 1.9419\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9395 - val_loss: 1.9459\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9389 - val_loss: 1.9400\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9380 - val_loss: 1.9401\n",
      "Top-2 accuracy = 0.483\n",
      "27\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1525 - val_loss: 2.1141\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0846 - val_loss: 2.0538\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0235 - val_loss: 2.0025\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9892 - val_loss: 1.9786\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9688 - val_loss: 1.9621\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9548 - val_loss: 1.9523\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9475 - val_loss: 1.9495\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9443 - val_loss: 1.9452\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9420 - val_loss: 1.9442\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9412 - val_loss: 1.9464\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9398 - val_loss: 1.9405\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9393 - val_loss: 1.9420\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9378 - val_loss: 1.9401\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9376 - val_loss: 1.9386\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9363 - val_loss: 1.9413\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9382\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9365 - val_loss: 1.9378\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9356 - val_loss: 1.9374\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9354 - val_loss: 1.9412\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9375 - val_loss: 1.9372\n",
      "Top-2 accuracy = 0.484\n",
      "28\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1331 - val_loss: 2.0456\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0079 - val_loss: 1.9854\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9732 - val_loss: 1.9648\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9583 - val_loss: 1.9607\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9512 - val_loss: 1.9525\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9460 - val_loss: 1.9487\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9454 - val_loss: 1.9471\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9418 - val_loss: 1.9443\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9392 - val_loss: 1.9432\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9394 - val_loss: 1.9442\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9395 - val_loss: 1.9427\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9362 - val_loss: 1.9399\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9353 - val_loss: 1.9443\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9369 - val_loss: 1.9386\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9339 - val_loss: 1.9392\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9340 - val_loss: 1.9420\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9354 - val_loss: 1.9382\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9341 - val_loss: 1.9485\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9344 - val_loss: 1.9425\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9326 - val_loss: 1.9484\n",
      "Top-2 accuracy = 0.48\n",
      "29\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1846 - val_loss: 2.1725\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1633 - val_loss: 2.1541\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1472 - val_loss: 2.1401\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1352 - val_loss: 2.1298\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1269 - val_loss: 2.1228\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1211 - val_loss: 2.1178\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1171 - val_loss: 2.1144\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1143 - val_loss: 2.1119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1125 - val_loss: 2.1104\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1113 - val_loss: 2.1093\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1106 - val_loss: 2.1087\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1080\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "0\n",
      "minmaxU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1445 - val_loss: 2.0777\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0198 - val_loss: 1.9880\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9739 - val_loss: 1.9650\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9554 - val_loss: 1.9544\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9457 - val_loss: 1.9429\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9387 - val_loss: 1.9392\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9368 - val_loss: 1.9406\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9345 - val_loss: 1.9436\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9333 - val_loss: 1.9382\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9339 - val_loss: 1.9358\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9326 - val_loss: 1.9357\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9443\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9360 - val_loss: 1.9349\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9308 - val_loss: 1.9379\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9312 - val_loss: 1.9386\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9304 - val_loss: 1.9346\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9301 - val_loss: 1.9346\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9290 - val_loss: 1.9457\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9315 - val_loss: 1.9354\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9312 - val_loss: 1.9347\n",
      "Top-2 accuracy = 0.486\n",
      "1\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0971 - val_loss: 2.0144\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9799 - val_loss: 1.9613\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9547 - val_loss: 1.9524\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9458 - val_loss: 1.9453\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9423 - val_loss: 1.9535\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9418 - val_loss: 1.9461\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9375 - val_loss: 1.9467\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9363 - val_loss: 1.9473\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9370 - val_loss: 1.9384\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9344 - val_loss: 1.9432\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9355 - val_loss: 1.9365\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9336 - val_loss: 1.9390\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9333 - val_loss: 1.9409\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9455\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9331 - val_loss: 1.9366\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9314 - val_loss: 1.9349\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9304 - val_loss: 1.9367\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9313 - val_loss: 1.9380\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9303 - val_loss: 1.9337\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9307 - val_loss: 1.9608\n",
      "Top-2 accuracy = 0.473\n",
      "2\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 2.1008 - val_loss: 2.0010\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9997 - val_loss: 1.9730\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9713 - val_loss: 1.9941\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9670 - val_loss: 1.9632\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9559 - val_loss: 1.9500\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9481 - val_loss: 1.9716\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9469 - val_loss: 1.9442\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9410 - val_loss: 1.9450\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9422 - val_loss: 1.9449\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9436 - val_loss: 1.9463\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9399 - val_loss: 1.9399\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9387 - val_loss: 1.9429\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9414 - val_loss: 1.9584\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9507 - val_loss: 1.9396\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9405 - val_loss: 1.9371\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9371 - val_loss: 1.9371\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9373 - val_loss: 1.9365\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9382 - val_loss: 1.9355\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9349 - val_loss: 1.9396\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9342 - val_loss: 1.9355\n",
      "Top-2 accuracy = 0.485\n",
      "3\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1435 - val_loss: 2.0901\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0380 - val_loss: 1.9857\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9620 - val_loss: 1.9654\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9501 - val_loss: 1.9471\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9400 - val_loss: 1.9473\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9382 - val_loss: 1.9409\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9352 - val_loss: 1.9462\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9344 - val_loss: 1.9399\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9342 - val_loss: 1.9380\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9330 - val_loss: 1.9378\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9323 - val_loss: 1.9495\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9334 - val_loss: 1.9515\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9353 - val_loss: 1.9428\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9309 - val_loss: 1.9363\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9305 - val_loss: 1.9371\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9301 - val_loss: 1.9431\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9305 - val_loss: 1.9368\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9309 - val_loss: 1.9363\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9302 - val_loss: 1.9365\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9292 - val_loss: 1.9368\n",
      "Top-2 accuracy = 0.484\n",
      "4\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1111 - val_loss: 2.0321\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9864 - val_loss: 1.9595\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9472 - val_loss: 1.9452\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9391 - val_loss: 1.9431\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9364 - val_loss: 1.9413\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9367 - val_loss: 1.9511\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9356 - val_loss: 1.9381\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9337 - val_loss: 1.9437\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9338 - val_loss: 1.9442\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9332 - val_loss: 1.9523\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9348 - val_loss: 1.9463\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9317 - val_loss: 1.9369\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9316 - val_loss: 1.9390\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9305 - val_loss: 1.9420\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9308 - val_loss: 1.9369\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9331 - val_loss: 1.9358\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9302 - val_loss: 1.9358\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9313 - val_loss: 1.9347\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9289 - val_loss: 1.9389\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9302 - val_loss: 1.9378\n",
      "Top-2 accuracy = 0.48\n",
      "5\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1780 - val_loss: 2.1537\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1217 - val_loss: 2.0820\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0550 - val_loss: 2.0290\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0125 - val_loss: 1.9977\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9865 - val_loss: 1.9782\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9729 - val_loss: 1.9679\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9637 - val_loss: 1.9617\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9590 - val_loss: 1.9610\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9559 - val_loss: 1.9557\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9542 - val_loss: 1.9541\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9525 - val_loss: 1.9651\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9547 - val_loss: 1.9521\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9508 - val_loss: 1.9562\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9538 - val_loss: 1.9506\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9503 - val_loss: 1.9543\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9492 - val_loss: 1.9579\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9497 - val_loss: 1.9489\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9490 - val_loss: 1.9576\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9495 - val_loss: 1.9486\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9476 - val_loss: 1.9471\n",
      "Top-2 accuracy = 0.482\n",
      "6\n",
      "normalizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1741 - val_loss: 2.1470\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1191 - val_loss: 2.0960\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0747 - val_loss: 2.0594\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0258 - val_loss: 1.9984\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9809 - val_loss: 1.9911\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9668 - val_loss: 1.9720\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9627 - val_loss: 1.9596\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9587 - val_loss: 1.9578\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9551 - val_loss: 1.9549\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9533 - val_loss: 1.9600\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9525 - val_loss: 1.9533\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9530 - val_loss: 1.9522\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9524 - val_loss: 1.9648\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9529 - val_loss: 1.9512\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9512 - val_loss: 1.9611\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9506 - val_loss: 1.9540\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9502 - val_loss: 1.9510\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9508 - val_loss: 1.9503\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9501 - val_loss: 1.9500\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9490 - val_loss: 1.9561\n",
      "Top-2 accuracy = 0.478\n",
      "7\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1357 - val_loss: 2.0618\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0132 - val_loss: 1.9835\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9678 - val_loss: 1.9678\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9566 - val_loss: 1.9569\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9487 - val_loss: 1.9501\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9445 - val_loss: 1.9493\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9423 - val_loss: 1.9481\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9402 - val_loss: 1.9552\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9394 - val_loss: 1.9427\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9394 - val_loss: 1.9446\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9363 - val_loss: 1.9401\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9364 - val_loss: 1.9427\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9342 - val_loss: 1.9403\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9340 - val_loss: 1.9389\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9327 - val_loss: 1.9376\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9332 - val_loss: 1.9387\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9313 - val_loss: 1.9411\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9326 - val_loss: 1.9371\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9322 - val_loss: 1.9387\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9314 - val_loss: 1.9393\n",
      "Top-2 accuracy = 0.483\n",
      "8\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1514 - val_loss: 2.0540\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0250 - val_loss: 1.9971\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9789 - val_loss: 1.9694\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9610 - val_loss: 1.9563\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9525 - val_loss: 1.9493\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9484 - val_loss: 1.9499\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9448 - val_loss: 1.9462\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9424 - val_loss: 1.9420\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9406 - val_loss: 1.9461\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9405 - val_loss: 1.9417\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9394 - val_loss: 1.9654\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9427 - val_loss: 1.9396\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9362 - val_loss: 1.9394\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9350 - val_loss: 1.9395\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9350 - val_loss: 1.9391\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9338 - val_loss: 1.9469\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9335 - val_loss: 1.9380\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9336 - val_loss: 1.9399\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9335 - val_loss: 1.9400\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9336 - val_loss: 1.9361\n",
      "Top-2 accuracy = 0.486\n",
      "9\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1448 - val_loss: 2.0990\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0728 - val_loss: 2.0380\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0115 - val_loss: 1.9924\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9804 - val_loss: 1.9737\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9685 - val_loss: 1.9662\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9616 - val_loss: 1.9625\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9582 - val_loss: 1.9574\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9533 - val_loss: 1.9540\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9502 - val_loss: 1.9505\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9475 - val_loss: 1.9491\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9458 - val_loss: 1.9484\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9450 - val_loss: 1.9462\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9435 - val_loss: 1.9458\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9428 - val_loss: 1.9454\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9420 - val_loss: 1.9435\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9406 - val_loss: 1.9437\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9407 - val_loss: 1.9426\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9415\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9399 - val_loss: 1.9413\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9390 - val_loss: 1.9406\n",
      "Top-2 accuracy = 0.485\n",
      "10\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1336 - val_loss: 2.0350\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9889 - val_loss: 1.9766\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9611 - val_loss: 1.9500\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9435 - val_loss: 1.9432\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9381 - val_loss: 1.9503\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9375 - val_loss: 1.9779\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9411 - val_loss: 1.9413\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9352 - val_loss: 1.9419\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9330 - val_loss: 1.9494\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9344 - val_loss: 1.9395\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9346 - val_loss: 1.9371\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9330 - val_loss: 1.9399\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9335 - val_loss: 1.9374\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9325 - val_loss: 1.9413\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9331 - val_loss: 1.9369\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9303 - val_loss: 1.9362\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9312 - val_loss: 1.9401\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9313 - val_loss: 1.9446\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9330 - val_loss: 1.9368\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9307 - val_loss: 1.9361\n",
      "Top-2 accuracy = 0.483\n",
      "11\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1737 - val_loss: 2.1426\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1205 - val_loss: 2.1098\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1109 - val_loss: 2.1076\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1073\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1071\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1090 - val_loss: 2.1067\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1079 - val_loss: 2.1048\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1016 - val_loss: 2.0946\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0805 - val_loss: 2.0663\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0464 - val_loss: 2.0254\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0082 - val_loss: 1.9903\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9720 - val_loss: 1.9592\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9523 - val_loss: 1.9492\n",
      "Top-2 accuracy = 0.484\n",
      "12\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1399 - val_loss: 2.0768\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0286 - val_loss: 1.9958\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9778 - val_loss: 1.9673\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9583 - val_loss: 1.9553\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9500 - val_loss: 1.9503\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9474 - val_loss: 1.9476\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9435 - val_loss: 1.9449\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9423 - val_loss: 1.9508\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9412 - val_loss: 1.9432\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9393 - val_loss: 1.9499\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9389 - val_loss: 1.9458\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9410 - val_loss: 1.9425\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9369 - val_loss: 1.9390\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9361 - val_loss: 1.9390\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9352 - val_loss: 1.9391\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9353 - val_loss: 1.9426\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9347 - val_loss: 1.9383\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.9394\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9341 - val_loss: 1.9422\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9342 - val_loss: 1.9393\n",
      "Top-2 accuracy = 0.481\n",
      "13\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1849 - val_loss: 2.1727\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1635 - val_loss: 2.1543\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1475 - val_loss: 2.1403\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1357 - val_loss: 2.1302\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1271 - val_loss: 2.1228\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1210 - val_loss: 2.1176\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1169 - val_loss: 2.1141\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1142 - val_loss: 2.1118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1124 - val_loss: 2.1102\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "14\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1685 - val_loss: 2.1314\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0785 - val_loss: 2.0357\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0077 - val_loss: 1.9889\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9745 - val_loss: 1.9690\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9590 - val_loss: 1.9580\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9503 - val_loss: 1.9504\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9459 - val_loss: 1.9473\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9415 - val_loss: 1.9436\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9403 - val_loss: 1.9422\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9385 - val_loss: 1.9418\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9389 - val_loss: 1.9415\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9369 - val_loss: 1.9423\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9367 - val_loss: 1.9399\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9368 - val_loss: 1.9405\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9369 - val_loss: 1.9386\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9365 - val_loss: 1.9439\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9372 - val_loss: 1.9383\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9367 - val_loss: 1.9390\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9351 - val_loss: 1.9393\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9361 - val_loss: 1.9373\n",
      "Top-2 accuracy = 0.483\n",
      "15\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1521 - val_loss: 2.1196\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1139 - val_loss: 2.1097\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1102 - val_loss: 2.1077\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1078\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "16\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1459 - val_loss: 2.1207\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1167 - val_loss: 2.1118\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1118 - val_loss: 2.1089\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1078\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1078\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1073\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1073\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "17\n",
      "standardizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1302 - val_loss: 2.0257\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9855 - val_loss: 1.9665\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9593 - val_loss: 1.9624\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9493 - val_loss: 1.9460\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9370 - val_loss: 1.9412\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9321 - val_loss: 1.9369\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9316 - val_loss: 1.9416\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9298 - val_loss: 1.9337\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9293 - val_loss: 1.9346\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9284 - val_loss: 1.9343\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9285 - val_loss: 1.9353\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9284 - val_loss: 1.9348\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9270 - val_loss: 1.9345\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9279 - val_loss: 1.9378\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9271 - val_loss: 1.9373\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9270 - val_loss: 1.9337\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9274 - val_loss: 1.9347\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9266 - val_loss: 1.9346\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9275 - val_loss: 1.9369\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9268 - val_loss: 1.9319\n",
      "Top-2 accuracy = 0.487\n",
      "18\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1790 - val_loss: 2.1372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0496 - val_loss: 1.9952\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9735 - val_loss: 1.9648\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9537 - val_loss: 1.9575\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9449 - val_loss: 1.9465\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9397 - val_loss: 1.9434\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9387 - val_loss: 1.9487\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9370 - val_loss: 1.9431\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9354 - val_loss: 1.9414\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9343 - val_loss: 1.9400\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9337 - val_loss: 1.9382\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9316 - val_loss: 1.9392\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9317 - val_loss: 1.9383\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9309 - val_loss: 1.9394\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9311 - val_loss: 1.9395\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9311 - val_loss: 1.9408\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9318 - val_loss: 1.9370\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9311 - val_loss: 1.9375\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9304 - val_loss: 1.9419\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9309 - val_loss: 1.9393\n",
      "Top-2 accuracy = 0.482\n",
      "19\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1744 - val_loss: 2.1359\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0904 - val_loss: 2.0529\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0272 - val_loss: 2.0040\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9886 - val_loss: 1.9774\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9694 - val_loss: 1.9682\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9621 - val_loss: 1.9617\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9565 - val_loss: 1.9584\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9555 - val_loss: 1.9557\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9485 - val_loss: 1.9495\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9446 - val_loss: 1.9459\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9411 - val_loss: 1.9490\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9405 - val_loss: 1.9469\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9419 - val_loss: 1.9460\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9395 - val_loss: 1.9448\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9386 - val_loss: 1.9438\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9381 - val_loss: 1.9420\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9382 - val_loss: 1.9461\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9377 - val_loss: 1.9431\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9376 - val_loss: 1.9399\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9411\n",
      "Top-2 accuracy = 0.484\n",
      "20\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1691 - val_loss: 2.1306\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1159 - val_loss: 2.1080\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1101 - val_loss: 2.1075\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Top-2 accuracy = 0.384\n",
      "21\n",
      "maxabsN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1591 - val_loss: 2.1232\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0976 - val_loss: 2.0665\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0452 - val_loss: 2.0146\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9960 - val_loss: 1.9776\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9672 - val_loss: 1.9626\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9572 - val_loss: 1.9641\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9549 - val_loss: 1.9574\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9509 - val_loss: 1.9538\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9487 - val_loss: 1.9594\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9499 - val_loss: 1.9496\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9473 - val_loss: 1.9503\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9469 - val_loss: 1.9485\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9468 - val_loss: 1.9484\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9461 - val_loss: 1.9563\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9460 - val_loss: 1.9506\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9464 - val_loss: 1.9596\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9518 - val_loss: 1.9523\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9465 - val_loss: 1.9610\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9536 - val_loss: 1.9545\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9466 - val_loss: 1.9488\n",
      "Top-2 accuracy = 0.482\n",
      "22\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1625 - val_loss: 2.1317\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0927 - val_loss: 2.0615\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0260 - val_loss: 2.0081\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9900 - val_loss: 1.9809\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9728 - val_loss: 1.9702\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9629 - val_loss: 1.9613\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9566 - val_loss: 1.9568\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9543 - val_loss: 1.9542\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9516 - val_loss: 1.9524\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9519 - val_loss: 1.9512\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9505 - val_loss: 1.9531\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9508 - val_loss: 1.9500\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9495 - val_loss: 1.9500\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9489 - val_loss: 1.9489\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9492 - val_loss: 1.9492\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9485 - val_loss: 1.9492\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9481 - val_loss: 1.9480\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9476 - val_loss: 1.9485\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9477 - val_loss: 1.9499\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9481 - val_loss: 1.9472\n",
      "Top-2 accuracy = 0.484\n",
      "23\n",
      "standardizei|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1640 - val_loss: 2.1209\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0832 - val_loss: 2.0602\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0416 - val_loss: 2.0285\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0120 - val_loss: 2.0010\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9845 - val_loss: 1.9736\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9640 - val_loss: 1.9604\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9564 - val_loss: 1.9559\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9517 - val_loss: 1.9512\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9459 - val_loss: 1.9485\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9446 - val_loss: 1.9479\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9443 - val_loss: 1.9449\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9423 - val_loss: 1.9480\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9427 - val_loss: 1.9442\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9414 - val_loss: 1.9439\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9421 - val_loss: 1.9431\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9403 - val_loss: 1.9438\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9398 - val_loss: 1.9493\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9401 - val_loss: 1.9442\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9401 - val_loss: 1.9413\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9388 - val_loss: 1.9419\n",
      "Top-2 accuracy = 0.482\n",
      "24\n",
      "maxabso|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1039 - val_loss: 2.0119\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9802 - val_loss: 1.9641\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9517 - val_loss: 1.9502\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9460 - val_loss: 1.9483\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9426 - val_loss: 1.9480\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9420 - val_loss: 1.9461\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9386 - val_loss: 1.9448\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9369 - val_loss: 1.9453\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9371 - val_loss: 1.9415\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9351 - val_loss: 1.9411\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9347 - val_loss: 1.9416\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9350 - val_loss: 1.9377\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9332 - val_loss: 1.9381\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9357 - val_loss: 1.9394\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9335 - val_loss: 1.9377\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9321 - val_loss: 1.9390\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9315 - val_loss: 1.9383\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9312 - val_loss: 1.9380\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9310 - val_loss: 1.9363\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9309 - val_loss: 1.9372\n",
      "Top-2 accuracy = 0.486\n",
      "25\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1833 - val_loss: 2.1688\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1568 - val_loss: 2.1439\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1348 - val_loss: 2.1256\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1212 - val_loss: 2.1156\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1140 - val_loss: 2.1107\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1111 - val_loss: 2.1087\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1101 - val_loss: 2.1081\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "26\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1480 - val_loss: 2.0818\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0226 - val_loss: 1.9866\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9764 - val_loss: 1.9682\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9651 - val_loss: 1.9595\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9587 - val_loss: 1.9552\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9553 - val_loss: 1.9534\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9526 - val_loss: 1.9510\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9501 - val_loss: 1.9473\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9467 - val_loss: 1.9458\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9456 - val_loss: 1.9439\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9433 - val_loss: 1.9419\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9422 - val_loss: 1.9418\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9408 - val_loss: 1.9406\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9406 - val_loss: 1.9391\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9387 - val_loss: 1.9389\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9378 - val_loss: 1.9378\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9368 - val_loss: 1.9370\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9362 - val_loss: 1.9367\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9358 - val_loss: 1.9371\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9348 - val_loss: 1.9366\n",
      "Top-2 accuracy = 0.484\n",
      "27\n",
      "standardizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1845 - val_loss: 2.1724\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1630 - val_loss: 2.1538\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1470 - val_loss: 2.1401\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1354 - val_loss: 2.1300\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1269 - val_loss: 2.1227\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1209 - val_loss: 2.1177\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1170 - val_loss: 2.1142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1143 - val_loss: 2.1119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1125 - val_loss: 2.1103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1114 - val_loss: 2.1093\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1081\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Top-2 accuracy = 0.384\n",
      "28\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1686 - val_loss: 2.1414\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1262 - val_loss: 2.1149\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0874 - val_loss: 2.0497\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0247 - val_loss: 2.0052\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9924 - val_loss: 1.9799\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9729 - val_loss: 1.9659\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9611 - val_loss: 1.9573\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9548 - val_loss: 1.9522\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9500 - val_loss: 1.9496\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9474 - val_loss: 1.9474\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9466 - val_loss: 1.9476\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9454 - val_loss: 1.9468\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9456 - val_loss: 1.9452\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9438 - val_loss: 1.9449\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9442 - val_loss: 1.9432\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9425 - val_loss: 1.9435\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9427 - val_loss: 1.9431\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9419 - val_loss: 1.9424\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9415 - val_loss: 1.9419\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9416 - val_loss: 1.9415\n",
      "Top-2 accuracy = 0.483\n",
      "29\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1257 - val_loss: 2.0363\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9993 - val_loss: 1.9803\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9635 - val_loss: 1.9512\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9419 - val_loss: 1.9423\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9348 - val_loss: 1.9402\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9340 - val_loss: 1.9402\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9325 - val_loss: 1.9426\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9313 - val_loss: 1.9366\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9277 - val_loss: 1.9335\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9273 - val_loss: 1.9373\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9272 - val_loss: 1.9390\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9275 - val_loss: 1.9324\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9265 - val_loss: 1.9348\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9261 - val_loss: 1.9322\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9259 - val_loss: 1.9320\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9270 - val_loss: 1.9325\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9253 - val_loss: 1.9327\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9327\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9345\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9320\n",
      "Top-2 accuracy = 0.486\n",
      "0\n",
      "normalizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1773 - val_loss: 2.1578\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1395 - val_loss: 2.1196\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0935 - val_loss: 2.0643\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0409 - val_loss: 2.0242\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0127 - val_loss: 2.0048\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9944 - val_loss: 1.9912\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9833 - val_loss: 1.9812\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9746 - val_loss: 1.9737\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9659 - val_loss: 1.9654\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9601 - val_loss: 1.9662\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9576 - val_loss: 1.9562\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9530 - val_loss: 1.9627\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9554 - val_loss: 1.9569\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9500 - val_loss: 1.9508\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9489 - val_loss: 1.9518\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9480 - val_loss: 1.9488\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9464 - val_loss: 1.9483\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9457 - val_loss: 1.9477\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9465 - val_loss: 1.9479\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9456 - val_loss: 1.9470\n",
      "Top-2 accuracy = 0.482\n",
      "1\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1513 - val_loss: 2.1163\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1006 - val_loss: 2.0763\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0500 - val_loss: 2.0125\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9911 - val_loss: 1.9726\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9626 - val_loss: 1.9557\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9506 - val_loss: 1.9549\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9479 - val_loss: 1.9487\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9438 - val_loss: 1.9462\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9424 - val_loss: 1.9442\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9412 - val_loss: 1.9428\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9399 - val_loss: 1.9422\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9399 - val_loss: 1.9424\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9501\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9384 - val_loss: 1.9423\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9368 - val_loss: 1.9407\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9367 - val_loss: 1.9402\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9364 - val_loss: 1.9401\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9368 - val_loss: 1.9392\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9361 - val_loss: 1.9391\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9372 - val_loss: 1.9393\n",
      "Top-2 accuracy = 0.481\n",
      "2\n",
      "standardizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1126 - val_loss: 2.0210\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9773 - val_loss: 1.9558\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9468 - val_loss: 1.9477\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9405 - val_loss: 1.9443\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9364 - val_loss: 1.9419\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9347 - val_loss: 1.9390\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9342 - val_loss: 1.9380\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9319 - val_loss: 1.9385\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9324 - val_loss: 1.9366\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9325 - val_loss: 1.9363\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9306 - val_loss: 1.9357\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9300 - val_loss: 1.9364\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9295 - val_loss: 1.9354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9288 - val_loss: 1.9447\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9296 - val_loss: 1.9364\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9289 - val_loss: 1.9343\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9287 - val_loss: 1.9398\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9292 - val_loss: 1.9356\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9286 - val_loss: 1.9392\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9279 - val_loss: 1.9372\n",
      "Top-2 accuracy = 0.484\n",
      "3\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1796 - val_loss: 2.1539\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1261 - val_loss: 2.0980\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0693 - val_loss: 2.0361\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0135 - val_loss: 1.9908\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9797 - val_loss: 1.9708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9663 - val_loss: 1.9734\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9615 - val_loss: 1.9651\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9604 - val_loss: 1.9563\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9553 - val_loss: 1.9536\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9543 - val_loss: 1.9584\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9528 - val_loss: 1.9595\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9537 - val_loss: 1.9582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9527 - val_loss: 1.9573\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9522 - val_loss: 1.9495\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9499 - val_loss: 1.9486\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9490 - val_loss: 1.9495\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9496 - val_loss: 1.9532\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9486 - val_loss: 1.9474\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9482 - val_loss: 1.9486\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9476 - val_loss: 1.9469\n",
      "Top-2 accuracy = 0.482\n",
      "4\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1096 - val_loss: 2.0245\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9879 - val_loss: 1.9692\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9596 - val_loss: 1.9575\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9482 - val_loss: 1.9490\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9428 - val_loss: 1.9459\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9387 - val_loss: 1.9415\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9381 - val_loss: 1.9560\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9378 - val_loss: 1.9434\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9345 - val_loss: 1.9420\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9353 - val_loss: 1.9374\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9325 - val_loss: 1.9386\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9326 - val_loss: 1.9395\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9321 - val_loss: 1.9371\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9310 - val_loss: 1.9370\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9309 - val_loss: 1.9482\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9339 - val_loss: 1.9379\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9301 - val_loss: 1.9453\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9294 - val_loss: 1.9382\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9314 - val_loss: 1.9376\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9292 - val_loss: 1.9358\n",
      "Top-2 accuracy = 0.483\n",
      "5\n",
      "standardizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.0957 - val_loss: 2.0157\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9806 - val_loss: 1.9608\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9454 - val_loss: 1.9451\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9363 - val_loss: 1.9480\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9347 - val_loss: 1.9388\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9314 - val_loss: 1.9370\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9311 - val_loss: 1.9406\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9307 - val_loss: 1.9375\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9293 - val_loss: 1.9363\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9288 - val_loss: 1.9358\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9275 - val_loss: 1.9354\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9273 - val_loss: 1.9336\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9270 - val_loss: 1.9344\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9285 - val_loss: 1.9384\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9274 - val_loss: 1.9341\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9260 - val_loss: 1.9345\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9262 - val_loss: 1.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9250 - val_loss: 1.9329\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9262 - val_loss: 1.9335\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9247 - val_loss: 1.9321\n",
      "Top-2 accuracy = 0.488\n",
      "6\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1486 - val_loss: 2.0998\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0591 - val_loss: 2.0214\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0025 - val_loss: 1.9892\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9821 - val_loss: 1.9787\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9720 - val_loss: 1.9707\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9656 - val_loss: 1.9654\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9619 - val_loss: 1.9613\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9564 - val_loss: 1.9537\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9509 - val_loss: 1.9515\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9491 - val_loss: 1.9491\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9463 - val_loss: 1.9462\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9443 - val_loss: 1.9453\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9429 - val_loss: 1.9443\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9425 - val_loss: 1.9441\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9413 - val_loss: 1.9434\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9404 - val_loss: 1.9414\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9394 - val_loss: 1.9421\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9388 - val_loss: 1.9410\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9384 - val_loss: 1.9402\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9380 - val_loss: 1.9398\n",
      "Top-2 accuracy = 0.481\n",
      "7\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1314 - val_loss: 2.0727\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0186 - val_loss: 1.9807\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9659 - val_loss: 1.9572\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9461 - val_loss: 1.9485\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9391 - val_loss: 1.9436\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9375 - val_loss: 1.9408\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9346 - val_loss: 1.9430\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9341 - val_loss: 1.9396\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9322 - val_loss: 1.9551\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9330 - val_loss: 1.9387\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9315 - val_loss: 1.9380\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9302 - val_loss: 1.9374\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9301 - val_loss: 1.9372\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9293 - val_loss: 1.9368\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9289 - val_loss: 1.9392\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9298 - val_loss: 1.9367\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9290 - val_loss: 1.9355\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9282 - val_loss: 1.9359\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9279 - val_loss: 1.9360\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9280 - val_loss: 1.9372\n",
      "Top-2 accuracy = 0.481\n",
      "8\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1401 - val_loss: 2.0574\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0147 - val_loss: 1.9941\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9765 - val_loss: 1.9702\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9663 - val_loss: 1.9603\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9582 - val_loss: 1.9603\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9546 - val_loss: 1.9531\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9510 - val_loss: 1.9495\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9488 - val_loss: 1.9480\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9480 - val_loss: 1.9479\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9444 - val_loss: 1.9439\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9469 - val_loss: 1.9428\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9405 - val_loss: 1.9427\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9417 - val_loss: 1.9469\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9413 - val_loss: 1.9492\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9424 - val_loss: 1.9436\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9400 - val_loss: 1.9429\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9384 - val_loss: 1.9435\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9388 - val_loss: 1.9416\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9391 - val_loss: 1.9435\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9384 - val_loss: 1.9413\n",
      "Top-2 accuracy = 0.484\n",
      "9\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1483 - val_loss: 2.0886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0414 - val_loss: 1.9979\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9732 - val_loss: 1.9541\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9440 - val_loss: 1.9424\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9370 - val_loss: 1.9402\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9334 - val_loss: 1.9417\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9328 - val_loss: 1.9363\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9309 - val_loss: 1.9349\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9298 - val_loss: 1.9338\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9283 - val_loss: 1.9367\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9278 - val_loss: 1.9351\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9274 - val_loss: 1.9403\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9298 - val_loss: 1.9359\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9267 - val_loss: 1.9347\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9271 - val_loss: 1.9358\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9276 - val_loss: 1.9325\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9251 - val_loss: 1.9332\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9366\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9276 - val_loss: 1.9318\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9320\n",
      "Top-2 accuracy = 0.486\n",
      "10\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1642 - val_loss: 2.1199\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0661 - val_loss: 2.0111\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9909 - val_loss: 1.9822\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9739 - val_loss: 1.9738\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9660 - val_loss: 1.9677\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9622 - val_loss: 1.9654\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9593 - val_loss: 1.9619\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9567 - val_loss: 1.9603\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9548 - val_loss: 1.9597\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9531 - val_loss: 1.9562\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9511 - val_loss: 1.9543\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9493 - val_loss: 1.9535\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9483 - val_loss: 1.9520\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9461 - val_loss: 1.9499\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9452 - val_loss: 1.9488\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9441 - val_loss: 1.9481\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9431 - val_loss: 1.9468\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9432 - val_loss: 1.9468\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9418 - val_loss: 1.9463\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9413 - val_loss: 1.9461\n",
      "Top-2 accuracy = 0.48\n",
      "11\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1331 - val_loss: 2.0715\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0397 - val_loss: 2.0134\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9959 - val_loss: 1.9858\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9759 - val_loss: 1.9713\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9665 - val_loss: 1.9683\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9627 - val_loss: 1.9596\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9577 - val_loss: 1.9571\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9562 - val_loss: 1.9551\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9536 - val_loss: 1.9541\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9522 - val_loss: 1.9546\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9510 - val_loss: 1.9522\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9505 - val_loss: 1.9516\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9493 - val_loss: 1.9498\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9472 - val_loss: 1.9535\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9471 - val_loss: 1.9488\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9452 - val_loss: 1.9479\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9458 - val_loss: 1.9476\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9449 - val_loss: 1.9464\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9441 - val_loss: 1.9460\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9444 - val_loss: 1.9494\n",
      "Top-2 accuracy = 0.478\n",
      "12\n",
      "minmaxa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1847 - val_loss: 2.1724\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1633 - val_loss: 2.1540\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1473 - val_loss: 2.1403\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1355 - val_loss: 2.1301\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1270 - val_loss: 2.1228\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1210 - val_loss: 2.1177\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1169 - val_loss: 2.1142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1142 - val_loss: 2.1119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1125 - val_loss: 2.1103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1114 - val_loss: 2.1094\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1107 - val_loss: 2.1087\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1103 - val_loss: 2.1083\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1100 - val_loss: 2.1080\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "13\n",
      "normalizei|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1726 - val_loss: 2.1465\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1255 - val_loss: 2.1038\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0773 - val_loss: 2.0324\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0073 - val_loss: 1.9910\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9853 - val_loss: 1.9810\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9758 - val_loss: 1.9734\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9695 - val_loss: 1.9661\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9646 - val_loss: 1.9633\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9616 - val_loss: 1.9598\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9587 - val_loss: 1.9569\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9566 - val_loss: 1.9556\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9554 - val_loss: 1.9546\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9538 - val_loss: 1.9530\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9531 - val_loss: 1.9523\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9521 - val_loss: 1.9517\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9519 - val_loss: 1.9516\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9508 - val_loss: 1.9504\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9507 - val_loss: 1.9498\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9497 - val_loss: 1.9490\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9522 - val_loss: 1.9488\n",
      "Top-2 accuracy = 0.483\n",
      "14\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1716 - val_loss: 2.1394\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1063 - val_loss: 2.0723\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0431 - val_loss: 2.0215\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0043 - val_loss: 1.9964\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9840 - val_loss: 1.9803\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9732 - val_loss: 1.9722\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9673 - val_loss: 1.9685\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9634 - val_loss: 1.9635\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9594 - val_loss: 1.9623\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9573 - val_loss: 1.9614\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9553 - val_loss: 1.9666\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9551 - val_loss: 1.9619\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9538 - val_loss: 1.9564\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9515 - val_loss: 1.9553\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9508 - val_loss: 1.9518\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9492 - val_loss: 1.9513\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9489 - val_loss: 1.9502\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9477 - val_loss: 1.9500\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9477 - val_loss: 1.9499\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9472 - val_loss: 1.9554\n",
      "Top-2 accuracy = 0.476\n",
      "15\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1580 - val_loss: 2.1152\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1108 - val_loss: 2.1073\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1100 - val_loss: 2.1077\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1099 - val_loss: 2.1080\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1101 - val_loss: 2.1077\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1102 - val_loss: 2.1077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Top-2 accuracy = 0.384\n",
      "16\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1391 - val_loss: 2.0812\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0364 - val_loss: 2.0025\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9882 - val_loss: 1.9798\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9667 - val_loss: 1.9598\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9520 - val_loss: 1.9558\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9444 - val_loss: 1.9461\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9416 - val_loss: 1.9493\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9410 - val_loss: 1.9475\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9398 - val_loss: 1.9415\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9377 - val_loss: 1.9395\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9371 - val_loss: 1.9405\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9360 - val_loss: 1.9395\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9361 - val_loss: 1.9396\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9356 - val_loss: 1.9387\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9350 - val_loss: 1.9377\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9348 - val_loss: 1.9411\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9348 - val_loss: 1.9374\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.9368\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9343 - val_loss: 1.9372\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9336 - val_loss: 1.9387\n",
      "Top-2 accuracy = 0.483\n",
      "17\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1672 - val_loss: 2.1291\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1153 - val_loss: 2.1080\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1073\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1073\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1073\n",
      "Top-2 accuracy = 0.384\n",
      "18\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1375 - val_loss: 2.0464\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0069 - val_loss: 1.9906\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9790 - val_loss: 1.9712\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9650 - val_loss: 1.9684\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9580 - val_loss: 1.9564\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9495 - val_loss: 1.9481\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9412 - val_loss: 1.9517\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9398 - val_loss: 1.9487\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9390 - val_loss: 1.9429\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9391 - val_loss: 1.9409\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9347 - val_loss: 1.9498\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9363 - val_loss: 1.9390\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9344 - val_loss: 1.9425\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9336 - val_loss: 1.9388\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9342 - val_loss: 1.9397\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9333 - val_loss: 1.9428\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9336 - val_loss: 1.9389\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9327 - val_loss: 1.9388\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9336 - val_loss: 1.9392\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9318 - val_loss: 1.9366\n",
      "Top-2 accuracy = 0.486\n",
      "19\n",
      "minmaxO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1149 - val_loss: 2.0132\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9906 - val_loss: 1.9603\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9493 - val_loss: 1.9525\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9439 - val_loss: 1.9564\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9427 - val_loss: 1.9537\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9365 - val_loss: 1.9400\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9359 - val_loss: 1.9385\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9345 - val_loss: 1.9400\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9331 - val_loss: 1.9362\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9333 - val_loss: 1.9377\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9320 - val_loss: 1.9396\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9343 - val_loss: 1.9364\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9320 - val_loss: 1.9378\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9319 - val_loss: 1.9365\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9331 - val_loss: 1.9398\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9323 - val_loss: 1.9382\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9312 - val_loss: 1.9357\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9314 - val_loss: 1.9356\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9310 - val_loss: 1.9355\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9305 - val_loss: 1.9503\n",
      "Top-2 accuracy = 0.481\n",
      "20\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 2.1641 - val_loss: 2.1015\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0388 - val_loss: 1.9967\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9747 - val_loss: 1.9682\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9547 - val_loss: 1.9545\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9467 - val_loss: 1.9516\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9417 - val_loss: 1.9445\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9397 - val_loss: 1.9416\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9343 - val_loss: 1.9430\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9361 - val_loss: 1.9421\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9342 - val_loss: 1.9390\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9329 - val_loss: 1.9391\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9311 - val_loss: 1.9384\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9321 - val_loss: 1.9506\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9342 - val_loss: 1.9435\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9321 - val_loss: 1.9377\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9309 - val_loss: 1.9434\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9314 - val_loss: 1.9367\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9294 - val_loss: 1.9364\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9298 - val_loss: 1.9515\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9396 - val_loss: 1.9432\n",
      "Top-2 accuracy = 0.484\n",
      "21\n",
      "standardizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 2.1442 - val_loss: 2.0667\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.0195 - val_loss: 1.9971\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9803 - val_loss: 1.9759\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9746 - val_loss: 1.9818\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9703 - val_loss: 1.9692\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9567 - val_loss: 1.9493\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9399 - val_loss: 1.9452\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9354 - val_loss: 1.9412\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9344 - val_loss: 1.9406\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9327 - val_loss: 1.9390\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9313 - val_loss: 1.9465\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9315 - val_loss: 1.9419\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9314 - val_loss: 1.9434\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9306 - val_loss: 1.9370\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9332 - val_loss: 1.9369\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9290 - val_loss: 1.9411\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9294 - val_loss: 1.9368\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9286 - val_loss: 1.9378\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9281 - val_loss: 1.9370\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9278 - val_loss: 1.9547\n",
      "Top-2 accuracy = 0.474\n",
      "22\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 2.0908 - val_loss: 2.0158\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0045 - val_loss: 2.0042\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9983 - val_loss: 2.0018\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9978 - val_loss: 2.0017\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9985 - val_loss: 2.0021\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9957 - val_loss: 1.9935\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0034 - val_loss: 2.0334\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0431 - val_loss: 2.0304\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0720 - val_loss: 2.0819\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0829 - val_loss: 2.0812\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0831 - val_loss: 2.0898\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0899 - val_loss: 2.1025\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1102 - val_loss: 2.1083\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1102 - val_loss: 2.1079\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1103 - val_loss: 2.1082\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1102 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1101 - val_loss: 2.1087\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1104 - val_loss: 2.1077\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1102 - val_loss: 2.1079\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Top-2 accuracy = 0.384\n",
      "23\n",
      "robustV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1361 - val_loss: 2.0815\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0666 - val_loss: 2.0443\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0201 - val_loss: 1.9981\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9741 - val_loss: 1.9630\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9545 - val_loss: 1.9517\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9442 - val_loss: 1.9424\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9371 - val_loss: 1.9745\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9382 - val_loss: 1.9403\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9342 - val_loss: 1.9381\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9327 - val_loss: 1.9362\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9315 - val_loss: 1.9395\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9313 - val_loss: 1.9367\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9326 - val_loss: 1.9388\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9321 - val_loss: 1.9376\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9310 - val_loss: 1.9365\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9293 - val_loss: 1.9353\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9296 - val_loss: 1.9365\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9292 - val_loss: 1.9341\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9299 - val_loss: 1.9340\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9280 - val_loss: 1.9378\n",
      "Top-2 accuracy = 0.476\n",
      "24\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1139 - val_loss: 2.0207\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9794 - val_loss: 1.9578\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9436 - val_loss: 1.9668\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9392 - val_loss: 1.9404\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9344 - val_loss: 1.9394\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9340 - val_loss: 1.9398\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9314 - val_loss: 1.9375\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9300 - val_loss: 1.9479\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9307 - val_loss: 1.9349\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9326 - val_loss: 1.9372\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9299 - val_loss: 1.9343\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9284 - val_loss: 1.9373\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9278 - val_loss: 1.9405\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9289 - val_loss: 1.9328\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9276 - val_loss: 1.9350\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9280 - val_loss: 1.9317\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9268 - val_loss: 1.9382\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9364 - val_loss: 1.9386\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9314 - val_loss: 1.9359\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9307 - val_loss: 1.9349\n",
      "Top-2 accuracy = 0.481\n",
      "25\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1552 - val_loss: 2.0988\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0617 - val_loss: 2.0281\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9950 - val_loss: 1.9693\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9574 - val_loss: 1.9570\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9485 - val_loss: 1.9456\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9427 - val_loss: 1.9432\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9430 - val_loss: 1.9419\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9407 - val_loss: 1.9412\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9394 - val_loss: 1.9413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9383 - val_loss: 1.9482\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9387 - val_loss: 1.9402\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9378 - val_loss: 1.9405\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9366 - val_loss: 1.9388\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9369 - val_loss: 1.9417\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9364 - val_loss: 1.9389\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9356 - val_loss: 1.9383\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9356 - val_loss: 1.9392\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9357 - val_loss: 1.9372\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9354 - val_loss: 1.9404\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9355 - val_loss: 1.9373\n",
      "Top-2 accuracy = 0.484\n",
      "26\n",
      "maxabsh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1543 - val_loss: 2.1108\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1105 - val_loss: 2.1078\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1102 - val_loss: 2.1083\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1102 - val_loss: 2.1075\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1100 - val_loss: 2.1076\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1101 - val_loss: 2.1074\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1101 - val_loss: 2.1075\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1102 - val_loss: 2.1075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1102 - val_loss: 2.1076\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1101 - val_loss: 2.1080\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1104 - val_loss: 2.1076\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1100 - val_loss: 2.1077\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1102 - val_loss: 2.1074\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1101 - val_loss: 2.1077\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1102 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Top-2 accuracy = 0.384\n",
      "27\n",
      "standardizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1701 - val_loss: 2.1234\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0623 - val_loss: 2.0210\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0024 - val_loss: 1.9850\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9741 - val_loss: 1.9666\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9615 - val_loss: 1.9577\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9547 - val_loss: 1.9523\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9494 - val_loss: 1.9505\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9462 - val_loss: 1.9469\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9445 - val_loss: 1.9530\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9447 - val_loss: 1.9447\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9407 - val_loss: 1.9424\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9415\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9386 - val_loss: 1.9416\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9382 - val_loss: 1.9406\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9374 - val_loss: 1.9420\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9378 - val_loss: 1.9395\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9413\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9373 - val_loss: 1.9388\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9366 - val_loss: 1.9428\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9361 - val_loss: 1.9387\n",
      "Top-2 accuracy = 0.484\n",
      "28\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1051 - val_loss: 2.0327\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0016 - val_loss: 1.9909\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9675 - val_loss: 1.9612\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9506 - val_loss: 1.9477\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9445 - val_loss: 1.9481\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9417 - val_loss: 1.9452\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9411 - val_loss: 1.9450\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9405 - val_loss: 1.9417\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9394 - val_loss: 1.9389\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9371 - val_loss: 1.9400\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9365 - val_loss: 1.9376\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9356 - val_loss: 1.9366\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9341 - val_loss: 1.9514\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9352 - val_loss: 1.9422\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9362 - val_loss: 1.9350\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9336 - val_loss: 1.9349\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9342 - val_loss: 1.9365\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9342 - val_loss: 1.9353\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9333 - val_loss: 1.9352\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9317 - val_loss: 1.9371\n",
      "Top-2 accuracy = 0.482\n",
      "29\n",
      "standardizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1848 - val_loss: 2.1727\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1635 - val_loss: 2.1542\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1476 - val_loss: 2.1405\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1356 - val_loss: 2.1302\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1273 - val_loss: 2.1231\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1212 - val_loss: 2.1178\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1169 - val_loss: 2.1142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1142 - val_loss: 2.1118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1124 - val_loss: 2.1102\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1101 - val_loss: 2.1081\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "0\n",
      "normalizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1726 - val_loss: 2.1350\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0703 - val_loss: 2.0090\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9898 - val_loss: 1.9794\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9732 - val_loss: 1.9697\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9607 - val_loss: 1.9568\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9464 - val_loss: 1.9468\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9405 - val_loss: 1.9428\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9374 - val_loss: 1.9415\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9389 - val_loss: 1.9525\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9375 - val_loss: 1.9408\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9353 - val_loss: 1.9440\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9360 - val_loss: 1.9400\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9340 - val_loss: 1.9385\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9334 - val_loss: 1.9445\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9352 - val_loss: 1.9445\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9343 - val_loss: 1.9372\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9320 - val_loss: 1.9403\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9322 - val_loss: 1.9368\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9313 - val_loss: 1.9395\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9312 - val_loss: 1.9363\n",
      "Top-2 accuracy = 0.484\n",
      "1\n",
      "normalizeG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 2.1456 - val_loss: 2.1141\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1124 - val_loss: 2.1079\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1105 - val_loss: 2.1078\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1100 - val_loss: 2.1078\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1102 - val_loss: 2.1073\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1099 - val_loss: 2.1078\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1100 - val_loss: 2.1079\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1102 - val_loss: 2.1079\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1102 - val_loss: 2.1074\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1099 - val_loss: 2.1077\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1102 - val_loss: 2.1076\n",
      "Top-2 accuracy = 0.384\n",
      "2\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1445 - val_loss: 2.0914\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0498 - val_loss: 2.0112\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9950 - val_loss: 1.9813\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9723 - val_loss: 1.9646\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9544 - val_loss: 1.9568\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9457 - val_loss: 1.9458\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9420 - val_loss: 1.9442\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9398 - val_loss: 1.9519\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9386 - val_loss: 1.9448\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9366 - val_loss: 1.9410\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9359 - val_loss: 1.9393\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9354 - val_loss: 1.9390\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9344 - val_loss: 1.9382\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9332 - val_loss: 1.9452\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9338 - val_loss: 1.9384\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9334 - val_loss: 1.9417\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9330 - val_loss: 1.9390\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9319 - val_loss: 1.9382\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9326 - val_loss: 1.9390\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9316 - val_loss: 1.9416\n",
      "Top-2 accuracy = 0.48\n",
      "3\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1444 - val_loss: 2.0825\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0415 - val_loss: 2.0076\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9815 - val_loss: 1.9722\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9683 - val_loss: 1.9599\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9548 - val_loss: 1.9545\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9499 - val_loss: 1.9507\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9477 - val_loss: 1.9483\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9469 - val_loss: 1.9469\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9460 - val_loss: 1.9517\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9474 - val_loss: 1.9639\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9483 - val_loss: 1.9461\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9452 - val_loss: 1.9449\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9431 - val_loss: 1.9449\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9429 - val_loss: 1.9529\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9452 - val_loss: 1.9507\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9430 - val_loss: 1.9445\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9421 - val_loss: 1.9576\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9444 - val_loss: 1.9514\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9445 - val_loss: 1.9435\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9433 - val_loss: 1.9431\n",
      "Top-2 accuracy = 0.481\n",
      "4\n",
      "minmaxt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1845 - val_loss: 2.1712\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1516 - val_loss: 2.1234\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0946 - val_loss: 2.0683\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0398 - val_loss: 2.0077\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9947 - val_loss: 1.9836\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9720 - val_loss: 1.9696\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9623 - val_loss: 1.9631\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9591 - val_loss: 1.9633\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9559 - val_loss: 1.9569\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9540 - val_loss: 1.9545\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9526 - val_loss: 1.9582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9509 - val_loss: 1.9512\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9501 - val_loss: 1.9518\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9496 - val_loss: 1.9688\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9506 - val_loss: 1.9610\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9601 - val_loss: 1.9510\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9481 - val_loss: 1.9484\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9474 - val_loss: 1.9509\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9488 - val_loss: 1.9481\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9475 - val_loss: 1.9476\n",
      "Top-2 accuracy = 0.483\n",
      "5\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1847 - val_loss: 2.1725\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1633 - val_loss: 2.1541\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1473 - val_loss: 2.1402\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1355 - val_loss: 2.1301\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1270 - val_loss: 2.1228\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1209 - val_loss: 2.1176\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1168 - val_loss: 2.1140\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1141 - val_loss: 2.1118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1124 - val_loss: 2.1102\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1102 - val_loss: 2.1082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "6\n",
      "robustg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1344 - val_loss: 2.0422\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9998 - val_loss: 1.9773\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9663 - val_loss: 1.9586\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9508 - val_loss: 1.9471\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9461 - val_loss: 1.9474\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9442 - val_loss: 1.9434\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9393 - val_loss: 1.9456\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9370 - val_loss: 1.9508\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9375 - val_loss: 1.9419\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9345 - val_loss: 1.9398\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9332 - val_loss: 1.9471\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9336 - val_loss: 1.9380\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9319 - val_loss: 1.9405\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9331 - val_loss: 1.9384\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9317 - val_loss: 1.9364\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9307 - val_loss: 1.9369\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9300 - val_loss: 1.9376\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9296 - val_loss: 1.9395\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9323 - val_loss: 1.9421\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9312 - val_loss: 1.9388\n",
      "Top-2 accuracy = 0.483\n",
      "7\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1726 - val_loss: 2.1299\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0725 - val_loss: 2.0175\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9826 - val_loss: 1.9679\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9598 - val_loss: 1.9601\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9534 - val_loss: 1.9604\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9498 - val_loss: 1.9512\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9480 - val_loss: 1.9520\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9443 - val_loss: 1.9470\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9421 - val_loss: 1.9443\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9403 - val_loss: 1.9440\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9394 - val_loss: 1.9421\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9395 - val_loss: 1.9432\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9390 - val_loss: 1.9490\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9385 - val_loss: 1.9409\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9367 - val_loss: 1.9395\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9368 - val_loss: 1.9412\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9355 - val_loss: 1.9422\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9383 - val_loss: 1.9387\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9348 - val_loss: 1.9381\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9339 - val_loss: 1.9394\n",
      "Top-2 accuracy = 0.483\n",
      "8\n",
      "minmaxa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1196 - val_loss: 2.0245\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9846 - val_loss: 1.9589\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9470 - val_loss: 1.9523\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9402 - val_loss: 1.9440\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9387 - val_loss: 1.9437\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9346 - val_loss: 1.9489\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9339 - val_loss: 1.9414\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9346 - val_loss: 1.9446\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9351 - val_loss: 1.9400\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9334 - val_loss: 1.9380\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9337 - val_loss: 1.9417\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9326 - val_loss: 1.9400\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9315 - val_loss: 1.9444\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9307 - val_loss: 1.9365\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9313 - val_loss: 1.9465\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9325 - val_loss: 1.9387\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9318 - val_loss: 1.9363\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9303 - val_loss: 1.9456\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9323 - val_loss: 1.9406\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9288 - val_loss: 1.9409\n",
      "Top-2 accuracy = 0.486\n",
      "9\n",
      "normalizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1033 - val_loss: 2.0139\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9816 - val_loss: 1.9654\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9557 - val_loss: 1.9582\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9487 - val_loss: 1.9463\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9423 - val_loss: 1.9409\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9381 - val_loss: 1.9473\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9381 - val_loss: 1.9383\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9366 - val_loss: 1.9372\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9348 - val_loss: 1.9514\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9363 - val_loss: 1.9358\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9332 - val_loss: 1.9416\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9332 - val_loss: 1.9363\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9331 - val_loss: 1.9385\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9321 - val_loss: 1.9365\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9309 - val_loss: 1.9346\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9316 - val_loss: 1.9375\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9302 - val_loss: 1.9368\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9300 - val_loss: 1.9331\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9307 - val_loss: 1.9440\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9296 - val_loss: 1.9358\n",
      "Top-2 accuracy = 0.485\n",
      "10\n",
      "maxabsf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1347 - val_loss: 2.1060\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0935 - val_loss: 2.0549\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0106 - val_loss: 1.9854\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9747 - val_loss: 1.9690\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9638 - val_loss: 1.9626\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9600 - val_loss: 1.9589\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9563 - val_loss: 1.9695\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9543 - val_loss: 1.9552\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9512 - val_loss: 1.9597\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9508 - val_loss: 1.9533\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9511 - val_loss: 1.9542\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9500 - val_loss: 1.9552\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9487 - val_loss: 1.9529\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9480 - val_loss: 1.9511\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9468 - val_loss: 1.9502\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9471 - val_loss: 1.9508\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9466 - val_loss: 1.9499\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9458 - val_loss: 1.9496\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9454 - val_loss: 1.9484\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9444 - val_loss: 1.9495\n",
      "Top-2 accuracy = 0.483\n",
      "11\n",
      "minmaxQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1067 - val_loss: 2.0186\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0111 - val_loss: 2.0239\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0856 - val_loss: 2.0822\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0592 - val_loss: 2.0951\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0885 - val_loss: 2.0858\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0929 - val_loss: 2.0851\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0369 - val_loss: 2.0172\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0388 - val_loss: 2.0115\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0543 - val_loss: 2.0746\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0648 - val_loss: 2.0595\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0622 - val_loss: 2.0656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0659 - val_loss: 2.0655\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0657 - val_loss: 2.0650\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0695 - val_loss: 2.0635\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0625 - val_loss: 2.0625\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0640 - val_loss: 2.0672\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0669 - val_loss: 2.0676\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0680 - val_loss: 2.0680\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0679 - val_loss: 2.0678\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0679 - val_loss: 2.0681\n",
      "Top-2 accuracy = 0.402\n",
      "12\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1103 - val_loss: 2.0331\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.0047 - val_loss: 1.9865\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9699 - val_loss: 1.9790\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9594 - val_loss: 1.9587\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9507 - val_loss: 1.9949\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9514 - val_loss: 1.9462\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9425 - val_loss: 1.9417\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9385 - val_loss: 1.9483\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9386 - val_loss: 1.9402\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9375 - val_loss: 1.9370\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9372 - val_loss: 1.9374\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9348 - val_loss: 1.9385\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9341 - val_loss: 1.9372\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9349 - val_loss: 1.9363\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9336 - val_loss: 1.9383\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9327 - val_loss: 1.9420\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9340 - val_loss: 1.9386\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9320 - val_loss: 1.9353\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9336 - val_loss: 1.9410\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9354 - val_loss: 1.9357\n",
      "Top-2 accuracy = 0.486\n",
      "13\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1568 - val_loss: 2.1144\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1114 - val_loss: 2.1075\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1077\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1077\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1073\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1101 - val_loss: 2.1075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1060\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1012 - val_loss: 2.0916\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0765 - val_loss: 2.0384\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0347 - val_loss: 2.0443\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0810 - val_loss: 2.0883\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0557 - val_loss: 2.0542\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0474 - val_loss: 2.0355\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0331 - val_loss: 2.0298\n",
      "Top-2 accuracy = 0.442\n",
      "14\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1687 - val_loss: 2.1296\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0781 - val_loss: 2.0439\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0199 - val_loss: 2.0042\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9905 - val_loss: 1.9946\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9764 - val_loss: 1.9766\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9622 - val_loss: 1.9644\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9545 - val_loss: 1.9548\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9491 - val_loss: 1.9580\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9477 - val_loss: 1.9571\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9443 - val_loss: 1.9485\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9423 - val_loss: 1.9487\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9418 - val_loss: 1.9440\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9414 - val_loss: 1.9442\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9410 - val_loss: 1.9456\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9404 - val_loss: 1.9442\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9391 - val_loss: 1.9525\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9387 - val_loss: 1.9434\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9388 - val_loss: 1.9414\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9377 - val_loss: 1.9439\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9388 - val_loss: 1.9443\n",
      "Top-2 accuracy = 0.481\n",
      "15\n",
      "robustI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1716 - val_loss: 2.1341\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1055 - val_loss: 2.0819\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0711 - val_loss: 2.0604\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0535 - val_loss: 2.0485\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0391 - val_loss: 2.0302\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0184 - val_loss: 2.0059\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9969 - val_loss: 1.9899\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9793 - val_loss: 1.9768\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9681 - val_loss: 1.9674\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9604 - val_loss: 1.9630\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9549 - val_loss: 1.9573\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9507 - val_loss: 1.9533\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9472 - val_loss: 1.9509\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9459 - val_loss: 1.9535\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9442 - val_loss: 1.9485\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9408 - val_loss: 1.9487\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9402 - val_loss: 1.9455\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9399 - val_loss: 1.9484\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9391 - val_loss: 1.9432\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9370 - val_loss: 1.9420\n",
      "Top-2 accuracy = 0.481\n",
      "16\n",
      "minmaxR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1353 - val_loss: 2.0607\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0147 - val_loss: 1.9949\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9870 - val_loss: 1.9712\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9648 - val_loss: 1.9592\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9535 - val_loss: 1.9507\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9484 - val_loss: 1.9516\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9451 - val_loss: 1.9468\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9432 - val_loss: 1.9444\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9415 - val_loss: 1.9440\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9394 - val_loss: 1.9441\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9397 - val_loss: 1.9439\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9391 - val_loss: 1.9407\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9383 - val_loss: 1.9393\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9368 - val_loss: 1.9396\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9378 - val_loss: 1.9509\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9398 - val_loss: 1.9384\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9358 - val_loss: 1.9398\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9368 - val_loss: 1.9392\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9379 - val_loss: 1.9457\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9351 - val_loss: 1.9433\n",
      "Top-2 accuracy = 0.484\n",
      "17\n",
      "maxabsd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1528 - val_loss: 2.0866\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0461 - val_loss: 2.0064\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9774 - val_loss: 1.9588\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9537 - val_loss: 1.9487\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9464 - val_loss: 1.9478\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9425 - val_loss: 1.9447\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9420 - val_loss: 1.9429\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9387 - val_loss: 1.9454\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9401 - val_loss: 1.9466\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9398 - val_loss: 1.9401\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9394 - val_loss: 1.9381\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9359 - val_loss: 1.9451\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9454 - val_loss: 1.9391\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9361 - val_loss: 1.9391\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9351 - val_loss: 1.9414\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9358 - val_loss: 1.9467\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9380 - val_loss: 1.9361\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9354 - val_loss: 1.9373\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9342 - val_loss: 1.9363\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9340 - val_loss: 1.9420\n",
      "Top-2 accuracy = 0.482\n",
      "18\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.0914 - val_loss: 1.9908\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9902 - val_loss: 1.9798\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9746 - val_loss: 1.9703\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9626 - val_loss: 1.9598\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9565 - val_loss: 1.9559\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9516 - val_loss: 1.9524\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9452 - val_loss: 1.9659\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9422 - val_loss: 1.9542\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9372 - val_loss: 1.9371\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9350 - val_loss: 1.9421\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9353 - val_loss: 1.9377\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9337 - val_loss: 1.9414\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9333 - val_loss: 1.9381\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9365 - val_loss: 1.9366\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9325 - val_loss: 1.9354\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9323 - val_loss: 1.9415\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9354 - val_loss: 1.9377\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9319 - val_loss: 1.9393\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9327 - val_loss: 1.9436\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9304 - val_loss: 1.9354\n",
      "Top-2 accuracy = 0.484\n",
      "19\n",
      "maxabsT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1667 - val_loss: 2.1241\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1142 - val_loss: 2.1085\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1087 - val_loss: 2.1015\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0615 - val_loss: 2.0122\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9879 - val_loss: 1.9714\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9624 - val_loss: 1.9629\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9562 - val_loss: 1.9546\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9494 - val_loss: 1.9491\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9460 - val_loss: 1.9467\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9444 - val_loss: 1.9538\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9449 - val_loss: 1.9475\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9419 - val_loss: 1.9474\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9429 - val_loss: 1.9485\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9406 - val_loss: 1.9503\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9416 - val_loss: 1.9426\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9403 - val_loss: 1.9481\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9408 - val_loss: 1.9505\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9382 - val_loss: 1.9417\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9374 - val_loss: 1.9411\n",
      "Top-2 accuracy = 0.481\n",
      "20\n",
      "standardizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1566 - val_loss: 2.0770\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0095 - val_loss: 1.9880\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9807 - val_loss: 1.9819\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9797 - val_loss: 1.9817\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9835 - val_loss: 1.9855\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9854 - val_loss: 1.9867\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9863 - val_loss: 1.9879\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9864 - val_loss: 1.9879\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9963 - val_loss: 2.0158\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0499 - val_loss: 2.1084\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1116 - val_loss: 2.1081\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1103 - val_loss: 2.1076\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1100 - val_loss: 2.1073\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1102 - val_loss: 2.1073\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1103 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1102 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Top-2 accuracy = 0.384\n",
      "21\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1717 - val_loss: 2.1372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0951 - val_loss: 2.0603\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0435 - val_loss: 2.0311\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0180 - val_loss: 2.0084\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9958 - val_loss: 1.9861\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9794 - val_loss: 1.9783\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9718 - val_loss: 1.9632\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9611 - val_loss: 1.9603\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9574 - val_loss: 1.9669\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9572 - val_loss: 1.9539\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9549 - val_loss: 1.9529\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9540 - val_loss: 1.9523\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9535 - val_loss: 1.9516\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9528 - val_loss: 1.9520\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9530 - val_loss: 1.9529\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9525 - val_loss: 1.9509\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9523 - val_loss: 1.9508\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9518 - val_loss: 1.9507\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9517 - val_loss: 1.9510\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9517 - val_loss: 1.9505\n",
      "Top-2 accuracy = 0.479\n",
      "22\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1820 - val_loss: 2.1673\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1547 - val_loss: 2.1438\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1350 - val_loss: 2.1281\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1235 - val_loss: 2.1190\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1169 - val_loss: 2.1138\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1133 - val_loss: 2.1110\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1115 - val_loss: 2.1095\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1106 - val_loss: 2.1087\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1102 - val_loss: 2.1082\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "23\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 2.1413 - val_loss: 2.1087\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1102 - val_loss: 2.1078\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1100 - val_loss: 2.1073\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1103 - val_loss: 2.1074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1101 - val_loss: 2.1080\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1100 - val_loss: 2.1077\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1100 - val_loss: 2.1076\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1099 - val_loss: 2.1078\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1099 - val_loss: 2.1077\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1101 - val_loss: 2.1087\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1104 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1098 - val_loss: 2.1082\n",
      "Top-2 accuracy = 0.384\n",
      "24\n",
      "normalizee|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_7564 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1885 - val_loss: 2.1731\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1636 - val_loss: 2.1543\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1473 - val_loss: 2.1404\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1356 - val_loss: 2.1302\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1272 - val_loss: 2.1230\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1211 - val_loss: 2.1178\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1169 - val_loss: 2.1141\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1142 - val_loss: 2.1118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1124 - val_loss: 2.1102\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1112 - val_loss: 2.1091\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1103 - val_loss: 2.1079\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1088 - val_loss: 2.1048\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1032 - val_loss: 2.0945\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0893 - val_loss: 2.0786\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0730 - val_loss: 2.0663\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0627 - val_loss: 2.0586\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0478 - val_loss: 2.0266\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0160 - val_loss: 2.0090\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0021 - val_loss: 1.9948\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9876 - val_loss: 1.9829\n",
      "Top-2 accuracy = 0.468\n",
      "25\n",
      "minmaxA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1437 - val_loss: 2.0718\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0209 - val_loss: 2.0008\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9746 - val_loss: 1.9618\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9575 - val_loss: 1.9528\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9462 - val_loss: 1.9478\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9437 - val_loss: 1.9600\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9438 - val_loss: 1.9444\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9428 - val_loss: 1.9426\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9399 - val_loss: 1.9438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9415 - val_loss: 1.9486\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9397 - val_loss: 1.9548\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9400 - val_loss: 1.9411\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9378 - val_loss: 1.9500\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9399 - val_loss: 1.9449\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9373 - val_loss: 1.9449\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9388 - val_loss: 1.9418\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9390 - val_loss: 1.9403\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9392 - val_loss: 1.9402\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9372 - val_loss: 1.9381\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9367 - val_loss: 1.9398\n",
      "Top-2 accuracy = 0.481\n",
      "26\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1470 - val_loss: 2.1093\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1102 - val_loss: 2.1077\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1079\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1101 - val_loss: 2.1076\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1076\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "27\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1496 - val_loss: 2.0789\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0262 - val_loss: 1.9997\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9981 - val_loss: 2.0038\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9865 - val_loss: 1.9918\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9760 - val_loss: 1.9727\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9670 - val_loss: 1.9702\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9615 - val_loss: 1.9584\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9537 - val_loss: 1.9534\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9519 - val_loss: 1.9513\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9476 - val_loss: 1.9487\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9559 - val_loss: 1.9504\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9451 - val_loss: 1.9491\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9422 - val_loss: 1.9571\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9429 - val_loss: 1.9480\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9409 - val_loss: 1.9468\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9388 - val_loss: 1.9518\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9385 - val_loss: 1.9433\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9376 - val_loss: 1.9432\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9375 - val_loss: 1.9430\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9362 - val_loss: 1.9455\n",
      "Top-2 accuracy = 0.482\n",
      "28\n",
      "minmaxz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 2.1425 - val_loss: 2.1074\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1099 - val_loss: 2.1086\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1100 - val_loss: 2.1077\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1100 - val_loss: 2.1083\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1100 - val_loss: 2.1076\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1099 - val_loss: 2.1077\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1099 - val_loss: 2.1094\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1101 - val_loss: 2.1077\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1102 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1101 - val_loss: 2.1075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1098 - val_loss: 2.1082\n",
      "Top-2 accuracy = 0.384\n",
      "29\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 2.1326 - val_loss: 2.1087\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1104 - val_loss: 2.1077\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1100 - val_loss: 2.1076\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1101 - val_loss: 2.1075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1099 - val_loss: 2.1077\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1100 - val_loss: 2.1078\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1101 - val_loss: 2.1074\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1101 - val_loss: 2.1078\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1101 - val_loss: 2.1082\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1100 - val_loss: 2.1076\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1102 - val_loss: 2.1078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1099 - val_loss: 2.1083\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1100 - val_loss: 2.1072\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1099 - val_loss: 2.1073\n",
      "Top-2 accuracy = 0.384\n",
      "0\n",
      "normalizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1273 - val_loss: 2.0696\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0302 - val_loss: 1.9922\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9661 - val_loss: 1.9587\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9477 - val_loss: 1.9536\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9420 - val_loss: 1.9431\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9365 - val_loss: 1.9471\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9346 - val_loss: 1.9390\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9330 - val_loss: 1.9419\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9315 - val_loss: 1.9385\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9306 - val_loss: 1.9378\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9293 - val_loss: 1.9368\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9295 - val_loss: 1.9383\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9283 - val_loss: 1.9345\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9279 - val_loss: 1.9337\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9283 - val_loss: 1.9342\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9273 - val_loss: 1.9427\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9285 - val_loss: 1.9361\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9270 - val_loss: 1.9360\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9270 - val_loss: 1.9354\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9267 - val_loss: 1.9331\n",
      "Top-2 accuracy = 0.486\n",
      "1\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1650 - val_loss: 2.1268\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1127 - val_loss: 2.0987\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0803 - val_loss: 2.0505\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0305 - val_loss: 2.0137\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0018 - val_loss: 1.9969\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9864 - val_loss: 1.9811\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9758 - val_loss: 1.9740\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9693 - val_loss: 1.9680\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9641 - val_loss: 1.9650\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9602 - val_loss: 1.9615\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9577 - val_loss: 1.9601\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9554 - val_loss: 1.9609\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9531 - val_loss: 1.9540\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9515 - val_loss: 1.9525\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9508 - val_loss: 1.9528\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9497 - val_loss: 1.9499\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9481 - val_loss: 1.9495\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9470 - val_loss: 1.9494\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9472 - val_loss: 1.9503\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9468 - val_loss: 1.9480\n",
      "Top-2 accuracy = 0.481\n",
      "2\n",
      "maxabsT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1744 - val_loss: 2.1453\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1100 - val_loss: 2.0688\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0470 - val_loss: 2.0218\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0101 - val_loss: 2.0017\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9894 - val_loss: 1.9858\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9758 - val_loss: 1.9826\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9684 - val_loss: 1.9724\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9678 - val_loss: 1.9625\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9571 - val_loss: 1.9575\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9551 - val_loss: 1.9541\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9512 - val_loss: 1.9525\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9502 - val_loss: 1.9506\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9481 - val_loss: 1.9573\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9494 - val_loss: 1.9489\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9466 - val_loss: 1.9491\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9463 - val_loss: 1.9520\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9451 - val_loss: 1.9482\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9441 - val_loss: 1.9571\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9440 - val_loss: 1.9462\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9448 - val_loss: 1.9468\n",
      "Top-2 accuracy = 0.481\n",
      "3\n",
      "maxabsV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1803 - val_loss: 2.1607\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1400 - val_loss: 2.1259\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1188 - val_loss: 2.1144\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1123 - val_loss: 2.1092\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1084 - val_loss: 2.1039\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0829 - val_loss: 2.0506\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0173 - val_loss: 2.0055\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9864 - val_loss: 1.9851\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9706 - val_loss: 1.9727\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9592 - val_loss: 1.9710\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9558 - val_loss: 2.0056\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9587 - val_loss: 1.9691\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9515 - val_loss: 1.9553\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9495 - val_loss: 1.9494\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9493 - val_loss: 1.9514\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9476 - val_loss: 1.9713\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9562 - val_loss: 1.9483\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9466 - val_loss: 1.9673\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9541 - val_loss: 1.9476\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9468 - val_loss: 1.9470\n",
      "Top-2 accuracy = 0.479\n",
      "4\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1809 - val_loss: 2.1635\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1474 - val_loss: 2.1320\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1229 - val_loss: 2.1146\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1125 - val_loss: 2.1089\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1101 - val_loss: 2.1077\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1073\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1073\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "5\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1371 - val_loss: 2.0699\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0248 - val_loss: 1.9940\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9896 - val_loss: 1.9857\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9657 - val_loss: 1.9561\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9446 - val_loss: 1.9518\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9398 - val_loss: 1.9432\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9377 - val_loss: 1.9410\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9354 - val_loss: 1.9421\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9344 - val_loss: 1.9377\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9344 - val_loss: 1.9403\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9335 - val_loss: 1.9366\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9316 - val_loss: 1.9375\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9319 - val_loss: 1.9389\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9319 - val_loss: 1.9361\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9304 - val_loss: 1.9367\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9299 - val_loss: 1.9479\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9311 - val_loss: 1.9383\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9303 - val_loss: 1.9348\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9301 - val_loss: 1.9391\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9288 - val_loss: 1.9439\n",
      "Top-2 accuracy = 0.477\n",
      "6\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1598 - val_loss: 2.1289\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1191 - val_loss: 2.1104\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1106 - val_loss: 2.1084\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1078\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1100 - val_loss: 2.1077\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1078\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1073\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Top-2 accuracy = 0.384\n",
      "7\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1801 - val_loss: 2.1591\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1359 - val_loss: 2.1182\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1132 - val_loss: 2.1090\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1100 - val_loss: 2.1077\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Top-2 accuracy = 0.384\n",
      "8\n",
      "maxabsh|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_7635 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1617 - val_loss: 2.0918\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0571 - val_loss: 2.0259\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0131 - val_loss: 1.9977\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9922 - val_loss: 1.9851\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9816 - val_loss: 1.9782\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9747 - val_loss: 1.9735\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9695 - val_loss: 1.9694\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9657 - val_loss: 1.9670\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9620 - val_loss: 1.9637\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9587 - val_loss: 1.9610\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9557 - val_loss: 1.9583\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9525 - val_loss: 1.9559\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9500 - val_loss: 1.9533\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9472 - val_loss: 1.9511\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9451 - val_loss: 1.9491\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9431 - val_loss: 1.9466\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9414 - val_loss: 1.9452\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9399 - val_loss: 1.9440\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9385 - val_loss: 1.9428\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9374 - val_loss: 1.9419\n",
      "Top-2 accuracy = 0.487\n",
      "9\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1844 - val_loss: 2.1722\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1628 - val_loss: 2.1537\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1468 - val_loss: 2.1398\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1350 - val_loss: 2.1297\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1267 - val_loss: 2.1225\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1210 - val_loss: 2.1176\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1170 - val_loss: 2.1142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1142 - val_loss: 2.1118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1125 - val_loss: 2.1103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1101 - val_loss: 2.1082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "10\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1849 - val_loss: 2.1706\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1516 - val_loss: 2.1247\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0993 - val_loss: 2.0762\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0617 - val_loss: 2.0497\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0404 - val_loss: 2.0374\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0271 - val_loss: 2.0225\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0160 - val_loss: 2.0132\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0073 - val_loss: 2.0054\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0000 - val_loss: 1.9990\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9938 - val_loss: 1.9947\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9884 - val_loss: 1.9904\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9842 - val_loss: 1.9863\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9806 - val_loss: 1.9823\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9774 - val_loss: 1.9797\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9743 - val_loss: 1.9770\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9718 - val_loss: 1.9751\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9694 - val_loss: 1.9739\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9675 - val_loss: 1.9726\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9656 - val_loss: 1.9710\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9643 - val_loss: 1.9696\n",
      "Top-2 accuracy = 0.481\n",
      "11\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1775 - val_loss: 2.1493\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1149 - val_loss: 2.0822\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0496 - val_loss: 2.0183\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9913 - val_loss: 1.9774\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9644 - val_loss: 1.9622\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9542 - val_loss: 1.9534\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9491 - val_loss: 1.9544\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9464 - val_loss: 1.9497\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9460 - val_loss: 1.9469\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9424 - val_loss: 1.9472\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9413 - val_loss: 1.9453\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9396 - val_loss: 1.9433\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9385 - val_loss: 1.9452\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9374 - val_loss: 1.9438\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9378 - val_loss: 1.9517\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9382 - val_loss: 1.9461\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9358 - val_loss: 1.9407\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9351 - val_loss: 1.9477\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9347 - val_loss: 1.9407\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9358 - val_loss: 1.9396\n",
      "Top-2 accuracy = 0.483\n",
      "12\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1474 - val_loss: 2.1123\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1110 - val_loss: 2.1076\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1077\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1100 - val_loss: 2.1079\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1073\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1101 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1077\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1099 - val_loss: 2.1073\n",
      "Top-2 accuracy = 0.384\n",
      "13\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1193 - val_loss: 2.0269\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9804 - val_loss: 1.9722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9613 - val_loss: 1.9671\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9574 - val_loss: 1.9592\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9549 - val_loss: 1.9565\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9537 - val_loss: 1.9577\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9504 - val_loss: 1.9562\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9483 - val_loss: 1.9554\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9466 - val_loss: 1.9494\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9432 - val_loss: 1.9478\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9430 - val_loss: 1.9475\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9427 - val_loss: 1.9496\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9416 - val_loss: 1.9447\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9403 - val_loss: 1.9451\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9400 - val_loss: 1.9455\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9465\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9390 - val_loss: 1.9440\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9409 - val_loss: 1.9462\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9400 - val_loss: 1.9449\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9376 - val_loss: 1.9463\n",
      "Top-2 accuracy = 0.481\n",
      "14\n",
      "standardizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1789 - val_loss: 2.1574\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1436 - val_loss: 2.1307\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1248 - val_loss: 2.1179\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1158 - val_loss: 2.1116\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1118 - val_loss: 2.1088\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1103 - val_loss: 2.1079\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "15\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1471 - val_loss: 2.1136\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1124 - val_loss: 2.1073\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1075\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1073\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1075\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1073\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1100 - val_loss: 2.1074\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1099 - val_loss: 2.1076\n",
      "Top-2 accuracy = 0.384\n",
      "16\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1684 - val_loss: 2.1327\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0940 - val_loss: 2.0521\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0227 - val_loss: 2.0040\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9868 - val_loss: 1.9768\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9646 - val_loss: 1.9649\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9505 - val_loss: 1.9506\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9436 - val_loss: 1.9504\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9412 - val_loss: 1.9450\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9380 - val_loss: 1.9410\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9365 - val_loss: 1.9402\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9360 - val_loss: 1.9391\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9353 - val_loss: 1.9399\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9345 - val_loss: 1.9424\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9341 - val_loss: 1.9401\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9339 - val_loss: 1.9401\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9337 - val_loss: 1.9374\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9326 - val_loss: 1.9377\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9318 - val_loss: 1.9376\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9324 - val_loss: 1.9397\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9356 - val_loss: 1.9354\n",
      "Top-2 accuracy = 0.486\n",
      "17\n",
      "minmaxb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1595 - val_loss: 2.1057\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0607 - val_loss: 2.0340\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0125 - val_loss: 1.9804\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9699 - val_loss: 1.9693\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9598 - val_loss: 1.9563\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9543 - val_loss: 1.9529\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9501 - val_loss: 1.9502\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9479 - val_loss: 1.9499\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9467 - val_loss: 1.9464\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9447 - val_loss: 1.9465\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9436 - val_loss: 1.9455\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9436 - val_loss: 1.9462\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9422 - val_loss: 1.9436\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9413 - val_loss: 1.9425\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9410 - val_loss: 1.9422\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9405 - val_loss: 1.9415\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9395 - val_loss: 1.9394\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9390 - val_loss: 1.9411\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9386 - val_loss: 1.9399\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9379 - val_loss: 1.9390\n",
      "Top-2 accuracy = 0.483\n",
      "18\n",
      "robustv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1528 - val_loss: 2.1238\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1091 - val_loss: 2.0897\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0655 - val_loss: 2.0396\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0193 - val_loss: 2.0047\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9952 - val_loss: 1.9880\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9809 - val_loss: 1.9761\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9678 - val_loss: 1.9668\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9595 - val_loss: 1.9592\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9533 - val_loss: 1.9557\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9502 - val_loss: 1.9530\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9478 - val_loss: 1.9527\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9464 - val_loss: 1.9501\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9441 - val_loss: 1.9500\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9424 - val_loss: 1.9471\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9413 - val_loss: 1.9465\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9404 - val_loss: 1.9453\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9393 - val_loss: 1.9450\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9385 - val_loss: 1.9440\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9384 - val_loss: 1.9434\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9372 - val_loss: 1.9430\n",
      "Top-2 accuracy = 0.483\n",
      "19\n",
      "minmaxG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1881 - val_loss: 2.1727\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1634 - val_loss: 2.1542\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1477 - val_loss: 2.1406\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1358 - val_loss: 2.1304\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1274 - val_loss: 2.1231\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1213 - val_loss: 2.1179\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1172 - val_loss: 2.1143\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1144 - val_loss: 2.1119\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1125 - val_loss: 2.1103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1114 - val_loss: 2.1093\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1106 - val_loss: 2.1087\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1102 - val_loss: 2.1082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "20\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1700 - val_loss: 2.1465\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1348 - val_loss: 2.1220\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1191 - val_loss: 2.1129\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1134 - val_loss: 2.1095\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1110 - val_loss: 2.1083\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1102 - val_loss: 2.1077\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.1075\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1073\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1073\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1074\n",
      "Top-2 accuracy = 0.384\n",
      "21\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0960 - val_loss: 2.0172\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9885 - val_loss: 1.9789\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9575 - val_loss: 1.9538\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9475 - val_loss: 1.9521\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9417 - val_loss: 1.9468\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9398 - val_loss: 1.9430\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9358 - val_loss: 1.9398\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9346 - val_loss: 1.9402\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9326 - val_loss: 1.9412\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9333 - val_loss: 1.9400\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9310 - val_loss: 1.9416\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9310 - val_loss: 1.9443\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9323 - val_loss: 1.9390\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9305 - val_loss: 1.9397\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9306 - val_loss: 1.9402\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9294 - val_loss: 1.9400\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9301 - val_loss: 1.9354\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9289 - val_loss: 1.9389\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9289 - val_loss: 1.9357\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9284 - val_loss: 1.9384\n",
      "Top-2 accuracy = 0.482\n",
      "22\n",
      "minmaxn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1844 - val_loss: 2.1723\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1629 - val_loss: 2.1538\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1468 - val_loss: 2.1400\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1353 - val_loss: 2.1299\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1268 - val_loss: 2.1227\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1210 - val_loss: 2.1177\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1170 - val_loss: 2.1142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1142 - val_loss: 2.1118\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1124 - val_loss: 2.1102\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1113 - val_loss: 2.1092\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1106 - val_loss: 2.1086\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1102 - val_loss: 2.1082\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1080\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1098 - val_loss: 2.1078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1077\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1097 - val_loss: 2.1076\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1096 - val_loss: 2.1075\n",
      "Top-2 accuracy = 0.384\n",
      "23\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1585 - val_loss: 2.0982\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0324 - val_loss: 1.9906\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9774 - val_loss: 1.9703\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9667 - val_loss: 1.9662\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9601 - val_loss: 1.9583\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9556 - val_loss: 1.9558\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9535 - val_loss: 1.9515\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9502 - val_loss: 1.9497\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9492 - val_loss: 1.9492\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9480 - val_loss: 1.9478\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9470 - val_loss: 1.9476\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9467 - val_loss: 1.9459\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9462 - val_loss: 1.9464\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9451 - val_loss: 1.9455\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9447 - val_loss: 1.9507\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9446 - val_loss: 1.9446\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9435 - val_loss: 1.9444\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9433 - val_loss: 1.9452\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9432 - val_loss: 1.9461\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9444 - val_loss: 1.9430\n",
      "Top-2 accuracy = 0.483\n",
      "24\n",
      "standardizem|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1688 - val_loss: 2.1281\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0774 - val_loss: 2.0359\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0015 - val_loss: 1.9897\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9733 - val_loss: 1.9812\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9631 - val_loss: 1.9628\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9558 - val_loss: 1.9536\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9494 - val_loss: 1.9506\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9434 - val_loss: 1.9468\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9413 - val_loss: 1.9468\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9406 - val_loss: 1.9419\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9376 - val_loss: 1.9428\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9395 - val_loss: 1.9599\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9401 - val_loss: 1.9483\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9373 - val_loss: 1.9406\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9357 - val_loss: 1.9514\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9368 - val_loss: 1.9427\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9351 - val_loss: 1.9392\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9343 - val_loss: 1.9408\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9349 - val_loss: 1.9441\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9339 - val_loss: 1.9391\n",
      "Top-2 accuracy = 0.485\n",
      "25\n",
      "minmaxO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1637 - val_loss: 2.1306\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1047 - val_loss: 2.0755\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0530 - val_loss: 2.0325\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0163 - val_loss: 1.9985\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9876 - val_loss: 1.9808\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9728 - val_loss: 1.9697\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9639 - val_loss: 1.9568\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9532 - val_loss: 1.9547\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9491 - val_loss: 1.9579\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9489 - val_loss: 1.9445\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9432 - val_loss: 1.9519\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9429 - val_loss: 1.9413\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9401 - val_loss: 1.9423\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9399 - val_loss: 1.9409\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9403\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9385 - val_loss: 1.9387\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9369 - val_loss: 1.9389\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9371 - val_loss: 1.9384\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9371 - val_loss: 1.9381\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9364 - val_loss: 1.9382\n",
      "Top-2 accuracy = 0.486\n",
      "26\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1663 - val_loss: 2.1204\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0810 - val_loss: 2.0459\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0193 - val_loss: 1.9977\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9859 - val_loss: 1.9785\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9724 - val_loss: 1.9721\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9656 - val_loss: 1.9678\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9613 - val_loss: 1.9618\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9572 - val_loss: 1.9585\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9536 - val_loss: 1.9545\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9494 - val_loss: 1.9535\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9468 - val_loss: 1.9511\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9442 - val_loss: 1.9476\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9424 - val_loss: 1.9462\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9412 - val_loss: 1.9451\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9404 - val_loss: 1.9439\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9391 - val_loss: 1.9434\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9384 - val_loss: 1.9434\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9376 - val_loss: 1.9432\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9388 - val_loss: 1.9426\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9371 - val_loss: 1.9417\n",
      "Top-2 accuracy = 0.484\n",
      "27\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1668 - val_loss: 2.1238\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0999 - val_loss: 2.0838\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0605 - val_loss: 2.0435\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.0347 - val_loss: 2.0388\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0422 - val_loss: 2.0375\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0389 - val_loss: 2.0373\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0374 - val_loss: 2.0343\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0357 - val_loss: 2.0314\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0352 - val_loss: 2.0318\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0353 - val_loss: 2.0216\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0229 - val_loss: 2.0161\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0196 - val_loss: 2.0145\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0191 - val_loss: 2.0142\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0165 - val_loss: 2.0126\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0154 - val_loss: 2.0120\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0151 - val_loss: 2.0118\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0150 - val_loss: 2.0116\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0193 - val_loss: 2.0154\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0205 - val_loss: 2.0175\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0191 - val_loss: 2.0172\n",
      "Top-2 accuracy = 0.45\n",
      "28\n",
      "minmaxW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1574 - val_loss: 2.1174\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0730 - val_loss: 2.0294\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9911 - val_loss: 1.9848\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9661 - val_loss: 1.9584\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9547 - val_loss: 1.9553\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9511 - val_loss: 1.9559\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9492 - val_loss: 1.9481\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9455 - val_loss: 1.9482\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9442 - val_loss: 1.9474\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9474 - val_loss: 1.9446\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9441 - val_loss: 1.9435\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9426 - val_loss: 1.9426\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9408 - val_loss: 1.9430\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9417 - val_loss: 1.9418\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9404 - val_loss: 1.9411\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9402 - val_loss: 1.9436\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9396 - val_loss: 1.9544\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9419 - val_loss: 1.9410\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9396 - val_loss: 1.9400\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9384 - val_loss: 1.9397\n",
      "Top-2 accuracy = 0.482\n",
      "29\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1307 - val_loss: 2.0636\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0194 - val_loss: 1.9925\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9735 - val_loss: 1.9708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9666 - val_loss: 1.9716\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9617 - val_loss: 1.9623\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9572 - val_loss: 1.9585\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9539 - val_loss: 1.9536\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9492 - val_loss: 1.9503\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9471 - val_loss: 1.9501\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9457 - val_loss: 1.9493\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9445 - val_loss: 1.9474\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9437 - val_loss: 1.9569\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9438 - val_loss: 1.9453\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9453 - val_loss: 1.9447\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9418 - val_loss: 1.9462\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9409 - val_loss: 1.9492\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9414 - val_loss: 1.9434\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9406 - val_loss: 1.9446\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9404 - val_loss: 1.9448\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9411 - val_loss: 1.9463\n",
      "Top-2 accuracy = 0.481\n"
     ]
    }
   ],
   "source": [
    "top2 = []\n",
    "\n",
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"accuracy\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [MulticlassDL(n_classes=9, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20)],\n",
    "    \"post_train_hooks\": [top2_hook],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"eclipse-9class\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        MulticlassDL(n_classes=9, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.3252099880006857\n",
      "Top-2 Accuracy: 0.49000057139592024\n"
     ]
    }
   ],
   "source": [
    "interp = DODGEInterpreter(files=['./eclipse-9class.txt'], max_by=0, \n",
    "                          metrics=['accuracy'])\n",
    "results = interp.interpret()['eclipse-9class.txt']\n",
    "print('Top-1 Accuracy:', np.median(results['accuracy']))\n",
    "print('Top-2 Accuracy:', np.median(np.amax(np.array(top2).reshape(10,30), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
