{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from raise_utils.learners import MulticlassDL, FeedforwardDL\n",
    "from raise_utils.data import Data\n",
    "from raise_utils.hyperparams import DODGE\n",
    "from raise_utils.interpret import DODGEInterpreter\n",
    "from keras.utils import to_categorical\n",
    "from raise_utils.hooks import Hook\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./chromium-common.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>bugID</th>\n",
       "      <th>user_comments</th>\n",
       "      <th>system_records</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350007</td>\n",
       "      <td>['inactive', 'v1', 'app', 'window', 'seems', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>350009</td>\n",
       "      <td>['enable', 'api', 'features', 'json', 'block',...</td>\n",
       "      <td>['blocking', 'chromium', 'blocking', 'chromium...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>350029</td>\n",
       "      <td>['webkitpersistentstorage', 'infobar', 'doesn'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>350031</td>\n",
       "      <td>['unable', 'pass', 'pp', 'reported', 'nona', '...</td>\n",
       "      <td>['cc', 'raymes', 'mgiuca']</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>350045</td>\n",
       "      <td>['chrome', 'chromeos', 'reported', 'dharani', ...</td>\n",
       "      <td>['owner', 'reve']</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   bugID  \\\n",
       "0           0             0  350007   \n",
       "1           9             9  350009   \n",
       "2          13            13  350029   \n",
       "3          18            18  350031   \n",
       "4          21            21  350045   \n",
       "\n",
       "                                       user_comments  \\\n",
       "0  ['inactive', 'v1', 'app', 'window', 'seems', '...   \n",
       "1  ['enable', 'api', 'features', 'json', 'block',...   \n",
       "2  ['webkitpersistentstorage', 'infobar', 'doesn'...   \n",
       "3  ['unable', 'pass', 'pp', 'reported', 'nona', '...   \n",
       "4  ['chrome', 'chromeos', 'reported', 'dharani', ...   \n",
       "\n",
       "                                      system_records  s1  s2  s3   s4  s5  s6  \\\n",
       "0                                                 []   1   1   0   24   1   0   \n",
       "1  ['blocking', 'chromium', 'blocking', 'chromium...   4   1   3   36   1   0   \n",
       "2                                                 []   1   1   0   26   1   0   \n",
       "3                         ['cc', 'raymes', 'mgiuca']   3   2   1  245   1   0   \n",
       "4                                  ['owner', 'reve']   4   3   1   37   1   0   \n",
       "\n",
       "          s7  s8      s9   y  \n",
       "0  [0, 0, 0]   1  [1, 0]  24  \n",
       "1  [0, 0, 0]   1  [1, 1]  18  \n",
       "2  [0, 0, 0]   1  [1, 0]  64  \n",
       "3  [0, 0, 0]   3  [1, 1]  14  \n",
       "4  [0, 0, 0]   2  [1, 1]   6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'bugID', 'Unnamed: 0.1'], axis=1, inplace=True)\n",
    "_df = df[['s1', 's2', 's3', 's4', 's5', 's6', 's8', 'y']]\n",
    "_df['s70'] = df['s7'].apply(lambda x: eval(x)[0])\n",
    "_df['s71'] = df['s7'].apply(lambda x: eval(x)[1])\n",
    "_df['s72'] = df['s7'].apply(lambda x: eval(x)[2])\n",
    "_df['s90'] = df['s9'].apply(lambda x: eval(x)[0])\n",
    "_df['s91'] = df['s9'].apply(lambda x: eval(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = _df.drop('y', axis=1)\n",
    "y = _df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = np.where(data.y_train < 5, 0, 1)\n",
    "data.y_test = np.where(data.y_test < 5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14721"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.y_test) + len(data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7641304347826087"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.y_train) / len(data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for WFO\n",
    "data.y_train = 1 - data.y_train\n",
    "data.y_test = 1 - data.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2358695652173913"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.y_train) / len(data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f355490>, 'loss': 'binary_crossentropy', 'n_epochs': 20, 'n_layers': 3, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f355f70>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14cb8d1f0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14cb8d130>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14fd235b0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14fb70220>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14cb8d0a0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14fb70730>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14fb70820>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x15016d250>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x148837640>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1488379a0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x148837910>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x148837130>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14a3b7190>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f3f1490>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f3f1400>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f3f17f0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f3f1c70>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f3f1b20>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f785970>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1501aa070>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1501aa3a0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1501aa3d0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1501aaa90>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1501aa880>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14fd54f70>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14fd54970>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14fd54c70>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f6cbfa0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f6cbbe0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f343970>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f3435e0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f343d00>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14f343670>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14cf2fa90>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x142b56610>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x142b569d0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x142b56700>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x142b56220>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x142b561f0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d987b50>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d987bb0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14d987a00>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14bc5adc0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x146244520>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14ef3b040>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x145e29ee0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x147f1e970>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14efb1370>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14efb18e0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmaxP|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_693 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7355 - val_loss: 2.5360\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7177 - val_loss: 2.5569\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7114 - val_loss: 2.5609\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7042 - val_loss: 2.5145\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6944 - val_loss: 2.5375\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6836 - val_loss: 2.5026\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6598 - val_loss: 2.4183\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.5765 - val_loss: 2.1328\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3967 - val_loss: 1.8765\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3680 - val_loss: 1.8181\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3633 - val_loss: 1.8254\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3588 - val_loss: 1.8881\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3513 - val_loss: 1.8327\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3505 - val_loss: 1.7221\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3508 - val_loss: 1.9348\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3486 - val_loss: 1.8384\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3487 - val_loss: 1.7373\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3511 - val_loss: 1.7674\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3481 - val_loss: 1.8710\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3477 - val_loss: 1.8008\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3473 - val_loss: 1.8133\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3471 - val_loss: 1.7695\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3470 - val_loss: 1.7955\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3465 - val_loss: 1.7596\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3466 - val_loss: 1.6906\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3470 - val_loss: 1.8467\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3463 - val_loss: 1.8069\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3462 - val_loss: 1.8425\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3461 - val_loss: 1.7022\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3461 - val_loss: 1.6695\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3461 - val_loss: 1.8246\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3466 - val_loss: 1.7546\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3461 - val_loss: 1.8415\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3457 - val_loss: 1.8142\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3458 - val_loss: 1.9373\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3463 - val_loss: 1.8462\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3461 - val_loss: 1.7676\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3456 - val_loss: 1.8201\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3450 - val_loss: 1.8290\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3460 - val_loss: 1.7405\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3458 - val_loss: 1.7336\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3458 - val_loss: 1.8068\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3450 - val_loss: 1.8030\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3451 - val_loss: 1.7010\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3453 - val_loss: 1.8586\n",
      "1\n",
      "standardizer|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_700 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7675 - val_loss: 2.4462\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7160 - val_loss: 2.4971\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7118 - val_loss: 2.4979\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7103 - val_loss: 2.4581\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7093 - val_loss: 2.5520\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7072 - val_loss: 2.4941\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7037 - val_loss: 2.5021\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6958 - val_loss: 2.5095\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6766 - val_loss: 2.4305\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6349 - val_loss: 2.3332\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.5618 - val_loss: 2.1749\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4616 - val_loss: 2.0452\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4058 - val_loss: 1.9561\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3813 - val_loss: 1.8973\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3706 - val_loss: 1.8477\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3643 - val_loss: 1.7724\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3604 - val_loss: 1.7974\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3560 - val_loss: 1.8536\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3541 - val_loss: 1.9039\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3513 - val_loss: 1.7948\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3491 - val_loss: 1.8000\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3472 - val_loss: 1.7763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3472 - val_loss: 1.7352\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3463 - val_loss: 1.7640\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3448 - val_loss: 1.7770\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3449 - val_loss: 1.7950\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3442 - val_loss: 1.8306\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3431 - val_loss: 1.7880\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3427 - val_loss: 1.7753\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3431 - val_loss: 1.7968\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3421 - val_loss: 1.8097\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3421 - val_loss: 1.8194\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3423 - val_loss: 1.7996\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3412 - val_loss: 1.8422\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3413 - val_loss: 1.7801\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3412 - val_loss: 1.7769\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.7768\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.7812\n",
      "2\n",
      "standardizem|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_704 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7177 - val_loss: 2.5181\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7073 - val_loss: 2.5440\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7035 - val_loss: 2.4382\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.6995 - val_loss: 2.5148\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6792 - val_loss: 2.5518\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.6050 - val_loss: 2.2726\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.4881 - val_loss: 1.7672\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3958 - val_loss: 1.9677\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3606 - val_loss: 2.1114\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3505 - val_loss: 1.6962\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3431 - val_loss: 1.7827\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3396 - val_loss: 1.7768\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3375 - val_loss: 1.6992\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3339 - val_loss: 1.7971\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3319 - val_loss: 1.9005\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3324 - val_loss: 1.7182\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3350 - val_loss: 1.9786\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3309 - val_loss: 1.6928\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3305 - val_loss: 1.6669\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3265 - val_loss: 1.8649\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3267 - val_loss: 1.6487\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3275 - val_loss: 1.5911\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3281 - val_loss: 1.6486\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3253 - val_loss: 1.8339\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3277 - val_loss: 1.6870\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3247 - val_loss: 1.4992\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3248 - val_loss: 1.6657\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3232 - val_loss: 1.8965\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3223 - val_loss: 1.6020\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3243 - val_loss: 1.7234\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3227 - val_loss: 1.7696\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3236 - val_loss: 1.6529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3241 - val_loss: 1.6583\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3237 - val_loss: 1.7358\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3204 - val_loss: 1.8246\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3209 - val_loss: 1.5826\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3207 - val_loss: 1.8481\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3207 - val_loss: 1.6151\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3201 - val_loss: 1.7367\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3196 - val_loss: 1.9244\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3206 - val_loss: 1.7209\n",
      "3\n",
      "minmaxa|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_711 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 2.5047\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7190 - val_loss: 2.5282\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7165 - val_loss: 2.5334\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7142 - val_loss: 2.5332\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7131 - val_loss: 2.5404\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7125 - val_loss: 2.5063\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7118 - val_loss: 2.5526\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7109 - val_loss: 2.5386\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7092 - val_loss: 2.5680\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7025 - val_loss: 2.5324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6788 - val_loss: 2.3895\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6231 - val_loss: 2.3226\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.5465 - val_loss: 2.2054\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4803 - val_loss: 2.0807\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4354 - val_loss: 1.9952\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4077 - val_loss: 2.0031\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3907 - val_loss: 1.9049\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3791 - val_loss: 1.8467\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3713 - val_loss: 1.8312\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3661 - val_loss: 1.7590\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3620 - val_loss: 1.7854\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3592 - val_loss: 1.8237\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3565 - val_loss: 1.8732\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3550 - val_loss: 1.7814\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3534 - val_loss: 1.8371\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3519 - val_loss: 1.7101\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3511 - val_loss: 1.8220\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3505 - val_loss: 1.8262\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3498 - val_loss: 1.7954\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3495 - val_loss: 1.8338\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3492 - val_loss: 1.7942\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3479 - val_loss: 1.7887\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3474 - val_loss: 1.7770\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3469 - val_loss: 1.9128\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3471 - val_loss: 1.8457\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3462 - val_loss: 1.7618\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3460 - val_loss: 1.8096\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3459 - val_loss: 1.8318\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3455 - val_loss: 1.8085\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3452 - val_loss: 1.8163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3450 - val_loss: 1.7519\n",
      "4\n",
      "robustS|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_714 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7541 - val_loss: 2.5548\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7122 - val_loss: 2.5955\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7042 - val_loss: 2.5685\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6763 - val_loss: 2.5337\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.5287 - val_loss: 1.8094\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3716 - val_loss: 1.7080\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3519 - val_loss: 1.8673\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3461 - val_loss: 1.8542\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3418 - val_loss: 1.8481\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3430 - val_loss: 1.8341\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3384 - val_loss: 1.8133\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3370 - val_loss: 1.7966\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3365 - val_loss: 1.8887\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3346 - val_loss: 1.7697\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3331 - val_loss: 1.5670\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3333 - val_loss: 1.7389\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3322 - val_loss: 1.8647\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3342 - val_loss: 1.7881\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3300 - val_loss: 1.6878\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3295 - val_loss: 1.8314\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3310 - val_loss: 1.6550\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3294 - val_loss: 1.9188\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3300 - val_loss: 1.6924\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3282 - val_loss: 1.5896\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3286 - val_loss: 1.8518\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3293 - val_loss: 1.7709\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3280 - val_loss: 1.7517\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3257 - val_loss: 1.8068\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3262 - val_loss: 1.8427\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3264 - val_loss: 1.9955\n",
      "5\n",
      "minmaxt|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_720 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7207 - val_loss: 2.4455\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7105 - val_loss: 2.4981\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7004 - val_loss: 2.3937\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6656 - val_loss: 2.4523\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.5705 - val_loss: 2.2114\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.4719 - val_loss: 1.9401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4102 - val_loss: 1.8060\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3793 - val_loss: 1.7777\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3652 - val_loss: 1.7585\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3567 - val_loss: 1.5985\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3532 - val_loss: 1.7937\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3483 - val_loss: 1.7599\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3465 - val_loss: 1.8507\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3452 - val_loss: 1.7637\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3435 - val_loss: 1.6786\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3427 - val_loss: 1.7467\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3427 - val_loss: 1.9581\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3417 - val_loss: 1.8483\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.7713\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3401 - val_loss: 1.7334\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3401 - val_loss: 1.8269\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3401 - val_loss: 1.7858\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3396 - val_loss: 1.8265\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3391 - val_loss: 1.7909\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3398 - val_loss: 1.7807\n",
      "6\n",
      "standardizeg|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_723 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7270 - val_loss: 2.5129\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7131 - val_loss: 2.5102\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7098 - val_loss: 2.6325\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7069 - val_loss: 2.4846\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7012 - val_loss: 2.5221\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6893 - val_loss: 2.5717\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6516 - val_loss: 2.3773\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.5066 - val_loss: 2.0309\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4070 - val_loss: 1.7775\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3693 - val_loss: 1.9152\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3557 - val_loss: 1.7920\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3489 - val_loss: 1.7644\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3470 - val_loss: 1.7750\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3438 - val_loss: 1.7836\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3421 - val_loss: 1.8455\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3399 - val_loss: 1.8659\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3387 - val_loss: 1.7239\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3380 - val_loss: 1.7341\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3394 - val_loss: 1.7016\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3361 - val_loss: 1.8060\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3371 - val_loss: 1.8552\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3352 - val_loss: 1.6659\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3363 - val_loss: 1.8137\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3335 - val_loss: 1.6726\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3362 - val_loss: 1.6434\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3329 - val_loss: 1.8770\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3322 - val_loss: 1.8534\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3321 - val_loss: 1.7707\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3322 - val_loss: 1.7374\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3305 - val_loss: 1.7954\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3306 - val_loss: 1.7006\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3301 - val_loss: 1.8001\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3304 - val_loss: 1.8154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3310 - val_loss: 1.7962\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3304 - val_loss: 1.7809\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3308 - val_loss: 1.7458\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3295 - val_loss: 1.8586\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3296 - val_loss: 1.7828\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3289 - val_loss: 1.8352\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3302 - val_loss: 1.8763\n",
      "7\n",
      "standardizeC|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_730 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7483 - val_loss: 2.5071\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7194 - val_loss: 2.5653\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7152 - val_loss: 2.5142\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7126 - val_loss: 2.5430\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7098 - val_loss: 2.4978\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7075 - val_loss: 2.4918\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7056 - val_loss: 2.5325\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7032 - val_loss: 2.5103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6980 - val_loss: 2.4693\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6868 - val_loss: 2.4491\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6564 - val_loss: 2.3958\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.5919 - val_loss: 2.1906\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.5056 - val_loss: 1.9094\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4278 - val_loss: 1.7236\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3873 - val_loss: 2.0504\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3701 - val_loss: 1.8602\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3618 - val_loss: 1.7437\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3552 - val_loss: 1.7962\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3516 - val_loss: 1.7575\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3499 - val_loss: 1.9134\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3469 - val_loss: 1.7579\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3457 - val_loss: 2.0024\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3443 - val_loss: 1.6392\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3423 - val_loss: 1.8445\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3430 - val_loss: 1.7578\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3416 - val_loss: 1.8591\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3397 - val_loss: 1.8904\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3390 - val_loss: 1.7099\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3380 - val_loss: 1.8235\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3380 - val_loss: 1.8379\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.7603\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3365 - val_loss: 1.6943\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3360 - val_loss: 1.7792\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3352 - val_loss: 1.8015\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3356 - val_loss: 1.8025\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3348 - val_loss: 1.7833\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3336 - val_loss: 1.6549\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3338 - val_loss: 1.8570\n",
      "8\n",
      "maxabsC|rf\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.8168 - val_loss: 2.3369\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7129 - val_loss: 2.4961\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6065 - val_loss: 2.2631\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4787 - val_loss: 2.1550\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4073 - val_loss: 1.9587\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3755 - val_loss: 1.9722\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3622 - val_loss: 1.9551\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3555 - val_loss: 1.8769\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3512 - val_loss: 1.8599\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3483 - val_loss: 1.8004\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3466 - val_loss: 1.8376\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3455 - val_loss: 1.7451\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3443 - val_loss: 1.9122\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3436 - val_loss: 1.7871\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3434 - val_loss: 1.7967\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3430 - val_loss: 1.8153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3424 - val_loss: 1.8018\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3422 - val_loss: 1.8226\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3420 - val_loss: 1.7539\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3420 - val_loss: 1.8378\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3417 - val_loss: 1.7816\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3418 - val_loss: 1.7558\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3415 - val_loss: 1.8057\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3415 - val_loss: 1.9308\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3416 - val_loss: 1.7933\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3409 - val_loss: 1.7503\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3410 - val_loss: 1.8030\n",
      "9\n",
      "minmaxE|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_738 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7549 - val_loss: 2.5444\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7155 - val_loss: 2.4692\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7124 - val_loss: 2.5192\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7098 - val_loss: 2.6283\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.7045 - val_loss: 2.5064\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6866 - val_loss: 2.3080\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.6351 - val_loss: 2.3676\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.5218 - val_loss: 2.0388\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.4291 - val_loss: 1.8340\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3861 - val_loss: 1.7909\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3634 - val_loss: 1.7052\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3541 - val_loss: 1.8236\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3490 - val_loss: 1.8509\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3464 - val_loss: 1.7901\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3442 - val_loss: 1.7024\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3444 - val_loss: 1.7265\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3421 - val_loss: 1.8271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3422 - val_loss: 1.7823\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3411 - val_loss: 1.8051\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3411 - val_loss: 1.7023\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3402 - val_loss: 1.9490\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.7355\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.6971\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3392 - val_loss: 1.6859\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3393 - val_loss: 1.7653\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3394 - val_loss: 1.9585\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3387 - val_loss: 1.7538\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3394 - val_loss: 1.7373\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3394 - val_loss: 1.7932\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3376 - val_loss: 1.7364\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3381 - val_loss: 1.7746\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3381 - val_loss: 1.9271\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3376 - val_loss: 1.7538\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3366 - val_loss: 1.7486\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.3373 - val_loss: 1.7811\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3368 - val_loss: 1.8028\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3360 - val_loss: 1.8368\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.8773\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.3378 - val_loss: 1.8682\n",
      "10\n",
      "maxabsK|rf\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 1.7425 - val_loss: 2.5524\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7335 - val_loss: 2.5122\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7335 - val_loss: 2.5588\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7336 - val_loss: 2.6027\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7335 - val_loss: 2.5922\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.5421\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7332 - val_loss: 2.6312\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7333 - val_loss: 2.6645\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7337 - val_loss: 2.5750\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 1.7334 - val_loss: 2.5939\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.5614\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.5273\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.7068\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7339 - val_loss: 2.5978\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7335 - val_loss: 2.6025\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7333 - val_loss: 2.5033\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.5216\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.5835\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7336 - val_loss: 2.4896\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7335 - val_loss: 2.5367\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.5919\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7333 - val_loss: 2.5485\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.5467\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.5350\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.5381\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7335 - val_loss: 2.5596\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.5387\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.6060\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7334 - val_loss: 2.6277\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.7335 - val_loss: 2.6173\n",
      "Epoch 31/50\n",
      " 61/123 [=============>................] - ETA: 0s - loss: 1.7331"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fba1cf11529b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdodge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDODGE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdodge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/raise_utils/hyperparams/dodge.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m                     model.set_data(data.x_train, data.y_train,\n\u001b[1;32m     74\u001b[0m                                    data.x_test, data.y_test)\n\u001b[0;32m---> 75\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0;31m# Run post-training hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/raise_utils/learners/feedforward.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         self.model.fit(np.array(self.x_train), np.array(self.y_train), batch_size=512, epochs=self.n_epochs,\n\u001b[0m\u001b[1;32m     90\u001b[0m                        validation_split=0.2, verbose=self.verbose, callbacks=[\n\u001b[1;32m     91\u001b[0m             \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"d2h\", \"accuracy\", \"pd\", \"prec\", \"pf\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [FeedforwardDL(random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20, weighted=True, wfo=True)],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"chromium\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        FeedforwardDL(random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=50, weighted=True, wfo=True))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': array([0.68258957, 0.68333238, 0.68316096, 0.68327524, 0.68418947,\n",
      "       0.68373236, 0.68241815, 0.68396092, 0.68310382, 0.68253243]), 'pd': array([0.69987184, 0.71490155, 0.71897938, 0.70511476, 0.67062799,\n",
      "       0.71292089, 0.7117558 , 0.68134685, 0.68728883, 0.70068741]), 'pf': array([0.66848431, 0.66471672, 0.66326311, 0.66769638, 0.68070009,\n",
      "       0.66583243, 0.66452736, 0.67653864, 0.67332496, 0.66814798])}\n",
      "acc: 0.683218101822753\n",
      "pd: 0.7029010835372247\n",
      "pf: 0.6679221824229984\n"
     ]
    }
   ],
   "source": [
    "interp = DODGEInterpreter(files=['./chromium.txt'], max_by=0, \n",
    "                          metrics=['accuracy', 'pd', 'pf'])\n",
    "results = interp.interpret()['chromium.txt']\n",
    "print(results)\n",
    "print('acc:', np.median(results['accuracy']))\n",
    "print('pd:', np.median(results['pd']))\n",
    "print('pf:', np.median(results['pf']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2 = []\n",
    "\n",
    "def top_2(model, x_test, y_test):\n",
    "    probs = model.model.predict(x_test)\n",
    "    best_n = np.argsort(probs, axis=-1)[:, -2:]\n",
    "    correct = 0\n",
    "    total = len(y_test)\n",
    "    \n",
    "    for i, pred in enumerate(best_n):\n",
    "        if np.argmax(y_test[i], axis=-1) in pred:\n",
    "            correct += 1\n",
    "    print('Top-2 accuracy =', round(correct / total, 3))\n",
    "    top2.append(correct / total)\n",
    "\n",
    "top2_hook = Hook(name='top2', function=top_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = np.where(data.y_train < 2, 0, np.where(data.y_train < 6, 1, 2))\n",
    "data.y_test = np.where(data.y_test < 2, 0, np.where(data.y_test < 6, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y_train = to_categorical(data.y_train, num_classes=3)\n",
    "data.y_test = to_categorical(data.y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425c6eb0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425c6e50>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425ec820>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425ecb80>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425ece20>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425fe100>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425ec8b0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425fe610>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425fe8b0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425feb50>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1425fedf0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1426050d0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142605370>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142605610>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1426058b0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142605b50>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142605df0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14260c0d0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14260c370>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14260c610>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14260c8b0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14260cb50>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14260cdf0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1426140d0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142614370>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142614610>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1426148b0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142614b50>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142614df0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14261b0d0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14261b370>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14261b610>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14261b8b0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 5, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14261bb50>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14261bdf0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1426220d0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142622370>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142622610>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1426228b0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142622b50>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142622df0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1426280d0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142628370>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142628610>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1426288b0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142628b50>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142628df0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14262f0d0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14262f370>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 2, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14262f610>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 4, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x14262f8b0>, 'loss': 'categorical_crossentropy', 'n_classes': 3, 'n_epochs': 20, 'n_layers': 3, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardizeI|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0870 - val_loss: 1.0506\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0303 - val_loss: 1.0116\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 0.9874\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9856 - val_loss: 0.9756\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9725 - val_loss: 0.9560\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9622 - val_loss: 0.9502\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9574 - val_loss: 0.9465\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9539 - val_loss: 0.9434\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9506 - val_loss: 0.9413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9482 - val_loss: 0.9396\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9470 - val_loss: 0.9387\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9454 - val_loss: 0.9381\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9444 - val_loss: 0.9375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9433 - val_loss: 0.9366\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9422 - val_loss: 0.9358\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9412 - val_loss: 0.9353\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9402 - val_loss: 0.9352\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9393 - val_loss: 0.9337\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9385 - val_loss: 0.9334\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9375 - val_loss: 0.9330\n",
      "Top-2 accuracy = 0.835\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/raise_utils/learners/multiclassdl.py:84: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "1\n",
      "minmaxR|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0913 - val_loss: 1.0844\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0804 - val_loss: 1.0766\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0752 - val_loss: 1.0730\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0728 - val_loss: 1.0715\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0718 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "2\n",
      "maxabsO|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0887 - val_loss: 1.0753\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0601 - val_loss: 1.0380\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0234 - val_loss: 1.0002\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9987 - val_loss: 0.9809\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9846 - val_loss: 0.9700\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9758 - val_loss: 0.9621\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9696 - val_loss: 0.9571\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9653 - val_loss: 0.9537\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9628 - val_loss: 0.9523\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9612 - val_loss: 0.9506\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9592 - val_loss: 0.9493\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9585 - val_loss: 0.9475\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9571 - val_loss: 0.9471\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9565 - val_loss: 0.9462\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9556 - val_loss: 0.9463\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9554 - val_loss: 0.9454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9549 - val_loss: 0.9446\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9544 - val_loss: 0.9439\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9542 - val_loss: 0.9440\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9538 - val_loss: 0.9437\n",
      "Top-2 accuracy = 0.831\n",
      "3\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_17 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0360 - val_loss: 0.9828\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9724 - val_loss: 0.9503\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9419\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 0.9372\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9343\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9372 - val_loss: 0.9326\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9322\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9341 - val_loss: 0.9310\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9332 - val_loss: 0.9311\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9325 - val_loss: 0.9311\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9311 - val_loss: 0.9286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9298 - val_loss: 0.9291\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9309 - val_loss: 0.9282\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9294 - val_loss: 0.9277\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9279 - val_loss: 0.9262\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9280 - val_loss: 0.9258\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9266 - val_loss: 0.9273\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9262 - val_loss: 0.9249\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9260 - val_loss: 0.9263\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9267 - val_loss: 0.9247\n",
      "Top-2 accuracy = 0.841\n",
      "4\n",
      "minmaxs|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0816 - val_loss: 1.0724\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0704 - val_loss: 1.0637\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0446 - val_loss: 1.0079\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9902 - val_loss: 0.9637\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9682 - val_loss: 0.9538\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9623 - val_loss: 0.9508\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9612 - val_loss: 0.9478\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9585 - val_loss: 0.9478\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9569 - val_loss: 0.9476\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9568 - val_loss: 0.9477\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9555 - val_loss: 0.9453\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9556 - val_loss: 0.9441\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9548 - val_loss: 0.9442\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9545 - val_loss: 0.9437\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9548 - val_loss: 0.9458\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 0.9437\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9534 - val_loss: 0.9435\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9535 - val_loss: 0.9426\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 0.9434\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9533 - val_loss: 0.9430\n",
      "Top-2 accuracy = 0.824\n",
      "5\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_28 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0544 - val_loss: 1.0116\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0001 - val_loss: 0.9805\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9793 - val_loss: 0.9667\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9691 - val_loss: 0.9594\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9626 - val_loss: 0.9549\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9580 - val_loss: 0.9516\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9547 - val_loss: 0.9497\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9520 - val_loss: 0.9475\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9495 - val_loss: 0.9461\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9475 - val_loss: 0.9442\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9461 - val_loss: 0.9422\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9440 - val_loss: 0.9416\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9426 - val_loss: 0.9394\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9410 - val_loss: 0.9381\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9400 - val_loss: 0.9371\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9400 - val_loss: 0.9363\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9376 - val_loss: 0.9348\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9363 - val_loss: 0.9339\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9354 - val_loss: 0.9332\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9348 - val_loss: 0.9327\n",
      "Top-2 accuracy = 0.835\n",
      "6\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_31 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.1185 - val_loss: 1.0318\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0165 - val_loss: 0.9888\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9885 - val_loss: 0.9697\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9760 - val_loss: 0.9637\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9714 - val_loss: 0.9600\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9679 - val_loss: 0.9581\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9658 - val_loss: 0.9552\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9637 - val_loss: 0.9533\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9614 - val_loss: 0.9517\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9592 - val_loss: 0.9498\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9577 - val_loss: 0.9481\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9562 - val_loss: 0.9470\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9549 - val_loss: 0.9449\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9534 - val_loss: 0.9438\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9437\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9518 - val_loss: 0.9418\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9507 - val_loss: 0.9402\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9499 - val_loss: 0.9396\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9492 - val_loss: 0.9393\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9378\n",
      "Top-2 accuracy = 0.829\n",
      "7\n",
      "robustV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_34 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 3179051483136.0000 - val_loss: 1.0939\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0881 - val_loss: 1.0827\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0795 - val_loss: 1.0763\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0751 - val_loss: 1.0731\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0729 - val_loss: 1.0717\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0720 - val_loss: 1.0711\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0717 - val_loss: 1.0709\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0714 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0713 - val_loss: 1.0707\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0713 - val_loss: 1.0708\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0711 - val_loss: 1.0707\n",
      "Top-2 accuracy = 0.724\n",
      "8\n",
      "robustF|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_39 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0343 - val_loss: 0.9667\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9641 - val_loss: 0.9469\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9533 - val_loss: 0.9408\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9475 - val_loss: 0.9363\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9429 - val_loss: 0.9326\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9390 - val_loss: 0.9301\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9362 - val_loss: 0.9278\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9339 - val_loss: 0.9260\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9321 - val_loss: 0.9255\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9307 - val_loss: 0.9242\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9296 - val_loss: 0.9245\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9288 - val_loss: 0.9229\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9279 - val_loss: 0.9230\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9271 - val_loss: 0.9226\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9266 - val_loss: 0.9225\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9223\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9256 - val_loss: 0.9218\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9253 - val_loss: 0.9226\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9250 - val_loss: 0.9213\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9244 - val_loss: 0.9211\n",
      "Top-2 accuracy = 0.842\n",
      "9\n",
      "standardizeY|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_43 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0456 - val_loss: 0.9846\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9777 - val_loss: 0.9599\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9630 - val_loss: 0.9520\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9567 - val_loss: 0.9481\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9529 - val_loss: 0.9446\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9498 - val_loss: 0.9414\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9467 - val_loss: 0.9387\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9439 - val_loss: 0.9361\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9415 - val_loss: 0.9339\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9395 - val_loss: 0.9326\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9379 - val_loss: 0.9316\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9365 - val_loss: 0.9301\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9352 - val_loss: 0.9287\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9344 - val_loss: 0.9281\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9332 - val_loss: 0.9271\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9324 - val_loss: 0.9264\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9317 - val_loss: 0.9254\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9309 - val_loss: 0.9257\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9303 - val_loss: 0.9243\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9298 - val_loss: 0.9237\n",
      "Top-2 accuracy = 0.842\n",
      "10\n",
      "maxabsT|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_46 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0469 - val_loss: 0.9870\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9881 - val_loss: 0.9711\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9770 - val_loss: 0.9624\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9689 - val_loss: 0.9551\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9623 - val_loss: 0.9509\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9587 - val_loss: 0.9453\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9556 - val_loss: 0.9446\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 0.9423\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9529 - val_loss: 0.9428\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9519 - val_loss: 0.9404\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9516 - val_loss: 0.9394\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9500 - val_loss: 0.9404\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9501 - val_loss: 0.9391\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9493 - val_loss: 0.9377\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9379\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9484 - val_loss: 0.9367\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9478 - val_loss: 0.9365\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9482 - val_loss: 0.9364\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9469 - val_loss: 0.9363\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9474 - val_loss: 0.9353\n",
      "Top-2 accuracy = 0.829\n",
      "11\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_53 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 103139638247424.0000 - val_loss: 10945606713344.0000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 6414528937984.0000 - val_loss: 7163931000832.0000\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 6703711518720.0000 - val_loss: 13179730001920.0000\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 7504058646528.0000 - val_loss: 7193875709952.0000\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 6193909596160.0000 - val_loss: 5444200300544.0000\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5445115183104.0000 - val_loss: 4905125281792.0000\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5263881404416.0000 - val_loss: 3303449821184.0000\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4635802730496.0000 - val_loss: 4184420909056.0000\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5873988534272.0000 - val_loss: 1041107058688.0000\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 7601620779008.0000 - val_loss: 4432243195904.0000\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5142259695616.0000 - val_loss: 6868645183488.0000\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5967258845184.0000 - val_loss: 4356505075712.0000\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 6860212011008.0000 - val_loss: 6726334545920.0000\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5400378736640.0000 - val_loss: 6242854502400.0000\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5869990838272.0000 - val_loss: 5236441219072.0000\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5124819255296.0000 - val_loss: 6998786572288.0000\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3676494102528.0000 - val_loss: 8946640224256.0000\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 7217600790528.0000 - val_loss: 9262176665600.0000\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5778765774848.0000 - val_loss: 7571880017920.0000\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4540574203904.0000 - val_loss: 7041901395968.0000\n",
      "Top-2 accuracy = 0.822\n",
      "12\n",
      "maxabsU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0322 - val_loss: 0.9621\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9687 - val_loss: 0.9560\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9652 - val_loss: 0.9546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9633 - val_loss: 0.9512\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9586 - val_loss: 0.9454\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 0.9420\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 0.9409\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9516 - val_loss: 0.9407\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 0.9405\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9467 - val_loss: 0.9402\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9468 - val_loss: 0.9383\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9448 - val_loss: 0.9345\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9384\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9333\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9354\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9428 - val_loss: 0.9333\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9394 - val_loss: 0.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9347\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9406 - val_loss: 0.9315\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9375 - val_loss: 0.9310\n",
      "Top-2 accuracy = 0.833\n",
      "13\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_63 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0402 - val_loss: 0.9857\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9804 - val_loss: 0.9589\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9663 - val_loss: 0.9496\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9563 - val_loss: 0.9413\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9469 - val_loss: 0.9348\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9409 - val_loss: 0.9322\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9391 - val_loss: 0.9306\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9354 - val_loss: 0.9298\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9339 - val_loss: 0.9287\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9327 - val_loss: 0.9279\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9312 - val_loss: 0.9279\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9306 - val_loss: 0.9272\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9301 - val_loss: 0.9266\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9292 - val_loss: 0.9268\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9291 - val_loss: 0.9260\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9278 - val_loss: 0.9257\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9273 - val_loss: 0.9256\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9273 - val_loss: 0.9260\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9266 - val_loss: 0.9247\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9264 - val_loss: 0.9251\n",
      "Top-2 accuracy = 0.844\n",
      "14\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_67 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0177 - val_loss: 0.9699\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9725 - val_loss: 0.9585\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9656 - val_loss: 0.9538\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9613 - val_loss: 0.9504\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9598 - val_loss: 0.9492\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9579 - val_loss: 0.9484\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9568 - val_loss: 0.9462\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9561 - val_loss: 0.9514\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 0.9466\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9549 - val_loss: 0.9461\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9544 - val_loss: 0.9432\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9532 - val_loss: 0.9442\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9535 - val_loss: 0.9427\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9527 - val_loss: 0.9417\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9519 - val_loss: 0.9414\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9514 - val_loss: 0.9410\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9512 - val_loss: 0.9398\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9505 - val_loss: 0.9414\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9522 - val_loss: 0.9396\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9500 - val_loss: 0.9396\n",
      "Top-2 accuracy = 0.829\n",
      "15\n",
      "normalizeq|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_73 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0734 - val_loss: 1.0375\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0120 - val_loss: 0.9833\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9855 - val_loss: 0.9717\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9793 - val_loss: 0.9679\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9757 - val_loss: 0.9650\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9732 - val_loss: 0.9631\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9717 - val_loss: 0.9616\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9702 - val_loss: 0.9600\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9687 - val_loss: 0.9586\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9673 - val_loss: 0.9576\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9663 - val_loss: 0.9571\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9649 - val_loss: 0.9553\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9638 - val_loss: 0.9540\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9628 - val_loss: 0.9527\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9615 - val_loss: 0.9515\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9603 - val_loss: 0.9504\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9594 - val_loss: 0.9497\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9584 - val_loss: 0.9486\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9577 - val_loss: 0.9478\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9569 - val_loss: 0.9466\n",
      "Top-2 accuracy = 0.829\n",
      "16\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0503 - val_loss: 0.9867\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9798 - val_loss: 0.9613\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9672 - val_loss: 0.9531\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9624 - val_loss: 0.9495\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9595 - val_loss: 0.9492\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9575 - val_loss: 0.9452\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9561 - val_loss: 0.9455\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9565 - val_loss: 0.9449\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 0.9419\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 0.9418\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9404\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9515 - val_loss: 0.9397\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9400\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9497 - val_loss: 0.9380\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9492 - val_loss: 0.9367\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9474 - val_loss: 0.9387\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9469 - val_loss: 0.9339\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 0.9336\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9359\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9429 - val_loss: 0.9395\n",
      "Top-2 accuracy = 0.829\n",
      "17\n",
      "normalizex|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_81 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0625 - val_loss: 1.0383\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0204 - val_loss: 0.9938\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9911 - val_loss: 0.9740\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9810 - val_loss: 0.9681\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9771 - val_loss: 0.9654\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9741 - val_loss: 0.9630\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9717 - val_loss: 0.9609\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9701 - val_loss: 0.9594\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9680 - val_loss: 0.9595\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9666 - val_loss: 0.9567\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9653 - val_loss: 0.9556\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9640 - val_loss: 0.9548\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9631 - val_loss: 0.9537\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9617 - val_loss: 0.9530\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9611 - val_loss: 0.9520\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9602 - val_loss: 0.9514\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9594 - val_loss: 0.9506\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9585 - val_loss: 0.9501\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9580 - val_loss: 0.9492\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9574 - val_loss: 0.9490\n",
      "Top-2 accuracy = 0.829\n",
      "18\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_84 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0765 - val_loss: 1.0390\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9953 - val_loss: 0.9624\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9593 - val_loss: 0.9486\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9497 - val_loss: 0.9413\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9387\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9409 - val_loss: 0.9346\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9383 - val_loss: 0.9319\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9366 - val_loss: 0.9312\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9352 - val_loss: 0.9306\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9350 - val_loss: 0.9297\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9336 - val_loss: 0.9289\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9331 - val_loss: 0.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9322 - val_loss: 0.9275\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9321 - val_loss: 0.9277\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9313 - val_loss: 0.9276\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9313 - val_loss: 0.9268\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9300 - val_loss: 0.9261\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9297 - val_loss: 0.9257\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9296 - val_loss: 0.9255\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9288 - val_loss: 0.9267\n",
      "Top-2 accuracy = 0.837\n",
      "19\n",
      "standardizea|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_89 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0683 - val_loss: 1.0454\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0360 - val_loss: 1.0134\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0042 - val_loss: 0.9817\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9789 - val_loss: 0.9652\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9698 - val_loss: 0.9600\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9667 - val_loss: 0.9580\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9652 - val_loss: 0.9568\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9639 - val_loss: 0.9557\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9627 - val_loss: 0.9539\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9614 - val_loss: 0.9529\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9605 - val_loss: 0.9522\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9600 - val_loss: 0.9517\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9591 - val_loss: 0.9509\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9584 - val_loss: 0.9498\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9578 - val_loss: 0.9491\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9572 - val_loss: 0.9483\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9565 - val_loss: 0.9478\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9559 - val_loss: 0.9469\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9556 - val_loss: 0.9466\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9548 - val_loss: 0.9453\n",
      "Top-2 accuracy = 0.829\n",
      "20\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_96 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 5321.9038 - val_loss: 67.7328\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 18.0243 - val_loss: 6.4269\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 6.3066 - val_loss: 5.3950\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 7.4281 - val_loss: 6.0086\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 6.7356 - val_loss: 14.4294\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 8.0591 - val_loss: 10.3684\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 8.2052 - val_loss: 39.5161\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 13.1424 - val_loss: 16.8339\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 6.2764 - val_loss: 13.1990\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 8.2207 - val_loss: 4.3186\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 7.0697 - val_loss: 6.0089\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 6.8981 - val_loss: 14.7790\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 5.0260 - val_loss: 5.5505\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 7.2025 - val_loss: 3.1826\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 5.3975 - val_loss: 3.4259\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 7.1415 - val_loss: 31.2328\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 12.0425 - val_loss: 3.2753\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 4.8210 - val_loss: 4.1368\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 3.8861 - val_loss: 15.2878\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 7.0663 - val_loss: 17.0803\n",
      "Top-2 accuracy = 0.667\n",
      "21\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_102 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0335 - val_loss: 0.9813\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9758 - val_loss: 0.9590\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9603 - val_loss: 0.9508\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9524 - val_loss: 0.9460\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9481 - val_loss: 0.9417\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9450 - val_loss: 0.9397\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9430 - val_loss: 0.9369\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9362\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9394 - val_loss: 0.9345\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9384 - val_loss: 0.9337\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9374 - val_loss: 0.9321\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9362 - val_loss: 0.9314\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9351 - val_loss: 0.9313\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9347 - val_loss: 0.9304\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9340 - val_loss: 0.9299\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9337 - val_loss: 0.9297\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9330 - val_loss: 0.9290\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9323 - val_loss: 0.9283\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9319 - val_loss: 0.9277\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9314 - val_loss: 0.9287\n",
      "Top-2 accuracy = 0.837\n",
      "22\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_106 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 626990465941504.0000 - val_loss: 193588419887104.0000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 73645913276416.0000 - val_loss: 19183171534848.0000\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 15959642341376.0000 - val_loss: 14067958808576.0000\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 12162106916864.0000 - val_loss: 12038620315648.0000\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 10479790456832.0000 - val_loss: 8698940882944.0000\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 8975024128000.0000 - val_loss: 8938405756928.0000\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 8419699851264.0000 - val_loss: 7679075942400.0000\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 6493055746048.0000 - val_loss: 5372279521280.0000\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 6070141976576.0000 - val_loss: 6236443508736.0000\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 5200049864704.0000 - val_loss: 6466237890560.0000\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5644980060160.0000 - val_loss: 7414086107136.0000\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4560671211520.0000 - val_loss: 8571890171904.0000\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 6343128252416.0000 - val_loss: 2736060366848.0000\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4666769801216.0000 - val_loss: 7658640769024.0000\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4966198542336.0000 - val_loss: 4278967861248.0000\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 4394990960640.0000 - val_loss: 3607552589824.0000\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3937968062464.0000 - val_loss: 3850280370176.0000\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3461472321536.0000 - val_loss: 5541576835072.0000\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 5285470535680.0000 - val_loss: 6887630700544.0000\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 3466503389184.0000 - val_loss: 4660597882880.0000\n",
      "Top-2 accuracy = 0.691\n",
      "23\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_109 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0694 - val_loss: 1.0569\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0468 - val_loss: 1.0287\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0112 - val_loss: 0.9886\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9874 - val_loss: 0.9727\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9784 - val_loss: 0.9657\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9735 - val_loss: 0.9629\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9723 - val_loss: 0.9606\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9705 - val_loss: 0.9594\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9692 - val_loss: 0.9602\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9687 - val_loss: 0.9577\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9688 - val_loss: 0.9578\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9675 - val_loss: 0.9565\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9667 - val_loss: 0.9564\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9665 - val_loss: 0.9560\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9661 - val_loss: 0.9565\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9659 - val_loss: 0.9551\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9652 - val_loss: 0.9542\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9647 - val_loss: 0.9542\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9643 - val_loss: 0.9536\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9639 - val_loss: 0.9533\n",
      "Top-2 accuracy = 0.823\n",
      "24\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0627 - val_loss: 1.0119\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9828 - val_loss: 0.9611\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9606 - val_loss: 0.9541\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9517 - val_loss: 0.9446\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9461 - val_loss: 0.9416\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9451 - val_loss: 0.9400\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9415 - val_loss: 0.9381\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9403 - val_loss: 0.9392\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9366\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9391 - val_loss: 0.9374\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9395 - val_loss: 0.9381\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9383 - val_loss: 0.9335\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9374 - val_loss: 0.9340\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9381 - val_loss: 0.9359\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9337\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9336\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9372 - val_loss: 0.9309\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9348 - val_loss: 0.9311\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 0.9313\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 0.9324\n",
      "Top-2 accuracy = 0.833\n",
      "25\n",
      "normalizej|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0731 - val_loss: 1.0447\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9617\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9569 - val_loss: 0.9480\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 0.9444\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 0.9428\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9411\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9408\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9395\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9383\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9423 - val_loss: 0.9393\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9417 - val_loss: 0.9365\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9357\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9352\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9387 - val_loss: 0.9353\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9383 - val_loss: 0.9352\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9390 - val_loss: 0.9332\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9327\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9373 - val_loss: 0.9347\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9375 - val_loss: 0.9330\n",
      "Top-2 accuracy = 0.829\n",
      "26\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_126 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0925 - val_loss: 1.0665\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0588 - val_loss: 1.0475\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0372 - val_loss: 1.0164\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0041 - val_loss: 0.9853\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9845 - val_loss: 0.9720\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9753 - val_loss: 0.9653\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9687 - val_loss: 0.9592\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9647 - val_loss: 0.9562\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9612 - val_loss: 0.9539\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9587 - val_loss: 0.9521\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9572 - val_loss: 0.9505\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9556 - val_loss: 0.9492\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9545 - val_loss: 0.9484\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9532 - val_loss: 0.9481\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9468\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9516 - val_loss: 0.9457\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9503 - val_loss: 0.9453\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9446\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9442\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9436\n",
      "Top-2 accuracy = 0.825\n",
      "27\n",
      "normalizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0623 - val_loss: 1.0021\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9847 - val_loss: 0.9759\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9770 - val_loss: 0.9628\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9694 - val_loss: 0.9622\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9690 - val_loss: 0.9592\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9690 - val_loss: 0.9577\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9642 - val_loss: 0.9602\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9666 - val_loss: 0.9621\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9624 - val_loss: 0.9550\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9588 - val_loss: 0.9548\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9561 - val_loss: 0.9551\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9555 - val_loss: 0.9608\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9552 - val_loss: 0.9456\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9517 - val_loss: 0.9516\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9498 - val_loss: 0.9594\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9502 - val_loss: 0.9452\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9485 - val_loss: 0.9404\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9479 - val_loss: 0.9423\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9460 - val_loss: 0.9428\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 0.9385\n",
      "Top-2 accuracy = 0.828\n",
      "28\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_136 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0668 - val_loss: 1.0562\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0496 - val_loss: 1.0375\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0292 - val_loss: 1.0135\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0085 - val_loss: 0.9931\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9926 - val_loss: 0.9786\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9821 - val_loss: 0.9702\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9758 - val_loss: 0.9656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9726 - val_loss: 0.9629\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9702 - val_loss: 0.9620\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9691 - val_loss: 0.9611\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9681 - val_loss: 0.9611\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9675 - val_loss: 0.9602\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9668 - val_loss: 0.9603\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9665 - val_loss: 0.9597\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9661 - val_loss: 0.9598\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9661 - val_loss: 0.9596\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9656 - val_loss: 0.9591\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9653 - val_loss: 0.9590\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9650 - val_loss: 0.9586\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9646 - val_loss: 0.9581\n",
      "Top-2 accuracy = 0.811\n",
      "29\n",
      "maxabsa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0911 - val_loss: 1.0843\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0804 - val_loss: 1.0765\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0749 - val_loss: 1.0728\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0726 - val_loss: 1.0715\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0718 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "0\n",
      "standardizeU|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_147 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0326 - val_loss: 0.9863\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9757 - val_loss: 0.9555\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9577 - val_loss: 0.9470\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9449\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9415\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9450 - val_loss: 0.9406\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9401\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9424 - val_loss: 0.9405\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9389\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9408 - val_loss: 0.9385\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9378\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9392 - val_loss: 0.9365\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9383 - val_loss: 0.9364\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9367\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9347\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9344\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9353 - val_loss: 0.9339\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9348 - val_loss: 0.9333\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 0.9333\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9333 - val_loss: 0.9334\n",
      "Top-2 accuracy = 0.836\n",
      "1\n",
      "robustI|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_152 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.1180 - val_loss: 1.0803\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0600 - val_loss: 1.0447\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0311 - val_loss: 1.0172\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0079 - val_loss: 0.9953\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9915 - val_loss: 0.9804\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9809 - val_loss: 0.9711\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9733 - val_loss: 0.9651\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9679 - val_loss: 0.9610\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9644 - val_loss: 0.9583\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9618 - val_loss: 0.9564\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9597 - val_loss: 0.9544\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9579 - val_loss: 0.9527\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9565 - val_loss: 0.9511\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 0.9501\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9487\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9477\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9468\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 0.9455\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9494 - val_loss: 0.9451\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9491 - val_loss: 0.9444\n",
      "Top-2 accuracy = 0.828\n",
      "2\n",
      "minmaxp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0854 - val_loss: 1.0707\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0506 - val_loss: 1.0204\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0110 - val_loss: 0.9938\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 0.9853\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9847 - val_loss: 0.9729\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9779 - val_loss: 0.9684\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9737 - val_loss: 0.9652\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9699 - val_loss: 0.9611\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9669 - val_loss: 0.9601\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9655 - val_loss: 0.9593\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9645 - val_loss: 0.9566\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9635 - val_loss: 0.9575\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9614 - val_loss: 0.9567\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9606 - val_loss: 0.9533\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9606 - val_loss: 0.9529\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9597 - val_loss: 0.9534\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9588 - val_loss: 0.9520\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9591 - val_loss: 0.9510\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9571 - val_loss: 0.9515\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9589 - val_loss: 0.9582\n",
      "Top-2 accuracy = 0.812\n",
      "3\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0713 - val_loss: 1.0518\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0147 - val_loss: 0.9771\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9732 - val_loss: 0.9638\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9640 - val_loss: 0.9578\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9586 - val_loss: 0.9519\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9540 - val_loss: 0.9473\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9437\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9408\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9395\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9437 - val_loss: 0.9375\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9354\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9379\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9348\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9387 - val_loss: 0.9330\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9329\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9325\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 0.9323\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9314\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9314\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 0.9319\n",
      "Top-2 accuracy = 0.831\n",
      "4\n",
      "standardizea|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_164 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0248 - val_loss: 0.9838\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9759 - val_loss: 0.9640\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9625 - val_loss: 0.9538\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 0.9478\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9493 - val_loss: 0.9445\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9459 - val_loss: 0.9420\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9437 - val_loss: 0.9398\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9415 - val_loss: 0.9386\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9403 - val_loss: 0.9371\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9391 - val_loss: 0.9345\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9382 - val_loss: 0.9339\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9370 - val_loss: 0.9332\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9363 - val_loss: 0.9322\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 0.9321\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9346 - val_loss: 0.9313\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9343 - val_loss: 0.9310\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 0.9301\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9326 - val_loss: 0.9295\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9324 - val_loss: 0.9288\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9314 - val_loss: 0.9289\n",
      "Top-2 accuracy = 0.837\n",
      "5\n",
      "normalizeb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_167 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0452 - val_loss: 0.9773\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9691 - val_loss: 0.9573\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9583 - val_loss: 0.9506\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 0.9461\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9434\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9410\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9369\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 0.9391\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9354\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9346\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9328\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 0.9320\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9359 - val_loss: 0.9311\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9354 - val_loss: 0.9302\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9346 - val_loss: 0.9304\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9340 - val_loss: 0.9294\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9331 - val_loss: 0.9289\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9332 - val_loss: 0.9284\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9323 - val_loss: 0.9289\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 0.9280\n",
      "Top-2 accuracy = 0.837\n",
      "6\n",
      "minmaxr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0792 - val_loss: 1.0621\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0479 - val_loss: 1.0090\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9930 - val_loss: 0.9751\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9746 - val_loss: 0.9649\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9678 - val_loss: 0.9589\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9637 - val_loss: 0.9561\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9610 - val_loss: 0.9547\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9593 - val_loss: 0.9534\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9584 - val_loss: 0.9528\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9575 - val_loss: 0.9524\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9570 - val_loss: 0.9516\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 0.9510\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9556 - val_loss: 0.9525\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9557 - val_loss: 0.9505\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 0.9502\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9552 - val_loss: 0.9515\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 0.9512\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9541 - val_loss: 0.9506\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9545 - val_loss: 0.9501\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9535 - val_loss: 0.9493\n",
      "Top-2 accuracy = 0.826\n",
      "7\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0507\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0285 - val_loss: 0.9995\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9897 - val_loss: 0.9731\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9713 - val_loss: 0.9574\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9617 - val_loss: 0.9542\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9579 - val_loss: 0.9525\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 0.9494\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9509 - val_loss: 0.9475\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9479 - val_loss: 0.9409\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9402\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 0.9388\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9397\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9424 - val_loss: 0.9456\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 0.9368\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9363\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9423 - val_loss: 0.9410\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9354\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9401 - val_loss: 0.9359\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9401 - val_loss: 0.9378\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9338\n",
      "Top-2 accuracy = 0.83\n",
      "8\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_183 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0910 - val_loss: 1.0840\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0803 - val_loss: 1.0763\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0748 - val_loss: 1.0728\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0726 - val_loss: 1.0714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0718 - val_loss: 1.0709\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "9\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0706 - val_loss: 1.0539\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0251 - val_loss: 0.9872\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9800 - val_loss: 0.9669\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9703 - val_loss: 0.9626\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9669 - val_loss: 0.9606\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9650 - val_loss: 0.9578\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 0.9569\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9607 - val_loss: 0.9547\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9587 - val_loss: 0.9537\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9570 - val_loss: 0.9513\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 0.9497\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9534 - val_loss: 0.9481\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9525 - val_loss: 0.9473\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9461\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9494 - val_loss: 0.9445\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9489 - val_loss: 0.9444\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9430\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9468 - val_loss: 0.9424\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 0.9415\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9451 - val_loss: 0.9412\n",
      "Top-2 accuracy = 0.826\n",
      "10\n",
      "minmaxX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0811 - val_loss: 1.0707\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0658 - val_loss: 1.0261\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9917 - val_loss: 0.9699\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9795 - val_loss: 0.9688\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9754 - val_loss: 0.9651\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9709 - val_loss: 0.9597\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9678 - val_loss: 0.9568\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9649 - val_loss: 0.9576\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9625 - val_loss: 0.9538\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9598 - val_loss: 0.9513\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9582 - val_loss: 0.9482\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9560 - val_loss: 0.9476\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9470\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 0.9564\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9533 - val_loss: 0.9427\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9416\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 0.9422\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9490 - val_loss: 0.9417\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 0.9404\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9475 - val_loss: 0.9463\n",
      "Top-2 accuracy = 0.822\n",
      "11\n",
      "robustR|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_199 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0815 - val_loss: 0.9818\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9782 - val_loss: 0.9720\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9693 - val_loss: 0.9571\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9611 - val_loss: 0.9553\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9550 - val_loss: 0.9494\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9519 - val_loss: 0.9446\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9505 - val_loss: 0.9427\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9491 - val_loss: 0.9440\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9466 - val_loss: 0.9423\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9399\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9457 - val_loss: 0.9431\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9435 - val_loss: 0.9466\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9480 - val_loss: 0.9405\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9409\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9417 - val_loss: 0.9458\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9436 - val_loss: 0.9360\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9397 - val_loss: 0.9368\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9396 - val_loss: 0.9353\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9446\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9385 - val_loss: 0.9379\n",
      "Top-2 accuracy = 0.829\n",
      "12\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_204 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0817 - val_loss: 1.0615\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0470 - val_loss: 1.0260\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0136 - val_loss: 0.9933\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9887 - val_loss: 0.9756\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9776 - val_loss: 0.9692\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9728 - val_loss: 0.9664\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9703 - val_loss: 0.9644\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9684 - val_loss: 0.9630\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9668 - val_loss: 0.9623\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9656 - val_loss: 0.9608\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9646 - val_loss: 0.9601\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9634 - val_loss: 0.9591\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9627 - val_loss: 0.9584\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9619 - val_loss: 0.9577\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9608 - val_loss: 0.9570\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9600 - val_loss: 0.9563\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9592 - val_loss: 0.9554\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9584 - val_loss: 0.9547\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9576 - val_loss: 0.9538\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9568 - val_loss: 0.9530\n",
      "Top-2 accuracy = 0.821\n",
      "13\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0979 - val_loss: 1.0732\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0701 - val_loss: 1.0668\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0646 - val_loss: 1.0589\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0513 - val_loss: 1.0391\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0297 - val_loss: 1.0139\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0075 - val_loss: 0.9941\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 0.9861\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9888 - val_loss: 0.9805\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9848 - val_loss: 0.9771\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9811 - val_loss: 0.9724\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9770 - val_loss: 0.9703\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9742 - val_loss: 0.9678\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9730 - val_loss: 0.9663\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9718 - val_loss: 0.9661\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9711 - val_loss: 0.9646\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9702 - val_loss: 0.9637\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9701 - val_loss: 0.9661\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9698 - val_loss: 0.9629\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9687 - val_loss: 0.9619\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9687 - val_loss: 0.9621\n",
      "Top-2 accuracy = 0.816\n",
      "14\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_214 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0867 - val_loss: 1.0419\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0131 - val_loss: 0.9807\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9791 - val_loss: 0.9660\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9674 - val_loss: 0.9574\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9602 - val_loss: 0.9535\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9559 - val_loss: 0.9503\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9531 - val_loss: 0.9482\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9513 - val_loss: 0.9469\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9499 - val_loss: 0.9457\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9486 - val_loss: 0.9443\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9473 - val_loss: 0.9432\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9461 - val_loss: 0.9424\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9449 - val_loss: 0.9414\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9440 - val_loss: 0.9407\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9430 - val_loss: 0.9402\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9420 - val_loss: 0.9382\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9411 - val_loss: 0.9374\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9402 - val_loss: 0.9373\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9392 - val_loss: 0.9359\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9388 - val_loss: 0.9353\n",
      "Top-2 accuracy = 0.831\n",
      "15\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0850 - val_loss: 1.0741\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0672 - val_loss: 1.0579\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0285 - val_loss: 0.9908\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 0.9792\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 0.9763\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9832 - val_loss: 0.9725\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9799 - val_loss: 0.9731\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9783 - val_loss: 0.9724\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9756 - val_loss: 0.9659\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9737 - val_loss: 0.9667\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9733 - val_loss: 0.9652\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9704 - val_loss: 0.9592\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9664 - val_loss: 0.9586\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9663 - val_loss: 0.9588\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9644 - val_loss: 0.9559\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9630 - val_loss: 0.9548\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9616 - val_loss: 0.9554\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9605 - val_loss: 0.9543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9605 - val_loss: 0.9519\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9603 - val_loss: 0.9513\n",
      "Top-2 accuracy = 0.816\n",
      "16\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0850 - val_loss: 1.0763\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0742 - val_loss: 1.0719\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0722 - val_loss: 1.0710\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0711\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0718 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "17\n",
      "robustN|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_229 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0618 - val_loss: 1.0411\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0375 - val_loss: 1.0182\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0074 - val_loss: 0.9822\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9756 - val_loss: 0.9605\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9624 - val_loss: 0.9544\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9588 - val_loss: 0.9523\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9575 - val_loss: 0.9515\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9562 - val_loss: 0.9504\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9554 - val_loss: 0.9497\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9546 - val_loss: 0.9489\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9541 - val_loss: 0.9482\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9535 - val_loss: 0.9491\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9528 - val_loss: 0.9469\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9516 - val_loss: 0.9456\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9505 - val_loss: 0.9451\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9497 - val_loss: 0.9437\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9436\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9489 - val_loss: 0.9432\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9482 - val_loss: 0.9427\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9480 - val_loss: 0.9427\n",
      "Top-2 accuracy = 0.829\n",
      "18\n",
      "robustV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0906 - val_loss: 1.0836\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0798 - val_loss: 1.0761\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0747 - val_loss: 1.0727\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0726 - val_loss: 1.0714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "19\n",
      "normalized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0300 - val_loss: 0.9823\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9769 - val_loss: 0.9570\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 0.9491\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9572 - val_loss: 0.9462\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 0.9443\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 0.9454\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9509 - val_loss: 0.9432\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9498 - val_loss: 0.9433\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 0.9406\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9399\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9465 - val_loss: 0.9390\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9469 - val_loss: 0.9391\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 0.9385\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9443 - val_loss: 0.9389\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 0.9374\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9436 - val_loss: 0.9382\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9431 - val_loss: 0.9384\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9357\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9418 - val_loss: 0.9377\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9418 - val_loss: 0.9355\n",
      "Top-2 accuracy = 0.832\n",
      "20\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0803 - val_loss: 1.0569\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0369 - val_loss: 1.0132\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0065 - val_loss: 0.9938\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 0.9817\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9811 - val_loss: 0.9674\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9699 - val_loss: 0.9624\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9659 - val_loss: 0.9604\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9639 - val_loss: 0.9563\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9608 - val_loss: 0.9547\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9590 - val_loss: 0.9535\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9578 - val_loss: 0.9533\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9562 - val_loss: 0.9522\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9560 - val_loss: 0.9511\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 0.9518\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9551 - val_loss: 0.9516\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9502\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9533 - val_loss: 0.9496\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9528 - val_loss: 0.9495\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9520 - val_loss: 0.9485\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9520 - val_loss: 0.9490\n",
      "Top-2 accuracy = 0.824\n",
      "21\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_249 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0604 - val_loss: 1.0183\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 0.9806\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9886 - val_loss: 0.9748\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9827 - val_loss: 0.9671\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9765 - val_loss: 0.9632\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9730 - val_loss: 0.9603\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9697 - val_loss: 0.9597\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9678 - val_loss: 0.9568\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9653 - val_loss: 0.9552\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9630 - val_loss: 0.9535\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 0.9516\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9607 - val_loss: 0.9566\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9600 - val_loss: 0.9510\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9594 - val_loss: 0.9502\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9578 - val_loss: 0.9545\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9570 - val_loss: 0.9496\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9572 - val_loss: 0.9516\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 0.9479\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9557 - val_loss: 0.9480\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 0.9471\n",
      "Top-2 accuracy = 0.82\n",
      "22\n",
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0839 - val_loss: 1.0690\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0539 - val_loss: 1.0364\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0226 - val_loss: 1.0051\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9848\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9833 - val_loss: 0.9743\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9753 - val_loss: 0.9670\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9694 - val_loss: 0.9621\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9651 - val_loss: 0.9579\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9607 - val_loss: 0.9525\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9571 - val_loss: 0.9501\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9554 - val_loss: 0.9486\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 0.9462\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9455\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9520 - val_loss: 0.9444\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9438\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9497 - val_loss: 0.9449\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9492 - val_loss: 0.9422\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 0.9432\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 0.9424\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9481 - val_loss: 0.9414\n",
      "Top-2 accuracy = 0.83\n",
      "23\n",
      "maxabsD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0698 - val_loss: 1.0359\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0107 - val_loss: 0.9817\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9848 - val_loss: 0.9670\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9741 - val_loss: 0.9606\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9681 - val_loss: 0.9565\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9641 - val_loss: 0.9527\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9612 - val_loss: 0.9507\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9590 - val_loss: 0.9498\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9570 - val_loss: 0.9480\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9556 - val_loss: 0.9478\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9543 - val_loss: 0.9467\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9534 - val_loss: 0.9474\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9524 - val_loss: 0.9453\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9515 - val_loss: 0.9451\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9509 - val_loss: 0.9450\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9505 - val_loss: 0.9436\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9498 - val_loss: 0.9432\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9432\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 0.9424\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9478 - val_loss: 0.9425\n",
      "Top-2 accuracy = 0.822\n",
      "24\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0862 - val_loss: 1.0647\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0400 - val_loss: 1.0027\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 0.9704\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9766 - val_loss: 0.9660\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9711 - val_loss: 0.9574\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9674 - val_loss: 0.9568\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9653 - val_loss: 0.9538\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9617 - val_loss: 0.9533\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9618 - val_loss: 0.9578\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9605 - val_loss: 0.9559\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9593 - val_loss: 0.9548\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9592 - val_loss: 0.9494\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9572 - val_loss: 0.9493\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9576 - val_loss: 0.9516\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9557 - val_loss: 0.9465\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9545 - val_loss: 0.9484\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9469\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 0.9450\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9537 - val_loss: 0.9447\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9524 - val_loss: 0.9483\n",
      "Top-2 accuracy = 0.822\n",
      "25\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 0.9940\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9808 - val_loss: 0.9644\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9628 - val_loss: 0.9514\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9566 - val_loss: 0.9489\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 0.9452\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9436\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9492 - val_loss: 0.9418\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9418\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9467 - val_loss: 0.9407\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 0.9417\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9446 - val_loss: 0.9384\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 0.9382\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9430 - val_loss: 0.9378\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9374\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9379\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9373\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9415 - val_loss: 0.9355\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9421 - val_loss: 0.9353\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9354\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9347\n",
      "Top-2 accuracy = 0.829\n",
      "26\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_270 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.1016 - val_loss: 1.0686\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0546 - val_loss: 1.0351\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0250 - val_loss: 1.0055\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0036 - val_loss: 0.9881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9919 - val_loss: 0.9783\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9839 - val_loss: 0.9715\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9782 - val_loss: 0.9662\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9738 - val_loss: 0.9622\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9699 - val_loss: 0.9590\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9668 - val_loss: 0.9570\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9649 - val_loss: 0.9560\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9633 - val_loss: 0.9550\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9619 - val_loss: 0.9536\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9609 - val_loss: 0.9529\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9598 - val_loss: 0.9522\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9589 - val_loss: 0.9519\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9584 - val_loss: 0.9509\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9576 - val_loss: 0.9503\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9571 - val_loss: 0.9498\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9566 - val_loss: 0.9497\n",
      "Top-2 accuracy = 0.822\n",
      "27\n",
      "robusth|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0907 - val_loss: 1.0829\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0783 - val_loss: 1.0738\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0726 - val_loss: 1.0710\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "28\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0081 - val_loss: 0.9701\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9635 - val_loss: 0.9587\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9552 - val_loss: 0.9513\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 0.9444\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 0.9436\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9436 - val_loss: 0.9408\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9407 - val_loss: 0.9373\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9366\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9385 - val_loss: 0.9345\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9342\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9368 - val_loss: 0.9329\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9318\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9339\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9353 - val_loss: 0.9326\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9327\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9306\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9296\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9339 - val_loss: 0.9297\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9334 - val_loss: 0.9288\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9287\n",
      "Top-2 accuracy = 0.832\n",
      "29\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0802 - val_loss: 1.0708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "0\n",
      "minmaxK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0262 - val_loss: 0.9740\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9668 - val_loss: 0.9523\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9567 - val_loss: 0.9470\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 0.9445\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9421\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 0.9443\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.9413\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9402\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 0.9455\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9510\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9390\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9466 - val_loss: 0.9399\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9368\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9460 - val_loss: 0.9413\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9375\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9362\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9460 - val_loss: 0.9352\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9370\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 0.9385\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9436 - val_loss: 0.9350\n",
      "Top-2 accuracy = 0.828\n",
      "1\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0729 - val_loss: 1.0710\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0719 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0710\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0713\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0718 - val_loss: 1.0709\n",
      "Top-2 accuracy = 0.724\n",
      "2\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_302 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0372 - val_loss: 1.0023\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9962 - val_loss: 0.9733\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9769 - val_loss: 0.9633\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9682 - val_loss: 0.9562\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9620 - val_loss: 0.9506\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9572 - val_loss: 0.9478\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9542 - val_loss: 0.9447\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9425\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9503 - val_loss: 0.9407\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9486 - val_loss: 0.9396\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9475 - val_loss: 0.9392\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9407\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9460 - val_loss: 0.9368\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.9367\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9361\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9349\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9348\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9422 - val_loss: 0.9346\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9421 - val_loss: 0.9340\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9409 - val_loss: 0.9333\n",
      "Top-2 accuracy = 0.834\n",
      "3\n",
      "standardizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0547 - val_loss: 1.0239\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0141 - val_loss: 0.9966\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 0.9804\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9804 - val_loss: 0.9699\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9723 - val_loss: 0.9636\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9674 - val_loss: 0.9596\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9642 - val_loss: 0.9567\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 0.9542\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9600 - val_loss: 0.9526\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9585 - val_loss: 0.9512\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9571 - val_loss: 0.9495\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9559 - val_loss: 0.9481\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9549 - val_loss: 0.9472\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9539 - val_loss: 0.9466\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9530 - val_loss: 0.9457\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9522 - val_loss: 0.9456\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9519 - val_loss: 0.9444\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9440\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9436\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9502 - val_loss: 0.9431\n",
      "Top-2 accuracy = 0.827\n",
      "4\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0353 - val_loss: 0.9860\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9749 - val_loss: 0.9580\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9594 - val_loss: 0.9506\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9462\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9457\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 0.9409\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 0.9404\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9436 - val_loss: 0.9382\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 0.9386\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9375\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 0.9362\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9400 - val_loss: 0.9351\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9396 - val_loss: 0.9351\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9344\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 0.9349\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9332\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9375 - val_loss: 0.9325\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 0.9369\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9373 - val_loss: 0.9321\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 0.9348\n",
      "Top-2 accuracy = 0.831\n",
      "5\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_315 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0657 - val_loss: 1.0452\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0285 - val_loss: 1.0034\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9968 - val_loss: 0.9797\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9832 - val_loss: 0.9712\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9783 - val_loss: 0.9678\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9762 - val_loss: 0.9668\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9747 - val_loss: 0.9654\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9734 - val_loss: 0.9641\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9726 - val_loss: 0.9631\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9712 - val_loss: 0.9621\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9704 - val_loss: 0.9614\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9693 - val_loss: 0.9611\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9683 - val_loss: 0.9596\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9674 - val_loss: 0.9588\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9665 - val_loss: 0.9583\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9656 - val_loss: 0.9581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9654 - val_loss: 0.9584\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9647 - val_loss: 0.9564\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9638 - val_loss: 0.9564\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9632 - val_loss: 0.9552\n",
      "Top-2 accuracy = 0.825\n",
      "6\n",
      "maxabsB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0690 - val_loss: 1.0496\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0331 - val_loss: 1.0084\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0055 - val_loss: 0.9913\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 0.9830\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9870 - val_loss: 0.9750\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9802 - val_loss: 0.9692\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9756 - val_loss: 0.9656\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9732 - val_loss: 0.9634\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9709 - val_loss: 0.9624\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9693 - val_loss: 0.9604\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9681 - val_loss: 0.9592\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9673 - val_loss: 0.9586\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9671 - val_loss: 0.9577\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9657 - val_loss: 0.9572\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9654 - val_loss: 0.9558\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9643 - val_loss: 0.9556\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9635 - val_loss: 0.9563\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9628 - val_loss: 0.9551\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9621 - val_loss: 0.9535\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9620 - val_loss: 0.9552\n",
      "Top-2 accuracy = 0.821\n",
      "7\n",
      "minmaxP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0768 - val_loss: 1.0707\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0653 - val_loss: 1.0244\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9925 - val_loss: 0.9692\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9649 - val_loss: 0.9532\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9595 - val_loss: 0.9501\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9570 - val_loss: 0.9887\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9618 - val_loss: 0.9460\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9536 - val_loss: 0.9442\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9524 - val_loss: 0.9443\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9517 - val_loss: 0.9440\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9506 - val_loss: 0.9422\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9497 - val_loss: 0.9410\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9501 - val_loss: 0.9461\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9491 - val_loss: 0.9407\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9475 - val_loss: 0.9398\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9468 - val_loss: 0.9395\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9471 - val_loss: 0.9431\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9482 - val_loss: 0.9383\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9468 - val_loss: 0.9411\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9455 - val_loss: 0.9369\n",
      "Top-2 accuracy = 0.828\n",
      "8\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0874 - val_loss: 1.0757\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0653 - val_loss: 1.0504\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0281 - val_loss: 1.0007\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9951 - val_loss: 0.9804\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9831 - val_loss: 0.9719\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9772 - val_loss: 0.9671\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9737 - val_loss: 0.9644\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9710 - val_loss: 0.9629\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9696 - val_loss: 0.9609\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9679 - val_loss: 0.9603\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9668 - val_loss: 0.9585\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9658 - val_loss: 0.9574\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9644 - val_loss: 0.9569\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9637 - val_loss: 0.9561\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9633 - val_loss: 0.9553\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9628 - val_loss: 0.9551\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9620 - val_loss: 0.9549\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9618 - val_loss: 0.9542\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9615 - val_loss: 0.9535\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9610 - val_loss: 0.9540\n",
      "Top-2 accuracy = 0.82\n",
      "9\n",
      "minmaxF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0722 - val_loss: 1.0316\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9703 - val_loss: 0.9595\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9645 - val_loss: 0.9564\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9634 - val_loss: 0.9548\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9616 - val_loss: 0.9545\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9611 - val_loss: 0.9538\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9604 - val_loss: 0.9530\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9600 - val_loss: 0.9525\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9596 - val_loss: 0.9528\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9582 - val_loss: 0.9527\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9585 - val_loss: 0.9508\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9579 - val_loss: 0.9509\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9568 - val_loss: 0.9490\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9561 - val_loss: 0.9496\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9559 - val_loss: 0.9487\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 0.9492\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9553 - val_loss: 0.9471\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 0.9465\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9466\n",
      "Top-2 accuracy = 0.822\n",
      "10\n",
      "standardizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0433 - val_loss: 1.0057\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9826\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9778 - val_loss: 0.9653\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9677 - val_loss: 0.9612\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9637 - val_loss: 0.9565\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9601 - val_loss: 0.9560\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9577 - val_loss: 0.9523\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9553 - val_loss: 0.9521\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9502\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9522 - val_loss: 0.9474\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9500 - val_loss: 0.9518\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9503 - val_loss: 0.9472\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9483 - val_loss: 0.9452\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9474 - val_loss: 0.9448\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9468 - val_loss: 0.9439\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9458 - val_loss: 0.9421\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9447 - val_loss: 0.9411\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9447 - val_loss: 0.9417\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9438 - val_loss: 0.9400\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9452 - val_loss: 0.9420\n",
      "Top-2 accuracy = 0.827\n",
      "11\n",
      "normalizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0819 - val_loss: 1.0607\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0349 - val_loss: 1.0037\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9816 - val_loss: 0.9626\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9678 - val_loss: 0.9578\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9634 - val_loss: 0.9543\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9608 - val_loss: 0.9525\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9594 - val_loss: 0.9511\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9576 - val_loss: 0.9499\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9559 - val_loss: 0.9491\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9552 - val_loss: 0.9490\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9546 - val_loss: 0.9482\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9467\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9533 - val_loss: 0.9467\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9520 - val_loss: 0.9463\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9518 - val_loss: 0.9455\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9450\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9446\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9445\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9449\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9495 - val_loss: 0.9434\n",
      "Top-2 accuracy = 0.827\n",
      "12\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0240 - val_loss: 0.9788\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9713 - val_loss: 0.9586\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9593 - val_loss: 0.9509\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 0.9466\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9514 - val_loss: 0.9536\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9429\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9482 - val_loss: 0.9418\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9416\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9456 - val_loss: 0.9408\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9402\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 0.9387\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9428 - val_loss: 0.9422\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 0.9375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9424 - val_loss: 0.9392\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9406 - val_loss: 0.9377\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 0.9417\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9397 - val_loss: 0.9356\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9408 - val_loss: 0.9350\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9364\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.9356\n",
      "Top-2 accuracy = 0.83\n",
      "13\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0399 - val_loss: 0.9844\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9719 - val_loss: 0.9561\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 0.9456\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9470\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9470 - val_loss: 0.9430\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 0.9391\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9437 - val_loss: 0.9375\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 0.9369\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9367\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9368\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9418 - val_loss: 0.9425\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9401 - val_loss: 0.9367\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9406 - val_loss: 0.9341\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9336\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9342\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9386 - val_loss: 0.9375\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9335\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 0.9323\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9345\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9328\n",
      "Top-2 accuracy = 0.831\n",
      "14\n",
      "maxabsa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0376 - val_loss: 0.9913\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9811 - val_loss: 0.9665\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9655 - val_loss: 0.9557\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9567 - val_loss: 0.9475\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9494 - val_loss: 0.9454\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9383\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9366\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9431 - val_loss: 0.9358\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9346\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9352\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9335\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9326\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9388 - val_loss: 0.9326\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9319\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9315\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9373 - val_loss: 0.9321\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9315\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9367 - val_loss: 0.9310\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9361 - val_loss: 0.9309\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 0.9311\n",
      "Top-2 accuracy = 0.83\n",
      "15\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0852 - val_loss: 1.0766\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0641 - val_loss: 1.0387\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0129 - val_loss: 0.9838\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9836 - val_loss: 0.9706\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9753 - val_loss: 0.9655\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9708 - val_loss: 0.9623\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9680 - val_loss: 0.9599\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9667 - val_loss: 0.9588\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9653 - val_loss: 0.9579\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9645 - val_loss: 0.9567\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 0.9564\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9620 - val_loss: 0.9544\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9612 - val_loss: 0.9538\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9602 - val_loss: 0.9534\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9610 - val_loss: 0.9527\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9589 - val_loss: 0.9511\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9581 - val_loss: 0.9505\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9573 - val_loss: 0.9507\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9567 - val_loss: 0.9495\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 0.9476\n",
      "Top-2 accuracy = 0.823\n",
      "16\n",
      "maxabsw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0554 - val_loss: 1.0015\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9775 - val_loss: 0.9598\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.9421\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9409 - val_loss: 0.9339\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9327\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9373 - val_loss: 0.9362\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9365 - val_loss: 0.9321\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9345\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9374\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9329\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9344 - val_loss: 0.9312\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9341 - val_loss: 0.9301\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9292\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9290\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9333 - val_loss: 0.9382\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9344 - val_loss: 0.9354\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9353 - val_loss: 0.9294\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9327 - val_loss: 0.9311\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9323 - val_loss: 0.9290\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9305\n",
      "Top-2 accuracy = 0.834\n",
      "17\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0959 - val_loss: 1.0792\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0620\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0543 - val_loss: 1.0462\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0418 - val_loss: 1.0357\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0327 - val_loss: 1.0270\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0258 - val_loss: 1.0183\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0148 - val_loss: 1.0021\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 0.9937\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 0.9882\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9896 - val_loss: 0.9843\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9857 - val_loss: 0.9791\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9818 - val_loss: 0.9761\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9794 - val_loss: 0.9732\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9768 - val_loss: 0.9713\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9748 - val_loss: 0.9693\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9732 - val_loss: 0.9673\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9720 - val_loss: 0.9659\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9710 - val_loss: 0.9645\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9698 - val_loss: 0.9640\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9692 - val_loss: 0.9635\n",
      "Top-2 accuracy = 0.823\n",
      "18\n",
      "maxabsO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0707 - val_loss: 1.0338\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9993 - val_loss: 0.9685\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9684 - val_loss: 0.9577\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9611 - val_loss: 0.9530\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9562 - val_loss: 0.9483\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9451\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9497 - val_loss: 0.9445\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 0.9418\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9405\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 0.9398\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 0.9391\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9437 - val_loss: 0.9378\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9386\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9417 - val_loss: 0.9365\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9408 - val_loss: 0.9390\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9353\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9346\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 0.9344\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9350\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.9337\n",
      "Top-2 accuracy = 0.831\n",
      "19\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0592 - val_loss: 1.0208\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9964 - val_loss: 0.9810\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9754 - val_loss: 0.9560\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9584 - val_loss: 0.9618\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9565 - val_loss: 0.9527\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9538 - val_loss: 0.9445\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9507 - val_loss: 0.9459\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9510 - val_loss: 0.9444\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9479 - val_loss: 0.9413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9487 - val_loss: 0.9416\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 0.9424\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9470 - val_loss: 0.9476\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9485 - val_loss: 0.9410\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9463 - val_loss: 0.9494\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 0.9407\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9464 - val_loss: 0.9391\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9465 - val_loss: 0.9399\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9455 - val_loss: 0.9395\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9464 - val_loss: 0.9380\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9457 - val_loss: 0.9449\n",
      "Top-2 accuracy = 0.829\n",
      "20\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0542 - val_loss: 0.9991\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9757 - val_loss: 0.9555\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 0.9460\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9445 - val_loss: 0.9344\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9332\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9401 - val_loss: 0.9317\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9376 - val_loss: 0.9302\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9375 - val_loss: 0.9334\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.9320\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9359 - val_loss: 0.9306\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9308\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9353 - val_loss: 0.9306\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9290\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9349 - val_loss: 0.9351\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9374 - val_loss: 0.9287\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9343 - val_loss: 0.9304\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9350 - val_loss: 0.9312\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 0.9320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9299\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9341 - val_loss: 0.9327\n",
      "Top-2 accuracy = 0.832\n",
      "21\n",
      "robustw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0606 - val_loss: 1.0212\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0035 - val_loss: 0.9825\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9788 - val_loss: 0.9678\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9692 - val_loss: 0.9602\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9620 - val_loss: 0.9556\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9545 - val_loss: 0.9495\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9512 - val_loss: 0.9520\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9483 - val_loss: 0.9426\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9415\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 0.9385\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9438 - val_loss: 0.9376\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9434 - val_loss: 0.9410\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9418 - val_loss: 0.9383\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9413 - val_loss: 0.9377\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9406 - val_loss: 0.9362\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9398 - val_loss: 0.9373\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 0.9360\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.9364\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9397 - val_loss: 0.9371\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.9359\n",
      "Top-2 accuracy = 0.827\n",
      "22\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0917 - val_loss: 1.0824\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0756 - val_loss: 1.0645\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0558 - val_loss: 1.0403\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0334 - val_loss: 1.0192\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0163 - val_loss: 1.0042\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0044 - val_loss: 0.9945\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 0.9876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9904 - val_loss: 0.9826\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9852 - val_loss: 0.9783\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9814 - val_loss: 0.9760\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9785 - val_loss: 0.9722\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9759 - val_loss: 0.9699\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9742 - val_loss: 0.9702\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9723 - val_loss: 0.9668\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9709 - val_loss: 0.9658\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9694 - val_loss: 0.9645\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9685 - val_loss: 0.9638\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9674 - val_loss: 0.9625\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9667 - val_loss: 0.9616\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9662 - val_loss: 0.9614\n",
      "Top-2 accuracy = 0.821\n",
      "23\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0614 - val_loss: 0.9997\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9719 - val_loss: 0.9573\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9566 - val_loss: 0.9538\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9513 - val_loss: 0.9450\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9420\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9450 - val_loss: 0.9396\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 0.9442\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9379\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9405 - val_loss: 0.9362\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9401 - val_loss: 0.9355\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9386 - val_loss: 0.9349\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9329\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.9482\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9381\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9368 - val_loss: 0.9319\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9322\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9298\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 0.9321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9314\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.9285\n",
      "Top-2 accuracy = 0.834\n",
      "24\n",
      "normalizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0742 - val_loss: 1.0599\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0345 - val_loss: 0.9943\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9801 - val_loss: 0.9593\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9606 - val_loss: 0.9498\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9534 - val_loss: 0.9433\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9492 - val_loss: 0.9419\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9486 - val_loss: 0.9403\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9371\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9436 - val_loss: 0.9382\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9358\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9418 - val_loss: 0.9359\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9411 - val_loss: 0.9347\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9346\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9337\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9395 - val_loss: 0.9331\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9326\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9389 - val_loss: 0.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9374 - val_loss: 0.9319\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9322\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9368 - val_loss: 0.9327\n",
      "Top-2 accuracy = 0.83\n",
      "25\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0878 - val_loss: 1.0744\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0591 - val_loss: 1.0455\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0353 - val_loss: 1.0268\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0204 - val_loss: 1.0149\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0109 - val_loss: 1.0075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 1.0004\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9959\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 0.9914\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9899 - val_loss: 0.9867\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9850 - val_loss: 0.9842\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9819 - val_loss: 0.9795\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9784 - val_loss: 0.9768\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9758 - val_loss: 0.9740\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9730 - val_loss: 0.9712\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9714 - val_loss: 0.9703\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9692 - val_loss: 0.9675\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9684 - val_loss: 0.9662\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9658 - val_loss: 0.9650\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9643 - val_loss: 0.9648\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9643 - val_loss: 0.9638\n",
      "Top-2 accuracy = 0.824\n",
      "26\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0249 - val_loss: 0.9892\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9765 - val_loss: 0.9649\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9649 - val_loss: 0.9596\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9604 - val_loss: 0.9565\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9580 - val_loss: 0.9536\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9553 - val_loss: 0.9510\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 0.9489\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9507 - val_loss: 0.9487\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9485 - val_loss: 0.9443\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9470 - val_loss: 0.9436\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9419\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 0.9411\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9405\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9436 - val_loss: 0.9398\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9400\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9384\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9418 - val_loss: 0.9375\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9410 - val_loss: 0.9389\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9413 - val_loss: 0.9374\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9384\n",
      "Top-2 accuracy = 0.83\n",
      "27\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0460 - val_loss: 0.9858\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9633 - val_loss: 0.9432\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9446 - val_loss: 0.9414\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9407 - val_loss: 0.9426\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9402 - val_loss: 0.9363\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9388 - val_loss: 0.9352\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9382 - val_loss: 0.9332\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 0.9371\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9397 - val_loss: 0.9344\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9362 - val_loss: 0.9331\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9351\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9373 - val_loss: 0.9378\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9367 - val_loss: 0.9343\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9322\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9335\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9361 - val_loss: 0.9317\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9367 - val_loss: 0.9385\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9373 - val_loss: 0.9327\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9356 - val_loss: 0.9314\n",
      "Top-2 accuracy = 0.831\n",
      "28\n",
      "robusth|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0768 - val_loss: 1.0376\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9732\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9741 - val_loss: 0.9638\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9653 - val_loss: 0.9574\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9596 - val_loss: 0.9545\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9566 - val_loss: 0.9555\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9545 - val_loss: 0.9508\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9532 - val_loss: 0.9487\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9518 - val_loss: 0.9474\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9513 - val_loss: 0.9466\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 0.9483\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9496 - val_loss: 0.9461\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9458\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9460\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9479 - val_loss: 0.9457\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9470 - val_loss: 0.9460\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9470 - val_loss: 0.9436\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9469 - val_loss: 0.9453\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9441\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 0.9441\n",
      "Top-2 accuracy = 0.829\n",
      "29\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0704 - val_loss: 1.0460\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0255 - val_loss: 0.9991\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9941 - val_loss: 0.9776\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9765 - val_loss: 0.9661\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9660 - val_loss: 0.9621\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9625 - val_loss: 0.9532\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9594 - val_loss: 0.9532\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9585 - val_loss: 0.9525\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9568 - val_loss: 0.9504\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9559 - val_loss: 0.9513\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9555 - val_loss: 0.9513\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9559 - val_loss: 0.9485\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 0.9488\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9470\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 0.9503\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9518 - val_loss: 0.9460\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 0.9464\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9513 - val_loss: 0.9474\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9511 - val_loss: 0.9544\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9524 - val_loss: 0.9454\n",
      "Top-2 accuracy = 0.827\n",
      "0\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0803 - val_loss: 1.0711\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "1\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0509 - val_loss: 1.0046\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9846 - val_loss: 0.9703\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9653 - val_loss: 0.9572\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9586 - val_loss: 0.9536\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 0.9500\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9514 - val_loss: 0.9502\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9515 - val_loss: 0.9498\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9461\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9486 - val_loss: 0.9447\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9447\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9476 - val_loss: 0.9441\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9434\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9465 - val_loss: 0.9436\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9458 - val_loss: 0.9426\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9438\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9465 - val_loss: 0.9418\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9458 - val_loss: 0.9417\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9448 - val_loss: 0.9423\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9448 - val_loss: 0.9562\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9465 - val_loss: 0.9483\n",
      "Top-2 accuracy = 0.831\n",
      "2\n",
      "normalizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0788 - val_loss: 1.0708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0711 - val_loss: 1.0692\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0341 - val_loss: 0.9689\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9534 - val_loss: 0.9405\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9354\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 0.9344\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9383 - val_loss: 0.9338\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 0.9328\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9375 - val_loss: 0.9327\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9365 - val_loss: 0.9317\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9321\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9357 - val_loss: 0.9314\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9315\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9309\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9347 - val_loss: 0.9350\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9311\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9303\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9348 - val_loss: 0.9307\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9355 - val_loss: 0.9414\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9307\n",
      "Top-2 accuracy = 0.83\n",
      "3\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0672 - val_loss: 1.0142\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0025 - val_loss: 0.9834\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9808 - val_loss: 0.9681\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9712 - val_loss: 0.9653\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9657 - val_loss: 0.9591\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9624 - val_loss: 0.9548\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9594 - val_loss: 0.9528\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9553 - val_loss: 0.9505\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9524 - val_loss: 0.9506\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9521 - val_loss: 0.9453\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9515 - val_loss: 0.9445\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9492 - val_loss: 0.9419\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 0.9414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9457 - val_loss: 0.9415\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9414\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9448 - val_loss: 0.9390\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9390\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9422 - val_loss: 0.9458\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9421\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9391\n",
      "Top-2 accuracy = 0.825\n",
      "4\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_448 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0633 - val_loss: 1.0149\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9895 - val_loss: 0.9648\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9656 - val_loss: 0.9554\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.9517\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9563 - val_loss: 0.9493\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9535 - val_loss: 0.9471\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9517 - val_loss: 0.9451\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9499 - val_loss: 0.9432\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9475 - val_loss: 0.9426\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9464 - val_loss: 0.9411\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9401\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9437 - val_loss: 0.9390\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9423 - val_loss: 0.9377\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9410 - val_loss: 0.9376\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9400 - val_loss: 0.9359\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9394 - val_loss: 0.9353\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9387 - val_loss: 0.9355\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9379 - val_loss: 0.9340\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9378 - val_loss: 0.9351\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9371 - val_loss: 0.9334\n",
      "Top-2 accuracy = 0.837\n",
      "5\n",
      "maxabsB|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_454 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0879 - val_loss: 1.0724\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0448 - val_loss: 1.0085\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0015 - val_loss: 0.9847\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9839 - val_loss: 0.9714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9745 - val_loss: 0.9646\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9702 - val_loss: 0.9611\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9661 - val_loss: 0.9578\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9634 - val_loss: 0.9556\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9608 - val_loss: 0.9540\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9598 - val_loss: 0.9526\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9576 - val_loss: 0.9511\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9560 - val_loss: 0.9503\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9549 - val_loss: 0.9493\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9539 - val_loss: 0.9482\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9531 - val_loss: 0.9472\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9524 - val_loss: 0.9464\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9517 - val_loss: 0.9464\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9509 - val_loss: 0.9447\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9445\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9435\n",
      "Top-2 accuracy = 0.827\n",
      "6\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0306 - val_loss: 0.9744\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9597 - val_loss: 0.9455\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9458 - val_loss: 0.9393\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9470\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9433 - val_loss: 0.9388\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9414 - val_loss: 0.9371\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9371\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9405 - val_loss: 0.9406\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9419 - val_loss: 0.9351\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9402 - val_loss: 0.9365\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9370\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 0.9360\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 0.9349\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9392 - val_loss: 0.9363\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9390 - val_loss: 0.9380\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9383 - val_loss: 0.9344\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 0.9369\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9373 - val_loss: 0.9345\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9382 - val_loss: 0.9346\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9377 - val_loss: 0.9333\n",
      "Top-2 accuracy = 0.826\n",
      "7\n",
      "robustH|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0877 - val_loss: 1.0738\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0607 - val_loss: 1.0291\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0081 - val_loss: 0.9843\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9828 - val_loss: 0.9686\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9707 - val_loss: 0.9590\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9654 - val_loss: 0.9549\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9626 - val_loss: 0.9520\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9587 - val_loss: 0.9495\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9573 - val_loss: 0.9492\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9574 - val_loss: 0.9478\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9557 - val_loss: 0.9464\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9545 - val_loss: 0.9455\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9535 - val_loss: 0.9495\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9537 - val_loss: 0.9445\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9524 - val_loss: 0.9436\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9517 - val_loss: 0.9435\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9505 - val_loss: 0.9424\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9424\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9494 - val_loss: 0.9413\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9487 - val_loss: 0.9410\n",
      "Top-2 accuracy = 0.826\n",
      "8\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_472 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0918 - val_loss: 1.0846\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0808 - val_loss: 1.0768\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0751 - val_loss: 1.0730\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0727 - val_loss: 1.0715\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0713 - val_loss: 1.0670\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0405 - val_loss: 1.0147\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0105 - val_loss: 1.0000\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9996 - val_loss: 0.9915\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9928 - val_loss: 0.9852\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9881 - val_loss: 0.9811\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9847 - val_loss: 0.9777\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9822 - val_loss: 0.9755\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9799 - val_loss: 0.9736\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9782 - val_loss: 0.9717\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9769 - val_loss: 0.9703\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9758 - val_loss: 0.9690\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9748 - val_loss: 0.9680\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9738 - val_loss: 0.9670\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9728 - val_loss: 0.9662\n",
      "Top-2 accuracy = 0.818\n",
      "9\n",
      "normalizeg|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_478 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0438 - val_loss: 0.9725\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9685 - val_loss: 0.9534\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9576 - val_loss: 0.9470\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9430\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9403\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9466 - val_loss: 0.9419\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 0.9374\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9415 - val_loss: 0.9340\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9339\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.9318\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9320\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9313\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 0.9296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 0.9288\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9289\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9289\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 0.9273\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 0.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9269\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9263\n",
      "Top-2 accuracy = 0.837\n",
      "10\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_485 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0322 - val_loss: 0.9743\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9701 - val_loss: 0.9565\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9596 - val_loss: 0.9511\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9554 - val_loss: 0.9482\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9525 - val_loss: 0.9458\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9498 - val_loss: 0.9428\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9478 - val_loss: 0.9423\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9464 - val_loss: 0.9401\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9446 - val_loss: 0.9391\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9428 - val_loss: 0.9377\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9419 - val_loss: 0.9370\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9407 - val_loss: 0.9361\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9400 - val_loss: 0.9361\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9390 - val_loss: 0.9351\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9375 - val_loss: 0.9338\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9371 - val_loss: 0.9337\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9366 - val_loss: 0.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9358 - val_loss: 0.9327\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9350 - val_loss: 0.9316\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9344 - val_loss: 0.9309\n",
      "Top-2 accuracy = 0.835\n",
      "11\n",
      "minmaxr|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_489 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0357 - val_loss: 1.0009\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 0.9721\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9754 - val_loss: 0.9603\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9676 - val_loss: 0.9575\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9639 - val_loss: 0.9536\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9612 - val_loss: 0.9530\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9601 - val_loss: 0.9530\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9585 - val_loss: 0.9503\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9573 - val_loss: 0.9491\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9569 - val_loss: 0.9507\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9565 - val_loss: 0.9497\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9556 - val_loss: 0.9470\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 0.9468\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 0.9465\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9533 - val_loss: 0.9464\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9527 - val_loss: 0.9463\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9448\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9520 - val_loss: 0.9468\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9442\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9513 - val_loss: 0.9443\n",
      "Top-2 accuracy = 0.825\n",
      "12\n",
      "standardizej|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0346 - val_loss: 0.9889\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9802 - val_loss: 0.9662\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9649 - val_loss: 0.9559\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9574 - val_loss: 0.9514\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9560 - val_loss: 0.9479\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9507 - val_loss: 0.9448\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9510 - val_loss: 0.9434\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9479 - val_loss: 0.9423\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9491 - val_loss: 0.9481\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9482 - val_loss: 0.9425\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9471 - val_loss: 0.9410\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9461 - val_loss: 0.9507\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9445 - val_loss: 0.9438\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9450 - val_loss: 0.9398\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9440 - val_loss: 0.9384\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9405 - val_loss: 0.9417\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9435 - val_loss: 0.9419\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9414 - val_loss: 0.9424\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9391 - val_loss: 0.9367\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9385 - val_loss: 0.9381\n",
      "Top-2 accuracy = 0.829\n",
      "13\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_500 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.3059 - val_loss: 1.0361\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0134 - val_loss: 0.9903\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9925 - val_loss: 0.9794\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9819 - val_loss: 0.9695\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9732 - val_loss: 0.9634\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9677 - val_loss: 0.9589\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9630 - val_loss: 0.9540\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9586 - val_loss: 0.9499\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 0.9486\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9453\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9513 - val_loss: 0.9433\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9421\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9480 - val_loss: 0.9396\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9393\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.9384\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9442 - val_loss: 0.9381\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9426 - val_loss: 0.9388\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9423 - val_loss: 0.9379\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9365\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9411 - val_loss: 0.9362\n",
      "Top-2 accuracy = 0.826\n",
      "14\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0910 - val_loss: 1.0841\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0802 - val_loss: 1.0765\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0749 - val_loss: 1.0729\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0727 - val_loss: 1.0715\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0709\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "15\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0336 - val_loss: 0.9841\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9664 - val_loss: 0.9477\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9416\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 0.9391\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9426 - val_loss: 0.9399\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9370\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 0.9359\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 0.9358\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 0.9351\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9359 - val_loss: 0.9354\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 0.9339\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9345\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 0.9331\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9327 - val_loss: 0.9339\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9323 - val_loss: 0.9332\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9323 - val_loss: 0.9334\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 0.9320\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9314 - val_loss: 0.9317\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9304 - val_loss: 0.9321\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9305 - val_loss: 0.9346\n",
      "Top-2 accuracy = 0.837\n",
      "16\n",
      "standardizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0854 - val_loss: 1.0768\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0748 - val_loss: 1.0723\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0725 - val_loss: 1.0712\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0718 - val_loss: 1.0709\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "17\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0456 - val_loss: 0.9845\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9697 - val_loss: 0.9519\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9447\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9490 - val_loss: 0.9417\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9467 - val_loss: 0.9408\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 0.9393\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9442 - val_loss: 0.9383\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9434 - val_loss: 0.9400\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9434 - val_loss: 0.9379\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9373\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9375\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9417 - val_loss: 0.9364\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9408 - val_loss: 0.9377\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9360\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9397 - val_loss: 0.9394\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9392 - val_loss: 0.9353\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9387 - val_loss: 0.9392\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9363\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 0.9369\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9385 - val_loss: 0.9362\n",
      "Top-2 accuracy = 0.83\n",
      "18\n",
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0700 - val_loss: 1.0476\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0355 - val_loss: 1.0187\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9799\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9713 - val_loss: 0.9600\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9622 - val_loss: 0.9544\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9591 - val_loss: 0.9526\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9570 - val_loss: 0.9510\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9565 - val_loss: 0.9500\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9550 - val_loss: 0.9486\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9539 - val_loss: 0.9481\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9535 - val_loss: 0.9477\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9474\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9527 - val_loss: 0.9475\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9524 - val_loss: 0.9466\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9463\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9518 - val_loss: 0.9461\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 0.9463\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9513 - val_loss: 0.9462\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9471\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9513 - val_loss: 0.9453\n",
      "Top-2 accuracy = 0.828\n",
      "19\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0725 - val_loss: 1.0499\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0346 - val_loss: 1.0092\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0055 - val_loss: 0.9941\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9952 - val_loss: 0.9862\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9866 - val_loss: 0.9740\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9816 - val_loss: 0.9712\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9792 - val_loss: 0.9713\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9781 - val_loss: 0.9689\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9767 - val_loss: 0.9683\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9748 - val_loss: 0.9664\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9717 - val_loss: 0.9659\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9690 - val_loss: 0.9622\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9674 - val_loss: 0.9641\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9656 - val_loss: 0.9614\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9664 - val_loss: 0.9615\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9642 - val_loss: 0.9590\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9638 - val_loss: 0.9591\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9632 - val_loss: 0.9583\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 0.9574\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 0.9594\n",
      "Top-2 accuracy = 0.829\n",
      "20\n",
      "robustw|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_539 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0475 - val_loss: 0.9980\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9900 - val_loss: 0.9691\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9706 - val_loss: 0.9575\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9606 - val_loss: 0.9503\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9548 - val_loss: 0.9462\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9511 - val_loss: 0.9441\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9486 - val_loss: 0.9412\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 0.9414\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 0.9385\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9426 - val_loss: 0.9383\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9413 - val_loss: 0.9369\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9405 - val_loss: 0.9366\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9392 - val_loss: 0.9360\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9385 - val_loss: 0.9345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.9335\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9339\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9367 - val_loss: 0.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 0.9333\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9344 - val_loss: 0.9315\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 0.9305\n",
      "Top-2 accuracy = 0.834\n",
      "21\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0613 - val_loss: 1.0340\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0155 - val_loss: 0.9907\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9896 - val_loss: 0.9749\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9779 - val_loss: 0.9649\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9693 - val_loss: 0.9579\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9644 - val_loss: 0.9536\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9607 - val_loss: 0.9516\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9585 - val_loss: 0.9491\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 0.9493\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 0.9476\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9460\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9529 - val_loss: 0.9458\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9453\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9514 - val_loss: 0.9450\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9509 - val_loss: 0.9442\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9509 - val_loss: 0.9457\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.9445\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9436\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9430\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9422\n",
      "Top-2 accuracy = 0.828\n",
      "22\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0879 - val_loss: 1.0796\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0729 - val_loss: 1.0647\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0577 - val_loss: 1.0515\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0405 - val_loss: 1.0286\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.0124\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0082 - val_loss: 1.0037\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9878\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9855 - val_loss: 0.9782\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9793 - val_loss: 0.9724\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9755 - val_loss: 0.9676\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9694 - val_loss: 0.9641\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9672 - val_loss: 0.9626\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9649 - val_loss: 0.9617\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9640 - val_loss: 0.9588\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 0.9595\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 0.9577\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9611 - val_loss: 0.9591\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9612 - val_loss: 0.9549\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9602 - val_loss: 0.9553\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9603 - val_loss: 0.9581\n",
      "Top-2 accuracy = 0.828\n",
      "23\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0914 - val_loss: 1.0841\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0801 - val_loss: 1.0763\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0747 - val_loss: 1.0727\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0726 - val_loss: 1.0714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "24\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0186 - val_loss: 0.9869\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9694 - val_loss: 0.9554\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9528 - val_loss: 0.9459\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9523 - val_loss: 0.9669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9553 - val_loss: 0.9476\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9491 - val_loss: 0.9481\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9502 - val_loss: 0.9454\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9497 - val_loss: 0.9417\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9503 - val_loss: 0.9406\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9486 - val_loss: 0.9589\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9581 - val_loss: 0.9455\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9492 - val_loss: 0.9403\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9474 - val_loss: 0.9468\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9487 - val_loss: 0.9497\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9476 - val_loss: 0.9447\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9477 - val_loss: 0.9427\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9468 - val_loss: 0.9409\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9509 - val_loss: 0.9427\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9477 - val_loss: 0.9432\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9496 - val_loss: 0.9704\n",
      "Top-2 accuracy = 0.804\n",
      "25\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0828 - val_loss: 1.0598\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0491 - val_loss: 1.0387\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0317 - val_loss: 1.0196\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0145 - val_loss: 1.0073\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0055 - val_loss: 1.0000\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9953 - val_loss: 0.9918\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9891 - val_loss: 0.9818\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9822 - val_loss: 0.9788\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9804 - val_loss: 0.9725\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9738 - val_loss: 0.9777\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9736 - val_loss: 0.9664\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9690 - val_loss: 0.9651\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9669 - val_loss: 0.9616\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9642 - val_loss: 0.9593\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9632 - val_loss: 0.9584\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9601 - val_loss: 0.9633\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9593 - val_loss: 0.9718\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9606 - val_loss: 0.9533\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9551 - val_loss: 0.9532\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9546 - val_loss: 0.9527\n",
      "Top-2 accuracy = 0.826\n",
      "26\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0297 - val_loss: 0.9702\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9673 - val_loss: 0.9539\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9583 - val_loss: 0.9479\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9470\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9512 - val_loss: 0.9510\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9385\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9369\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9400\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9441\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9456 - val_loss: 0.9378\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9349\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9422 - val_loss: 0.9353\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9434 - val_loss: 0.9348\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9413 - val_loss: 0.9351\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9407 - val_loss: 0.9430\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9420 - val_loss: 0.9367\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9401 - val_loss: 0.9325\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9395 - val_loss: 0.9424\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9412 - val_loss: 0.9323\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9393 - val_loss: 0.9342\n",
      "Top-2 accuracy = 0.831\n",
      "27\n",
      "maxabsT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0224 - val_loss: 0.9565\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9577 - val_loss: 0.9540\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9526 - val_loss: 0.9427\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 0.9443\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9471 - val_loss: 0.9428\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 0.9360\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9466 - val_loss: 0.9434\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9448 - val_loss: 0.9358\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9442 - val_loss: 0.9366\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9447 - val_loss: 0.9494\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9447 - val_loss: 0.9370\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9411 - val_loss: 0.9365\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9424 - val_loss: 0.9400\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.9394\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9416 - val_loss: 0.9364\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9396 - val_loss: 0.9329\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.9315\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9425\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9365\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9342\n",
      "Top-2 accuracy = 0.833\n",
      "28\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0345 - val_loss: 0.9900\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9765 - val_loss: 0.9651\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9631 - val_loss: 0.9584\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9582 - val_loss: 0.9521\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9531 - val_loss: 0.9471\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 0.9465\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 0.9420\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 0.9400\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9387\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9371\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9365\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9406 - val_loss: 0.9402\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9390 - val_loss: 0.9354\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 0.9343\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9343\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9353\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 0.9342\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 0.9344\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 0.9337\n",
      "Top-2 accuracy = 0.832\n",
      "29\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0809 - val_loss: 1.0708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0688 - val_loss: 1.0603\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0435 - val_loss: 1.0176\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9753\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9734 - val_loss: 0.9652\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9656 - val_loss: 0.9586\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9620 - val_loss: 0.9579\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9582 - val_loss: 0.9536\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 0.9527\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 0.9492\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9512\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9513 - val_loss: 0.9472\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9505 - val_loss: 0.9483\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9466\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9450\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9444\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9468 - val_loss: 0.9442\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9460 - val_loss: 0.9432\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9451 - val_loss: 0.9436\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9428\n",
      "Top-2 accuracy = 0.831\n",
      "0\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0958 - val_loss: 1.0708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0514 - val_loss: 1.0165\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9938 - val_loss: 0.9723\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9717 - val_loss: 0.9636\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9673 - val_loss: 0.9587\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9628 - val_loss: 0.9571\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9607 - val_loss: 0.9557\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9580 - val_loss: 0.9492\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 0.9468\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9525 - val_loss: 0.9438\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9494 - val_loss: 0.9428\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9457\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9475 - val_loss: 0.9410\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.9388\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9442 - val_loss: 0.9426\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9434 - val_loss: 0.9379\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9441 - val_loss: 0.9469\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 0.9356\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9428 - val_loss: 0.9353\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9418 - val_loss: 0.9342\n",
      "Top-2 accuracy = 0.83\n",
      "1\n",
      "normalizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0881 - val_loss: 1.0296\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9686\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9715 - val_loss: 0.9573\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9633 - val_loss: 0.9539\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9596 - val_loss: 0.9507\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9578 - val_loss: 0.9539\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9574 - val_loss: 0.9490\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 0.9489\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 0.9527\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9537 - val_loss: 0.9454\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9519 - val_loss: 0.9454\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9514 - val_loss: 0.9473\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9515 - val_loss: 0.9463\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9448\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9480\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9431\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9427\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 0.9429\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9473 - val_loss: 0.9429\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9467 - val_loss: 0.9444\n",
      "Top-2 accuracy = 0.826\n",
      "2\n",
      "robustp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0462 - val_loss: 0.9913\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9762 - val_loss: 0.9575\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9622 - val_loss: 0.9518\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9571 - val_loss: 0.9498\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9460\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9450\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9492 - val_loss: 0.9424\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9416\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9464 - val_loss: 0.9427\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9464 - val_loss: 0.9393\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9379\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9424\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9387\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 0.9419\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9374\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9379\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9370\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9418 - val_loss: 0.9432\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9418 - val_loss: 0.9355\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 0.9391\n",
      "Top-2 accuracy = 0.828\n",
      "3\n",
      "normalizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0931 - val_loss: 1.0803\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0765 - val_loss: 1.0728\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0723 - val_loss: 1.0710\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0707\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0714 - val_loss: 1.0706\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0710 - val_loss: 1.0695\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0668 - val_loss: 1.0571\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0378 - val_loss: 1.0089\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9806\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9840 - val_loss: 0.9699\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9761 - val_loss: 0.9628\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9701 - val_loss: 0.9571\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9660 - val_loss: 0.9538\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9630 - val_loss: 0.9515\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9617 - val_loss: 0.9508\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9598 - val_loss: 0.9494\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9587 - val_loss: 0.9484\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9585 - val_loss: 0.9482\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9568 - val_loss: 0.9470\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9562 - val_loss: 0.9477\n",
      "Top-2 accuracy = 0.818\n",
      "4\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0449 - val_loss: 0.9783\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9595 - val_loss: 0.9498\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9426\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 0.9429\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9374\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9359\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9383 - val_loss: 0.9354\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9365\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 0.9321\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9359 - val_loss: 0.9323\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9297\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9346 - val_loss: 0.9289\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9293\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9323 - val_loss: 0.9289\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.9292\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9307 - val_loss: 0.9290\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9314 - val_loss: 0.9276\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9307 - val_loss: 0.9299\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9304 - val_loss: 0.9279\n",
      "Top-2 accuracy = 0.834\n",
      "5\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0473 - val_loss: 1.0013\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9840 - val_loss: 0.9638\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9659 - val_loss: 0.9545\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.9519\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 0.9487\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9487\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9528 - val_loss: 0.9463\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 0.9463\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9515 - val_loss: 0.9452\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9439\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9504 - val_loss: 0.9431\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9444\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 0.9432\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9435\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9421\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9417\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9408\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 0.9411\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 0.9399\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9446 - val_loss: 0.9414\n",
      "Top-2 accuracy = 0.83\n",
      "6\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0910 - val_loss: 1.0840\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0800 - val_loss: 1.0762\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0747 - val_loss: 1.0727\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0726 - val_loss: 1.0714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0718 - val_loss: 1.0709\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "7\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0597 - val_loss: 1.0135\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9886 - val_loss: 0.9646\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9683 - val_loss: 0.9571\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 0.9522\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9574 - val_loss: 0.9485\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 0.9464\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9514 - val_loss: 0.9453\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9502 - val_loss: 0.9429\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9423\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9471 - val_loss: 0.9415\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9395\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 0.9389\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9387\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9426 - val_loss: 0.9394\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9422 - val_loss: 0.9392\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9415 - val_loss: 0.9383\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9408 - val_loss: 0.9360\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9400 - val_loss: 0.9363\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9353\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9393 - val_loss: 0.9356\n",
      "Top-2 accuracy = 0.828\n",
      "8\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0368 - val_loss: 0.9840\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9656 - val_loss: 0.9476\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9366\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 0.9354\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9352\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9349 - val_loss: 0.9355\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 0.9360\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9323 - val_loss: 0.9366\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9347\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9321 - val_loss: 0.9346\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9319 - val_loss: 0.9323\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9317 - val_loss: 0.9330\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9302 - val_loss: 0.9323\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9306 - val_loss: 0.9313\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 0.9330\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9301 - val_loss: 0.9316\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9296 - val_loss: 0.9343\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 0.9307\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9308 - val_loss: 0.9380\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 0.9309\n",
      "Top-2 accuracy = 0.837\n",
      "9\n",
      "maxabsG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0495 - val_loss: 0.9780\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9702 - val_loss: 0.9594\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9598 - val_loss: 0.9496\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 0.9481\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9518 - val_loss: 0.9464\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9446\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9434\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9448 - val_loss: 0.9404\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9412\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9500\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9422 - val_loss: 0.9400\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9396 - val_loss: 0.9372\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9378 - val_loss: 0.9360\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9354\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9349\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9355 - val_loss: 0.9333\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9344\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 0.9328\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9331 - val_loss: 0.9321\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9327 - val_loss: 0.9331\n",
      "Top-2 accuracy = 0.833\n",
      "10\n",
      "standardizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0193 - val_loss: 0.9668\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9704 - val_loss: 0.9608\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9660 - val_loss: 0.9550\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9602 - val_loss: 0.9498\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 0.9505\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 0.9455\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9504 - val_loss: 0.9434\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 0.9419\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9468 - val_loss: 0.9413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 0.9395\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9446 - val_loss: 0.9404\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9385\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9431 - val_loss: 0.9381\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 0.9395\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9376\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9364\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9360\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9367\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9399 - val_loss: 0.9360\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9395 - val_loss: 0.9360\n",
      "Top-2 accuracy = 0.832\n",
      "11\n",
      "normalizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0854 - val_loss: 1.0697\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0413 - val_loss: 0.9932\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9874 - val_loss: 0.9727\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9775 - val_loss: 0.9661\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9701 - val_loss: 0.9607\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9652 - val_loss: 0.9558\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 0.9542\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.9524\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9579 - val_loss: 0.9506\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9571 - val_loss: 0.9501\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9564 - val_loss: 0.9490\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9560 - val_loss: 0.9537\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 0.9485\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 0.9472\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9537 - val_loss: 0.9471\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9533 - val_loss: 0.9471\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9540 - val_loss: 0.9467\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9461\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9531 - val_loss: 0.9450\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9475\n",
      "Top-2 accuracy = 0.825\n",
      "12\n",
      "robustv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0314 - val_loss: 0.9786\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9636 - val_loss: 0.9481\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9523 - val_loss: 0.9442\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9480 - val_loss: 0.9417\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 0.9449\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9396\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9441 - val_loss: 0.9400\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9432 - val_loss: 0.9398\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9424 - val_loss: 0.9471\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 0.9371\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9381\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9379\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9412 - val_loss: 0.9376\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9399 - val_loss: 0.9357\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9415 - val_loss: 0.9364\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9388 - val_loss: 0.9350\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9359\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9389 - val_loss: 0.9367\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9382 - val_loss: 0.9343\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 0.9339\n",
      "Top-2 accuracy = 0.826\n",
      "13\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0728 - val_loss: 1.0362\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0069 - val_loss: 0.9844\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9794 - val_loss: 0.9681\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9670 - val_loss: 0.9591\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9614 - val_loss: 0.9540\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9559 - val_loss: 0.9497\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 0.9468\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9511 - val_loss: 0.9489\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9490 - val_loss: 0.9426\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9473 - val_loss: 0.9434\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9460 - val_loss: 0.9426\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9459 - val_loss: 0.9403\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9443 - val_loss: 0.9397\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9447 - val_loss: 0.9399\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9434 - val_loss: 0.9429\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9432 - val_loss: 0.9381\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9422 - val_loss: 0.9426\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9392\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9422 - val_loss: 0.9370\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9367\n",
      "Top-2 accuracy = 0.831\n",
      "14\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_650 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0341 - val_loss: 0.9649\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9680 - val_loss: 0.9553\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9596 - val_loss: 0.9529\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.9545 - val_loss: 0.9460\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9425\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9469 - val_loss: 0.9432\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 0.9378\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9431 - val_loss: 0.9360\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.9346\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9394 - val_loss: 0.9333\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9383 - val_loss: 0.9339\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9368 - val_loss: 0.9316\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 0.9307\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9358 - val_loss: 0.9300\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9297\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9341 - val_loss: 0.9318\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9335 - val_loss: 0.9288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9303\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9330 - val_loss: 0.9276\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9305\n",
      "Top-2 accuracy = 0.834\n",
      "15\n",
      "maxabsB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0251 - val_loss: 0.9678\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9547 - val_loss: 0.9436\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 0.9385\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9392 - val_loss: 0.9348\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9383 - val_loss: 0.9336\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9367 - val_loss: 0.9366\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9331\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9361 - val_loss: 0.9392\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9356 - val_loss: 0.9329\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9348 - val_loss: 0.9334\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9314\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 0.9303\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9334 - val_loss: 0.9354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.9302\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.9299\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9325 - val_loss: 0.9292\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9314\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9332 - val_loss: 0.9292\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9315 - val_loss: 0.9325\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9333 - val_loss: 0.9316\n",
      "Top-2 accuracy = 0.832\n",
      "16\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0328 - val_loss: 0.9715\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9554 - val_loss: 0.9386\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9397 - val_loss: 0.9328\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 0.9376\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 0.9295\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9315\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9333 - val_loss: 0.9306\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 0.9324\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9335 - val_loss: 0.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.9311\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9330 - val_loss: 0.9281\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 0.9274\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9312 - val_loss: 0.9283\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9298\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9309 - val_loss: 0.9279\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9276\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9305 - val_loss: 0.9278\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 0.9270\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9273\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9305 - val_loss: 0.9273\n",
      "Top-2 accuracy = 0.834\n",
      "17\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0485 - val_loss: 1.0187\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9977 - val_loss: 0.9719\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9610 - val_loss: 0.9470\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9414\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9411\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9396\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9400\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9385\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9391\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9409 - val_loss: 0.9379\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9412 - val_loss: 0.9437\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9414 - val_loss: 0.9385\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9370\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9399 - val_loss: 0.9370\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9363\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9413\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9364\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 0.9420\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9409 - val_loss: 0.9367\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9370\n",
      "Top-2 accuracy = 0.828\n",
      "18\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0908 - val_loss: 1.0838\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0798 - val_loss: 1.0762\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0748 - val_loss: 1.0728\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0727 - val_loss: 1.0715\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "19\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0587 - val_loss: 1.0348\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0273 - val_loss: 1.0057\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0080 - val_loss: 0.9917\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9833\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9955 - val_loss: 0.9844\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9839\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 0.9790\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9858 - val_loss: 0.9737\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9820 - val_loss: 0.9689\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9774 - val_loss: 0.9662\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9756 - val_loss: 0.9633\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9742 - val_loss: 0.9626\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9732 - val_loss: 0.9631\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9724 - val_loss: 0.9606\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9728 - val_loss: 0.9608\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9707 - val_loss: 0.9594\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9676 - val_loss: 0.9545\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 0.9525\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9613 - val_loss: 0.9526\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9605 - val_loss: 0.9533\n",
      "Top-2 accuracy = 0.825\n",
      "20\n",
      "normalizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0829 - val_loss: 1.0709\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0709\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0710\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0709\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "21\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0720 - val_loss: 1.0570\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0379 - val_loss: 1.0002\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 0.9768\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9821 - val_loss: 0.9720\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9773 - val_loss: 0.9652\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9744 - val_loss: 0.9629\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9720 - val_loss: 0.9638\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9682 - val_loss: 0.9589\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9621 - val_loss: 0.9511\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9587 - val_loss: 0.9497\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9568 - val_loss: 0.9500\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9554 - val_loss: 0.9479\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 0.9477\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 0.9466\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9524 - val_loss: 0.9494\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9524 - val_loss: 0.9466\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9457\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9503 - val_loss: 0.9459\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9443\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9498 - val_loss: 0.9458\n",
      "Top-2 accuracy = 0.822\n",
      "22\n",
      "maxabsR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0724 - val_loss: 1.0214\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9688 - val_loss: 0.9452\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9405\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.9351\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 0.9342\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9331\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9348 - val_loss: 0.9317\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9340 - val_loss: 0.9328\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.9325\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9325 - val_loss: 0.9325\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9327 - val_loss: 0.9316\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9318 - val_loss: 0.9303\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9318\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9334 - val_loss: 0.9312\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9333\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9317 - val_loss: 0.9307\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9311 - val_loss: 0.9352\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 0.9305\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9308 - val_loss: 0.9288\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 0.9307\n",
      "Top-2 accuracy = 0.833\n",
      "23\n",
      "normalizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0844 - val_loss: 1.0535\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0017 - val_loss: 0.9582\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9590 - val_loss: 0.9491\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9510 - val_loss: 0.9427\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9437 - val_loss: 0.9362\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9446 - val_loss: 0.9368\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9399 - val_loss: 0.9388\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9393 - val_loss: 0.9342\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9366 - val_loss: 0.9343\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9391 - val_loss: 0.9326\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9368 - val_loss: 0.9374\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9359 - val_loss: 0.9313\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9361 - val_loss: 0.9310\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9352 - val_loss: 0.9435\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9366 - val_loss: 0.9307\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9349 - val_loss: 0.9310\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9350 - val_loss: 0.9340\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9348 - val_loss: 0.9342\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9340 - val_loss: 0.9297\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9337 - val_loss: 0.9300\n",
      "Top-2 accuracy = 0.835\n",
      "24\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0908 - val_loss: 1.0838\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0799 - val_loss: 1.0762\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0748 - val_loss: 1.0728\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0726 - val_loss: 1.0714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0718 - val_loss: 1.0709\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "25\n",
      "standardizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0222 - val_loss: 0.9689\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9581 - val_loss: 0.9446\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9438 - val_loss: 0.9377\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9402 - val_loss: 0.9497\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9401 - val_loss: 0.9416\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9381 - val_loss: 0.9407\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9376 - val_loss: 0.9375\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9379 - val_loss: 0.9359\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9368 - val_loss: 0.9363\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9366 - val_loss: 0.9334\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9334\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9340 - val_loss: 0.9343\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9376\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9346 - val_loss: 0.9524\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9379 - val_loss: 0.9319\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9330 - val_loss: 0.9326\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9333 - val_loss: 0.9325\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9346 - val_loss: 0.9361\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9335 - val_loss: 0.9338\n",
      "Top-2 accuracy = 0.833\n",
      "26\n",
      "normalizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0757 - val_loss: 1.0409\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 0.9713\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9636 - val_loss: 0.9535\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9554 - val_loss: 0.9483\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9519 - val_loss: 0.9479\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9505 - val_loss: 0.9496\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9442\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9489 - val_loss: 0.9470\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 0.9461\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9501\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 0.9421\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9457\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9415\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9422\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9420\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9457\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 0.9417\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9450 - val_loss: 0.9401\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9446 - val_loss: 0.9407\n",
      "Top-2 accuracy = 0.829\n",
      "27\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0767 - val_loss: 1.0483\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0286 - val_loss: 1.0064\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9857 - val_loss: 0.9651\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9576 - val_loss: 0.9482\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9474 - val_loss: 0.9469\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9434 - val_loss: 0.9450\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9415 - val_loss: 0.9407\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 0.9373\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9398 - val_loss: 0.9368\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9396 - val_loss: 0.9363\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9390 - val_loss: 0.9360\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9357\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9385 - val_loss: 0.9365\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9385 - val_loss: 0.9358\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9382 - val_loss: 0.9401\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 0.9357\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9367\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9367\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9385 - val_loss: 0.9366\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9373 - val_loss: 0.9358\n",
      "Top-2 accuracy = 0.832\n",
      "28\n",
      "standardizeq|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_721 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0373 - val_loss: 0.9799\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9754 - val_loss: 0.9616\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9633 - val_loss: 0.9541\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9570 - val_loss: 0.9495\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9530 - val_loss: 0.9452\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9493 - val_loss: 0.9421\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9468 - val_loss: 0.9404\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9407\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9438 - val_loss: 0.9374\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9419 - val_loss: 0.9360\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9408 - val_loss: 0.9357\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9346\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9387 - val_loss: 0.9352\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9390 - val_loss: 0.9335\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9376 - val_loss: 0.9333\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9368 - val_loss: 0.9325\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9367 - val_loss: 0.9331\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9364 - val_loss: 0.9317\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9363 - val_loss: 0.9316\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9319\n",
      "Top-2 accuracy = 0.837\n",
      "29\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0870 - val_loss: 1.0661\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0451 - val_loss: 1.0180\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9972 - val_loss: 0.9794\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9741 - val_loss: 0.9635\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9631 - val_loss: 0.9552\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9576 - val_loss: 0.9528\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9551 - val_loss: 0.9546\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9555 - val_loss: 0.9486\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9531 - val_loss: 0.9509\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9527 - val_loss: 0.9512\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9516 - val_loss: 0.9504\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9522 - val_loss: 0.9465\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9505 - val_loss: 0.9465\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9513 - val_loss: 0.9465\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9494 - val_loss: 0.9471\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9495 - val_loss: 0.9513\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9488 - val_loss: 0.9453\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9490 - val_loss: 0.9438\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9479 - val_loss: 0.9458\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9482 - val_loss: 0.9467\n",
      "Top-2 accuracy = 0.825\n",
      "0\n",
      "normalizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0361 - val_loss: 0.9874\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9755 - val_loss: 0.9600\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9612 - val_loss: 0.9504\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9545 - val_loss: 0.9458\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9440\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9490 - val_loss: 0.9443\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9492 - val_loss: 0.9427\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9460 - val_loss: 0.9422\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9459 - val_loss: 0.9396\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9381\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9369\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9428 - val_loss: 0.9387\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9426 - val_loss: 0.9372\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9356\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.9359\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9410 - val_loss: 0.9344\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 0.9386\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9351\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9341\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9392 - val_loss: 0.9332\n",
      "Top-2 accuracy = 0.83\n",
      "1\n",
      "normalized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0692 - val_loss: 1.0155\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9741 - val_loss: 0.9506\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9527 - val_loss: 0.9429\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9479 - val_loss: 0.9406\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9465 - val_loss: 0.9417\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9396\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9426 - val_loss: 0.9359\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9414 - val_loss: 0.9370\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9406 - val_loss: 0.9356\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9397 - val_loss: 0.9346\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.9343\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9378 - val_loss: 0.9359\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 0.9375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 0.9344\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 0.9371\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9362 - val_loss: 0.9376\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9322\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9355 - val_loss: 0.9320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 0.9337\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9349 - val_loss: 0.9318\n",
      "Top-2 accuracy = 0.83\n",
      "2\n",
      "normalizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0905 - val_loss: 1.0827\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0773 - val_loss: 1.0715\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0632 - val_loss: 1.0525\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0416 - val_loss: 1.0315\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0228 - val_loss: 1.0148\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0087 - val_loss: 1.0023\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9929\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9901 - val_loss: 0.9852\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9833 - val_loss: 0.9784\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9779 - val_loss: 0.9736\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9742 - val_loss: 0.9691\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9710 - val_loss: 0.9672\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9685 - val_loss: 0.9637\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9667 - val_loss: 0.9623\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9651 - val_loss: 0.9602\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9632 - val_loss: 0.9590\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9625 - val_loss: 0.9572\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9615 - val_loss: 0.9560\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9597 - val_loss: 0.9553\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9589 - val_loss: 0.9547\n",
      "Top-2 accuracy = 0.828\n",
      "3\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0331 - val_loss: 0.9839\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9696 - val_loss: 0.9504\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9425\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9534\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9454\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9418 - val_loss: 0.9375\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9379\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9345\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9437 - val_loss: 0.9351\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9339\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9346\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 0.9334\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9409\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.9389\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9367\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9420\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9308\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9348 - val_loss: 0.9320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 0.9447\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9308\n",
      "Top-2 accuracy = 0.834\n",
      "4\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_749 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0853 - val_loss: 1.0708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0604 - val_loss: 1.0490\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0419 - val_loss: 1.0339\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0283 - val_loss: 1.0202\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0172 - val_loss: 1.0103\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0084 - val_loss: 1.0020\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0014 - val_loss: 0.9961\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9955 - val_loss: 0.9890\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9911 - val_loss: 0.9868\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9877 - val_loss: 0.9806\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9847 - val_loss: 0.9775\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9824 - val_loss: 0.9747\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9804 - val_loss: 0.9726\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9783 - val_loss: 0.9707\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9766 - val_loss: 0.9714\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9757 - val_loss: 0.9683\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9738 - val_loss: 0.9664\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9727 - val_loss: 0.9659\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9717 - val_loss: 0.9639\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9707 - val_loss: 0.9633\n",
      "Top-2 accuracy = 0.82\n",
      "5\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0347 - val_loss: 0.9921\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9826 - val_loss: 0.9639\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9559 - val_loss: 0.9502\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9469 - val_loss: 0.9418\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9464 - val_loss: 0.9421\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9438 - val_loss: 0.9435\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9453 - val_loss: 0.9406\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9388\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9410 - val_loss: 0.9376\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9418 - val_loss: 0.9378\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 0.9399\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9373\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9405 - val_loss: 0.9360\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9406 - val_loss: 0.9412\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9407 - val_loss: 0.9367\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9397 - val_loss: 0.9414\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9414 - val_loss: 0.9384\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9397\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 0.9380\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 0.9362\n",
      "Top-2 accuracy = 0.831\n",
      "6\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 1.0134 - val_loss: 0.9587\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9608 - val_loss: 0.9482\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9527 - val_loss: 0.9486\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9596\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9455\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9482 - val_loss: 0.9390\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9373\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9378\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9436 - val_loss: 0.9366\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9417 - val_loss: 0.9368\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 0.9353\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9341\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9401 - val_loss: 0.9340\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9406 - val_loss: 0.9343\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9347\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9553\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9355\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 0.9371\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9317\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9392 - val_loss: 0.9375\n",
      "Top-2 accuracy = 0.83\n",
      "7\n",
      "minmaxo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0792 - val_loss: 1.0601\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0480 - val_loss: 1.0247\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0136 - val_loss: 0.9964\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 0.9824\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9831 - val_loss: 0.9718\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9740 - val_loss: 0.9651\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9689 - val_loss: 0.9594\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9648 - val_loss: 0.9566\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 0.9547\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9608 - val_loss: 0.9556\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9602 - val_loss: 0.9525\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9584 - val_loss: 0.9509\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9576 - val_loss: 0.9507\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9569 - val_loss: 0.9513\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9565 - val_loss: 0.9492\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 0.9484\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9552 - val_loss: 0.9487\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9551 - val_loss: 0.9481\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 0.9480\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9540 - val_loss: 0.9477\n",
      "Top-2 accuracy = 0.824\n",
      "8\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0728 - val_loss: 1.0459\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0246 - val_loss: 1.0066\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9981 - val_loss: 0.9877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9819 - val_loss: 0.9721\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9699 - val_loss: 0.9621\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9606 - val_loss: 0.9585\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9581 - val_loss: 0.9509\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9536 - val_loss: 0.9551\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9514 - val_loss: 0.9477\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9501 - val_loss: 0.9450\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9485 - val_loss: 0.9594\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9495 - val_loss: 0.9435\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9474 - val_loss: 0.9437\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9471 - val_loss: 0.9435\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9457 - val_loss: 0.9422\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9450 - val_loss: 0.9457\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9459 - val_loss: 0.9446\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9450 - val_loss: 0.9458\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9481 - val_loss: 0.9461\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9447 - val_loss: 0.9420\n",
      "Top-2 accuracy = 0.832\n",
      "9\n",
      "normalizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0785 - val_loss: 1.0708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0710\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0718 - val_loss: 1.0708\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0706\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0602 - val_loss: 1.0128\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9913 - val_loss: 0.9753\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9730 - val_loss: 0.9573\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9635 - val_loss: 0.9534\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9611 - val_loss: 0.9702\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9584 - val_loss: 0.9504\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9552 - val_loss: 0.9529\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9546 - val_loss: 0.9502\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9537 - val_loss: 0.9475\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9503 - val_loss: 0.9492\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9499 - val_loss: 0.9467\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9446\n",
      "Top-2 accuracy = 0.825\n",
      "10\n",
      "minmaxR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0263 - val_loss: 0.9723\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9629 - val_loss: 0.9476\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9520 - val_loss: 0.9658\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9499 - val_loss: 0.9412\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9473 - val_loss: 0.9438\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9476 - val_loss: 0.9428\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9464 - val_loss: 0.9387\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9469 - val_loss: 0.9399\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9471 - val_loss: 0.9438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9473 - val_loss: 0.9482\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9490 - val_loss: 0.9379\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9479 - val_loss: 0.9387\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9457 - val_loss: 0.9379\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9452 - val_loss: 0.9385\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9465 - val_loss: 0.9424\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9454 - val_loss: 0.9389\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9460 - val_loss: 0.9376\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9455 - val_loss: 0.9453\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9463 - val_loss: 0.9436\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9463 - val_loss: 0.9404\n",
      "Top-2 accuracy = 0.829\n",
      "11\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0830 - val_loss: 1.0686\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0650 - val_loss: 1.0452\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0202 - val_loss: 0.9964\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9923 - val_loss: 0.9853\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9743 - val_loss: 0.9672\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9669 - val_loss: 0.9642\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9637 - val_loss: 0.9547\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9587 - val_loss: 0.9565\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9558 - val_loss: 0.9480\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 0.9478\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9525 - val_loss: 0.9453\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9442\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9428\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9484 - val_loss: 0.9444\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9479 - val_loss: 0.9436\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 0.9525\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9492 - val_loss: 0.9402\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9460 - val_loss: 0.9448\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9475 - val_loss: 0.9405\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9442 - val_loss: 0.9386\n",
      "Top-2 accuracy = 0.827\n",
      "12\n",
      "normalizej|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0056 - val_loss: 0.9738\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9576 - val_loss: 0.9460\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9493 - val_loss: 0.9519\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9474 - val_loss: 0.9390\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9460 - val_loss: 0.9366\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9447 - val_loss: 0.9355\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9464 - val_loss: 0.9430\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9437 - val_loss: 0.9365\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9338\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9342\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9414 - val_loss: 0.9329\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9335\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 0.9557\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9453 - val_loss: 0.9350\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9416 - val_loss: 0.9366\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9322\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9389 - val_loss: 0.9405\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9399 - val_loss: 0.9320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9405 - val_loss: 0.9322\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9445\n",
      "Top-2 accuracy = 0.823\n",
      "13\n",
      "maxabsB|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_787 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0755 - val_loss: 1.0683\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0643 - val_loss: 1.0549\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0302 - val_loss: 0.9962\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9923 - val_loss: 0.9774\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9803 - val_loss: 0.9709\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9763 - val_loss: 0.9687\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9746 - val_loss: 0.9682\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9743 - val_loss: 0.9668\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9727 - val_loss: 0.9646\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9717 - val_loss: 0.9645\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9724 - val_loss: 0.9641\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9704 - val_loss: 0.9629\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9700 - val_loss: 0.9615\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9697 - val_loss: 0.9650\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9693 - val_loss: 0.9608\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9686 - val_loss: 0.9604\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9680 - val_loss: 0.9611\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9679 - val_loss: 0.9596\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9673 - val_loss: 0.9596\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9667 - val_loss: 0.9583\n",
      "Top-2 accuracy = 0.819\n",
      "14\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0820 - val_loss: 1.0713\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Top-2 accuracy = 0.724\n",
      "15\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0303 - val_loss: 0.9826\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9723 - val_loss: 0.9614\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9605 - val_loss: 0.9538\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9540 - val_loss: 0.9494\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9518 - val_loss: 0.9459\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 0.9448\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 0.9475\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 0.9472\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9424\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 0.9422\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 0.9418\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 0.9409\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9433\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9424\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9410\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9430 - val_loss: 0.9404\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9430 - val_loss: 0.9396\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9431 - val_loss: 0.9402\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9423 - val_loss: 0.9409\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9394\n",
      "Top-2 accuracy = 0.832\n",
      "16\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0566 - val_loss: 0.9863\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9653 - val_loss: 0.9456\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9411 - val_loss: 0.9314\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9326\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9363 - val_loss: 0.9305\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9357 - val_loss: 0.9390\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9305\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 0.9294\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9325 - val_loss: 0.9292\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9289\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9326 - val_loss: 0.9300\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9316 - val_loss: 0.9296\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9317 - val_loss: 0.9344\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9280\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9312 - val_loss: 0.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9307 - val_loss: 0.9300\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9320 - val_loss: 0.9338\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9312 - val_loss: 0.9281\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9304 - val_loss: 0.9294\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9316 - val_loss: 0.9288\n",
      "Top-2 accuracy = 0.835\n",
      "17\n",
      "normalizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0911 - val_loss: 1.0842\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0804 - val_loss: 1.0766\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0750 - val_loss: 1.0729\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0729 - val_loss: 1.0716\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0720 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "18\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0721 - val_loss: 1.0272\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9811\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9766 - val_loss: 0.9658\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9677 - val_loss: 0.9593\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9616 - val_loss: 0.9550\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9573 - val_loss: 0.9525\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 0.9481\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9516 - val_loss: 0.9471\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9466\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9503 - val_loss: 0.9453\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 0.9432\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9470\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9415\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9471 - val_loss: 0.9533\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 0.9419\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9401\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 0.9401\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 0.9408\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9428\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 0.9401\n",
      "Top-2 accuracy = 0.829\n",
      "19\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0753 - val_loss: 1.0523\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 0.9639\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9641 - val_loss: 0.9583\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9590 - val_loss: 0.9516\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9561 - val_loss: 0.9481\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9540 - val_loss: 0.9484\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9534 - val_loss: 0.9544\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9534 - val_loss: 0.9473\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 0.9434\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9509 - val_loss: 0.9527\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9448\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9421\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 0.9415\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9403\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9420\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9399\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9471 - val_loss: 0.9402\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9464 - val_loss: 0.9475\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9489 - val_loss: 0.9419\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9475 - val_loss: 0.9399\n",
      "Top-2 accuracy = 0.829\n",
      "20\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_823 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0724 - val_loss: 1.0618\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0513 - val_loss: 1.0277\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0150 - val_loss: 0.9930\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9897 - val_loss: 0.9756\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9804 - val_loss: 0.9712\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9766 - val_loss: 0.9673\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9743 - val_loss: 0.9658\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9739 - val_loss: 0.9655\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9732 - val_loss: 0.9652\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9726 - val_loss: 0.9648\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9726 - val_loss: 0.9643\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9722 - val_loss: 0.9640\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9720 - val_loss: 0.9652\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9722 - val_loss: 0.9637\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9710 - val_loss: 0.9633\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9706 - val_loss: 0.9627\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9705 - val_loss: 0.9632\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9700 - val_loss: 0.9627\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9694 - val_loss: 0.9626\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9690 - val_loss: 0.9610\n",
      "Top-2 accuracy = 0.814\n",
      "21\n",
      "normalizeS|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0887 - val_loss: 1.0794\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0679 - val_loss: 1.0417\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 0.9809\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9758 - val_loss: 0.9664\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9657 - val_loss: 0.9563\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9614 - val_loss: 0.9522\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9590 - val_loss: 0.9524\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9585 - val_loss: 0.9514\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9574 - val_loss: 0.9515\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9560 - val_loss: 0.9486\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 0.9472\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 0.9468\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9467\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9467\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9534 - val_loss: 0.9468\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9528 - val_loss: 0.9459\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9459\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9459\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9465\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9497\n",
      "Top-2 accuracy = 0.819\n",
      "22\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0864 - val_loss: 1.0643\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0458 - val_loss: 1.0208\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0088 - val_loss: 0.9962\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 0.9887\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9908 - val_loss: 0.9867\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9880 - val_loss: 0.9831\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9889 - val_loss: 0.9815\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9845 - val_loss: 0.9812\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9819 - val_loss: 0.9798\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9805 - val_loss: 0.9792\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9802 - val_loss: 0.9780\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9792 - val_loss: 0.9765\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9784 - val_loss: 0.9757\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9771 - val_loss: 0.9753\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9756 - val_loss: 0.9752\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9750 - val_loss: 0.9757\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9747 - val_loss: 0.9738\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9736 - val_loss: 0.9733\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9731 - val_loss: 0.9734\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9729 - val_loss: 0.9731\n",
      "Top-2 accuracy = 0.825\n",
      "23\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0677 - val_loss: 1.0446\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0258 - val_loss: 1.0013\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9897 - val_loss: 0.9751\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9731 - val_loss: 0.9622\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9664 - val_loss: 0.9597\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9636 - val_loss: 0.9569\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9611 - val_loss: 0.9530\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.9524\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9588 - val_loss: 0.9530\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9578 - val_loss: 0.9511\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9573 - val_loss: 0.9505\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9569 - val_loss: 0.9517\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9559 - val_loss: 0.9504\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9561 - val_loss: 0.9505\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 0.9485\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9546 - val_loss: 0.9479\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 0.9484\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9540 - val_loss: 0.9475\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 0.9487\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 0.9518\n",
      "Top-2 accuracy = 0.829\n",
      "24\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0335 - val_loss: 0.9857\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9688 - val_loss: 0.9487\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9491 - val_loss: 0.9393\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9441 - val_loss: 0.9375\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9439 - val_loss: 0.9373\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 0.9356\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9407 - val_loss: 0.9417\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9401 - val_loss: 0.9343\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9334\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 0.9339\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9369 - val_loss: 0.9325\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9321\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9364 - val_loss: 0.9304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9354 - val_loss: 0.9312\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9359 - val_loss: 0.9305\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 0.9361\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9301\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 0.9342\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9351 - val_loss: 0.9330\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9359 - val_loss: 0.9312\n",
      "Top-2 accuracy = 0.83\n",
      "25\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0523 - val_loss: 0.9949\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9774 - val_loss: 0.9615\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9593 - val_loss: 0.9487\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9481 - val_loss: 0.9420\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9453 - val_loss: 0.9410\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9411 - val_loss: 0.9358\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9395 - val_loss: 0.9473\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9423 - val_loss: 0.9454\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 0.9341\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9391 - val_loss: 0.9367\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9387\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9382 - val_loss: 0.9363\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 0.9335\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9361\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9365 - val_loss: 0.9319\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9370 - val_loss: 0.9376\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9369 - val_loss: 0.9326\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9363 - val_loss: 0.9335\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9370 - val_loss: 0.9320\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9356 - val_loss: 0.9400\n",
      "Top-2 accuracy = 0.825\n",
      "26\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0746 - val_loss: 1.0215\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9796 - val_loss: 0.9655\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9573 - val_loss: 0.9581\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9698\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9443\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9465 - val_loss: 0.9448\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 0.9431\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 0.9417\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9436\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9553\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9434 - val_loss: 0.9367\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9370\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9373\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9408 - val_loss: 0.9359\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9356\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9390 - val_loss: 0.9377\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9345\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9390 - val_loss: 0.9349\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9387 - val_loss: 0.9418\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9386 - val_loss: 0.9369\n",
      "Top-2 accuracy = 0.828\n",
      "27\n",
      "robustz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0633 - val_loss: 1.0300\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0122 - val_loss: 0.9937\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9893 - val_loss: 0.9864\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9779 - val_loss: 0.9698\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9659 - val_loss: 0.9625\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9611 - val_loss: 0.9523\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9603 - val_loss: 0.9528\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9545 - val_loss: 0.9482\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9508 - val_loss: 0.9518\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9530 - val_loss: 0.9513\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9522 - val_loss: 0.9471\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9491 - val_loss: 0.9560\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9509 - val_loss: 0.9458\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9479 - val_loss: 0.9486\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9481 - val_loss: 0.9450\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9475 - val_loss: 0.9445\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9463 - val_loss: 0.9448\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9466 - val_loss: 0.9450\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9468 - val_loss: 0.9454\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9462 - val_loss: 0.9436\n",
      "Top-2 accuracy = 0.829\n",
      "28\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0374 - val_loss: 0.9800\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9705 - val_loss: 0.9592\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9588 - val_loss: 0.9523\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9541 - val_loss: 0.9489\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9523 - val_loss: 0.9474\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9497\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9490 - val_loss: 0.9468\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9497 - val_loss: 0.9432\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9417\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9456 - val_loss: 0.9415\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 0.9458\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.9410\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9457 - val_loss: 0.9435\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9444 - val_loss: 0.9407\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9434 - val_loss: 0.9413\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9426 - val_loss: 0.9387\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9428 - val_loss: 0.9377\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9429 - val_loss: 0.9396\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9417 - val_loss: 0.9372\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9418 - val_loss: 0.9396\n",
      "Top-2 accuracy = 0.831\n",
      "29\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0776 - val_loss: 1.0469\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0190 - val_loss: 0.9910\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9847 - val_loss: 0.9713\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9720 - val_loss: 0.9631\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9649 - val_loss: 0.9580\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9601 - val_loss: 0.9525\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9556 - val_loss: 0.9492\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9528 - val_loss: 0.9479\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9457\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9448\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 0.9434\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9470 - val_loss: 0.9429\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9467 - val_loss: 0.9429\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9420\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9451 - val_loss: 0.9411\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9442 - val_loss: 0.9407\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9394\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9434 - val_loss: 0.9395\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9424 - val_loss: 0.9385\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9382\n",
      "Top-2 accuracy = 0.831\n",
      "0\n",
      "robustq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0267 - val_loss: 0.9809\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9709 - val_loss: 0.9569\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9567 - val_loss: 0.9477\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9506 - val_loss: 0.9442\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9488 - val_loss: 0.9440\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9477 - val_loss: 0.9449\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 0.9473 - val_loss: 0.9415\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9477 - val_loss: 0.9405\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9451 - val_loss: 0.9436\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9455 - val_loss: 0.9410\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9452 - val_loss: 0.9459\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9447 - val_loss: 0.9388\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9448 - val_loss: 0.9394\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9436 - val_loss: 0.9416\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9440 - val_loss: 0.9391\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9429 - val_loss: 0.9374\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9425 - val_loss: 0.9372\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9397\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9423 - val_loss: 0.9380\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.9372\n",
      "Top-2 accuracy = 0.83\n",
      "1\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0721 - val_loss: 1.0372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0066 - val_loss: 0.9810\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9696 - val_loss: 0.9558\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9543 - val_loss: 0.9459\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9422\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9462 - val_loss: 0.9410\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9415\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9448 - val_loss: 0.9426\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9430\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9456 - val_loss: 0.9409\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9436 - val_loss: 0.9407\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9443 - val_loss: 0.9410\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9434 - val_loss: 0.9394\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9433 - val_loss: 0.9376\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9429 - val_loss: 0.9372\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9424 - val_loss: 0.9375\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9424 - val_loss: 0.9389\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9402\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 0.9372\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9392\n",
      "Top-2 accuracy = 0.832\n",
      "2\n",
      "maxabsc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0506 - val_loss: 0.9937\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9755 - val_loss: 0.9531\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9541 - val_loss: 0.9494\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9489 - val_loss: 0.9412\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9459 - val_loss: 0.9463\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9440 - val_loss: 0.9366\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9432 - val_loss: 0.9398\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.9343\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9393 - val_loss: 0.9332\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 0.9337\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9383 - val_loss: 0.9408\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 0.9330\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9375 - val_loss: 0.9431\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9370 - val_loss: 0.9338\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9364 - val_loss: 0.9356\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9373 - val_loss: 0.9302\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9347 - val_loss: 0.9317\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9346 - val_loss: 0.9295\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9341 - val_loss: 0.9307\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9339 - val_loss: 0.9360\n",
      "Top-2 accuracy = 0.826\n",
      "3\n",
      "maxabsC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0481 - val_loss: 0.9894\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9671 - val_loss: 0.9456\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9454 - val_loss: 0.9468\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9426 - val_loss: 0.9387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9376\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9372\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9374\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9352\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9384\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9385\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 0.9375\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9348\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 0.9365\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9365 - val_loss: 0.9341\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9345\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 0.9354\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9367 - val_loss: 0.9333\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9334\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9357 - val_loss: 0.9337\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9331\n",
      "Top-2 accuracy = 0.834\n",
      "4\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0906 - val_loss: 1.0765\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0618 - val_loss: 1.0291\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0028 - val_loss: 0.9769\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9804 - val_loss: 0.9685\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9758 - val_loss: 0.9650\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9732 - val_loss: 0.9629\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9703 - val_loss: 0.9590\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9665 - val_loss: 0.9562\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9639 - val_loss: 0.9539\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9609 - val_loss: 0.9508\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9585 - val_loss: 0.9498\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9570 - val_loss: 0.9481\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9557 - val_loss: 0.9467\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9546 - val_loss: 0.9453\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9537 - val_loss: 0.9451\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9456\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9443\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9516 - val_loss: 0.9441\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 0.9428\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9503 - val_loss: 0.9424\n",
      "Top-2 accuracy = 0.829\n",
      "5\n",
      "normalizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0296 - val_loss: 0.9677\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9582 - val_loss: 0.9546\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9476 - val_loss: 0.9422\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9448 - val_loss: 0.9596\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9445 - val_loss: 0.9409\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9380\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9412 - val_loss: 0.9349\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9391 - val_loss: 0.9378\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9395 - val_loss: 0.9362\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9370 - val_loss: 0.9387\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9348\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9353\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9335\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 0.9327\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9349 - val_loss: 0.9331\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9348 - val_loss: 0.9338\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9355 - val_loss: 0.9463\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9375 - val_loss: 0.9312\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9349 - val_loss: 0.9322\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9353 - val_loss: 0.9315\n",
      "Top-2 accuracy = 0.833\n",
      "6\n",
      "maxabsr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0790 - val_loss: 1.0326\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0017 - val_loss: 0.9721\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9691 - val_loss: 0.9584\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9608 - val_loss: 0.9499\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9567 - val_loss: 0.9483\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9560 - val_loss: 0.9495\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9543 - val_loss: 0.9468\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9531 - val_loss: 0.9483\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9521 - val_loss: 0.9530\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9549 - val_loss: 0.9475\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9472\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9519 - val_loss: 0.9493\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9514 - val_loss: 0.9457\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9501 - val_loss: 0.9455\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9503 - val_loss: 0.9460\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9499 - val_loss: 0.9458\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9498 - val_loss: 0.9453\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 0.9457\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 0.9464\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 0.9436\n",
      "Top-2 accuracy = 0.83\n",
      "7\n",
      "normalizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0181 - val_loss: 0.9821\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9604 - val_loss: 0.9575\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9487 - val_loss: 0.9375\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9425 - val_loss: 0.9343\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.9359\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9387 - val_loss: 0.9354\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 0.9343\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9363 - val_loss: 0.9345\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9372 - val_loss: 0.9311\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9363 - val_loss: 0.9305\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 0.9308\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9343 - val_loss: 0.9310\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9343 - val_loss: 0.9311\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9350 - val_loss: 0.9321\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9348 - val_loss: 0.9314\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9344 - val_loss: 0.9297\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9329 - val_loss: 0.9286\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9334 - val_loss: 0.9431\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9387 - val_loss: 0.9398\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9293\n",
      "Top-2 accuracy = 0.832\n",
      "8\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0753 - val_loss: 1.0710\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "9\n",
      "minmaxf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0790 - val_loss: 1.0567\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0410 - val_loss: 1.0210\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0074 - val_loss: 0.9921\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9850 - val_loss: 0.9745\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9739 - val_loss: 0.9651\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9680 - val_loss: 0.9607\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9639 - val_loss: 0.9602\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9602 - val_loss: 0.9542\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9580 - val_loss: 0.9514\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9560 - val_loss: 0.9561\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9556 - val_loss: 0.9488\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 0.9554\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 0.9511\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9531 - val_loss: 0.9519\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9528 - val_loss: 0.9464\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9531 - val_loss: 0.9472\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9527 - val_loss: 0.9475\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9520 - val_loss: 0.9470\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9517 - val_loss: 0.9476\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9523 - val_loss: 0.9476\n",
      "Top-2 accuracy = 0.83\n",
      "10\n",
      "maxabsV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0587 - val_loss: 1.0168\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9769 - val_loss: 0.9517\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9445\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9527 - val_loss: 0.9446\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9426\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9488\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9399\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9460 - val_loss: 0.9522\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9488 - val_loss: 0.9437\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9474 - val_loss: 0.9390\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9445\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9466 - val_loss: 0.9411\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9460 - val_loss: 0.9402\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9452 - val_loss: 0.9488\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9381\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9465 - val_loss: 0.9506\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9443 - val_loss: 0.9380\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9455 - val_loss: 0.9372\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 0.9371\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9368\n",
      "Top-2 accuracy = 0.83\n",
      "11\n",
      "normalizei|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0439 - val_loss: 0.9885\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9785 - val_loss: 0.9579\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9553 - val_loss: 0.9395\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9380 - val_loss: 0.9333\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9391 - val_loss: 0.9383\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9368 - val_loss: 0.9304\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9343 - val_loss: 0.9336\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9353 - val_loss: 0.9395\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9396 - val_loss: 0.9302\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9343 - val_loss: 0.9388\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9339 - val_loss: 0.9298\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 0.9411\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 0.9305\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9332 - val_loss: 0.9288\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9337 - val_loss: 0.9291\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9324 - val_loss: 0.9307\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9356 - val_loss: 0.9324\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9337 - val_loss: 0.9302\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9338 - val_loss: 0.9388\n",
      "Top-2 accuracy = 0.825\n",
      "12\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0913 - val_loss: 1.0843\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0805 - val_loss: 1.0766\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0750 - val_loss: 1.0729\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0726 - val_loss: 1.0714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "13\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0851 - val_loss: 1.0726\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0721 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0718 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0709\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0411 - val_loss: 0.9902\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0142 - val_loss: 0.9966\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0072 - val_loss: 1.0054\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0354 - val_loss: 1.0450\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0498 - val_loss: 1.0458\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0457\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0457\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0456\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0460\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0457\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0457\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0455\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0457\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0456\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0458\n",
      "Top-2 accuracy = 0.735\n",
      "14\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0784 - val_loss: 1.0717\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0718 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "15\n",
      "standardizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0813 - val_loss: 1.0627\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0455 - val_loss: 1.0270\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.0108 - val_loss: 0.9925\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9829 - val_loss: 0.9697\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9692 - val_loss: 0.9592\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9630 - val_loss: 0.9544\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9600 - val_loss: 0.9517\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9578 - val_loss: 0.9503\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9562 - val_loss: 0.9494\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9551 - val_loss: 0.9482\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9541 - val_loss: 0.9472\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9533 - val_loss: 0.9464\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9523 - val_loss: 0.9454\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9517 - val_loss: 0.9447\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9508 - val_loss: 0.9443\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9503 - val_loss: 0.9433\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9497 - val_loss: 0.9430\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9421\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9485 - val_loss: 0.9419\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9486 - val_loss: 0.9409\n",
      "Top-2 accuracy = 0.827\n",
      "16\n",
      "standardizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0663 - val_loss: 1.0115\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9815 - val_loss: 0.9634\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9636 - val_loss: 0.9593\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9595 - val_loss: 0.9535\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 0.9499\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 0.9471\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9460\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9423\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9462 - val_loss: 0.9426\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9456 - val_loss: 0.9428\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9451 - val_loss: 0.9429\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 0.9392\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9389\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9432 - val_loss: 0.9385\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9422 - val_loss: 0.9384\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9434 - val_loss: 0.9384\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9422 - val_loss: 0.9392\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9414 - val_loss: 0.9386\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9373\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9377\n",
      "Top-2 accuracy = 0.831\n",
      "17\n",
      "minmaxb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0269 - val_loss: 0.9803\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9788 - val_loss: 0.9612\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9645 - val_loss: 0.9548\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9556 - val_loss: 0.9483\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9525 - val_loss: 0.9620\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9519 - val_loss: 0.9429\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9489 - val_loss: 0.9411\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9465 - val_loss: 0.9391\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9380\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9385\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9368\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9450 - val_loss: 0.9376\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9435 - val_loss: 0.9394\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 0.9360\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9424 - val_loss: 0.9345\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9387\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9382\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9351\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9352\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9425\n",
      "Top-2 accuracy = 0.822\n",
      "18\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0046 - val_loss: 0.9663\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9508 - val_loss: 0.9522\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9474 - val_loss: 0.9395\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9413 - val_loss: 0.9389\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9407 - val_loss: 0.9498\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9412 - val_loss: 0.9416\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9419 - val_loss: 0.9481\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9403 - val_loss: 0.9366\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9393 - val_loss: 0.9409\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9382 - val_loss: 0.9448\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9398 - val_loss: 0.9367\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9373 - val_loss: 0.9378\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9391 - val_loss: 0.9368\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9381 - val_loss: 0.9360\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9368 - val_loss: 0.9353\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9359 - val_loss: 0.9363\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9365 - val_loss: 0.9357\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9374 - val_loss: 0.9375\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9382\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9389 - val_loss: 0.9343\n",
      "Top-2 accuracy = 0.831\n",
      "19\n",
      "normalizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0730 - val_loss: 1.0532\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0282 - val_loss: 0.9898\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9875 - val_loss: 0.9726\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9780 - val_loss: 0.9667\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9745 - val_loss: 0.9636\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9740 - val_loss: 0.9625\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9723 - val_loss: 0.9620\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9710 - val_loss: 0.9607\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9704 - val_loss: 0.9602\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9697 - val_loss: 0.9600\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9688 - val_loss: 0.9591\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9684 - val_loss: 0.9596\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9686 - val_loss: 0.9583\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9673 - val_loss: 0.9620\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9678 - val_loss: 0.9582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9671 - val_loss: 0.9571\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9658 - val_loss: 0.9583\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9654 - val_loss: 0.9578\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9653 - val_loss: 0.9560\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9662 - val_loss: 0.9561\n",
      "Top-2 accuracy = 0.82\n",
      "20\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0570 - val_loss: 0.9976\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9790 - val_loss: 0.9666\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9663 - val_loss: 0.9689\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 0.9550\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9593 - val_loss: 0.9570\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9562 - val_loss: 0.9497\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9549\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9515 - val_loss: 0.9451\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9482\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9454\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 0.9449\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9474 - val_loss: 0.9462\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 0.9450\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9468 - val_loss: 0.9426\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9463 - val_loss: 0.9420\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9456 - val_loss: 0.9430\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 0.9409\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9452 - val_loss: 0.9413\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9442 - val_loss: 0.9463\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9436\n",
      "Top-2 accuracy = 0.823\n",
      "21\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0913 - val_loss: 1.0812\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0777 - val_loss: 1.0744\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0735 - val_loss: 1.0719\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0721 - val_loss: 1.0711\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0707\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0711 - val_loss: 1.0688\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0646 - val_loss: 1.0526\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0389 - val_loss: 1.0189\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0133 - val_loss: 0.9971\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9961 - val_loss: 0.9840\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9840 - val_loss: 0.9733\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9757 - val_loss: 0.9666\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9694 - val_loss: 0.9611\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9631 - val_loss: 0.9606\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9600 - val_loss: 0.9524\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9564 - val_loss: 0.9501\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9556 - val_loss: 0.9521\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 0.9473\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 0.9471\n",
      "Top-2 accuracy = 0.827\n",
      "22\n",
      "maxabsY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0318 - val_loss: 0.9707\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9589 - val_loss: 0.9446\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9473 - val_loss: 0.9408\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 0.9385\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9388\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9369\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9353\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9355\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9387 - val_loss: 0.9339\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9338\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9331\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 0.9339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 0.9321\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 0.9329\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9369 - val_loss: 0.9318\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9318\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 0.9309\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9357 - val_loss: 0.9308\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9319\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9300\n",
      "Top-2 accuracy = 0.835\n",
      "23\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0309 - val_loss: 0.9712\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9530 - val_loss: 0.9480\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9389 - val_loss: 0.9378\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9369 - val_loss: 0.9570\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9402 - val_loss: 0.9358\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9359 - val_loss: 0.9413\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9370 - val_loss: 0.9327\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9384 - val_loss: 0.9321\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9367\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9376 - val_loss: 0.9324\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9340 - val_loss: 0.9410\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9344 - val_loss: 0.9316\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9469\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9369 - val_loss: 0.9300\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9334 - val_loss: 0.9304\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9303\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9341 - val_loss: 0.9337\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9329 - val_loss: 0.9319\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9343 - val_loss: 0.9375\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9356 - val_loss: 0.9339\n",
      "Top-2 accuracy = 0.83\n",
      "24\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0688 - val_loss: 1.0379\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0153 - val_loss: 0.9870\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9788 - val_loss: 0.9660\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9663 - val_loss: 0.9559\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9603 - val_loss: 0.9517\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9574 - val_loss: 0.9492\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 0.9472\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9533 - val_loss: 0.9455\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9516 - val_loss: 0.9447\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9436\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 0.9430\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9495 - val_loss: 0.9423\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9489 - val_loss: 0.9419\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 0.9418\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 0.9417\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 0.9411\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9404\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9471 - val_loss: 0.9404\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9467 - val_loss: 0.9401\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9396\n",
      "Top-2 accuracy = 0.827\n",
      "25\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0818 - val_loss: 1.0699\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0488 - val_loss: 1.0064\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9883 - val_loss: 0.9700\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9684 - val_loss: 0.9577\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9593 - val_loss: 0.9514\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9473\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9442\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9422\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9417\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9452 - val_loss: 0.9396\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 0.9396\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9430 - val_loss: 0.9385\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9430 - val_loss: 0.9394\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 0.9376\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9386\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9415 - val_loss: 0.9373\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9412 - val_loss: 0.9387\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9372\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9403 - val_loss: 0.9368\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9401 - val_loss: 0.9369\n",
      "Top-2 accuracy = 0.832\n",
      "26\n",
      "minmaxo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0780 - val_loss: 1.0710\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "27\n",
      "maxabsF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0436 - val_loss: 0.9879\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9762 - val_loss: 0.9607\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9563 - val_loss: 0.9513\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9501 - val_loss: 0.9406\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9453 - val_loss: 0.9450\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9450 - val_loss: 0.9415\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9417 - val_loss: 0.9473\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9414 - val_loss: 0.9359\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.9649\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 0.9477\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9414 - val_loss: 0.9465\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9406 - val_loss: 0.9552\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9451 - val_loss: 0.9374\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9381 - val_loss: 0.9361\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9390 - val_loss: 0.9338\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9373 - val_loss: 0.9464\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9376 - val_loss: 0.9341\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9367 - val_loss: 0.9330\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9372 - val_loss: 0.9315\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9363 - val_loss: 0.9408\n",
      "Top-2 accuracy = 0.826\n",
      "28\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0901 - val_loss: 1.0790\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0747 - val_loss: 1.0711\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "29\n",
      "normalizeG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0218 - val_loss: 0.9629\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9550 - val_loss: 0.9462\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 0.9555\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 0.9428\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9352\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9401 - val_loss: 0.9360\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9394 - val_loss: 0.9359\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9405 - val_loss: 0.9342\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9406 - val_loss: 0.9332\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9312\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9324\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9384\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9348\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9337\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9309\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9353\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9395 - val_loss: 0.9315\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9323\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9366 - val_loss: 0.9455\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9391 - val_loss: 0.9302\n",
      "Top-2 accuracy = 0.835\n",
      "0\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0319 - val_loss: 0.9826\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9627 - val_loss: 0.9520\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9481 - val_loss: 0.9401\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9420 - val_loss: 0.9389\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 0.9362\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 0.9329\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9372 - val_loss: 0.9449\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9384 - val_loss: 0.9313\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9352 - val_loss: 0.9378\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9366 - val_loss: 0.9307\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9343 - val_loss: 0.9314\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9343 - val_loss: 0.9305\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9335 - val_loss: 0.9303\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9330 - val_loss: 0.9326\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9330 - val_loss: 0.9308\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9320 - val_loss: 0.9344\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9341 - val_loss: 0.9321\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9314 - val_loss: 0.9321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9317 - val_loss: 0.9335\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9316 - val_loss: 0.9288\n",
      "Top-2 accuracy = 0.832\n",
      "1\n",
      "minmaxO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0926 - val_loss: 1.0757\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0727 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Top-2 accuracy = 0.724\n",
      "2\n",
      "robustK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0432 - val_loss: 1.0078\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0136 - val_loss: 1.0022\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0091 - val_loss: 0.9988\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0071 - val_loss: 0.9984\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0051 - val_loss: 0.9922\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.9860\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9920 - val_loss: 0.9808\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9869 - val_loss: 0.9755\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9842 - val_loss: 0.9765\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9881 - val_loss: 0.9770\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9865 - val_loss: 0.9754\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9836 - val_loss: 0.9758\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9830 - val_loss: 0.9725\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9821 - val_loss: 0.9717\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9818 - val_loss: 0.9727\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9810 - val_loss: 0.9720\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9810 - val_loss: 0.9726\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9800 - val_loss: 0.9719\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9791 - val_loss: 0.9715\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9788 - val_loss: 0.9708\n",
      "Top-2 accuracy = 0.803\n",
      "3\n",
      "maxabse|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0949 - val_loss: 1.0843\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0806 - val_loss: 1.0768\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0751 - val_loss: 1.0731\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0728 - val_loss: 1.0715\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "4\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0862 - val_loss: 1.0748\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0721 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "5\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0723 - val_loss: 1.0637\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0508 - val_loss: 1.0260\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0161 - val_loss: 0.9959\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 0.9777\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9811 - val_loss: 0.9676\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9726 - val_loss: 0.9612\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9674 - val_loss: 0.9562\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9640 - val_loss: 0.9541\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9624 - val_loss: 0.9519\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9600 - val_loss: 0.9507\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9587 - val_loss: 0.9503\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9577 - val_loss: 0.9490\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9572 - val_loss: 0.9491\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9576 - val_loss: 0.9490\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9565 - val_loss: 0.9490\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9554 - val_loss: 0.9531\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9571 - val_loss: 0.9472\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 0.9468\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 0.9464\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9538 - val_loss: 0.9467\n",
      "Top-2 accuracy = 0.82\n",
      "6\n",
      "robustm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0807 - val_loss: 1.0711\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "7\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0636 - val_loss: 1.0301\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0016 - val_loss: 0.9762\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9688 - val_loss: 0.9572\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9558 - val_loss: 0.9505\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9514 - val_loss: 0.9476\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9492 - val_loss: 0.9478\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9464 - val_loss: 0.9426\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9458 - val_loss: 0.9410\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9437 - val_loss: 0.9438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9445 - val_loss: 0.9402\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9419 - val_loss: 0.9425\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9425 - val_loss: 0.9399\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9420 - val_loss: 0.9381\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9403 - val_loss: 0.9374\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9407 - val_loss: 0.9375\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.9372\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9396 - val_loss: 0.9372\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9396 - val_loss: 0.9366\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9395 - val_loss: 0.9406\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9370\n",
      "Top-2 accuracy = 0.831\n",
      "8\n",
      "robustA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0531 - val_loss: 1.0052\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9784 - val_loss: 0.9552\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9580 - val_loss: 0.9465\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9531 - val_loss: 0.9440\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 0.9438\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9511 - val_loss: 0.9415\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9469 - val_loss: 0.9406\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9466 - val_loss: 0.9409\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9459 - val_loss: 0.9393\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9452 - val_loss: 0.9389\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 0.9401\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9442 - val_loss: 0.9392\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9431 - val_loss: 0.9375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9372\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 0.9375\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9422 - val_loss: 0.9375\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9412 - val_loss: 0.9361\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9361\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9418 - val_loss: 0.9369\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9408 - val_loss: 0.9393\n",
      "Top-2 accuracy = 0.829\n",
      "9\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0917 - val_loss: 1.0843\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0806 - val_loss: 1.0767\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0752 - val_loss: 1.0731\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0729 - val_loss: 1.0716\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "10\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0093 - val_loss: 0.9598\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9519 - val_loss: 0.9441\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9437 - val_loss: 0.9349\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9393 - val_loss: 0.9399\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9375 - val_loss: 0.9324\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9370 - val_loss: 0.9310\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9355 - val_loss: 0.9376\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9343 - val_loss: 0.9314\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9341 - val_loss: 0.9371\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9367 - val_loss: 0.9302\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 0.9312\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9335\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9336\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9331 - val_loss: 0.9286\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9330 - val_loss: 0.9295\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9311 - val_loss: 0.9309\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9324 - val_loss: 0.9304\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9311 - val_loss: 0.9311\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9329 - val_loss: 0.9296\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9309 - val_loss: 0.9292\n",
      "Top-2 accuracy = 0.833\n",
      "11\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1052 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0485 - val_loss: 1.0112\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9951 - val_loss: 0.9725\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9754 - val_loss: 0.9632\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9690 - val_loss: 0.9591\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9659 - val_loss: 0.9564\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9632 - val_loss: 0.9541\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9611 - val_loss: 0.9524\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9587 - val_loss: 0.9500\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9567 - val_loss: 0.9482\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9549 - val_loss: 0.9469\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9536 - val_loss: 0.9454\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9520 - val_loss: 0.9442\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9508 - val_loss: 0.9430\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9499 - val_loss: 0.9426\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9488 - val_loss: 0.9413\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9479 - val_loss: 0.9403\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9472 - val_loss: 0.9399\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9465 - val_loss: 0.9399\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9457 - val_loss: 0.9388\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.9450 - val_loss: 0.9378\n",
      "Top-2 accuracy = 0.831\n",
      "12\n",
      "standardizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0553 - val_loss: 1.0228\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9980 - val_loss: 0.9786\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9689 - val_loss: 0.9584\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9565 - val_loss: 0.9535\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9504 - val_loss: 0.9463\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9465 - val_loss: 0.9424\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9435 - val_loss: 0.9403\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9419 - val_loss: 0.9392\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9411 - val_loss: 0.9429\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9436 - val_loss: 0.9404\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.9390\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9414 - val_loss: 0.9459\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.9435\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9402 - val_loss: 0.9380\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9397 - val_loss: 0.9402\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9373\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9392 - val_loss: 0.9395\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9387\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9377 - val_loss: 0.9380\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9376 - val_loss: 0.9463\n",
      "Top-2 accuracy = 0.823\n",
      "13\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0605 - val_loss: 1.0057\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9649 - val_loss: 0.9497\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9436 - val_loss: 0.9365\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9392 - val_loss: 0.9379\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9372 - val_loss: 0.9320\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9363 - val_loss: 0.9320\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9357 - val_loss: 0.9493\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9372 - val_loss: 0.9310\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9357 - val_loss: 0.9355\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9360 - val_loss: 0.9337\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9367 - val_loss: 0.9337\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9352 - val_loss: 0.9345\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9348 - val_loss: 0.9315\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9352 - val_loss: 0.9324\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9333 - val_loss: 0.9304\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9357 - val_loss: 0.9299\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9343 - val_loss: 0.9338\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9344 - val_loss: 0.9317\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9326 - val_loss: 0.9317\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9331 - val_loss: 0.9338\n",
      "Top-2 accuracy = 0.836\n",
      "14\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0303 - val_loss: 0.9909\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9859 - val_loss: 0.9687\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9715 - val_loss: 0.9598\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9650 - val_loss: 0.9549\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9606 - val_loss: 0.9511\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9593 - val_loss: 0.9492\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9565 - val_loss: 0.9478\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 0.9477\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9537 - val_loss: 0.9454\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9535 - val_loss: 0.9455\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9523 - val_loss: 0.9439\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9515 - val_loss: 0.9440\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.9455\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9412\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9416\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 0.9411\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9456\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9419\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9405\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9403\n",
      "Top-2 accuracy = 0.828\n",
      "15\n",
      "robusty|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0327 - val_loss: 0.9848\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9639 - val_loss: 0.9462\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9456 - val_loss: 0.9458\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9436 - val_loss: 0.9457\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9428 - val_loss: 0.9379\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9385 - val_loss: 0.9355\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9384 - val_loss: 0.9404\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9441 - val_loss: 0.9338\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9333\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9365 - val_loss: 0.9354\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9364 - val_loss: 0.9355\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9331\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9357 - val_loss: 0.9339\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9367 - val_loss: 0.9324\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9348 - val_loss: 0.9316\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9352 - val_loss: 0.9321\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9353 - val_loss: 0.9325\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9350 - val_loss: 0.9369\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9358 - val_loss: 0.9330\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9354 - val_loss: 0.9361\n",
      "Top-2 accuracy = 0.83\n",
      "16\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0647 - val_loss: 1.0392\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9986 - val_loss: 0.9683\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9636 - val_loss: 0.9528\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9548 - val_loss: 0.9523\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9522 - val_loss: 0.9445\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9473 - val_loss: 0.9411\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9457 - val_loss: 0.9415\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9437 - val_loss: 0.9381\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9429 - val_loss: 0.9423\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9430 - val_loss: 0.9385\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9416 - val_loss: 0.9372\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9405 - val_loss: 0.9372\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 0.9354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9398 - val_loss: 0.9362\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 0.9341\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9359\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9389 - val_loss: 0.9350\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9379 - val_loss: 0.9341\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9376 - val_loss: 0.9368\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9377 - val_loss: 0.9336\n",
      "Top-2 accuracy = 0.834\n",
      "17\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0902 - val_loss: 1.0821\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0772 - val_loss: 1.0724\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0720 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "18\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0561 - val_loss: 1.0169\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 0.9789\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9778 - val_loss: 0.9639\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9671 - val_loss: 0.9626\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9615 - val_loss: 0.9516\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9580 - val_loss: 0.9496\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9545 - val_loss: 0.9518\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9539 - val_loss: 0.9483\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9522 - val_loss: 0.9475\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9517 - val_loss: 0.9482\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9515 - val_loss: 0.9475\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9449\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 0.9439\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9492 - val_loss: 0.9448\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 0.9460\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9443\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9479 - val_loss: 0.9464\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9474 - val_loss: 0.9436\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9428\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9434\n",
      "Top-2 accuracy = 0.825\n",
      "19\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0088 - val_loss: 0.9516\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9441 - val_loss: 0.9434\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9397 - val_loss: 0.9347\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9376 - val_loss: 0.9380\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9380 - val_loss: 0.9347\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9371 - val_loss: 0.9395\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9355 - val_loss: 0.9344\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9346 - val_loss: 0.9315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9337 - val_loss: 0.9321\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9342 - val_loss: 0.9308\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9350 - val_loss: 0.9334\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9334 - val_loss: 0.9347\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9330 - val_loss: 0.9307\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9328 - val_loss: 0.9332\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9330 - val_loss: 0.9350\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9334 - val_loss: 0.9300\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9331 - val_loss: 0.9306\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9315 - val_loss: 0.9326\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9316 - val_loss: 0.9308\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9307 - val_loss: 0.9337\n",
      "Top-2 accuracy = 0.834\n",
      "20\n",
      "minmaxP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0674 - val_loss: 1.0299\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9992 - val_loss: 0.9648\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9648 - val_loss: 0.9524\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9601 - val_loss: 0.9815\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9549 - val_loss: 0.9431\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9498 - val_loss: 0.9581\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9514 - val_loss: 0.9423\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9474 - val_loss: 0.9411\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9455 - val_loss: 0.9391\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9473 - val_loss: 0.9423\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9433 - val_loss: 0.9380\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9434 - val_loss: 0.9393\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9442 - val_loss: 0.9377\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9417 - val_loss: 0.9386\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9426 - val_loss: 0.9394\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9414 - val_loss: 0.9358\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9396 - val_loss: 0.9362\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9405 - val_loss: 0.9433\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9405 - val_loss: 0.9367\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9401 - val_loss: 0.9348\n",
      "Top-2 accuracy = 0.831\n",
      "21\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0820 - val_loss: 1.0599\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0314 - val_loss: 0.9886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9798 - val_loss: 0.9641\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9633 - val_loss: 0.9582\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9590 - val_loss: 0.9568\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9573 - val_loss: 0.9484\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 0.9484\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9538 - val_loss: 0.9470\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9535 - val_loss: 0.9488\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9540 - val_loss: 0.9467\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9546 - val_loss: 0.9494\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9545 - val_loss: 0.9459\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9526 - val_loss: 0.9551\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9532 - val_loss: 0.9455\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9538 - val_loss: 0.9459\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9541 - val_loss: 0.9449\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9516 - val_loss: 0.9446\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9511 - val_loss: 0.9458\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9528 - val_loss: 0.9453\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9516 - val_loss: 0.9450\n",
      "Top-2 accuracy = 0.825\n",
      "22\n",
      "robustY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0511 - val_loss: 0.9835\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9661 - val_loss: 0.9527\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9531 - val_loss: 0.9482\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9542 - val_loss: 0.9500\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9501 - val_loss: 0.9510\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9465 - val_loss: 0.9430\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9452 - val_loss: 0.9437\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9447 - val_loss: 0.9466\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9442 - val_loss: 0.9413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9423 - val_loss: 0.9407\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9422 - val_loss: 0.9394\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9428 - val_loss: 0.9408\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9409 - val_loss: 0.9388\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9406 - val_loss: 0.9364\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9402 - val_loss: 0.9369\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9389 - val_loss: 0.9380\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9384 - val_loss: 0.9358\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9375 - val_loss: 0.9479\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9413 - val_loss: 0.9363\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9379 - val_loss: 0.9430\n",
      "Top-2 accuracy = 0.829\n",
      "23\n",
      "normalizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0174 - val_loss: 0.9584\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9460 - val_loss: 0.9333\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9381 - val_loss: 0.9368\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9361 - val_loss: 0.9316\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9347 - val_loss: 0.9319\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9338 - val_loss: 0.9477\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9364 - val_loss: 0.9338\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9323 - val_loss: 0.9301\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9324 - val_loss: 0.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9316 - val_loss: 0.9322\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9308 - val_loss: 0.9343\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9321 - val_loss: 0.9327\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9312 - val_loss: 0.9296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9298 - val_loss: 0.9346\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9360 - val_loss: 0.9306\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9320 - val_loss: 0.9325\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9330 - val_loss: 0.9293\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9325 - val_loss: 0.9376\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9311 - val_loss: 0.9353\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9304 - val_loss: 0.9291\n",
      "Top-2 accuracy = 0.833\n",
      "24\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0722 - val_loss: 1.0523\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0355 - val_loss: 1.0069\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9916 - val_loss: 0.9745\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9745 - val_loss: 0.9648\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9671 - val_loss: 0.9594\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9632 - val_loss: 0.9571\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9608 - val_loss: 0.9533\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9593 - val_loss: 0.9521\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9573 - val_loss: 0.9510\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9562 - val_loss: 0.9532\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9562 - val_loss: 0.9503\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9546 - val_loss: 0.9481\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9538 - val_loss: 0.9497\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9538 - val_loss: 0.9474\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 0.9464\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9520 - val_loss: 0.9466\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9518 - val_loss: 0.9457\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9466\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9448\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9502 - val_loss: 0.9442\n",
      "Top-2 accuracy = 0.829\n",
      "25\n",
      "standardized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0903 - val_loss: 1.0823\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0777 - val_loss: 1.0735\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0727 - val_loss: 1.0711\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "26\n",
      "maxabsN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0333 - val_loss: 0.9834\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9633 - val_loss: 0.9424\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 0.9507\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9401 - val_loss: 0.9367\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9361\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9371 - val_loss: 0.9398\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9353\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9369 - val_loss: 0.9347\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9356\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9385 - val_loss: 0.9359\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9352 - val_loss: 0.9355\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9358 - val_loss: 0.9377\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9352 - val_loss: 0.9353\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 0.9335\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9361\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9344 - val_loss: 0.9418\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9355 - val_loss: 0.9324\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9338 - val_loss: 0.9320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9352 - val_loss: 0.9325\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9342 - val_loss: 0.9398\n",
      "Top-2 accuracy = 0.831\n",
      "27\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0907 - val_loss: 1.0838\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0798 - val_loss: 1.0761\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0747 - val_loss: 1.0727\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0727 - val_loss: 1.0715\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "28\n",
      "maxabsj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0436 - val_loss: 0.9950\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9780 - val_loss: 0.9618\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9570 - val_loss: 0.9492\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9498 - val_loss: 0.9743\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9501 - val_loss: 0.9419\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9429 - val_loss: 0.9415\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9416 - val_loss: 0.9392\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9410 - val_loss: 0.9392\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 0.9395\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 0.9383\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9402 - val_loss: 0.9404\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9402 - val_loss: 0.9379\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9388 - val_loss: 0.9375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 0.9424\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9406 - val_loss: 0.9369\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9377\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9376 - val_loss: 0.9385\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9384 - val_loss: 0.9373\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9362\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9369 - val_loss: 0.9362\n",
      "Top-2 accuracy = 0.828\n",
      "29\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0808 - val_loss: 1.0714\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0718 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "0\n",
      "maxabsW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0172 - val_loss: 0.9743\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9682 - val_loss: 0.9592\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9560 - val_loss: 0.9510\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9500 - val_loss: 0.9450\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9463 - val_loss: 0.9427\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9459 - val_loss: 0.9426\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9436 - val_loss: 0.9415\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9440 - val_loss: 0.9429\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.9404\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9415 - val_loss: 0.9392\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9410 - val_loss: 0.9389\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9415 - val_loss: 0.9408\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9401 - val_loss: 0.9399\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.9380\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9419\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9399 - val_loss: 0.9369\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9387 - val_loss: 0.9372\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 0.9383\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9365\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9405 - val_loss: 0.9375\n",
      "Top-2 accuracy = 0.833\n",
      "1\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0854 - val_loss: 1.0728\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0720 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Top-2 accuracy = 0.724\n",
      "2\n",
      "maxabsD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0519 - val_loss: 1.0112\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9881 - val_loss: 0.9664\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9592 - val_loss: 0.9494\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9499 - val_loss: 0.9442\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9438 - val_loss: 0.9404\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9423 - val_loss: 0.9375\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 0.9458\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9396 - val_loss: 0.9374\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9406\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9383 - val_loss: 0.9379\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9381 - val_loss: 0.9390\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9367\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9365 - val_loss: 0.9419\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9371 - val_loss: 0.9342\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9361 - val_loss: 0.9342\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9371 - val_loss: 0.9401\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 0.9342\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 0.9406\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9406 - val_loss: 0.9340\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9366 - val_loss: 0.9335\n",
      "Top-2 accuracy = 0.834\n",
      "3\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0500 - val_loss: 1.0095\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9858 - val_loss: 0.9672\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9654 - val_loss: 0.9579\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9623 - val_loss: 0.9543\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9578 - val_loss: 0.9522\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 0.9545\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9557 - val_loss: 0.9487\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9529 - val_loss: 0.9488\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9521 - val_loss: 0.9497\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9514 - val_loss: 0.9484\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9516 - val_loss: 0.9461\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9501 - val_loss: 0.9476\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9457\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9505 - val_loss: 0.9459\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 0.9467\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9489 - val_loss: 0.9458\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9486 - val_loss: 0.9449\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9459\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9486 - val_loss: 0.9451\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9481 - val_loss: 0.9434\n",
      "Top-2 accuracy = 0.832\n",
      "4\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0817 - val_loss: 1.0523\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0253 - val_loss: 0.9918\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9820 - val_loss: 0.9667\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9687 - val_loss: 0.9614\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9660 - val_loss: 0.9605\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9646 - val_loss: 0.9554\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9627 - val_loss: 0.9554\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9626 - val_loss: 0.9539\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9586 - val_loss: 0.9523\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9583 - val_loss: 0.9535\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9560 - val_loss: 0.9521\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9579 - val_loss: 0.9543\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9576 - val_loss: 0.9488\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9541 - val_loss: 0.9483\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9548 - val_loss: 0.9500\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9551 - val_loss: 0.9470\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9525 - val_loss: 0.9483\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9526 - val_loss: 0.9507\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9521 - val_loss: 0.9485\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9510 - val_loss: 0.9521\n",
      "Top-2 accuracy = 0.821\n",
      "5\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0846 - val_loss: 1.0711\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0667 - val_loss: 1.0293\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0066 - val_loss: 1.0014\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0005 - val_loss: 0.9941\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0039 - val_loss: 1.0062\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0124 - val_loss: 1.0384\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0066 - val_loss: 0.9892\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9973 - val_loss: 0.9873\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0020 - val_loss: 0.9966\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0012 - val_loss: 0.9920\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0129 - val_loss: 1.0365\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0332 - val_loss: 1.0182\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0279 - val_loss: 0.9981\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0077 - val_loss: 0.9879\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0168 - val_loss: 1.0273\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0142 - val_loss: 1.0094\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0127 - val_loss: 0.9936\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9981 - val_loss: 0.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9999 - val_loss: 1.0004\n",
      "Top-2 accuracy = 0.811\n",
      "6\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0155 - val_loss: 0.9853\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9676 - val_loss: 0.9536\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9525 - val_loss: 0.9470\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9492 - val_loss: 0.9492\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9492 - val_loss: 0.9421\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9484 - val_loss: 0.9485\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9510 - val_loss: 0.9501\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9403\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9453 - val_loss: 0.9422\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9459 - val_loss: 0.9452\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 0.9431\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9377\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9430 - val_loss: 0.9376\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9440 - val_loss: 0.9440\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9433 - val_loss: 0.9372\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9433 - val_loss: 0.9411\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9420 - val_loss: 0.9369\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9423 - val_loss: 0.9394\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9437 - val_loss: 0.9351\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9406 - val_loss: 0.9359\n",
      "Top-2 accuracy = 0.827\n",
      "7\n",
      "normalizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0404 - val_loss: 0.9720\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9714 - val_loss: 0.9569\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9632 - val_loss: 0.9994\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9650 - val_loss: 0.9517\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9567 - val_loss: 0.9553\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9572 - val_loss: 0.9525\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9564 - val_loss: 0.9543\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9563 - val_loss: 0.9558\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9524 - val_loss: 0.9442\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9512 - val_loss: 0.9453\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9542 - val_loss: 0.9429\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9525 - val_loss: 0.9477\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9490 - val_loss: 0.9545\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9499 - val_loss: 0.9421\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9497 - val_loss: 0.9481\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9498 - val_loss: 0.9697\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9505 - val_loss: 0.9418\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9486 - val_loss: 0.9411\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9488 - val_loss: 0.9405\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9476 - val_loss: 0.9442\n",
      "Top-2 accuracy = 0.825\n",
      "8\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0871 - val_loss: 1.0749\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0732 - val_loss: 1.0713\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0719 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "9\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0530 - val_loss: 0.9831\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9568 - val_loss: 0.9496\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9371\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9379 - val_loss: 0.9354\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9345\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9357 - val_loss: 0.9429\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9373 - val_loss: 0.9344\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 0.9352\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9320\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 0.9369\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 0.9317\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9345 - val_loss: 0.9324\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9340 - val_loss: 0.9317\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9324 - val_loss: 0.9326\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9330 - val_loss: 0.9320\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9326 - val_loss: 0.9355\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9323 - val_loss: 0.9313\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9326 - val_loss: 0.9436\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9366\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9337 - val_loss: 0.9309\n",
      "Top-2 accuracy = 0.834\n",
      "10\n",
      "normalizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0875 - val_loss: 1.0768\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0741 - val_loss: 1.0713\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "11\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0554 - val_loss: 1.0012\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9880 - val_loss: 0.9650\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9652 - val_loss: 0.9565\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9596 - val_loss: 0.9526\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 0.9536\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9540 - val_loss: 0.9471\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9509 - val_loss: 0.9451\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9502 - val_loss: 0.9439\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 0.9616\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 0.9458\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9415\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9464 - val_loss: 0.9466\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9451 - val_loss: 0.9397\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9404\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9440 - val_loss: 0.9401\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9439 - val_loss: 0.9377\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9425 - val_loss: 0.9366\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9417 - val_loss: 0.9384\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9395\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9367\n",
      "Top-2 accuracy = 0.829\n",
      "12\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0889 - val_loss: 1.0770\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0560 - val_loss: 1.0215\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0044 - val_loss: 0.9888\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9881 - val_loss: 0.9811\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9839 - val_loss: 0.9766\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9803 - val_loss: 0.9741\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9782 - val_loss: 0.9727\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9769 - val_loss: 0.9692\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9747 - val_loss: 0.9679\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9733 - val_loss: 0.9669\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9722 - val_loss: 0.9659\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9726 - val_loss: 0.9655\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9707 - val_loss: 0.9638\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9702 - val_loss: 0.9665\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9696 - val_loss: 0.9653\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9694 - val_loss: 0.9618\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9682 - val_loss: 0.9624\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9679 - val_loss: 0.9606\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9677 - val_loss: 0.9613\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9670 - val_loss: 0.9604\n",
      "Top-2 accuracy = 0.82\n",
      "13\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1209 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0369 - val_loss: 0.9714\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9701 - val_loss: 0.9559\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9588 - val_loss: 0.9488\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9458\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 0.9439\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9468 - val_loss: 0.9401\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.9374\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9418 - val_loss: 0.9375\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9357\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.9340\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 0.9358\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9362\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9323\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9331\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9316\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9326\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9314\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9305\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9315\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9317 - val_loss: 0.9302\n",
      "Top-2 accuracy = 0.834\n",
      "14\n",
      "robustd|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0441 - val_loss: 0.9968\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9809 - val_loss: 0.9658\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9583 - val_loss: 0.9481\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9450 - val_loss: 0.9382\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.9500\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9407 - val_loss: 0.9360\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9383 - val_loss: 0.9376\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9363\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9376 - val_loss: 0.9377\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9381 - val_loss: 0.9328\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9360 - val_loss: 0.9394\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9331\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9367 - val_loss: 0.9331\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9357 - val_loss: 0.9356\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9365 - val_loss: 0.9329\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9357 - val_loss: 0.9335\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9348 - val_loss: 0.9325\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9355 - val_loss: 0.9488\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9366 - val_loss: 0.9310\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9353 - val_loss: 0.9312\n",
      "Top-2 accuracy = 0.834\n",
      "15\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0908 - val_loss: 1.0839\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0801 - val_loss: 1.0762\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0748 - val_loss: 1.0728\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0726 - val_loss: 1.0714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0718 - val_loss: 1.0709\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "16\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0795 - val_loss: 1.0708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0707\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0640 - val_loss: 1.0214\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0125 - val_loss: 1.0130\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0028 - val_loss: 0.9935\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0005 - val_loss: 0.9912\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9890 - val_loss: 0.9862\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9917 - val_loss: 0.9984\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9998 - val_loss: 1.0020\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9911 - val_loss: 0.9851\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9882 - val_loss: 0.9853\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9987 - val_loss: 1.0063\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0046 - val_loss: 1.0036\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0021 - val_loss: 1.0048\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0009 - val_loss: 1.0004\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0049 - val_loss: 0.9996\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0022 - val_loss: 0.9986\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0020 - val_loss: 0.9999\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0089 - val_loss: 1.0374\n",
      "Top-2 accuracy = 0.778\n",
      "17\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0304 - val_loss: 0.9731\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9558 - val_loss: 0.9417\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9425 - val_loss: 0.9379\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9398 - val_loss: 0.9336\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9367 - val_loss: 0.9348\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9353 - val_loss: 0.9318\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9351 - val_loss: 0.9344\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9348 - val_loss: 0.9327\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9349 - val_loss: 0.9322\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9337 - val_loss: 0.9315\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9342 - val_loss: 0.9289\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9330 - val_loss: 0.9321\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9329 - val_loss: 0.9291\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9325 - val_loss: 0.9283\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9316 - val_loss: 0.9282\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9315 - val_loss: 0.9312\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9311 - val_loss: 0.9329\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9316 - val_loss: 0.9353\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9353 - val_loss: 0.9408\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9310 - val_loss: 0.9276\n",
      "Top-2 accuracy = 0.833\n",
      "18\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0375 - val_loss: 0.9828\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9776 - val_loss: 0.9630\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9611 - val_loss: 0.9520\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9512 - val_loss: 0.9442\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9462 - val_loss: 0.9408\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9441 - val_loss: 0.9398\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9395\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9427 - val_loss: 0.9389\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9419 - val_loss: 0.9381\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9414 - val_loss: 0.9376\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9403 - val_loss: 0.9390\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9393 - val_loss: 0.9363\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9390\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9351\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9355\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9377 - val_loss: 0.9367\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9382 - val_loss: 0.9353\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9368 - val_loss: 0.9343\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9337\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9365 - val_loss: 0.9376\n",
      "Top-2 accuracy = 0.83\n",
      "19\n",
      "standardizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0828 - val_loss: 1.0542\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0344 - val_loss: 1.0131\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9960 - val_loss: 0.9801\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9695 - val_loss: 0.9582\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9548 - val_loss: 0.9519\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9498 - val_loss: 0.9452\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9467 - val_loss: 0.9430\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9444 - val_loss: 0.9422\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9434 - val_loss: 0.9415\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9405\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9424 - val_loss: 0.9489\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9416 - val_loss: 0.9409\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9416 - val_loss: 0.9392\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9418 - val_loss: 0.9469\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9411 - val_loss: 0.9441\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 0.9426\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9396 - val_loss: 0.9420\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9399 - val_loss: 0.9385\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9383 - val_loss: 0.9365\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.937 - 0s 4ms/step - loss: 0.9379 - val_loss: 0.9366\n",
      "Top-2 accuracy = 0.829\n",
      "20\n",
      "standardizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0082 - val_loss: 0.9538\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9436 - val_loss: 0.9347\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9364 - val_loss: 0.9346\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9346 - val_loss: 0.9305\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9334 - val_loss: 0.9293\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9323 - val_loss: 0.9358\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9328 - val_loss: 0.9305\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9317 - val_loss: 0.9289\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9309 - val_loss: 0.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9318 - val_loss: 0.9281\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9309 - val_loss: 0.9289\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9300 - val_loss: 0.9432\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9349 - val_loss: 0.9284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9314 - val_loss: 0.9281\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9307 - val_loss: 0.9274\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9300 - val_loss: 0.9325\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9305 - val_loss: 0.9279\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9287 - val_loss: 0.9289\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9307 - val_loss: 0.9342\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9303 - val_loss: 0.9278\n",
      "Top-2 accuracy = 0.832\n",
      "21\n",
      "maxabsr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0703 - val_loss: 1.0314\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0030 - val_loss: 0.9906\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9758 - val_loss: 0.9641\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9594 - val_loss: 0.9519\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9498 - val_loss: 0.9517\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9448 - val_loss: 0.9503\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9430 - val_loss: 0.9384\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 0.9375\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9402 - val_loss: 0.9377\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9398 - val_loss: 0.9358\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9388 - val_loss: 0.9355\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9352\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9395 - val_loss: 0.9354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9377 - val_loss: 0.9345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9392 - val_loss: 0.9391\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9382 - val_loss: 0.9354\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9374 - val_loss: 0.9348\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9382 - val_loss: 0.9348\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9369 - val_loss: 0.9377\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9377 - val_loss: 0.9380\n",
      "Top-2 accuracy = 0.829\n",
      "22\n",
      "normalizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0229 - val_loss: 0.9732\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9614 - val_loss: 0.9505\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9491 - val_loss: 0.9418\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9425 - val_loss: 0.9372\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9405 - val_loss: 0.9387\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9392 - val_loss: 0.9369\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9388 - val_loss: 0.9379\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9376 - val_loss: 0.9351\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9373 - val_loss: 0.9318\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9361 - val_loss: 0.9369\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.9326\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9357 - val_loss: 0.9312\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9359 - val_loss: 0.9317\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9351 - val_loss: 0.9326\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9350 - val_loss: 0.9310\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9356 - val_loss: 0.9319\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 0.9303\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9351 - val_loss: 0.9329\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9350 - val_loss: 0.9302\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9351 - val_loss: 0.9307\n",
      "Top-2 accuracy = 0.833\n",
      "23\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0907 - val_loss: 1.0819\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0735 - val_loss: 1.0611\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0454 - val_loss: 1.0301\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0216 - val_loss: 1.0127\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0079 - val_loss: 1.0002\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 0.9913\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9894 - val_loss: 0.9847\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9833 - val_loss: 0.9802\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9789 - val_loss: 0.9773\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9763 - val_loss: 0.9731\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9726 - val_loss: 0.9699\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9699 - val_loss: 0.9673\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9682 - val_loss: 0.9651\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9661 - val_loss: 0.9640\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9654 - val_loss: 0.9619\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9634 - val_loss: 0.9611\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9625 - val_loss: 0.9594\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9613 - val_loss: 0.9609\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9612 - val_loss: 0.9602\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9597 - val_loss: 0.9568\n",
      "Top-2 accuracy = 0.826\n",
      "24\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.1001 - val_loss: 1.0748\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0514 - val_loss: 1.0072\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9866 - val_loss: 0.9662\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9642 - val_loss: 0.9555\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9523 - val_loss: 0.9459\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9464 - val_loss: 0.9461\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9434 - val_loss: 0.9392\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9414 - val_loss: 0.9368\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9409\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9396 - val_loss: 0.9366\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9357\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9387 - val_loss: 0.9357\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9380 - val_loss: 0.9347\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9371 - val_loss: 0.9364\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9362 - val_loss: 0.9343\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9368 - val_loss: 0.9338\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9363 - val_loss: 0.9349\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9354 - val_loss: 0.9355\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9355 - val_loss: 0.9360\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9353 - val_loss: 0.9350\n",
      "Top-2 accuracy = 0.831\n",
      "25\n",
      "standardizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 1.0623 - val_loss: 1.0120\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9941 - val_loss: 0.9855\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9837 - val_loss: 0.9818\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9753 - val_loss: 0.9789\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9656 - val_loss: 0.9525\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9566 - val_loss: 0.9469\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9547 - val_loss: 0.9566\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9532 - val_loss: 0.9415\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9480 - val_loss: 0.9417\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9480 - val_loss: 0.9499\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9461 - val_loss: 0.9546\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9449 - val_loss: 0.9402\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9429 - val_loss: 0.9373\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9421 - val_loss: 0.9359\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9427 - val_loss: 0.9386\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9412 - val_loss: 0.9472\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9594 - val_loss: 0.9606\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9471 - val_loss: 0.9423\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9417 - val_loss: 0.9357\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9409 - val_loss: 0.9567\n",
      "Top-2 accuracy = 0.821\n",
      "26\n",
      "normalizeq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0910 - val_loss: 1.0843\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0804 - val_loss: 1.0764\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0750 - val_loss: 1.0729\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0727 - val_loss: 1.0715\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "27\n",
      "minmaxX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0749 - val_loss: 1.0411\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0001 - val_loss: 0.9681\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9644 - val_loss: 0.9550\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9527 - val_loss: 0.9477\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9442\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9439\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9422\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9467 - val_loss: 0.9430\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9475 - val_loss: 0.9467\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9441\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9470 - val_loss: 0.9439\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 0.9429\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9460 - val_loss: 0.9408\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9452 - val_loss: 0.9412\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9451 - val_loss: 0.9499\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 0.9406\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9435\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9454 - val_loss: 0.9449\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9400\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9448 - val_loss: 0.9402\n",
      "Top-2 accuracy = 0.831\n",
      "28\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0819 - val_loss: 1.0612\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0187 - val_loss: 0.9916\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9851 - val_loss: 0.9781\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9800 - val_loss: 0.9853\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9858 - val_loss: 0.9821\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9840 - val_loss: 0.9768\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9838 - val_loss: 0.9765\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9822 - val_loss: 0.9754\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9833 - val_loss: 0.9753\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9840 - val_loss: 0.9753\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9835 - val_loss: 0.9768\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9821 - val_loss: 0.9758\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9799 - val_loss: 0.9756\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9781 - val_loss: 0.9753\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9782 - val_loss: 0.9756\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9840 - val_loss: 0.9765\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9804 - val_loss: 0.9741\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9771 - val_loss: 0.9750\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9753 - val_loss: 0.9721\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9645 - val_loss: 0.9635\n",
      "Top-2 accuracy = 0.815\n",
      "29\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0918 - val_loss: 1.0808\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0762 - val_loss: 1.0720\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0707\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0553 - val_loss: 1.0005\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9921 - val_loss: 0.9856\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9910 - val_loss: 0.9789\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9889 - val_loss: 0.9837\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0039 - val_loss: 1.0151\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0122 - val_loss: 0.9981\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0041 - val_loss: 1.0045\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9943 - val_loss: 0.9767\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9854 - val_loss: 0.9983\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0054 - val_loss: 0.9941\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9888 - val_loss: 0.9823\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9863 - val_loss: 0.9768\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9820 - val_loss: 0.9761\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9842 - val_loss: 0.9858\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9914 - val_loss: 0.9862\n",
      "Top-2 accuracy = 0.82\n",
      "0\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 23ms/step - loss: 1.0197 - val_loss: 0.9677\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9531 - val_loss: 0.9359\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.9411 - val_loss: 0.9402\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.9383 - val_loss: 0.9339\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9356 - val_loss: 0.9305\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9356 - val_loss: 0.9363\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9357 - val_loss: 0.9388\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9359 - val_loss: 0.9359\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9333 - val_loss: 0.9351\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9327 - val_loss: 0.9338\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9339 - val_loss: 0.9310\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9319 - val_loss: 0.9297\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9310 - val_loss: 0.9306\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9308 - val_loss: 0.9320\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9331 - val_loss: 0.9295\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9313 - val_loss: 0.9307\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9319 - val_loss: 0.9333\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9299 - val_loss: 0.9290\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9321 - val_loss: 0.9320\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.9294 - val_loss: 0.9294\n",
      "Top-2 accuracy = 0.832\n",
      "1\n",
      "maxabso|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0713 - val_loss: 1.0409\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0158 - val_loss: 0.9959\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9908 - val_loss: 0.9866\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9824 - val_loss: 0.9765\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9716 - val_loss: 0.9603\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9596 - val_loss: 0.9683\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9574 - val_loss: 0.9507\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9553 - val_loss: 0.9479\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9550 - val_loss: 0.9471\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9528 - val_loss: 0.9457\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9527 - val_loss: 0.9455\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9500 - val_loss: 0.9447\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9505 - val_loss: 0.9443\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9494 - val_loss: 0.9451\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9489 - val_loss: 0.9474\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9491 - val_loss: 0.9436\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 0.9484\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9480 - val_loss: 0.9414\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9462 - val_loss: 0.9404\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9452 - val_loss: 0.9412\n",
      "Top-2 accuracy = 0.829\n",
      "2\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0606 - val_loss: 1.0030\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9894 - val_loss: 0.9741\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9744 - val_loss: 0.9667\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9668 - val_loss: 0.9605\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9624 - val_loss: 0.9595\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9593 - val_loss: 0.9538\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9559 - val_loss: 0.9546\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9550 - val_loss: 0.9484\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9532 - val_loss: 0.9480\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9518 - val_loss: 0.9497\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9513 - val_loss: 0.9467\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9506 - val_loss: 0.9445\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9504 - val_loss: 0.9444\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9491 - val_loss: 0.9471\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9494 - val_loss: 0.9433\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9489 - val_loss: 0.9429\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9490 - val_loss: 0.9432\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9484 - val_loss: 0.9419\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9476 - val_loss: 0.9428\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 0.9420\n",
      "Top-2 accuracy = 0.827\n",
      "3\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0416 - val_loss: 0.9779\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9574 - val_loss: 0.9408\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9405\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9387 - val_loss: 0.9418\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9397 - val_loss: 0.9336\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9365 - val_loss: 0.9333\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9362 - val_loss: 0.9328\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9339 - val_loss: 0.9322\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9344 - val_loss: 0.9302\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9331 - val_loss: 0.9331\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9344 - val_loss: 0.9348\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9338 - val_loss: 0.9320\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9333 - val_loss: 0.9331\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9327 - val_loss: 0.9307\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9328 - val_loss: 0.9321\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9315 - val_loss: 0.9319\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9327 - val_loss: 0.9312\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9329 - val_loss: 0.9330\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9311 - val_loss: 0.9317\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9308 - val_loss: 0.9317\n",
      "Top-2 accuracy = 0.83\n",
      "4\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0757 - val_loss: 1.0708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0718 - val_loss: 1.0709\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0709\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0709\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "5\n",
      "normalizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0472 - val_loss: 1.0036\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9773 - val_loss: 0.9623\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9515 - val_loss: 0.9427\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9445 - val_loss: 0.9382\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9414 - val_loss: 0.9361\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9439 - val_loss: 0.9451\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9414 - val_loss: 0.9579\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9462 - val_loss: 0.9360\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9392 - val_loss: 0.9401\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9378 - val_loss: 0.9350\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9366 - val_loss: 0.9364\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9371 - val_loss: 0.9336\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9365 - val_loss: 0.9332\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9362 - val_loss: 0.9380\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9365 - val_loss: 0.9339\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9365 - val_loss: 0.9321\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9366 - val_loss: 0.9345\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9361 - val_loss: 0.9325\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9360 - val_loss: 0.9337\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9355 - val_loss: 0.9318\n",
      "Top-2 accuracy = 0.832\n",
      "6\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0060 - val_loss: 0.9578\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9492 - val_loss: 0.9441\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.9382\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9348 - val_loss: 0.9331\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9334 - val_loss: 0.9324\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9332 - val_loss: 0.9309\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9335 - val_loss: 0.9390\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9339 - val_loss: 0.9325\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9325 - val_loss: 0.9314\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9317 - val_loss: 0.9319\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9321 - val_loss: 0.9314\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9312 - val_loss: 0.9311\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9322 - val_loss: 0.9314\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9306 - val_loss: 0.9308\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9302 - val_loss: 0.9302\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9311 - val_loss: 0.9297\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9297 - val_loss: 0.9317\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9297 - val_loss: 0.9292\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9299 - val_loss: 0.9295\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9305 - val_loss: 0.9309\n",
      "Top-2 accuracy = 0.831\n",
      "7\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0073 - val_loss: 0.9656\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9604 - val_loss: 0.9470\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9479 - val_loss: 0.9411\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9438 - val_loss: 0.9379\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9412 - val_loss: 0.9366\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.9373\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9354\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9383 - val_loss: 0.9345\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 0.9385\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9364 - val_loss: 0.9319\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9352 - val_loss: 0.9329\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9350 - val_loss: 0.9313\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9341 - val_loss: 0.9336\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9344 - val_loss: 0.9330\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9336 - val_loss: 0.9324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9330 - val_loss: 0.9308\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9324 - val_loss: 0.9323\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9318 - val_loss: 0.9307\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.9300\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9311 - val_loss: 0.9310\n",
      "Top-2 accuracy = 0.837\n",
      "8\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0317 - val_loss: 0.9766\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9578 - val_loss: 0.9426\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9380 - val_loss: 0.9324\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9325 - val_loss: 0.9348\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9343 - val_loss: 0.9403\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9343 - val_loss: 0.9301\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9307 - val_loss: 0.9351\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9318 - val_loss: 0.9308\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9315 - val_loss: 0.9330\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9297 - val_loss: 0.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9300 - val_loss: 0.9283\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9296 - val_loss: 0.9288\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9288 - val_loss: 0.9310\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9289 - val_loss: 0.9289\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9304 - val_loss: 0.9303\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9299 - val_loss: 0.9293\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9306 - val_loss: 0.9292\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9284 - val_loss: 0.9305\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9287 - val_loss: 0.9280\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9281 - val_loss: 0.9281\n",
      "Top-2 accuracy = 0.83\n",
      "9\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0382 - val_loss: 0.9982\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9807 - val_loss: 0.9567\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9538 - val_loss: 0.9397\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9468 - val_loss: 0.9484\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9432 - val_loss: 0.9352\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9413 - val_loss: 0.9428\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9431 - val_loss: 0.9335\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9390 - val_loss: 0.9351\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9397 - val_loss: 0.9491\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9406 - val_loss: 0.9364\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9384 - val_loss: 0.9468\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9392 - val_loss: 0.9303\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9373 - val_loss: 0.9311\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9372 - val_loss: 0.9319\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9360 - val_loss: 0.9300\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9369 - val_loss: 0.9397\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9406 - val_loss: 0.9354\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9366 - val_loss: 0.9319\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9359 - val_loss: 0.9302\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9367 - val_loss: 0.9297\n",
      "Top-2 accuracy = 0.833\n",
      "10\n",
      "minmaxZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0823 - val_loss: 1.0663\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0562 - val_loss: 1.0378\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0363 - val_loss: 1.0234\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0197 - val_loss: 1.0154\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0297 - val_loss: 1.0031\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0100 - val_loss: 1.0076\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0138 - val_loss: 1.0111\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0183 - val_loss: 1.0147\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0130 - val_loss: 0.9913\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9987 - val_loss: 1.0466\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0481 - val_loss: 1.0329\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0482 - val_loss: 1.0626\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0621 - val_loss: 1.0586\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0586 - val_loss: 1.0564\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0588 - val_loss: 1.0653\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0646 - val_loss: 1.0636\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0598 - val_loss: 1.0535\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0528 - val_loss: 1.0467\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0305 - val_loss: 1.0013\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9981 - val_loss: 0.9899\n",
      "Top-2 accuracy = 0.806\n",
      "11\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0885 - val_loss: 1.0744\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0546 - val_loss: 1.0273\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0056 - val_loss: 0.9887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9841 - val_loss: 0.9766\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9745 - val_loss: 0.9658\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9651 - val_loss: 0.9565\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9588 - val_loss: 0.9522\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9559 - val_loss: 0.9543\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9540 - val_loss: 0.9483\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9526 - val_loss: 0.9497\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9512 - val_loss: 0.9460\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9496 - val_loss: 0.9439\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9477 - val_loss: 0.9456\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9478 - val_loss: 0.9424\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9467 - val_loss: 0.9455\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9472 - val_loss: 0.9411\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9454 - val_loss: 0.9409\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9449 - val_loss: 0.9415\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9454 - val_loss: 0.9463\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9443 - val_loss: 0.9410\n",
      "Top-2 accuracy = 0.831\n",
      "12\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0491 - val_loss: 1.0107\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0004 - val_loss: 0.9899\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9938 - val_loss: 0.9880\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9915 - val_loss: 0.9845\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9890 - val_loss: 0.9817\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9853 - val_loss: 0.9816\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9851 - val_loss: 0.9810\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9849 - val_loss: 0.9808\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9849 - val_loss: 0.9808\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9848 - val_loss: 0.9808\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9849 - val_loss: 0.9808\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9848 - val_loss: 0.9808\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9849 - val_loss: 0.9808\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9849 - val_loss: 0.9808\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9849 - val_loss: 0.9808\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9849 - val_loss: 0.9808\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9851 - val_loss: 0.9808\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9851 - val_loss: 0.9808\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9849 - val_loss: 0.9810\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9849 - val_loss: 0.9807\n",
      "Top-2 accuracy = 0.816\n",
      "13\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0515 - val_loss: 0.9781\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.9445\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 0.9406\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9416 - val_loss: 0.9381\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9403 - val_loss: 0.9362\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9344\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.9341\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 0.9340\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 0.9345\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9334\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9336\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 0.9335\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9325\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9341\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 0.9324\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9343\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9343\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9353 - val_loss: 0.9322\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 0.9320\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9357 - val_loss: 0.9328\n",
      "Top-2 accuracy = 0.834\n",
      "14\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0341 - val_loss: 0.9695\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9501 - val_loss: 0.9372\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9342 - val_loss: 0.9345\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9332 - val_loss: 0.9327\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9308 - val_loss: 0.9310\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9308 - val_loss: 0.9369\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9321 - val_loss: 0.9331\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9314 - val_loss: 0.9371\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9301 - val_loss: 0.9307\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9298 - val_loss: 0.9292\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9296 - val_loss: 0.9298\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9290 - val_loss: 0.9306\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9300 - val_loss: 0.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9291 - val_loss: 0.9336\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9290 - val_loss: 0.9340\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9287 - val_loss: 0.9300\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9284 - val_loss: 0.9304\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9299 - val_loss: 0.9283\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9285 - val_loss: 0.9300\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9288 - val_loss: 0.9295\n",
      "Top-2 accuracy = 0.833\n",
      "15\n",
      "standardizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0684 - val_loss: 1.0148\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9769 - val_loss: 0.9563\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9476 - val_loss: 0.9436\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9424 - val_loss: 0.9481\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9406 - val_loss: 0.9347\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9377 - val_loss: 0.9377\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9385 - val_loss: 0.9413\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9381 - val_loss: 0.9323\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9350 - val_loss: 0.9318\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9342 - val_loss: 0.9318\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9348 - val_loss: 0.9319\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9364 - val_loss: 0.9328\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9343 - val_loss: 0.9304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9350 - val_loss: 0.9333\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9343 - val_loss: 0.9311\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9352 - val_loss: 0.9310\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9345 - val_loss: 0.9332\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9350 - val_loss: 0.9299\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9322 - val_loss: 0.9321\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9329 - val_loss: 0.9369\n",
      "Top-2 accuracy = 0.827\n",
      "16\n",
      "standardizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.0501 - val_loss: 0.9935\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9832 - val_loss: 0.9598\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9447 - val_loss: 0.9333\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9367 - val_loss: 0.9350\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9367 - val_loss: 0.9323\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9347 - val_loss: 0.9303\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9328 - val_loss: 0.9321\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9333 - val_loss: 0.9348\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9355 - val_loss: 0.9329\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9311 - val_loss: 0.9457\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9326 - val_loss: 0.9303\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9307 - val_loss: 0.9339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9344 - val_loss: 0.9368\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9333 - val_loss: 0.9310\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9315 - val_loss: 0.9396\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9316 - val_loss: 0.9313\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9300 - val_loss: 0.9317\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9300 - val_loss: 0.9301\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9299 - val_loss: 0.9330\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9295 - val_loss: 0.9306\n",
      "Top-2 accuracy = 0.831\n",
      "17\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0203 - val_loss: 0.9734\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9712 - val_loss: 0.9602\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9592 - val_loss: 0.9522\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9539 - val_loss: 0.9565\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9530 - val_loss: 0.9472\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9489 - val_loss: 0.9459\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9485 - val_loss: 0.9450\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9473 - val_loss: 0.9477\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9468 - val_loss: 0.9450\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9455 - val_loss: 0.9435\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9454 - val_loss: 0.9566\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9462 - val_loss: 0.9426\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9440 - val_loss: 0.9453\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9452 - val_loss: 0.9424\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9437 - val_loss: 0.9417\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9442 - val_loss: 0.9413\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9431 - val_loss: 0.9424\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9429 - val_loss: 0.9417\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9433\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9432 - val_loss: 0.9416\n",
      "Top-2 accuracy = 0.826\n",
      "18\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.0865 - val_loss: 1.0741\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0720 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0709\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "19\n",
      "standardizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0903 - val_loss: 1.0827\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0783 - val_loss: 1.0741\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0732 - val_loss: 1.0715\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0718 - val_loss: 1.0709\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "20\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0840 - val_loss: 1.0730\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0720 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "21\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.0569 - val_loss: 1.0099\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9885 - val_loss: 0.9696\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9698 - val_loss: 0.9536\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9578 - val_loss: 0.9484\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9532 - val_loss: 0.9576\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9532 - val_loss: 0.9431\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9478 - val_loss: 0.9403\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9468 - val_loss: 0.9412\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9447 - val_loss: 0.9389\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9445 - val_loss: 0.9386\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9445 - val_loss: 0.9381\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9428 - val_loss: 0.9369\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9427 - val_loss: 0.9347\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9428 - val_loss: 0.9545\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9464 - val_loss: 0.9347\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9411 - val_loss: 0.9400\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9433 - val_loss: 0.9395\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9419 - val_loss: 0.9445\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9434 - val_loss: 0.9339\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9400 - val_loss: 0.9331\n",
      "Top-2 accuracy = 0.829\n",
      "22\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0337 - val_loss: 0.9789\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9645 - val_loss: 0.9497\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9498 - val_loss: 0.9478\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9463 - val_loss: 0.9410\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9430 - val_loss: 0.9414\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9392 - val_loss: 0.9366\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9380 - val_loss: 0.9330\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9356 - val_loss: 0.9354\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9367 - val_loss: 0.9316\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9345 - val_loss: 0.9320\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9354 - val_loss: 0.9382\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9342 - val_loss: 0.9353\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9349 - val_loss: 0.9452\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9336 - val_loss: 0.9271\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9360 - val_loss: 0.9313\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9337 - val_loss: 0.9288\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9316 - val_loss: 0.9302\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.9310 - val_loss: 0.9274\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9305 - val_loss: 0.9268\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9302 - val_loss: 0.9293\n",
      "Top-2 accuracy = 0.834\n",
      "23\n",
      "maxabsO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.0463 - val_loss: 0.9990\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0005 - val_loss: 0.9978\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0023 - val_loss: 1.0004\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9989 - val_loss: 0.9936\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0025 - val_loss: 1.0015\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9982 - val_loss: 0.9941\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9994 - val_loss: 0.9911\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.9989 - val_loss: 0.9935\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9985 - val_loss: 0.9926\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9984 - val_loss: 0.9930\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.9971 - val_loss: 0.9904\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9970 - val_loss: 0.9914\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9963 - val_loss: 0.9899\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9976 - val_loss: 0.9940\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9977 - val_loss: 0.9949\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9988 - val_loss: 0.9956\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0001 - val_loss: 1.0075\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9991 - val_loss: 0.9964\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0047 - val_loss: 1.0063\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0165 - val_loss: 1.0142\n",
      "Top-2 accuracy = 0.8\n",
      "24\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0862 - val_loss: 1.0731\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0719 - val_loss: 1.0709\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "25\n",
      "robustq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.0830 - val_loss: 1.0741\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0723 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0709\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0710\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.0717 - val_loss: 1.0709\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0717 - val_loss: 1.0709\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n",
      "26\n",
      "minmaxb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0476 - val_loss: 1.0115\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 0.9812\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9776 - val_loss: 0.9643\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9650 - val_loss: 0.9528\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9580 - val_loss: 0.9495\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 0.9456\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9519 - val_loss: 0.9436\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9451\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9419\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 0.9421\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9478 - val_loss: 0.9425\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9394\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9469 - val_loss: 0.9390\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9466 - val_loss: 0.9385\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 0.9387\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9465 - val_loss: 0.9418\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9393\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9464 - val_loss: 0.9397\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9464 - val_loss: 0.9391\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.9450 - val_loss: 0.9371\n",
      "Top-2 accuracy = 0.829\n",
      "27\n",
      "maxabsc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.0474 - val_loss: 0.9957\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9697 - val_loss: 0.9955\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9547 - val_loss: 0.9377\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9425 - val_loss: 0.9441\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9414 - val_loss: 0.9348\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9388 - val_loss: 0.9363\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9393 - val_loss: 0.9346\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9376 - val_loss: 0.9488\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9406 - val_loss: 0.9358\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9366 - val_loss: 0.9345\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9355 - val_loss: 0.9326\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9350 - val_loss: 0.9323\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9357 - val_loss: 0.9378\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9366 - val_loss: 0.9310\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9363 - val_loss: 0.9326\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9359 - val_loss: 0.9373\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9352 - val_loss: 0.9316\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9361 - val_loss: 0.9350\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9350 - val_loss: 0.9333\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9338 - val_loss: 0.9304\n",
      "Top-2 accuracy = 0.833\n",
      "28\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.0787 - val_loss: 1.0708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0717 - val_loss: 1.0708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0645 - val_loss: 1.0202\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0001 - val_loss: 0.9895\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9965 - val_loss: 0.9968\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9933 - val_loss: 0.9862\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9902 - val_loss: 0.9849\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9857 - val_loss: 0.9817\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9871 - val_loss: 0.9821\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9865 - val_loss: 0.9803\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9861 - val_loss: 0.9859\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9911 - val_loss: 0.9870\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9881 - val_loss: 0.9827\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9856 - val_loss: 0.9835\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9853 - val_loss: 0.9818\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9821 - val_loss: 0.9786\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9818 - val_loss: 0.9799\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9799 - val_loss: 0.9775\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 0.9771 - val_loss: 0.9722\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.9698 - val_loss: 0.9670\n",
      "Top-2 accuracy = 0.827\n",
      "29\n",
      "normalizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 4s 44ms/step - loss: 1.0911 - val_loss: 1.0841\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0802 - val_loss: 1.0763\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0748 - val_loss: 1.0727\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0726 - val_loss: 1.0714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0719 - val_loss: 1.0710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0716 - val_loss: 1.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.0715 - val_loss: 1.0708\n",
      "Top-2 accuracy = 0.724\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"accuracy\", \"pd\", \"prec\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [MulticlassDL(n_classes=3, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20)],\n",
    "    \"post_train_hooks\": [top2_hook],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"chromium-3class\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        MulticlassDL(n_classes=3, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5463973487229301"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([0.5467687560710817, 0.5476829895434546, 0.544997428718359, 0.44008913776355635, 0.5448831495343123, 0.5460259413747786, 0.5459688017827553, 0.5477972687275013, 0.547397291583338, 0.5482543854636878])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Chromium.ipynb', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [float(x.split('=')[1].strip().split(r'\\n')[0]) for x in lines if x.strip().startswith(r'\"Top-2 accuracy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.835,\n",
       " 0.724,\n",
       " 0.831,\n",
       " 0.841,\n",
       " 0.824,\n",
       " 0.835,\n",
       " 0.829,\n",
       " 0.724,\n",
       " 0.842,\n",
       " 0.842,\n",
       " 0.829,\n",
       " 0.822,\n",
       " 0.833,\n",
       " 0.844,\n",
       " 0.829,\n",
       " 0.829,\n",
       " 0.829,\n",
       " 0.829,\n",
       " 0.837,\n",
       " 0.829,\n",
       " 0.667,\n",
       " 0.837,\n",
       " 0.691,\n",
       " 0.823,\n",
       " 0.833,\n",
       " 0.829,\n",
       " 0.825,\n",
       " 0.828,\n",
       " 0.811,\n",
       " 0.724,\n",
       " 0.836,\n",
       " 0.828,\n",
       " 0.812,\n",
       " 0.831,\n",
       " 0.837,\n",
       " 0.837,\n",
       " 0.826,\n",
       " 0.83,\n",
       " 0.724,\n",
       " 0.826,\n",
       " 0.822,\n",
       " 0.829,\n",
       " 0.821,\n",
       " 0.816,\n",
       " 0.831,\n",
       " 0.816,\n",
       " 0.724,\n",
       " 0.829,\n",
       " 0.724,\n",
       " 0.832,\n",
       " 0.824,\n",
       " 0.82,\n",
       " 0.83,\n",
       " 0.822,\n",
       " 0.822,\n",
       " 0.829,\n",
       " 0.822,\n",
       " 0.724,\n",
       " 0.832,\n",
       " 0.724,\n",
       " 0.828,\n",
       " 0.724,\n",
       " 0.834,\n",
       " 0.827,\n",
       " 0.831,\n",
       " 0.825,\n",
       " 0.821,\n",
       " 0.828,\n",
       " 0.82,\n",
       " 0.822,\n",
       " 0.827,\n",
       " 0.827,\n",
       " 0.83,\n",
       " 0.831,\n",
       " 0.83,\n",
       " 0.823,\n",
       " 0.834,\n",
       " 0.823,\n",
       " 0.831,\n",
       " 0.829,\n",
       " 0.832,\n",
       " 0.827,\n",
       " 0.821,\n",
       " 0.834,\n",
       " 0.83,\n",
       " 0.824,\n",
       " 0.83,\n",
       " 0.831,\n",
       " 0.829,\n",
       " 0.827,\n",
       " 0.724,\n",
       " 0.831,\n",
       " 0.83,\n",
       " 0.825,\n",
       " 0.837,\n",
       " 0.827,\n",
       " 0.826,\n",
       " 0.826,\n",
       " 0.818,\n",
       " 0.837,\n",
       " 0.835,\n",
       " 0.825,\n",
       " 0.829,\n",
       " 0.826,\n",
       " 0.724,\n",
       " 0.837,\n",
       " 0.724,\n",
       " 0.83,\n",
       " 0.828,\n",
       " 0.829,\n",
       " 0.834,\n",
       " 0.828,\n",
       " 0.828,\n",
       " 0.724,\n",
       " 0.804,\n",
       " 0.826,\n",
       " 0.831,\n",
       " 0.833,\n",
       " 0.832,\n",
       " 0.831,\n",
       " 0.83,\n",
       " 0.826,\n",
       " 0.828,\n",
       " 0.818,\n",
       " 0.834,\n",
       " 0.83,\n",
       " 0.724,\n",
       " 0.828,\n",
       " 0.837,\n",
       " 0.833,\n",
       " 0.832,\n",
       " 0.825,\n",
       " 0.826,\n",
       " 0.831,\n",
       " 0.834,\n",
       " 0.832,\n",
       " 0.834,\n",
       " 0.828,\n",
       " 0.724,\n",
       " 0.825,\n",
       " 0.724,\n",
       " 0.822,\n",
       " 0.833,\n",
       " 0.835,\n",
       " 0.724,\n",
       " 0.833,\n",
       " 0.829,\n",
       " 0.832,\n",
       " 0.837,\n",
       " 0.825,\n",
       " 0.83,\n",
       " 0.83,\n",
       " 0.828,\n",
       " 0.834,\n",
       " 0.82,\n",
       " 0.831,\n",
       " 0.83,\n",
       " 0.824,\n",
       " 0.832,\n",
       " 0.825,\n",
       " 0.829,\n",
       " 0.827,\n",
       " 0.823,\n",
       " 0.819,\n",
       " 0.724,\n",
       " 0.832,\n",
       " 0.835,\n",
       " 0.724,\n",
       " 0.829,\n",
       " 0.829,\n",
       " 0.814,\n",
       " 0.819,\n",
       " 0.825,\n",
       " 0.829,\n",
       " 0.83,\n",
       " 0.825,\n",
       " 0.828,\n",
       " 0.829,\n",
       " 0.831,\n",
       " 0.831,\n",
       " 0.83,\n",
       " 0.832,\n",
       " 0.826,\n",
       " 0.834,\n",
       " 0.829,\n",
       " 0.833,\n",
       " 0.83,\n",
       " 0.832,\n",
       " 0.724,\n",
       " 0.83,\n",
       " 0.83,\n",
       " 0.825,\n",
       " 0.724,\n",
       " 0.735,\n",
       " 0.724,\n",
       " 0.827,\n",
       " 0.831,\n",
       " 0.822,\n",
       " 0.831,\n",
       " 0.82,\n",
       " 0.823,\n",
       " 0.827,\n",
       " 0.835,\n",
       " 0.83,\n",
       " 0.827,\n",
       " 0.832,\n",
       " 0.724,\n",
       " 0.826,\n",
       " 0.724,\n",
       " 0.835,\n",
       " 0.832,\n",
       " 0.724,\n",
       " 0.803,\n",
       " 0.724,\n",
       " 0.724,\n",
       " 0.82,\n",
       " 0.724,\n",
       " 0.831,\n",
       " 0.829,\n",
       " 0.724,\n",
       " 0.833,\n",
       " 0.831,\n",
       " 0.823,\n",
       " 0.836,\n",
       " 0.828,\n",
       " 0.83,\n",
       " 0.834,\n",
       " 0.724,\n",
       " 0.825,\n",
       " 0.834,\n",
       " 0.831,\n",
       " 0.825,\n",
       " 0.829,\n",
       " 0.833,\n",
       " 0.829,\n",
       " 0.724,\n",
       " 0.831,\n",
       " 0.724,\n",
       " 0.828,\n",
       " 0.724,\n",
       " 0.833,\n",
       " 0.724,\n",
       " 0.834,\n",
       " 0.832,\n",
       " 0.821,\n",
       " 0.811,\n",
       " 0.827,\n",
       " 0.825,\n",
       " 0.724,\n",
       " 0.834,\n",
       " 0.724,\n",
       " 0.829,\n",
       " 0.82,\n",
       " 0.834,\n",
       " 0.834,\n",
       " 0.724,\n",
       " 0.778,\n",
       " 0.833,\n",
       " 0.83,\n",
       " 0.829,\n",
       " 0.832,\n",
       " 0.829,\n",
       " 0.833,\n",
       " 0.826,\n",
       " 0.831,\n",
       " 0.821,\n",
       " 0.724,\n",
       " 0.831,\n",
       " 0.815,\n",
       " 0.82,\n",
       " 0.832,\n",
       " 0.829,\n",
       " 0.827,\n",
       " 0.83,\n",
       " 0.724,\n",
       " 0.832,\n",
       " 0.831,\n",
       " 0.837,\n",
       " 0.83,\n",
       " 0.833,\n",
       " 0.806,\n",
       " 0.831,\n",
       " 0.816,\n",
       " 0.834,\n",
       " 0.833,\n",
       " 0.827,\n",
       " 0.831,\n",
       " 0.826,\n",
       " 0.724,\n",
       " 0.724,\n",
       " 0.724,\n",
       " 0.829,\n",
       " 0.834,\n",
       " 0.8,\n",
       " 0.724,\n",
       " 0.724,\n",
       " 0.829,\n",
       " 0.833,\n",
       " 0.827,\n",
       " 0.724]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.829"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = np.where(data.y_train < 1, 0, np.where(data.y_train < 3, 1, np.where(data.y_train < 6, 2, np.where(data.y_train < 21, 3, 4))))\n",
    "data.y_test = np.where(data.y_test < 1, 0, np.where(data.y_test < 3, 1, np.where(data.y_test < 6, 2, np.where(data.y_test < 21, 3, 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y_train = to_categorical(data.y_train, num_classes=5)\n",
    "data.y_test = to_categorical(data.y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170ba87c0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170ba8ca0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170ba8550>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174026a90>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174026b20>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170bb12e0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170ba8bb0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170bb1f10>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170bb1b50>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170bb1790>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170bb1640>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170bb1fd0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740e26d0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740e5d60>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740e5670>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740e5ee0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740e5850>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740e55e0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174104df0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174104a30>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741045b0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174104a60>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174104dc0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741042e0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174104520>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741873d0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741876a0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741871f0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174187370>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x173e4b820>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740a64f0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x173e80940>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x172941550>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x172941ca0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x172941a60>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x172941160>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x172941af0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x172941f40>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1711747f0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x171174a30>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1711743a0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1711a68e0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1711a6280>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1711a6820>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1711a6af0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1711a6040>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1711a6a00>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 2, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1711a6370>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 3, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17401cf10>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 5, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17401c4c0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 4, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17401cbb0>, 'loss': 'categorical_crossentropy', 'n_classes': 5, 'n_epochs': 20, 'n_layers': 6, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robustR|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1603 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6032 - val_loss: 1.5985\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5926 - val_loss: 1.5894\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5756 - val_loss: 1.5670\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5524 - val_loss: 1.5474\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5359 - val_loss: 1.5353\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5255 - val_loss: 1.5249\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5114 - val_loss: 1.5095\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4963 - val_loss: 1.4926\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4815 - val_loss: 1.4783\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4734 - val_loss: 1.4732\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4696 - val_loss: 1.4742\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4679 - val_loss: 1.4672\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4650 - val_loss: 1.4654\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4629 - val_loss: 1.4650\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4617 - val_loss: 1.4628\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4598 - val_loss: 1.4616\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4589 - val_loss: 1.4611\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4578 - val_loss: 1.4606\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4573 - val_loss: 1.4587\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4559 - val_loss: 1.4580\n",
      "Top-2 accuracy = 0.594\n",
      "1\n",
      "maxabsd|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1610 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5980 - val_loss: 1.5870\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5650 - val_loss: 1.5444\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5125 - val_loss: 1.4919\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4758 - val_loss: 1.4693\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4611 - val_loss: 1.4592\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4516 - val_loss: 1.4516\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4456 - val_loss: 1.4474\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4423 - val_loss: 1.4441\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4399 - val_loss: 1.4421\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4375 - val_loss: 1.4407\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4356 - val_loss: 1.4382\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4344 - val_loss: 1.4367\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4334 - val_loss: 1.4356\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4322 - val_loss: 1.4352\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4315 - val_loss: 1.4340\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4307 - val_loss: 1.4333\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4305 - val_loss: 1.4327\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4295 - val_loss: 1.4331\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4289 - val_loss: 1.4336\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4279 - val_loss: 1.4309\n",
      "Top-2 accuracy = 0.61\n",
      "2\n",
      "normalizek|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1616 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5862 - val_loss: 1.5671\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5421 - val_loss: 1.5181\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4966 - val_loss: 1.4815\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4725 - val_loss: 1.4659\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4624 - val_loss: 1.4582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4553 - val_loss: 1.4522\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4502 - val_loss: 1.4473\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4460 - val_loss: 1.4438\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4426 - val_loss: 1.4410\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4399 - val_loss: 1.4386\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4372 - val_loss: 1.4366\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4353 - val_loss: 1.4351\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4337 - val_loss: 1.4340\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4325 - val_loss: 1.4325\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4314 - val_loss: 1.4320\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4302 - val_loss: 1.4309\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4295 - val_loss: 1.4305\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4284 - val_loss: 1.4300\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4281 - val_loss: 1.4293\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4276 - val_loss: 1.4288\n",
      "Top-2 accuracy = 0.607\n",
      "3\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1619 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 8.2266 - val_loss: 2.1930\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8799 - val_loss: 1.7136\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6508 - val_loss: 1.6209\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5980 - val_loss: 1.5918\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5758 - val_loss: 1.5742\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5607 - val_loss: 1.5619\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5496 - val_loss: 1.5522\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5396 - val_loss: 1.5430\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5319 - val_loss: 1.5345\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5222 - val_loss: 1.5254\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5175 - val_loss: 1.5170\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5074 - val_loss: 1.5142\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5018 - val_loss: 1.5013\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4938 - val_loss: 1.4944\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4869 - val_loss: 1.4850\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4829 - val_loss: 1.4803\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4784 - val_loss: 1.4803\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4745 - val_loss: 1.4700\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4698 - val_loss: 1.4664\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4663 - val_loss: 1.4613\n",
      "Top-2 accuracy = 0.588\n",
      "4\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1624 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5779 - val_loss: 1.5384\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4926 - val_loss: 1.4652\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4590 - val_loss: 1.4516\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4483 - val_loss: 1.4448\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4414 - val_loss: 1.4383\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4361 - val_loss: 1.4346\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4309\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4264\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4249\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4235\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4233 - val_loss: 1.4231\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4229\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4209 - val_loss: 1.4218\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4212\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4194 - val_loss: 1.4213\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4181 - val_loss: 1.4210\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4178 - val_loss: 1.4214\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4176 - val_loss: 1.4223\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4170 - val_loss: 1.4196\n",
      "Top-2 accuracy = 0.614\n",
      "5\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1630 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5792 - val_loss: 1.5351\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4813 - val_loss: 1.4552\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4473 - val_loss: 1.4452\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4402 - val_loss: 1.4382\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4345\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4307\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4277\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4260\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4258\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4241 - val_loss: 1.4238\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4226 - val_loss: 1.4239\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4237\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4207 - val_loss: 1.4222\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4222\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4196 - val_loss: 1.4201\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.4213\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4181 - val_loss: 1.4205\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4174 - val_loss: 1.4188\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4164 - val_loss: 1.4189\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4161 - val_loss: 1.4173\n",
      "Top-2 accuracy = 0.612\n",
      "6\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1636 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5585 - val_loss: 1.5217\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4927 - val_loss: 1.4708\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4632 - val_loss: 1.4548\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4536 - val_loss: 1.4476\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4428\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4425 - val_loss: 1.4384\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4381 - val_loss: 1.4346\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4345 - val_loss: 1.4325\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4322 - val_loss: 1.4303\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4300 - val_loss: 1.4293\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4282\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4278 - val_loss: 1.4267\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4265 - val_loss: 1.4255\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4256 - val_loss: 1.4250\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4240\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4239 - val_loss: 1.4235\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4229 - val_loss: 1.4227\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4222 - val_loss: 1.4219\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4218 - val_loss: 1.4215\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4212 - val_loss: 1.4211\n",
      "Top-2 accuracy = 0.609\n",
      "7\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1641 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5803 - val_loss: 1.5679\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5524 - val_loss: 1.5395\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5219 - val_loss: 1.5086\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4939 - val_loss: 1.4846\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4764 - val_loss: 1.4730\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4692 - val_loss: 1.4689\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4657 - val_loss: 1.4649\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4628 - val_loss: 1.4625\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4611 - val_loss: 1.4603\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4593 - val_loss: 1.4589\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4575 - val_loss: 1.4567\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4567 - val_loss: 1.4558\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4547 - val_loss: 1.4547\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4538 - val_loss: 1.4527\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4524 - val_loss: 1.4518\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4514 - val_loss: 1.4504\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4504 - val_loss: 1.4497\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4493 - val_loss: 1.4480\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4484 - val_loss: 1.4472\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4474 - val_loss: 1.4476\n",
      "Top-2 accuracy = 0.603\n",
      "8\n",
      "maxabsC|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1644 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5951 - val_loss: 1.5807\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5627 - val_loss: 1.5485\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5290 - val_loss: 1.5168\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5040 - val_loss: 1.4982\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4894 - val_loss: 1.4867\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4797 - val_loss: 1.4797\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4734 - val_loss: 1.4738\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4690 - val_loss: 1.4711\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4657 - val_loss: 1.4674\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4626 - val_loss: 1.4653\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4607 - val_loss: 1.4635\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4588 - val_loss: 1.4617\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4571 - val_loss: 1.4588\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4555 - val_loss: 1.4565\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4533 - val_loss: 1.4541\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4512 - val_loss: 1.4537\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4490 - val_loss: 1.4499\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4471 - val_loss: 1.4471\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4450 - val_loss: 1.4439\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4422 - val_loss: 1.4425\n",
      "Top-2 accuracy = 0.599\n",
      "9\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1649 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5858 - val_loss: 1.5800\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5693 - val_loss: 1.5612\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5415 - val_loss: 1.5253\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5111 - val_loss: 1.5012\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4916 - val_loss: 1.4850\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4790 - val_loss: 1.4759\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4724 - val_loss: 1.4712\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4684 - val_loss: 1.4672\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4651 - val_loss: 1.4643\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4634 - val_loss: 1.4631\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4617 - val_loss: 1.4634\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4610 - val_loss: 1.4609\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4600 - val_loss: 1.4606\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4593 - val_loss: 1.4593\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4587 - val_loss: 1.4587\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4582 - val_loss: 1.4583\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4574 - val_loss: 1.4578\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4568 - val_loss: 1.4570\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4564 - val_loss: 1.4573\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4561 - val_loss: 1.4560\n",
      "Top-2 accuracy = 0.591\n",
      "10\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1655 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5697 - val_loss: 1.5305\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4979 - val_loss: 1.4747\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4644 - val_loss: 1.4580\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4541 - val_loss: 1.4513\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4478 - val_loss: 1.4466\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4426 - val_loss: 1.4428\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4402 - val_loss: 1.4385\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4376 - val_loss: 1.4371\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4368\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4322\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4306\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4283\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4272\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4259\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4247 - val_loss: 1.4252\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4261\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4226\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4223\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4203 - val_loss: 1.4239\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4191 - val_loss: 1.4219\n",
      "Top-2 accuracy = 0.61\n",
      "11\n",
      "minmaxg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5793 - val_loss: 1.5493\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5196 - val_loss: 1.4929\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4748 - val_loss: 1.4677\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4598 - val_loss: 1.4598\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4541 - val_loss: 1.4612\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4508 - val_loss: 1.4511\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4507\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4460 - val_loss: 1.4513\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4440 - val_loss: 1.4461\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4428 - val_loss: 1.4486\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4426 - val_loss: 1.4420\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4402 - val_loss: 1.4431\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4395 - val_loss: 1.4393\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4424\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4377 - val_loss: 1.4392\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.4402\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4361 - val_loss: 1.4365\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4346 - val_loss: 1.4440\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4347\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4342\n",
      "Top-2 accuracy = 0.6\n",
      "12\n",
      "standardizeA|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1668 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5847 - val_loss: 1.5558\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5227 - val_loss: 1.4912\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4686 - val_loss: 1.4533\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4501 - val_loss: 1.4453\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4436 - val_loss: 1.4412\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4401 - val_loss: 1.4376\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4372 - val_loss: 1.4354\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4342 - val_loss: 1.4332\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4321 - val_loss: 1.4315\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4306 - val_loss: 1.4292\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4292 - val_loss: 1.4273\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4275 - val_loss: 1.4267\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4266 - val_loss: 1.4259\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4260 - val_loss: 1.4263\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4247\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4243\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4234\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4228\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4226\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4225\n",
      "Top-2 accuracy = 0.61\n",
      "13\n",
      "standardized|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1673 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5806 - val_loss: 1.5621\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5417 - val_loss: 1.5269\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5143 - val_loss: 1.5090\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4999 - val_loss: 1.4972\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4894 - val_loss: 1.4882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4813 - val_loss: 1.4809\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4747 - val_loss: 1.4747\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4695 - val_loss: 1.4705\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4653 - val_loss: 1.4672\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4616 - val_loss: 1.4641\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4581 - val_loss: 1.4611\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4548 - val_loss: 1.4576\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4519 - val_loss: 1.4548\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4496 - val_loss: 1.4526\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4476 - val_loss: 1.4506\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4461 - val_loss: 1.4490\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4450 - val_loss: 1.4478\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4440 - val_loss: 1.4466\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4432 - val_loss: 1.4456\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4426 - val_loss: 1.4449\n",
      "Top-2 accuracy = 0.6\n",
      "14\n",
      "normalizeZ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1679 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5881 - val_loss: 1.5648\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5141 - val_loss: 1.4719\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4615 - val_loss: 1.4544\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4516 - val_loss: 1.4480\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4460 - val_loss: 1.4429\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4412 - val_loss: 1.4389\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4379 - val_loss: 1.4361\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4353 - val_loss: 1.4332\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4320\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4297\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4281\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4287 - val_loss: 1.4273\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4253\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4251 - val_loss: 1.4247\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4234\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4233 - val_loss: 1.4223\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4222 - val_loss: 1.4215\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4209\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4201 - val_loss: 1.4200\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.4196\n",
      "Top-2 accuracy = 0.612\n",
      "15\n",
      "normalizeA|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1683 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5936 - val_loss: 1.5752\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5457 - val_loss: 1.5239\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5098 - val_loss: 1.5057\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4960 - val_loss: 1.4952\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4868 - val_loss: 1.4875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4798 - val_loss: 1.4817\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4744 - val_loss: 1.4769\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4699 - val_loss: 1.4730\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4665 - val_loss: 1.4700\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4641 - val_loss: 1.4674\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4619 - val_loss: 1.4654\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4600 - val_loss: 1.4632\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4588 - val_loss: 1.4617\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4570 - val_loss: 1.4599\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4558 - val_loss: 1.4583\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4547 - val_loss: 1.4575\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4536 - val_loss: 1.4555\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4524 - val_loss: 1.4540\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4512 - val_loss: 1.4532\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4506 - val_loss: 1.4515\n",
      "Top-2 accuracy = 0.6\n",
      "16\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1688 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5791 - val_loss: 1.5354\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4888 - val_loss: 1.4519\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4477 - val_loss: 1.4407\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4382\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4352 - val_loss: 1.4329\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4312\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4267\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4241\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4230\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4216\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4206\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4194\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4187 - val_loss: 1.4177\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4180 - val_loss: 1.4167\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4163 - val_loss: 1.4167\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4161 - val_loss: 1.4168\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4156 - val_loss: 1.4147\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4139 - val_loss: 1.4166\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4144 - val_loss: 1.4144\n",
      "Top-2 accuracy = 0.612\n",
      "17\n",
      "maxabsm|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1695 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5986 - val_loss: 1.5920\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5851 - val_loss: 1.5845\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5807 - val_loss: 1.5819\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5790 - val_loss: 1.5801\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5775 - val_loss: 1.5784\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5752 - val_loss: 1.5751\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5689 - val_loss: 1.5643\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5474 - val_loss: 1.5321\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5129 - val_loss: 1.5035\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4901 - val_loss: 1.4880\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4787 - val_loss: 1.4799\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4720 - val_loss: 1.4744\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4673 - val_loss: 1.4706\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4644 - val_loss: 1.4677\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4615 - val_loss: 1.4648\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4594 - val_loss: 1.4628\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4577 - val_loss: 1.4607\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4562 - val_loss: 1.4594\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4549 - val_loss: 1.4583\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4540 - val_loss: 1.4569\n",
      "Top-2 accuracy = 0.588\n",
      "18\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1700 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5892 - val_loss: 1.5662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5420 - val_loss: 1.5246\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5118 - val_loss: 1.5050\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4962 - val_loss: 1.4904\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4826 - val_loss: 1.4756\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4696 - val_loss: 1.4611\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4596 - val_loss: 1.4541\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4539 - val_loss: 1.4500\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4502 - val_loss: 1.4474\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4467 - val_loss: 1.4435\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4441 - val_loss: 1.4412\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4417 - val_loss: 1.4394\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4401 - val_loss: 1.4379\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4383 - val_loss: 1.4371\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4369 - val_loss: 1.4353\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4357 - val_loss: 1.4347\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4344 - val_loss: 1.4336\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4336 - val_loss: 1.4332\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4329 - val_loss: 1.4322\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4320 - val_loss: 1.4308\n",
      "Top-2 accuracy = 0.608\n",
      "19\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1705 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 8.2663 - val_loss: 4.0562\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.7999 - val_loss: 2.0171\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8306 - val_loss: 1.7324\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6915 - val_loss: 1.6602\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6399 - val_loss: 1.6257\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6142 - val_loss: 1.6038\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5944 - val_loss: 1.5890\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5799 - val_loss: 1.5723\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5608 - val_loss: 1.5562\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5463 - val_loss: 1.5459\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5368 - val_loss: 1.5385\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5313 - val_loss: 1.5342\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5276 - val_loss: 1.5305\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5244 - val_loss: 1.5276\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5216 - val_loss: 1.5251\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5193 - val_loss: 1.5225\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5170 - val_loss: 1.5198\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5151 - val_loss: 1.5177\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5130 - val_loss: 1.5159\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5114 - val_loss: 1.5145\n",
      "Top-2 accuracy = 0.533\n",
      "20\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1708 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6032 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5938 - val_loss: 1.5926\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5886 - val_loss: 1.5896\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5856 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "21\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1715 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5800 - val_loss: 1.5468\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5201 - val_loss: 1.5003\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4845 - val_loss: 1.4774\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4695 - val_loss: 1.4678\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4641 - val_loss: 1.4612\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4590 - val_loss: 1.4572\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4556 - val_loss: 1.4547\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4535 - val_loss: 1.4517\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4520 - val_loss: 1.4499\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4495 - val_loss: 1.4480\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4480 - val_loss: 1.4466\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4465 - val_loss: 1.4449\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4455 - val_loss: 1.4445\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4446 - val_loss: 1.4435\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4436 - val_loss: 1.4421\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4425 - val_loss: 1.4458\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4404\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4408 - val_loss: 1.4427\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4405 - val_loss: 1.4391\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4396 - val_loss: 1.4382\n",
      "Top-2 accuracy = 0.603\n",
      "22\n",
      "standardizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6033 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5939 - val_loss: 1.5927\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5886 - val_loss: 1.5895\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5858 - val_loss: 1.5882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5845 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5838 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "23\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5948 - val_loss: 1.5825\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5508 - val_loss: 1.5165\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4853 - val_loss: 1.4665\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4565 - val_loss: 1.4510\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4477 - val_loss: 1.4458\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4432 - val_loss: 1.4417\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4411 - val_loss: 1.4413\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4394 - val_loss: 1.4384\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4383 - val_loss: 1.4378\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4375\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4369 - val_loss: 1.4359\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4369\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4375\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4353\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 1.4352\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4327\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4326\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4315\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4338\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4310\n",
      "Top-2 accuracy = 0.603\n",
      "24\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1732 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5917 - val_loss: 1.5666\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5302 - val_loss: 1.5066\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4912 - val_loss: 1.4830\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4736 - val_loss: 1.4696\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4647 - val_loss: 1.4628\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4600 - val_loss: 1.4582\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4552 - val_loss: 1.4575\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4509 - val_loss: 1.4492\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4434\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4442 - val_loss: 1.4431\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4396 - val_loss: 1.4360\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4402\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4355\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4480\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4347 - val_loss: 1.4332\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4306\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4290\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.4272\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4245\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4232\n",
      "Top-2 accuracy = 0.611\n",
      "25\n",
      "normalizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5766 - val_loss: 1.5494\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5208 - val_loss: 1.4972\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4779 - val_loss: 1.4661\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4605 - val_loss: 1.4575\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4561 - val_loss: 1.4551\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4535 - val_loss: 1.4522\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4517 - val_loss: 1.4555\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4507 - val_loss: 1.4489\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4493 - val_loss: 1.4479\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4475 - val_loss: 1.4457\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4462 - val_loss: 1.4439\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4448 - val_loss: 1.4452\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4445 - val_loss: 1.4462\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4438 - val_loss: 1.4405\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4423 - val_loss: 1.4401\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4414 - val_loss: 1.4388\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4409 - val_loss: 1.4387\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4403 - val_loss: 1.4389\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4398 - val_loss: 1.4382\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4391 - val_loss: 1.4366\n",
      "Top-2 accuracy = 0.605\n",
      "26\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1742 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5878 - val_loss: 1.5645\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5343 - val_loss: 1.5046\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4835 - val_loss: 1.4655\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4621 - val_loss: 1.4573\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4559 - val_loss: 1.4534\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4529 - val_loss: 1.4482\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4505 - val_loss: 1.4460\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4476 - val_loss: 1.4450\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4455 - val_loss: 1.4411\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4433 - val_loss: 1.4396\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4421 - val_loss: 1.4439\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4405 - val_loss: 1.4370\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4393 - val_loss: 1.4344\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4378 - val_loss: 1.4329\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4355 - val_loss: 1.4329\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4340 - val_loss: 1.4299\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4332 - val_loss: 1.4313\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4331 - val_loss: 1.4319\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4265\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4296 - val_loss: 1.4266\n",
      "Top-2 accuracy = 0.612\n",
      "27\n",
      "robustK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6021 - val_loss: 1.5973\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5920 - val_loss: 1.5911\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5867 - val_loss: 1.5885\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5845 - val_loss: 1.5877\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "28\n",
      "maxabsa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5644 - val_loss: 1.5042\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4814 - val_loss: 1.4648\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4530 - val_loss: 1.4464\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4371\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4328\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4312\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4298\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4334\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4287\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4275\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4294\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4269\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4259\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4266\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4252\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4256\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4249\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4247\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4266\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-2 accuracy = 0.606\n",
      "29\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5607 - val_loss: 1.4920\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4558 - val_loss: 1.4383\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4314\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4283\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4267\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4280\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4264 - val_loss: 1.4256\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4267\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4261\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4237\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4238\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4265\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4238 - val_loss: 1.4250\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4228\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4230 - val_loss: 1.4252\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4229\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4227\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4212 - val_loss: 1.4230\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4204 - val_loss: 1.4219\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4222\n",
      "Top-2 accuracy = 0.606\n",
      "0\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1769 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5997 - val_loss: 1.5944\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5877 - val_loss: 1.5899\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5835 - val_loss: 1.5874\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5801 - val_loss: 1.5826\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5726 - val_loss: 1.5694\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5555 - val_loss: 1.5483\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5334 - val_loss: 1.5250\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5080 - val_loss: 1.4992\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4839 - val_loss: 1.4777\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4676 - val_loss: 1.4672\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4617 - val_loss: 1.4639\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4592 - val_loss: 1.4624\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4575 - val_loss: 1.4599\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4551 - val_loss: 1.4574\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4532 - val_loss: 1.4554\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4516 - val_loss: 1.4540\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4501 - val_loss: 1.4521\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4484 - val_loss: 1.4496\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4460 - val_loss: 1.4468\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4435 - val_loss: 1.4452\n",
      "Top-2 accuracy = 0.598\n",
      "1\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5992 - val_loss: 1.5928\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5870 - val_loss: 1.5883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5839 - val_loss: 1.5877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "2\n",
      "standardizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5991 - val_loss: 1.5841\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5703 - val_loss: 1.5585\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5282 - val_loss: 1.5087\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4937 - val_loss: 1.4915\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4806 - val_loss: 1.4798\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4712 - val_loss: 1.4723\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4652 - val_loss: 1.4676\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4609 - val_loss: 1.4638\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4578 - val_loss: 1.4615\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4558 - val_loss: 1.4597\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4542 - val_loss: 1.4584\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4530 - val_loss: 1.4577\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4523 - val_loss: 1.4573\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4518 - val_loss: 1.4566\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4514 - val_loss: 1.4574\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4508 - val_loss: 1.4559\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4508 - val_loss: 1.4558\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4505 - val_loss: 1.4559\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4503 - val_loss: 1.4556\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4504 - val_loss: 1.4552\n",
      "Top-2 accuracy = 0.59\n",
      "3\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5679 - val_loss: 1.5234\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4981 - val_loss: 1.4810\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4671 - val_loss: 1.4565\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4429\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4390 - val_loss: 1.4416\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4328\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4355\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4298\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4279\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4279\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4264\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4267\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4257\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4282\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4249\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4247\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4236\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4241\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4240\n",
      "Top-2 accuracy = 0.607\n",
      "4\n",
      "minmaxJ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1793 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5949 - val_loss: 1.5788\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5648 - val_loss: 1.5509\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5272 - val_loss: 1.5051\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4878 - val_loss: 1.4729\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4664 - val_loss: 1.4596\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4582 - val_loss: 1.4540\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4538 - val_loss: 1.4499\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4510 - val_loss: 1.4476\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4486 - val_loss: 1.4460\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4469 - val_loss: 1.4437\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4450 - val_loss: 1.4422\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4439 - val_loss: 1.4415\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4423 - val_loss: 1.4400\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4415 - val_loss: 1.4386\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4401 - val_loss: 1.4376\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4394 - val_loss: 1.4362\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4381 - val_loss: 1.4351\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4376 - val_loss: 1.4350\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4365 - val_loss: 1.4349\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4360 - val_loss: 1.4328\n",
      "Top-2 accuracy = 0.608\n",
      "5\n",
      "minmaxh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5562 - val_loss: 1.4824\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4465 - val_loss: 1.4331\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4314 - val_loss: 1.4364\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4300 - val_loss: 1.4244\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4243 - val_loss: 1.4283\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4223\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4239 - val_loss: 1.4242\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4239 - val_loss: 1.4259\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4223\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4229 - val_loss: 1.4220\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4221 - val_loss: 1.4220\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4219 - val_loss: 1.4240\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4215 - val_loss: 1.4274\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4227 - val_loss: 1.4238\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4208 - val_loss: 1.4245\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4216 - val_loss: 1.4214\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4208 - val_loss: 1.4207\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4218 - val_loss: 1.4257\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4203 - val_loss: 1.4296\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4208 - val_loss: 1.4218\n",
      "Top-2 accuracy = 0.606\n",
      "6\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6019 - val_loss: 1.5969\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5916 - val_loss: 1.5908\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5865 - val_loss: 1.5883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "7\n",
      "minmaxr|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1810 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5766 - val_loss: 1.5396\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4993 - val_loss: 1.4705\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4615 - val_loss: 1.4572\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4555 - val_loss: 1.4531\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4515 - val_loss: 1.4518\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4499 - val_loss: 1.4478\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4473 - val_loss: 1.4456\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4454 - val_loss: 1.4435\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4432 - val_loss: 1.4422\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4418 - val_loss: 1.4406\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4404 - val_loss: 1.4391\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4399 - val_loss: 1.4380\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4380 - val_loss: 1.4366\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4365 - val_loss: 1.4359\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4352 - val_loss: 1.4337\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4348 - val_loss: 1.4330\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4333 - val_loss: 1.4322\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4324 - val_loss: 1.4319\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4317 - val_loss: 1.4299\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4307 - val_loss: 1.4299\n",
      "Top-2 accuracy = 0.611\n",
      "8\n",
      "normalizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.6032 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5939 - val_loss: 1.5927\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5887 - val_loss: 1.5896\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5858 - val_loss: 1.5882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "9\n",
      "standardizez|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1819 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5795 - val_loss: 1.5482\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5269 - val_loss: 1.5047\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4819 - val_loss: 1.4622\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4515 - val_loss: 1.4450\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4431 - val_loss: 1.4399\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4368 - val_loss: 1.4358\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4322\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4298\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4266\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4250\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4230 - val_loss: 1.4240\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4207 - val_loss: 1.4244\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4208\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4188 - val_loss: 1.4208\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4182 - val_loss: 1.4216\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4175 - val_loss: 1.4193\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4162 - val_loss: 1.4201\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4158 - val_loss: 1.4200\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4152 - val_loss: 1.4193\n",
      "Top-2 accuracy = 0.61\n",
      "10\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6030 - val_loss: 1.5985\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5937 - val_loss: 1.5925\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5884 - val_loss: 1.5894\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5855 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "11\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5702 - val_loss: 1.5329\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4840 - val_loss: 1.4458\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4286\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4266\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4250\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4250\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4254\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4246\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4277\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4258\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4258\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4233 - val_loss: 1.4267\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4241\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4244\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4232 - val_loss: 1.4235\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4228 - val_loss: 1.4261\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4241\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4260\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4257\n",
      "Top-2 accuracy = 0.607\n",
      "12\n",
      "minmaxX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5738 - val_loss: 1.5446\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5047 - val_loss: 1.4790\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4606 - val_loss: 1.4525\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4449 - val_loss: 1.4426\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4377 - val_loss: 1.4377\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4357\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4362\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4336 - val_loss: 1.4374\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4339\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4321 - val_loss: 1.4375\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4338\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4325\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4356\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4315\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4305\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4301\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4302\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4294\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4311\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4299\n",
      "Top-2 accuracy = 0.606\n",
      "13\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5796 - val_loss: 1.5284\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4906 - val_loss: 1.4638\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4542 - val_loss: 1.4468\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4496\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4429 - val_loss: 1.4352\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4363 - val_loss: 1.4359\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4424\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4347 - val_loss: 1.4323\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4310\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4346\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4307\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4321\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4355\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4295\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4287\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4284\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4283\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4298\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4280\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4288\n",
      "Top-2 accuracy = 0.606\n",
      "14\n",
      "robustg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5456 - val_loss: 1.4789\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4549 - val_loss: 1.4404\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4328\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4278\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4270\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4246\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4254\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.4248\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4232\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4239\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4222\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4226 - val_loss: 1.4212\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4222 - val_loss: 1.4208\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4208\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4225\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4209 - val_loss: 1.4216\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4210 - val_loss: 1.4202\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4202 - val_loss: 1.4224\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4205 - val_loss: 1.4207\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.4213\n",
      "Top-2 accuracy = 0.608\n",
      "15\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5383 - val_loss: 1.4530\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4434 - val_loss: 1.4443\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4376 - val_loss: 1.4344\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4369\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4308\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4345\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4301\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4349 - val_loss: 1.4310\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4483\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4394\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4287\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4312\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4327\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4279\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4270\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4270\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4462\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4288\n",
      "Top-2 accuracy = 0.605\n",
      "16\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1862 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5842 - val_loss: 1.5552\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5251 - val_loss: 1.4966\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4838 - val_loss: 1.4715\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4690 - val_loss: 1.4630\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4626 - val_loss: 1.4598\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4600 - val_loss: 1.4567\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4573 - val_loss: 1.4557\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4553 - val_loss: 1.4540\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4539 - val_loss: 1.4516\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4526 - val_loss: 1.4499\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4507 - val_loss: 1.4494\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4497 - val_loss: 1.4474\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4484 - val_loss: 1.4475\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4475 - val_loss: 1.4466\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4467 - val_loss: 1.4457\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4458 - val_loss: 1.4459\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4455 - val_loss: 1.4438\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4443 - val_loss: 1.4436\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4437 - val_loss: 1.4427\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4435 - val_loss: 1.4427\n",
      "Top-2 accuracy = 0.605\n",
      "17\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1866 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5676 - val_loss: 1.5336\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5027 - val_loss: 1.4795\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4687 - val_loss: 1.4598\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4556 - val_loss: 1.4516\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4487 - val_loss: 1.4461\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4453 - val_loss: 1.4438\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4439 - val_loss: 1.4410\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4410 - val_loss: 1.4380\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4392 - val_loss: 1.4378\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4376 - val_loss: 1.4346\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4362 - val_loss: 1.4344\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4344 - val_loss: 1.4317\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4333 - val_loss: 1.4324\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4320 - val_loss: 1.4302\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4311 - val_loss: 1.4292\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4296 - val_loss: 1.4282\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4285 - val_loss: 1.4299\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4312 - val_loss: 1.4262\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4266\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4255\n",
      "Top-2 accuracy = 0.609\n",
      "18\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1871 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6010 - val_loss: 1.5774\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5488 - val_loss: 1.5140\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4930 - val_loss: 1.4754\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4708 - val_loss: 1.4631\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4611 - val_loss: 1.4563\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4557 - val_loss: 1.4520\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4514 - val_loss: 1.4482\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4482 - val_loss: 1.4456\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4456 - val_loss: 1.4430\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4434 - val_loss: 1.4409\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4417 - val_loss: 1.4391\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4401 - val_loss: 1.4375\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4386 - val_loss: 1.4358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4370 - val_loss: 1.4345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4358 - val_loss: 1.4331\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4346 - val_loss: 1.4318\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4334 - val_loss: 1.4305\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4323 - val_loss: 1.4300\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4314 - val_loss: 1.4285\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4302 - val_loss: 1.4273\n",
      "Top-2 accuracy = 0.607\n",
      "19\n",
      "maxabsg|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1875 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5770 - val_loss: 1.5506\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5174 - val_loss: 1.4972\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4798 - val_loss: 1.4675\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4593 - val_loss: 1.4533\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4503 - val_loss: 1.4469\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4452 - val_loss: 1.4436\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4417 - val_loss: 1.4399\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4390 - val_loss: 1.4371\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4367 - val_loss: 1.4345\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4349 - val_loss: 1.4330\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4334 - val_loss: 1.4324\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4321 - val_loss: 1.4305\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4308 - val_loss: 1.4297\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4296 - val_loss: 1.4296\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4286 - val_loss: 1.4274\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4274 - val_loss: 1.4264\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4266 - val_loss: 1.4262\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4257 - val_loss: 1.4251\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4248 - val_loss: 1.4247\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4238 - val_loss: 1.4238\n",
      "Top-2 accuracy = 0.611\n",
      "20\n",
      "normalizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5976 - val_loss: 1.5883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5706 - val_loss: 1.5596\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5352 - val_loss: 1.5112\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4745 - val_loss: 1.4819\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4550 - val_loss: 1.4456\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4422 - val_loss: 1.4411\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4402 - val_loss: 1.4365\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4363 - val_loss: 1.4372\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4332\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4341\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4310\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4424\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4303\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4316\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4278\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4276 - val_loss: 1.4270\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4271 - val_loss: 1.4260\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4275\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4287\n",
      "Top-2 accuracy = 0.601\n",
      "21\n",
      "minmaxb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1886 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5950 - val_loss: 1.5839\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5653 - val_loss: 1.5467\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5213 - val_loss: 1.5049\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4895 - val_loss: 1.4814\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4721 - val_loss: 1.4698\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4631 - val_loss: 1.4623\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4591 - val_loss: 1.4591\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4555 - val_loss: 1.4552\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4536 - val_loss: 1.4532\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4514 - val_loss: 1.4514\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4501 - val_loss: 1.4502\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4493 - val_loss: 1.4490\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4481 - val_loss: 1.4488\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4473 - val_loss: 1.4472\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4463 - val_loss: 1.4478\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4462 - val_loss: 1.4457\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4451 - val_loss: 1.4454\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4446 - val_loss: 1.4452\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4441 - val_loss: 1.4446\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4438 - val_loss: 1.4443\n",
      "Top-2 accuracy = 0.603\n",
      "22\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1892 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6005 - val_loss: 1.5895\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5777 - val_loss: 1.5677\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5562 - val_loss: 1.5453\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5351 - val_loss: 1.5260\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5200 - val_loss: 1.5142\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5102 - val_loss: 1.5058\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5041 - val_loss: 1.4996\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4983 - val_loss: 1.4945\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4936 - val_loss: 1.4902\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4899 - val_loss: 1.4864\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4861 - val_loss: 1.4829\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4826 - val_loss: 1.4810\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4799 - val_loss: 1.4764\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4763 - val_loss: 1.4737\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4734 - val_loss: 1.4720\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4714 - val_loss: 1.4688\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4691 - val_loss: 1.4679\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4677 - val_loss: 1.4656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4660 - val_loss: 1.4645\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4647 - val_loss: 1.4637\n",
      "Top-2 accuracy = 0.595\n",
      "23\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1896 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5889 - val_loss: 1.5807\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5718 - val_loss: 1.5680\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5541 - val_loss: 1.5416\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5248 - val_loss: 1.5095\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4974 - val_loss: 1.4868\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4800 - val_loss: 1.4734\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4704 - val_loss: 1.4663\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4643 - val_loss: 1.4612\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4598 - val_loss: 1.4573\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4567 - val_loss: 1.4542\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4539 - val_loss: 1.4516\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4520 - val_loss: 1.4499\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4504 - val_loss: 1.4485\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4489 - val_loss: 1.4466\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4474 - val_loss: 1.4452\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4460 - val_loss: 1.4437\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4450 - val_loss: 1.4426\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4436 - val_loss: 1.4415\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4431 - val_loss: 1.4407\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4424 - val_loss: 1.4402\n",
      "Top-2 accuracy = 0.603\n",
      "24\n",
      "robustd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5998 - val_loss: 1.5802\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5417 - val_loss: 1.5026\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4836 - val_loss: 1.4764\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4672 - val_loss: 1.4676\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4576 - val_loss: 1.4584\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4499 - val_loss: 1.4524\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4457 - val_loss: 1.4501\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4423 - val_loss: 1.4431\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4415\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4369 - val_loss: 1.4388\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4373\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4364\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4348\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4371\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4307 - val_loss: 1.4338\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4323\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4328\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4325\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4309\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4307\n",
      "Top-2 accuracy = 0.61\n",
      "25\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5910 - val_loss: 1.5894\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5846 - val_loss: 1.5877\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5836 - val_loss: 1.5879\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5881\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "26\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1911 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5689 - val_loss: 1.5241\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4905 - val_loss: 1.4702\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4651 - val_loss: 1.4620\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4598 - val_loss: 1.4576\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4555 - val_loss: 1.4529\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4530 - val_loss: 1.4510\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4489 - val_loss: 1.4480\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4460 - val_loss: 1.4444\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4428 - val_loss: 1.4420\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4406 - val_loss: 1.4392\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4383 - val_loss: 1.4359\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4359 - val_loss: 1.4333\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4341 - val_loss: 1.4322\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4327 - val_loss: 1.4321\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4313 - val_loss: 1.4349\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4307 - val_loss: 1.4286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4307 - val_loss: 1.4273\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4278 - val_loss: 1.4266\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4262 - val_loss: 1.4296\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4303\n",
      "Top-2 accuracy = 0.608\n",
      "27\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5767 - val_loss: 1.5265\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4675 - val_loss: 1.4421\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4304 - val_loss: 1.4290\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4261 - val_loss: 1.4405\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4263 - val_loss: 1.4340\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4247 - val_loss: 1.4306\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4233 - val_loss: 1.4269\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4225 - val_loss: 1.4259\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4222 - val_loss: 1.4258\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4223 - val_loss: 1.4296\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4233 - val_loss: 1.4272\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4217 - val_loss: 1.4510\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4266 - val_loss: 1.4260\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4206 - val_loss: 1.4254\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4212 - val_loss: 1.4259\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4211 - val_loss: 1.4257\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4197 - val_loss: 1.4240\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4203 - val_loss: 1.4229\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4197 - val_loss: 1.4248\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4199 - val_loss: 1.4237\n",
      "Top-2 accuracy = 0.606\n",
      "28\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5824 - val_loss: 1.5583\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5370 - val_loss: 1.5208\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5116 - val_loss: 1.5051\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4985 - val_loss: 1.4933\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4926 - val_loss: 1.4933\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4895 - val_loss: 1.4908\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4856 - val_loss: 1.4883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4864 - val_loss: 1.4896\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4805 - val_loss: 1.4808\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4803 - val_loss: 1.4824\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4778 - val_loss: 1.4792\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4789 - val_loss: 1.4817\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4770 - val_loss: 1.4794\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4791 - val_loss: 1.4768\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4774 - val_loss: 1.4784\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4772 - val_loss: 1.4765\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4744 - val_loss: 1.4757\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4738 - val_loss: 1.4757\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4769 - val_loss: 1.4762\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4731 - val_loss: 1.4710\n",
      "Top-2 accuracy = 0.582\n",
      "29\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1930 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5585 - val_loss: 1.5084\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4743 - val_loss: 1.4568\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4526 - val_loss: 1.4476\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4420\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4413 - val_loss: 1.4377\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4378 - val_loss: 1.4374\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4353 - val_loss: 1.4318\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4326 - val_loss: 1.4303\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4302 - val_loss: 1.4270\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4281 - val_loss: 1.4253\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4258 - val_loss: 1.4238\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4245 - val_loss: 1.4227\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4226 - val_loss: 1.4212\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4209\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4202 - val_loss: 1.4194\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4192 - val_loss: 1.4179\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4188 - val_loss: 1.4190\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4181 - val_loss: 1.4172\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4165 - val_loss: 1.4180\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4163 - val_loss: 1.4172\n",
      "Top-2 accuracy = 0.614\n",
      "0\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1935 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 6.6699 - val_loss: 3.3968\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.4730 - val_loss: 2.0291\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8896 - val_loss: 1.7970\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7445 - val_loss: 1.7049\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6753 - val_loss: 1.6551\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6343 - val_loss: 1.6247\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6087 - val_loss: 1.6046\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5911 - val_loss: 1.5917\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5782 - val_loss: 1.5818\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5693 - val_loss: 1.5744\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5625 - val_loss: 1.5688\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5585 - val_loss: 1.5628\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5526 - val_loss: 1.5591\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5486 - val_loss: 1.5562\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5453 - val_loss: 1.5533\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5421 - val_loss: 1.5495\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5380 - val_loss: 1.5468\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5349 - val_loss: 1.5434\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5317 - val_loss: 1.5435\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5289 - val_loss: 1.5357\n",
      "Top-2 accuracy = 0.544\n",
      "1\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5983 - val_loss: 1.5925\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5864 - val_loss: 1.5860\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5737 - val_loss: 1.5615\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5351 - val_loss: 1.5149\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4999 - val_loss: 1.4915\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4810 - val_loss: 1.4786\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4703 - val_loss: 1.4705\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4638 - val_loss: 1.4658\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4600 - val_loss: 1.4628\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4574 - val_loss: 1.4619\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4563 - val_loss: 1.4604\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4554 - val_loss: 1.4606\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4567 - val_loss: 1.4575\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4534 - val_loss: 1.4566\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4529 - val_loss: 1.4560\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4526 - val_loss: 1.4553\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4522 - val_loss: 1.4551\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4512 - val_loss: 1.4549\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4513 - val_loss: 1.4542\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4510 - val_loss: 1.4539\n",
      "Top-2 accuracy = 0.595\n",
      "2\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5793 - val_loss: 1.5191\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4728 - val_loss: 1.4554\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4525 - val_loss: 1.4459\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4436\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4444 - val_loss: 1.4443\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4426 - val_loss: 1.4390\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4415 - val_loss: 1.4459\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4469 - val_loss: 1.4503\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4359\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4370\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4343\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4346 - val_loss: 1.4424\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4364 - val_loss: 1.4319\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4333\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4369\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4312\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4303\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4418\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4303\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4328\n",
      "Top-2 accuracy = 0.602\n",
      "3\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5766 - val_loss: 1.5329\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4862 - val_loss: 1.4497\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4439 - val_loss: 1.4378\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4346\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4359 - val_loss: 1.4338\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4313\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4300\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4280\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4262\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4254\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4253\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4249\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4237\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4237\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4249\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4229\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4232 - val_loss: 1.4222\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4231 - val_loss: 1.4219\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4222 - val_loss: 1.4219\n",
      "Top-2 accuracy = 0.61\n",
      "4\n",
      "minmaxp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1957 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5959 - val_loss: 1.5864\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5759 - val_loss: 1.5693\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5566 - val_loss: 1.5500\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5366 - val_loss: 1.5285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5135 - val_loss: 1.5026\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4891 - val_loss: 1.4828\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4749 - val_loss: 1.4728\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4670 - val_loss: 1.4667\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4616 - val_loss: 1.4618\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4584 - val_loss: 1.4589\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4559 - val_loss: 1.4562\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4543 - val_loss: 1.4559\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4523 - val_loss: 1.4540\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4513 - val_loss: 1.4521\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4500 - val_loss: 1.4506\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4494 - val_loss: 1.4512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4481 - val_loss: 1.4482\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4470 - val_loss: 1.4465\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4459 - val_loss: 1.4455\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4449 - val_loss: 1.4448\n",
      "Top-2 accuracy = 0.602\n",
      "5\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6022 - val_loss: 1.5936\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5827 - val_loss: 1.5724\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5310 - val_loss: 1.4939\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4781 - val_loss: 1.4708\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4682 - val_loss: 1.4651\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4634 - val_loss: 1.4622\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4614 - val_loss: 1.4618\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4589 - val_loss: 1.4574\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4566 - val_loss: 1.4566\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4546 - val_loss: 1.4534\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4539 - val_loss: 1.4520\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4517 - val_loss: 1.4505\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4506 - val_loss: 1.4503\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4491 - val_loss: 1.4486\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4484\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4471 - val_loss: 1.4462\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4463 - val_loss: 1.4454\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4452 - val_loss: 1.4448\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4439\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4431 - val_loss: 1.4444\n",
      "Top-2 accuracy = 0.6\n",
      "6\n",
      "minmaxT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6014 - val_loss: 1.5922\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5732 - val_loss: 1.5513\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5388 - val_loss: 1.5290\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5228 - val_loss: 1.5174\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5126 - val_loss: 1.5077\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5032 - val_loss: 1.4981\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4946 - val_loss: 1.4910\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4885 - val_loss: 1.4853\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4833 - val_loss: 1.4807\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4792 - val_loss: 1.4772\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4764 - val_loss: 1.4750\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4728 - val_loss: 1.4722\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4701 - val_loss: 1.4688\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4677 - val_loss: 1.4668\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4656 - val_loss: 1.4660\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4642 - val_loss: 1.4634\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4620 - val_loss: 1.4619\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4607 - val_loss: 1.4601\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4592 - val_loss: 1.4592\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4579 - val_loss: 1.4574\n",
      "Top-2 accuracy = 0.602\n",
      "7\n",
      "maxabsr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5967 - val_loss: 1.5824\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5607 - val_loss: 1.5407\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5151 - val_loss: 1.4915\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4754 - val_loss: 1.4653\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4588 - val_loss: 1.4530\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4515 - val_loss: 1.4494\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4478 - val_loss: 1.4472\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4454 - val_loss: 1.4441\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4446 - val_loss: 1.4424\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4434 - val_loss: 1.4412\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4406\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4407 - val_loss: 1.4405\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4395 - val_loss: 1.4387\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4371\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4378 - val_loss: 1.4382\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4359\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4362 - val_loss: 1.4356\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4358 - val_loss: 1.4346\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4380\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4351\n",
      "Top-2 accuracy = 0.603\n",
      "8\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1979 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5534 - val_loss: 1.4896\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4687 - val_loss: 1.4558\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4542 - val_loss: 1.4495\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4502 - val_loss: 1.4465\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4463 - val_loss: 1.4436\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4443 - val_loss: 1.4421\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4420 - val_loss: 1.4390\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4405 - val_loss: 1.4375\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4392 - val_loss: 1.4380\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4364\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4342\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4362 - val_loss: 1.4339\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4352 - val_loss: 1.4318\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4325\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4307\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4290\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4411\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4266\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4292 - val_loss: 1.4272\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4273\n",
      "Top-2 accuracy = 0.608\n",
      "9\n",
      "robustY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5676 - val_loss: 1.5254\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4794 - val_loss: 1.4582\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4477 - val_loss: 1.4423\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4388 - val_loss: 1.4377\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4355 - val_loss: 1.4361\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4329 - val_loss: 1.4342\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4330 - val_loss: 1.4314\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4308 - val_loss: 1.4327\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4297\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4307\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4285 - val_loss: 1.4296\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4340\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4297\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4276\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4321\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4247 - val_loss: 1.4258\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4239 - val_loss: 1.4258\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4226 - val_loss: 1.4285\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4272 - val_loss: 1.4304\n",
      "Top-2 accuracy = 0.601\n",
      "10\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1993 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5824 - val_loss: 1.5630\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5279 - val_loss: 1.4983\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4806 - val_loss: 1.4686\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4645 - val_loss: 1.4597\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4578 - val_loss: 1.4549\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4538 - val_loss: 1.4516\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4502 - val_loss: 1.4496\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4476 - val_loss: 1.4458\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4450 - val_loss: 1.4437\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4426 - val_loss: 1.4413\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4407 - val_loss: 1.4409\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4386 - val_loss: 1.4383\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4365 - val_loss: 1.4387\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4363 - val_loss: 1.4347\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4340 - val_loss: 1.4334\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4329 - val_loss: 1.4325\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4319 - val_loss: 1.4313\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4311 - val_loss: 1.4303\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4297 - val_loss: 1.4293\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4295 - val_loss: 1.4286\n",
      "Top-2 accuracy = 0.607\n",
      "11\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6005 - val_loss: 1.5939\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5857 - val_loss: 1.5816\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5647 - val_loss: 1.5522\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5296 - val_loss: 1.5171\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4982 - val_loss: 1.4916\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4778 - val_loss: 1.4750\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4649 - val_loss: 1.4648\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4570 - val_loss: 1.4590\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4521 - val_loss: 1.4545\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4520\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4464 - val_loss: 1.4494\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4474\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4433 - val_loss: 1.4465\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4422 - val_loss: 1.4448\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4412 - val_loss: 1.4443\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4409 - val_loss: 1.4436\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4432\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4395 - val_loss: 1.4425\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4417\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4420\n",
      "Top-2 accuracy = 0.604\n",
      "12\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5683 - val_loss: 1.5269\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4931 - val_loss: 1.4577\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4437\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4337\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4291\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.4307\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4265\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4231\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4228 - val_loss: 1.4236\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4218\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4225\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4206 - val_loss: 1.4217\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4232 - val_loss: 1.4206\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.4247\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4199 - val_loss: 1.4206\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4183 - val_loss: 1.4195\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4180 - val_loss: 1.4194\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4179 - val_loss: 1.4195\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4168 - val_loss: 1.4175\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4165 - val_loss: 1.4181\n",
      "Top-2 accuracy = 0.613\n",
      "13\n",
      "normalizeq|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2010 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5817 - val_loss: 1.5508\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5021 - val_loss: 1.4684\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4612 - val_loss: 1.4550\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4515 - val_loss: 1.4479\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4440 - val_loss: 1.4408\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4380 - val_loss: 1.4352\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4344 - val_loss: 1.4312\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4292\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4278 - val_loss: 1.4256\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4254\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4248 - val_loss: 1.4265\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4236 - val_loss: 1.4228\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4230 - val_loss: 1.4215\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4199\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4196 - val_loss: 1.4194\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4198 - val_loss: 1.4197\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4183 - val_loss: 1.4189\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4178 - val_loss: 1.4179\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4173 - val_loss: 1.4181\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4171 - val_loss: 1.4182\n",
      "Top-2 accuracy = 0.612\n",
      "14\n",
      "robustp|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2017 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5530 - val_loss: 1.5011\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4708 - val_loss: 1.4559\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4494 - val_loss: 1.4478\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4423 - val_loss: 1.4428\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4385 - val_loss: 1.4385\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4344 - val_loss: 1.4350\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4317 - val_loss: 1.4323\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4295 - val_loss: 1.4306\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4277 - val_loss: 1.4286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4271\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4268\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4261\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4221 - val_loss: 1.4247\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4214 - val_loss: 1.4245\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4203 - val_loss: 1.4233\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4195 - val_loss: 1.4229\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4188 - val_loss: 1.4224\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.4227\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4178 - val_loss: 1.4217\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4171 - val_loss: 1.4213\n",
      "Top-2 accuracy = 0.611\n",
      "15\n",
      "minmaxR|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2022 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5955 - val_loss: 1.5821\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5656 - val_loss: 1.5516\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5268 - val_loss: 1.5101\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4964 - val_loss: 1.4892\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4824 - val_loss: 1.4793\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4748 - val_loss: 1.4739\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4703 - val_loss: 1.4702\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4672 - val_loss: 1.4667\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4645 - val_loss: 1.4644\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4621 - val_loss: 1.4622\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4598 - val_loss: 1.4593\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4576 - val_loss: 1.4568\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4559 - val_loss: 1.4549\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4534 - val_loss: 1.4526\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4517 - val_loss: 1.4512\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4503 - val_loss: 1.4499\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4492 - val_loss: 1.4482\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4473 - val_loss: 1.4465\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4461 - val_loss: 1.4455\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4451 - val_loss: 1.4453\n",
      "Top-2 accuracy = 0.605\n",
      "16\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5429 - val_loss: 1.4585\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4418 - val_loss: 1.4366\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4435\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4265\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4260\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4243\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4251 - val_loss: 1.4248\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4224 - val_loss: 1.4245\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4211 - val_loss: 1.4234\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4214 - val_loss: 1.4232\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4198 - val_loss: 1.4236\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4186 - val_loss: 1.4226\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4181 - val_loss: 1.4232\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4169 - val_loss: 1.4227\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4168 - val_loss: 1.4238\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4170 - val_loss: 1.4189\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4160 - val_loss: 1.4215\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4156 - val_loss: 1.4190\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4137 - val_loss: 1.4220\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4134 - val_loss: 1.4160\n",
      "Top-2 accuracy = 0.612\n",
      "17\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5703 - val_loss: 1.5171\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4699 - val_loss: 1.4411\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4350 - val_loss: 1.4453\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4336 - val_loss: 1.4324\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4291 - val_loss: 1.4270\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4273 - val_loss: 1.4391\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4268 - val_loss: 1.4246\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4249 - val_loss: 1.4263\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4234\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4236 - val_loss: 1.4247\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4242\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4231 - val_loss: 1.4238\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4261\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4247\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4225\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4215 - val_loss: 1.4232\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4215\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4205 - val_loss: 1.4215\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4263\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4205 - val_loss: 1.4215\n",
      "Top-2 accuracy = 0.609\n",
      "18\n",
      "minmaxh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5696 - val_loss: 1.5064\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4619 - val_loss: 1.4443\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4361 - val_loss: 1.4358\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4391\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4335\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4321\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4282\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4265\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4263\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4275\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4260\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4233 - val_loss: 1.4254\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4226 - val_loss: 1.4249\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4228 - val_loss: 1.4233\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4259\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4221\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4204 - val_loss: 1.4234\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4212 - val_loss: 1.4224\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4207 - val_loss: 1.4232\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4210 - val_loss: 1.4260\n",
      "Top-2 accuracy = 0.608\n",
      "19\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5578 - val_loss: 1.4959\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4602 - val_loss: 1.4388\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4328 - val_loss: 1.4264\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4290\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4238\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4234 - val_loss: 1.4208\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4214 - val_loss: 1.4234\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4221 - val_loss: 1.4192\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4196 - val_loss: 1.4204\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4189 - val_loss: 1.4189\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4188 - val_loss: 1.4210\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4172 - val_loss: 1.4197\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4172 - val_loss: 1.4180\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4175 - val_loss: 1.4184\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4154 - val_loss: 1.4161\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4160 - val_loss: 1.4199\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4160 - val_loss: 1.4166\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4148 - val_loss: 1.4158\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4142 - val_loss: 1.4151\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4142 - val_loss: 1.4157\n",
      "Top-2 accuracy = 0.614\n",
      "20\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5668 - val_loss: 1.5094\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4673 - val_loss: 1.4487\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4409 - val_loss: 1.4405\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4348\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4330\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4317\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4301\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4279\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4278\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4270\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4242 - val_loss: 1.4265\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4266\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4232 - val_loss: 1.4250\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4228 - val_loss: 1.4250\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4251\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4248\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4235\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4238\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4237\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4227\n",
      "Top-2 accuracy = 0.611\n",
      "21\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5889 - val_loss: 1.5835\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5704 - val_loss: 1.5640\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5511 - val_loss: 1.5453\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5278 - val_loss: 1.5165\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4951 - val_loss: 1.4859\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4745 - val_loss: 1.4692\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4627 - val_loss: 1.4618\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4579 - val_loss: 1.4586\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4555 - val_loss: 1.4560\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4535 - val_loss: 1.4538\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4523 - val_loss: 1.4525\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4505 - val_loss: 1.4510\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4490 - val_loss: 1.4515\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4482 - val_loss: 1.4493\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4472 - val_loss: 1.4488\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4461 - val_loss: 1.4476\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4458 - val_loss: 1.4471\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4447 - val_loss: 1.4459\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4434 - val_loss: 1.4512\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4457 - val_loss: 1.4446\n",
      "Top-2 accuracy = 0.605\n",
      "22\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5713 - val_loss: 1.5358\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5027 - val_loss: 1.4810\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4641 - val_loss: 1.4605\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4495 - val_loss: 1.4491\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4422 - val_loss: 1.4498\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4409 - val_loss: 1.4379\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4343 - val_loss: 1.4564\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4405 - val_loss: 1.4523\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4329 - val_loss: 1.4353\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4314 - val_loss: 1.4303\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.4308\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4293\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4305 - val_loss: 1.4312\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4292 - val_loss: 1.4354\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4314 - val_loss: 1.4318\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4282 - val_loss: 1.4298\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4272 - val_loss: 1.4288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4272 - val_loss: 1.4363\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4320\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4280 - val_loss: 1.4297\n",
      "Top-2 accuracy = 0.604\n",
      "23\n",
      "normalizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5942 - val_loss: 1.5620\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4955 - val_loss: 1.4573\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4310\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4284\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4246 - val_loss: 1.4253\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4229 - val_loss: 1.4250\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4223 - val_loss: 1.4272\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4240\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4218 - val_loss: 1.4246\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4221 - val_loss: 1.4248\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4223 - val_loss: 1.4304\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4228 - val_loss: 1.4240\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4289\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4209 - val_loss: 1.4230\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4207 - val_loss: 1.4248\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4211 - val_loss: 1.4226\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4198 - val_loss: 1.4244\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4197 - val_loss: 1.4240\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4202 - val_loss: 1.4232\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4209 - val_loss: 1.4220\n",
      "Top-2 accuracy = 0.608\n",
      "24\n",
      "standardizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5976 - val_loss: 1.5907\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5852 - val_loss: 1.5877\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5832 - val_loss: 1.5873\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5831 - val_loss: 1.5871\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5820 - val_loss: 1.5836\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5691 - val_loss: 1.5496\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5184 - val_loss: 1.4926\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4805 - val_loss: 1.4684\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4637 - val_loss: 1.4569\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4553 - val_loss: 1.4511\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4506 - val_loss: 1.4483\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4480 - val_loss: 1.4473\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4447\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4439 - val_loss: 1.4441\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4436 - val_loss: 1.4435\n",
      "Top-2 accuracy = 0.601\n",
      "25\n",
      "maxabsc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5736 - val_loss: 1.5329\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4899 - val_loss: 1.4605\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 1.4448\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4345\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4462\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4327\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4307 - val_loss: 1.4304\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.4290\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4288\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4282\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4303\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4273\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4264\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4253 - val_loss: 1.4260\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4268\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.4254\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4250\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4238 - val_loss: 1.4248\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4241 - val_loss: 1.4277\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4245\n",
      "Top-2 accuracy = 0.609\n",
      "26\n",
      "robustW|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2086 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5663 - val_loss: 1.5019\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4791 - val_loss: 1.4651\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4586 - val_loss: 1.4523\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4498 - val_loss: 1.4450\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4426 - val_loss: 1.4394\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4363\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4357\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4317\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4290\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4231 - val_loss: 1.4260\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4206 - val_loss: 1.4254\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4193 - val_loss: 1.4242\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4189 - val_loss: 1.4242\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4166 - val_loss: 1.4243\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4160 - val_loss: 1.4258\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4153 - val_loss: 1.4223\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4138 - val_loss: 1.4224\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4139 - val_loss: 1.4208\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4137 - val_loss: 1.4226\n",
      "Top-2 accuracy = 0.613\n",
      "27\n",
      "minmaxO|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5690 - val_loss: 1.5173\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4757 - val_loss: 1.4565\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4518 - val_loss: 1.4494\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4458\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4428 - val_loss: 1.4445\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4427 - val_loss: 1.4413\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4385 - val_loss: 1.4381\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4363 - val_loss: 1.4371\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4361\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4352 - val_loss: 1.4365\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4348\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4346 - val_loss: 1.4340\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4329\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4315\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4309\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4342\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4300\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4275\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4273\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4268\n",
      "Top-2 accuracy = 0.611\n",
      "28\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2096 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5665 - val_loss: 1.5418\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5074 - val_loss: 1.4825\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4708 - val_loss: 1.4689\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4636 - val_loss: 1.4639\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4595 - val_loss: 1.4576\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4554 - val_loss: 1.4534\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4514 - val_loss: 1.4493\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4543\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4477 - val_loss: 1.4529\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4479 - val_loss: 1.4424\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4417 - val_loss: 1.4406\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4392\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4385 - val_loss: 1.4416\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4381 - val_loss: 1.4363\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4364 - val_loss: 1.4376\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4377\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4360\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4320\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4321\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4310\n",
      "Top-2 accuracy = 0.607\n",
      "29\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5941 - val_loss: 1.5818\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5676 - val_loss: 1.5547\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5420 - val_loss: 1.5308\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5212 - val_loss: 1.5126\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5039 - val_loss: 1.4975\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4907 - val_loss: 1.4857\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4795 - val_loss: 1.4763\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4715 - val_loss: 1.4691\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4652 - val_loss: 1.4640\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4602 - val_loss: 1.4587\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4549 - val_loss: 1.4546\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4513 - val_loss: 1.4523\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4489 - val_loss: 1.4504\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4469 - val_loss: 1.4480\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4457 - val_loss: 1.4466\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4453\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4431 - val_loss: 1.4445\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4419 - val_loss: 1.4424\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4408 - val_loss: 1.4416\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4410\n",
      "Top-2 accuracy = 0.606\n",
      "0\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5416 - val_loss: 1.4843\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4466 - val_loss: 1.4274\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4281\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4233 - val_loss: 1.4255\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4217 - val_loss: 1.4226\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4217 - val_loss: 1.4242\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4202 - val_loss: 1.4249\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4217 - val_loss: 1.4296\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4209 - val_loss: 1.4223\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4203 - val_loss: 1.4223\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4197 - val_loss: 1.4246\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4199 - val_loss: 1.4267\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4201 - val_loss: 1.4230\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4199 - val_loss: 1.4214\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4199 - val_loss: 1.4218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4200 - val_loss: 1.4286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4217 - val_loss: 1.4219\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4181 - val_loss: 1.4214\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4183 - val_loss: 1.4252\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4188 - val_loss: 1.4223\n",
      "Top-2 accuracy = 0.609\n",
      "1\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5876 - val_loss: 1.5788\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5580 - val_loss: 1.5416\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5160 - val_loss: 1.5018\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4782 - val_loss: 1.4688\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4545 - val_loss: 1.4530\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4406\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4346 - val_loss: 1.4391\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4325\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4315\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4319\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4308\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4321\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4296\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4296\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4283\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4282\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4280\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4271\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.4281\n",
      "Top-2 accuracy = 0.605\n",
      "2\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6033 - val_loss: 1.5989\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5940 - val_loss: 1.5929\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5888 - val_loss: 1.5897\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5860 - val_loss: 1.5882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5845 - val_loss: 1.5877\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5838 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "3\n",
      "minmaxe|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5865 - val_loss: 1.5682\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5305 - val_loss: 1.4951\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4719 - val_loss: 1.4581\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4550 - val_loss: 1.4522\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4511 - val_loss: 1.4496\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4487 - val_loss: 1.4512\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4469 - val_loss: 1.4466\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4453 - val_loss: 1.4447\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4439 - val_loss: 1.4437\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4439 - val_loss: 1.4416\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4419 - val_loss: 1.4440\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4419 - val_loss: 1.4402\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4406 - val_loss: 1.4397\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4400 - val_loss: 1.4401\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4397 - val_loss: 1.4384\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4390 - val_loss: 1.4381\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4383 - val_loss: 1.4378\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4386 - val_loss: 1.4404\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4399 - val_loss: 1.4368\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4395\n",
      "Top-2 accuracy = 0.605\n",
      "4\n",
      "standardizej|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5485 - val_loss: 1.5067\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4848 - val_loss: 1.4728\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4576 - val_loss: 1.4519\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4407\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4321 - val_loss: 1.4325\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4278\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4276\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4267\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4302\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4237\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4207 - val_loss: 1.4249\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4202 - val_loss: 1.4233\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4205 - val_loss: 1.4231\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4194 - val_loss: 1.4224\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4187 - val_loss: 1.4245\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4188 - val_loss: 1.4221\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.4218\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.4211\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4175 - val_loss: 1.4232\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4179 - val_loss: 1.4204\n",
      "Top-2 accuracy = 0.607\n",
      "5\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5626 - val_loss: 1.5078\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4778 - val_loss: 1.4564\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4476 - val_loss: 1.4470\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4382 - val_loss: 1.4401\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4358\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4352\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4319\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4298\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4283\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4277\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4247 - val_loss: 1.4272\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4253 - val_loss: 1.4259\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4253\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4232 - val_loss: 1.4250\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4225 - val_loss: 1.4243\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4229 - val_loss: 1.4238\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4246\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4244\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4232\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4232\n",
      "Top-2 accuracy = 0.606\n",
      "6\n",
      "maxabso|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5778 - val_loss: 1.5276\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4859 - val_loss: 1.4617\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4441 - val_loss: 1.4374\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4348 - val_loss: 1.4303\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4323 - val_loss: 1.4285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4309 - val_loss: 1.4295\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4315 - val_loss: 1.4290\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4297\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4304 - val_loss: 1.4278\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4287 - val_loss: 1.4328\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4274\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4278 - val_loss: 1.4266\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4263\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4261\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4265 - val_loss: 1.4253\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4262 - val_loss: 1.4315\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4262\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4260\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4264 - val_loss: 1.4276\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4293\n",
      "Top-2 accuracy = 0.606\n",
      "7\n",
      "normalizeS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2145 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5745 - val_loss: 1.5463\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5090 - val_loss: 1.4810\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4651 - val_loss: 1.4567\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4529 - val_loss: 1.4498\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4474 - val_loss: 1.4461\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4441 - val_loss: 1.4426\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4412 - val_loss: 1.4394\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4381 - val_loss: 1.4383\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4356 - val_loss: 1.4337\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4329 - val_loss: 1.4328\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4310 - val_loss: 1.4295\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4286 - val_loss: 1.4286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4273 - val_loss: 1.4270\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4257 - val_loss: 1.4262\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4253 - val_loss: 1.4245\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4239 - val_loss: 1.4247\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4225 - val_loss: 1.4230\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4220 - val_loss: 1.4232\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4210 - val_loss: 1.4223\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4206 - val_loss: 1.4217\n",
      "Top-2 accuracy = 0.61\n",
      "8\n",
      "standardizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5516 - val_loss: 1.4939\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4623 - val_loss: 1.4447\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4296\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4251\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4253 - val_loss: 1.4253\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4244\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4222 - val_loss: 1.4231\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4225\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4224 - val_loss: 1.4234\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4214 - val_loss: 1.4310\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4230 - val_loss: 1.4231\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4204 - val_loss: 1.4281\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4202 - val_loss: 1.4215\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4207 - val_loss: 1.4208\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.4247\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4198 - val_loss: 1.4206\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4189 - val_loss: 1.4221\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4193 - val_loss: 1.4202\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4193 - val_loss: 1.4246\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4186 - val_loss: 1.4277\n",
      "Top-2 accuracy = 0.603\n",
      "9\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5265 - val_loss: 1.4553\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4275 - val_loss: 1.4441\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4231 - val_loss: 1.4234\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4205 - val_loss: 1.4295\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4220 - val_loss: 1.4212\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4205 - val_loss: 1.4220\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4194 - val_loss: 1.4326\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4195 - val_loss: 1.4203\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4187 - val_loss: 1.4195\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4181 - val_loss: 1.4220\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4179 - val_loss: 1.4265\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4191 - val_loss: 1.4298\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4185 - val_loss: 1.4233\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4178 - val_loss: 1.4184\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4178 - val_loss: 1.4260\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4175 - val_loss: 1.4205\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4194 - val_loss: 1.4214\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4177 - val_loss: 1.4201\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4185 - val_loss: 1.4234\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4182 - val_loss: 1.4187\n",
      "Top-2 accuracy = 0.609\n",
      "10\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5965 - val_loss: 1.5866\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5564 - val_loss: 1.5169\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4832 - val_loss: 1.4614\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4535 - val_loss: 1.4465\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4437 - val_loss: 1.4428\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4380\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4351\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4358 - val_loss: 1.4348\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4353 - val_loss: 1.4346\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4326\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4316\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4340\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4304\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4321\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4286 - val_loss: 1.4319\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4287\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4282\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4272\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4271\n",
      "Top-2 accuracy = 0.605\n",
      "11\n",
      "maxabsC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5875 - val_loss: 1.5876\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5750 - val_loss: 1.5534\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5185 - val_loss: 1.4947\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4761 - val_loss: 1.4697\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4564 - val_loss: 1.4599\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4479 - val_loss: 1.4529\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4411 - val_loss: 1.4416\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4369 - val_loss: 1.4374\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4339 - val_loss: 1.4372\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4336\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4335\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4322\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4311\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4289\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4350\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4272\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.4264\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4236 - val_loss: 1.4333\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4291\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4242 - val_loss: 1.4256\n",
      "Top-2 accuracy = 0.608\n",
      "12\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5580 - val_loss: 1.5108\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4836 - val_loss: 1.4647\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4583 - val_loss: 1.4515\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4493 - val_loss: 1.4447\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4446 - val_loss: 1.4414\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4420 - val_loss: 1.4386\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4362\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4379 - val_loss: 1.4360\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4370 - val_loss: 1.4339\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4334\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4353 - val_loss: 1.4321\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4343 - val_loss: 1.4321\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4322\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4303\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4295\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4296\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4307 - val_loss: 1.4297\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4284\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4282\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4283\n",
      "Top-2 accuracy = 0.606\n",
      "13\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5586 - val_loss: 1.5177\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4820 - val_loss: 1.4608\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4365\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4354\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4303\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4338\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4298\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4306\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4317\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4314\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4266\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4275\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4272\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4277\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4251\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4232\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4232\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4223 - val_loss: 1.4222\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4228 - val_loss: 1.4236\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4221 - val_loss: 1.4228\n",
      "Top-2 accuracy = 0.61\n",
      "14\n",
      "minmaxI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5573 - val_loss: 1.5150\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4874 - val_loss: 1.4712\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4568 - val_loss: 1.4516\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4468 - val_loss: 1.4484\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4433 - val_loss: 1.4451\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4424 - val_loss: 1.4426\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4410 - val_loss: 1.4424\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4400 - val_loss: 1.4410\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4400 - val_loss: 1.4432\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4424\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4390\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4383\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4377 - val_loss: 1.4384\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4380 - val_loss: 1.4376\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4372\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4365 - val_loss: 1.4382\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4359 - val_loss: 1.4373\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4362 - val_loss: 1.4375\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4360\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4349 - val_loss: 1.4353\n",
      "Top-2 accuracy = 0.605\n",
      "15\n",
      "minmaxf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5648 - val_loss: 1.5264\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4978 - val_loss: 1.4787\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4624 - val_loss: 1.4427\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4348 - val_loss: 1.4335\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4339 - val_loss: 1.4307\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4304 - val_loss: 1.4322\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4312 - val_loss: 1.4301\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4300 - val_loss: 1.4303\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4303 - val_loss: 1.4277\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4273 - val_loss: 1.4308\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4273 - val_loss: 1.4282\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4267 - val_loss: 1.4267\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4259 - val_loss: 1.4293\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4264 - val_loss: 1.4307\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4268 - val_loss: 1.4502\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4285 - val_loss: 1.4273\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4260 - val_loss: 1.4246\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4247 - val_loss: 1.4314\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4261 - val_loss: 1.4408\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4313 - val_loss: 1.4251\n",
      "Top-2 accuracy = 0.607\n",
      "16\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 20ms/step - loss: 1.5461 - val_loss: 1.4853\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4831 - val_loss: 1.4747\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4689 - val_loss: 1.4632\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4529 - val_loss: 1.4458\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4416 - val_loss: 1.4444\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4397 - val_loss: 1.4354\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4333 - val_loss: 1.4329\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4320 - val_loss: 1.4333\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4312 - val_loss: 1.4297\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4293 - val_loss: 1.4305\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4282 - val_loss: 1.4313\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4275 - val_loss: 1.4277\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4268 - val_loss: 1.4343\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4267 - val_loss: 1.4291\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4254 - val_loss: 1.4340\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4279 - val_loss: 1.4264\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4246 - val_loss: 1.4300\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4247 - val_loss: 1.4268\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4242 - val_loss: 1.4319\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4238 - val_loss: 1.4299\n",
      "Top-2 accuracy = 0.6\n",
      "17\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5886 - val_loss: 1.5862\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5386 - val_loss: 1.4948\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4685 - val_loss: 1.4545\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4434 - val_loss: 1.4596\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4374 - val_loss: 1.4313\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4294 - val_loss: 1.4278\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4345\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4276 - val_loss: 1.4268\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4247 - val_loss: 1.4318\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4245 - val_loss: 1.4350\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4238 - val_loss: 1.4245\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4237 - val_loss: 1.4328\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4313\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4227 - val_loss: 1.4241\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4211 - val_loss: 1.4242\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4207 - val_loss: 1.4284\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4218 - val_loss: 1.4237\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4196 - val_loss: 1.4245\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4209 - val_loss: 1.4241\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4195 - val_loss: 1.4231\n",
      "Top-2 accuracy = 0.61\n",
      "18\n",
      "standardizef|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2206 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6032 - val_loss: 1.5510\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5071 - val_loss: 1.4736\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4588 - val_loss: 1.4493\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4450 - val_loss: 1.4421\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4394 - val_loss: 1.4389\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4355 - val_loss: 1.4358\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4324 - val_loss: 1.4331\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4298 - val_loss: 1.4308\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4276 - val_loss: 1.4292\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4258 - val_loss: 1.4277\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4242 - val_loss: 1.4261\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4227 - val_loss: 1.4255\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4214 - val_loss: 1.4244\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4204 - val_loss: 1.4236\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4194 - val_loss: 1.4233\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4184 - val_loss: 1.4225\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4176 - val_loss: 1.4212\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4167 - val_loss: 1.4208\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4166 - val_loss: 1.4205\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4150 - val_loss: 1.4202\n",
      "Top-2 accuracy = 0.612\n",
      "19\n",
      "maxabsY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5698 - val_loss: 1.5005\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4554 - val_loss: 1.4292\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4328 - val_loss: 1.4258\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4251 - val_loss: 1.4329\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4246 - val_loss: 1.4361\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4231\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4216 - val_loss: 1.4232\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4215 - val_loss: 1.4239\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4219 - val_loss: 1.4235\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4222 - val_loss: 1.4358\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4219 - val_loss: 1.4219\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4216 - val_loss: 1.4211\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4204 - val_loss: 1.4233\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4204 - val_loss: 1.4217\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4200 - val_loss: 1.4212\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4200 - val_loss: 1.4215\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4191 - val_loss: 1.4229\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4194 - val_loss: 1.4271\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4200 - val_loss: 1.4205\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4189 - val_loss: 1.4212\n",
      "Top-2 accuracy = 0.609\n",
      "20\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6031 - val_loss: 1.5986\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5937 - val_loss: 1.5925\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5884 - val_loss: 1.5895\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5856 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5842 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "21\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5803 - val_loss: 1.5371\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4907 - val_loss: 1.4678\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4523 - val_loss: 1.4442\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4410 - val_loss: 1.4396\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4378 - val_loss: 1.4368\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4346\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4338\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4321\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4403\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4327\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4305\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4311\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4468\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4278\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4333\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4311\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4277\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4288\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4285\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4242 - val_loss: 1.4291\n",
      "Top-2 accuracy = 0.607\n",
      "22\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5752 - val_loss: 1.5464\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5109 - val_loss: 1.4918\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4738 - val_loss: 1.4662\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4578 - val_loss: 1.4544\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4508 - val_loss: 1.4491\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4462\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4468\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4431 - val_loss: 1.4421\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4413 - val_loss: 1.4415\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4399 - val_loss: 1.4401\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4393 - val_loss: 1.4387\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4374\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4368 - val_loss: 1.4365\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4361 - val_loss: 1.4391\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4363 - val_loss: 1.4358\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4343 - val_loss: 1.4345\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4356\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4341\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4331\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4330 - val_loss: 1.4417\n",
      "Top-2 accuracy = 0.602\n",
      "23\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6034 - val_loss: 1.5989\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5941 - val_loss: 1.5927\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5886 - val_loss: 1.5896\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5857 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "24\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5934 - val_loss: 1.5878\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5836 - val_loss: 1.5879\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5879\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5797 - val_loss: 1.5596\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5085 - val_loss: 1.4997\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4962 - val_loss: 1.4989\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4973 - val_loss: 1.4970\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4928 - val_loss: 1.4846\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4749 - val_loss: 1.4745\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4680 - val_loss: 1.4634\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4580 - val_loss: 1.4546\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4508 - val_loss: 1.4499\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4481 - val_loss: 1.4465\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4444 - val_loss: 1.4450\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4412 - val_loss: 1.4476\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4415 - val_loss: 1.4453\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4398 - val_loss: 1.4414\n",
      "Top-2 accuracy = 0.604\n",
      "25\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6028 - val_loss: 1.5977\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5785 - val_loss: 1.5590\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5409 - val_loss: 1.5245\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5123 - val_loss: 1.5009\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4936 - val_loss: 1.4895\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4838 - val_loss: 1.4800\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4800 - val_loss: 1.4750\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4777 - val_loss: 1.4751\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4752 - val_loss: 1.4718\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4737 - val_loss: 1.4723\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4722 - val_loss: 1.4689\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4686 - val_loss: 1.4694\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4659 - val_loss: 1.4656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4640 - val_loss: 1.4627\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4609 - val_loss: 1.4623\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4605 - val_loss: 1.4596\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4585 - val_loss: 1.4614\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4592 - val_loss: 1.4581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4573 - val_loss: 1.4567\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4567 - val_loss: 1.4561\n",
      "Top-2 accuracy = 0.587\n",
      "26\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6032 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5939 - val_loss: 1.5926\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5884 - val_loss: 1.5894\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5855 - val_loss: 1.5880\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5842 - val_loss: 1.5875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "27\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6034 - val_loss: 1.5989\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5941 - val_loss: 1.5929\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5887 - val_loss: 1.5896\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5858 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "28\n",
      "minmaxT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5751 - val_loss: 1.5339\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4860 - val_loss: 1.4639\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4467 - val_loss: 1.4415\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4392\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4309\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4292\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4506\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4307 - val_loss: 1.4370\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4289\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4288\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4294\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4274\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4267\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4297\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4250\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4289\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4240 - val_loss: 1.4308\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4268\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4251\n",
      "Top-2 accuracy = 0.611\n",
      "29\n",
      "maxabsv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5864 - val_loss: 1.5878\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "0\n",
      "minmaxZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6029 - val_loss: 1.5984\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5937 - val_loss: 1.5925\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5883 - val_loss: 1.5894\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5856 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5842 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "1\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5701 - val_loss: 1.5423\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5213 - val_loss: 1.5142\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4995 - val_loss: 1.4968\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4847 - val_loss: 1.4848\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4740 - val_loss: 1.4734\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4649 - val_loss: 1.4651\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4582 - val_loss: 1.4586\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4533 - val_loss: 1.4546\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4505 - val_loss: 1.4557\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4477 - val_loss: 1.4488\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4452 - val_loss: 1.4493\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4444 - val_loss: 1.4455\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4427 - val_loss: 1.4445\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4433 - val_loss: 1.4439\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4436\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4493\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4444 - val_loss: 1.4456\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4411 - val_loss: 1.4446\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4404 - val_loss: 1.4428\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4412 - val_loss: 1.4419\n",
      "Top-2 accuracy = 0.602\n",
      "2\n",
      "minmaxt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5756 - val_loss: 1.5318\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4989 - val_loss: 1.4748\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4634 - val_loss: 1.4527\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4497 - val_loss: 1.4453\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4429 - val_loss: 1.4392\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4383 - val_loss: 1.4362\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4380 - val_loss: 1.4346\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4336 - val_loss: 1.4327\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4327\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4318\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4302\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4306\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4301\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.4297\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4304\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4304\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4286 - val_loss: 1.4301\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4279\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4283\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4276\n",
      "Top-2 accuracy = 0.605\n",
      "3\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5911 - val_loss: 1.5725\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5389 - val_loss: 1.5172\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4972 - val_loss: 1.4883\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4804 - val_loss: 1.4779\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4694 - val_loss: 1.4705\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4635 - val_loss: 1.4699\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4627 - val_loss: 1.4647\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4602 - val_loss: 1.4660\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4595 - val_loss: 1.4631\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4565 - val_loss: 1.4606\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4552 - val_loss: 1.4586\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4544 - val_loss: 1.4581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4549 - val_loss: 1.4598\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4543 - val_loss: 1.4591\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4531 - val_loss: 1.4598\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4525 - val_loss: 1.4565\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4523 - val_loss: 1.4690\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4532 - val_loss: 1.4597\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4521 - val_loss: 1.4565\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4536 - val_loss: 1.4539\n",
      "Top-2 accuracy = 0.592\n",
      "4\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6015 - val_loss: 1.5863\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5666 - val_loss: 1.5429\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5145 - val_loss: 1.4978\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4849 - val_loss: 1.4806\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4718 - val_loss: 1.4714\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4641 - val_loss: 1.4635\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4583 - val_loss: 1.4586\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4553 - val_loss: 1.4558\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4513 - val_loss: 1.4530\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4499 - val_loss: 1.4499\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4471 - val_loss: 1.4499\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4458\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4473\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4442\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4435 - val_loss: 1.4460\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4433 - val_loss: 1.4410\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4408 - val_loss: 1.4415\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4403 - val_loss: 1.4405\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4397 - val_loss: 1.4393\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4397 - val_loss: 1.4386\n",
      "Top-2 accuracy = 0.603\n",
      "5\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5909 - val_loss: 1.5878\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5872\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5780 - val_loss: 1.5721\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5509 - val_loss: 1.5307\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4927 - val_loss: 1.4751\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4574 - val_loss: 1.4493\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4457\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4410\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4410\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.4367\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4363 - val_loss: 1.4370\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4365 - val_loss: 1.4378\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4329\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4332\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4325\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4372\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4344\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4336 - val_loss: 1.4321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4321 - val_loss: 1.4310\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4300\n",
      "Top-2 accuracy = 0.605\n",
      "6\n",
      "robustA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5827 - val_loss: 1.5445\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.4841 - val_loss: 1.4497\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4317\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4288\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4249 - val_loss: 1.4269\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4264\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4245\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4228 - val_loss: 1.4242\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4227 - val_loss: 1.4234\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4229\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4205 - val_loss: 1.4232\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4209 - val_loss: 1.4230\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4201 - val_loss: 1.4230\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4200 - val_loss: 1.4223\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4191 - val_loss: 1.4217\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4190 - val_loss: 1.4226\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4188 - val_loss: 1.4216\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4181 - val_loss: 1.4234\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4195 - val_loss: 1.4198\n",
      "Top-2 accuracy = 0.608\n",
      "7\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5686 - val_loss: 1.5360\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5056 - val_loss: 1.4805\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4631 - val_loss: 1.4502\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4463 - val_loss: 1.4397\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4407 - val_loss: 1.4368\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4377 - val_loss: 1.4349\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4334\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4346 - val_loss: 1.4330\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4365\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4320\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4307 - val_loss: 1.4310\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4298\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4296\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4287 - val_loss: 1.4296\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4306\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4278\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4276\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4273\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4286\n",
      "Top-2 accuracy = 0.61\n",
      "8\n",
      "robustR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6001 - val_loss: 1.5920\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5859 - val_loss: 1.5880\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "9\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2319 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9157 - val_loss: 1.7340\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.6624 - val_loss: 1.6050\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5794 - val_loss: 1.5564\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5425 - val_loss: 1.5306\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5220 - val_loss: 1.5169\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5107 - val_loss: 1.5088\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5040 - val_loss: 1.5036\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4997 - val_loss: 1.4996\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4962 - val_loss: 1.4963\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4934 - val_loss: 1.4932\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4905 - val_loss: 1.4899\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4878 - val_loss: 1.4867\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4850 - val_loss: 1.4838\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4826 - val_loss: 1.4813\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4802 - val_loss: 1.4789\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4779 - val_loss: 1.4764\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4759 - val_loss: 1.4743\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4738 - val_loss: 1.4725\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4719 - val_loss: 1.4705\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4701 - val_loss: 1.4689\n",
      "Top-2 accuracy = 0.594\n",
      "10\n",
      "robustd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5744 - val_loss: 1.5361\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4942 - val_loss: 1.4548\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4442 - val_loss: 1.4361\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4330 - val_loss: 1.4360\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4298 - val_loss: 1.4317\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4272 - val_loss: 1.4392\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4276 - val_loss: 1.4324\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4306\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4245 - val_loss: 1.4252\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4231 - val_loss: 1.4279\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4231 - val_loss: 1.4313\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4227 - val_loss: 1.4296\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4215 - val_loss: 1.4321\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4209 - val_loss: 1.4255\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4205 - val_loss: 1.4222\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4210 - val_loss: 1.4251\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4221 - val_loss: 1.4238\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4198 - val_loss: 1.4241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4213 - val_loss: 1.4253\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4197 - val_loss: 1.4271\n",
      "Top-2 accuracy = 0.604\n",
      "11\n",
      "standardizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5663 - val_loss: 1.5261\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5051 - val_loss: 1.4873\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4687 - val_loss: 1.4528\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4491 - val_loss: 1.4422\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4404\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4322\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4333 - val_loss: 1.4340\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4355 - val_loss: 1.4298\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4308\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4288\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4291\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4295\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4277\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4300\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4264\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4277\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4264\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4266\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4253 - val_loss: 1.4268\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4247 - val_loss: 1.4297\n",
      "Top-2 accuracy = 0.607\n",
      "12\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5972 - val_loss: 1.5826\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5655 - val_loss: 1.5490\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5347 - val_loss: 1.5214\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5074 - val_loss: 1.4927\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4781 - val_loss: 1.4669\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4592 - val_loss: 1.4527\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4481 - val_loss: 1.4441\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4424 - val_loss: 1.4405\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4392 - val_loss: 1.4381\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4372 - val_loss: 1.4371\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4355 - val_loss: 1.4400\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4347 - val_loss: 1.4350\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4331 - val_loss: 1.4342\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4341\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4340\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4311 - val_loss: 1.4323\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4306 - val_loss: 1.4325\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.4336\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4292 - val_loss: 1.4320\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4287 - val_loss: 1.4320\n",
      "Top-2 accuracy = 0.608\n",
      "13\n",
      "normalizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5541 - val_loss: 1.4924\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4591 - val_loss: 1.4384\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4317\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4307 - val_loss: 1.4296\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4308\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4264 - val_loss: 1.4284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4247 - val_loss: 1.4268\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4281\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4279\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4262\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4223 - val_loss: 1.4276\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4231 - val_loss: 1.4252\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4255\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4211 - val_loss: 1.4249\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4214 - val_loss: 1.4319\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4245\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4199 - val_loss: 1.4287\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4210 - val_loss: 1.4243\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4203 - val_loss: 1.4277\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4201 - val_loss: 1.4289\n",
      "Top-2 accuracy = 0.609\n",
      "14\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5815 - val_loss: 1.5613\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5012 - val_loss: 1.4744\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4514 - val_loss: 1.4551\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4395 - val_loss: 1.4377\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4364 - val_loss: 1.4601\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4363 - val_loss: 1.4424\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4333 - val_loss: 1.4439\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4303 - val_loss: 1.4463\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4313 - val_loss: 1.4294\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4266 - val_loss: 1.4286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4277 - val_loss: 1.4269\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4268 - val_loss: 1.4261\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4264 - val_loss: 1.4255\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4277\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4244\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4257\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4261 - val_loss: 1.4270\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4251 - val_loss: 1.4241\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4259\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4237 - val_loss: 1.4246\n",
      "Top-2 accuracy = 0.609\n",
      "15\n",
      "maxabsB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5538 - val_loss: 1.5169\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4838 - val_loss: 1.4636\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4474 - val_loss: 1.4391\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4375\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4289\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4289\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4294\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4292\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4283\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4268\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4277\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4291\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4253 - val_loss: 1.4281\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4264\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4261\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4283\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4341\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4262\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4241 - val_loss: 1.4268\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4241 - val_loss: 1.4260\n",
      "Top-2 accuracy = 0.607\n",
      "16\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5908 - val_loss: 1.5695\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5014 - val_loss: 1.4466\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4373 - val_loss: 1.4351\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4309 - val_loss: 1.4272\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4290 - val_loss: 1.4299\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4276\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4276 - val_loss: 1.4258\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4264\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4327\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4246\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4254\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4241 - val_loss: 1.4256\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4247 - val_loss: 1.4241\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4241 - val_loss: 1.4246\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4234 - val_loss: 1.4288\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4230 - val_loss: 1.4267\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4287\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4231 - val_loss: 1.4252\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4240 - val_loss: 1.4247\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4225 - val_loss: 1.4255\n",
      "Top-2 accuracy = 0.609\n",
      "17\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5480 - val_loss: 1.4951\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4671 - val_loss: 1.4862\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4441 - val_loss: 1.4361\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4348 - val_loss: 1.4407\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4350 - val_loss: 1.4305\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4293 - val_loss: 1.4269\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4296 - val_loss: 1.4267\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4265 - val_loss: 1.4266\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4272 - val_loss: 1.4324\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4283 - val_loss: 1.4277\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4259 - val_loss: 1.4253\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4237 - val_loss: 1.4312\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4257 - val_loss: 1.4238\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4244 - val_loss: 1.4312\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4260 - val_loss: 1.4704\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4405 - val_loss: 1.4266\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4243 - val_loss: 1.4360\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4255 - val_loss: 1.4231\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4253 - val_loss: 1.4354\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4259 - val_loss: 1.4236\n",
      "Top-2 accuracy = 0.607\n",
      "18\n",
      "standardized|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2366 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6033 - val_loss: 1.5986\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5921 - val_loss: 1.5836\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5581 - val_loss: 1.5330\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5161 - val_loss: 1.5030\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4940 - val_loss: 1.4891\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4816 - val_loss: 1.4795\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4735 - val_loss: 1.4726\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4675 - val_loss: 1.4670\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4626 - val_loss: 1.4625\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4589 - val_loss: 1.4577\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4553 - val_loss: 1.4548\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4526 - val_loss: 1.4521\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4507 - val_loss: 1.4502\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4486 - val_loss: 1.4482\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4472 - val_loss: 1.4466\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4457 - val_loss: 1.4451\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4445 - val_loss: 1.4434\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4430 - val_loss: 1.4421\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4415 - val_loss: 1.4404\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4400 - val_loss: 1.4388\n",
      "Top-2 accuracy = 0.603\n",
      "19\n",
      "normalizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5887 - val_loss: 1.5869\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5786 - val_loss: 1.5671\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5149 - val_loss: 1.4675\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4590 - val_loss: 1.4544\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4524 - val_loss: 1.4504\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4483 - val_loss: 1.4462\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4462 - val_loss: 1.4439\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4428\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4419\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4413 - val_loss: 1.4393\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4399 - val_loss: 1.4375\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4385 - val_loss: 1.4382\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4354\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4359 - val_loss: 1.4345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4338\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4338\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4345 - val_loss: 1.4319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4330 - val_loss: 1.4318\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4307\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4332\n",
      "Top-2 accuracy = 0.604\n",
      "20\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_2378 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5946 - val_loss: 1.5911\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5837 - val_loss: 1.5849\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5769 - val_loss: 1.5762\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5637 - val_loss: 1.5514\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5281 - val_loss: 1.5159\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5019 - val_loss: 1.4987\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4882 - val_loss: 1.4866\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4752 - val_loss: 1.4727\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4624 - val_loss: 1.4625\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4541 - val_loss: 1.4563\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4495 - val_loss: 1.4516\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4463 - val_loss: 1.4489\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4439 - val_loss: 1.4466\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4417 - val_loss: 1.4449\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4404 - val_loss: 1.4433\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4391 - val_loss: 1.4418\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4374 - val_loss: 1.4403\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4364 - val_loss: 1.4396\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4353 - val_loss: 1.4389\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4345 - val_loss: 1.4375\n",
      "Top-2 accuracy = 0.607\n",
      "21\n",
      "standardizej|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5601 - val_loss: 1.4670\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4385 - val_loss: 1.4291\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4254\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4233 - val_loss: 1.4244\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4233 - val_loss: 1.4248\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4347\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4219 - val_loss: 1.4250\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4227\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4200 - val_loss: 1.4230\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4196 - val_loss: 1.4243\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4194 - val_loss: 1.4235\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4190 - val_loss: 1.4233\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4193 - val_loss: 1.4211\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4193 - val_loss: 1.4240\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4198 - val_loss: 1.4231\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4183 - val_loss: 1.4211\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4196 - val_loss: 1.4210\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4180 - val_loss: 1.4217\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4179 - val_loss: 1.4206\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4173 - val_loss: 1.4218\n",
      "Top-2 accuracy = 0.606\n",
      "22\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6026 - val_loss: 1.5963\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5872 - val_loss: 1.5807\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5681 - val_loss: 1.5591\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5466 - val_loss: 1.5357\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5267 - val_loss: 1.5196\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5137 - val_loss: 1.5086\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5040 - val_loss: 1.5006\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4966 - val_loss: 1.4934\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4904 - val_loss: 1.4873\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4853 - val_loss: 1.4829\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4801 - val_loss: 1.4792\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4759 - val_loss: 1.4750\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4724 - val_loss: 1.4722\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4714 - val_loss: 1.4712\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4690 - val_loss: 1.4671\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4658 - val_loss: 1.4647\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4642 - val_loss: 1.4636\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4628 - val_loss: 1.4635\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4616 - val_loss: 1.4603\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4608 - val_loss: 1.4591\n",
      "Top-2 accuracy = 0.6\n",
      "23\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6031 - val_loss: 1.5986\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5939 - val_loss: 1.5926\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5885 - val_loss: 1.5895\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5857 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "24\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5988 - val_loss: 1.5907\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5842 - val_loss: 1.5868\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5783 - val_loss: 1.5696\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5304 - val_loss: 1.5031\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4905 - val_loss: 1.4839\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4760 - val_loss: 1.4743\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4684 - val_loss: 1.4691\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4643 - val_loss: 1.4628\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4599 - val_loss: 1.4613\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4575 - val_loss: 1.4568\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4541 - val_loss: 1.4546\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4513 - val_loss: 1.4519\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4494 - val_loss: 1.4486\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4458 - val_loss: 1.4452\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4439 - val_loss: 1.4431\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4421 - val_loss: 1.4419\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4409 - val_loss: 1.4408\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4396\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4389 - val_loss: 1.4409\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4397\n",
      "Top-2 accuracy = 0.6\n",
      "25\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5705 - val_loss: 1.4997\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4603 - val_loss: 1.4452\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4420 - val_loss: 1.4387\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4335\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4335 - val_loss: 1.4320\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4313\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4303\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4296\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4281\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4290\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4297\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4288\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4263\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4271\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4280\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4258\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4257\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4261\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4242\n",
      "Top-2 accuracy = 0.607\n",
      "26\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6030 - val_loss: 1.5985\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5937 - val_loss: 1.5925\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5883 - val_loss: 1.5894\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5856 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "27\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5649 - val_loss: 1.5267\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4951 - val_loss: 1.4734\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4563 - val_loss: 1.4500\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4416 - val_loss: 1.4378\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4333 - val_loss: 1.4295\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4303 - val_loss: 1.4400\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4282 - val_loss: 1.4355\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4266 - val_loss: 1.4429\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4254 - val_loss: 1.4230\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4229 - val_loss: 1.4261\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4233 - val_loss: 1.4281\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4217 - val_loss: 1.4217\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4202 - val_loss: 1.4252\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4195 - val_loss: 1.4233\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4227 - val_loss: 1.4219\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4200 - val_loss: 1.4213\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4194 - val_loss: 1.4237\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4202 - val_loss: 1.4237\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4205 - val_loss: 1.4264\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4206 - val_loss: 1.4242\n",
      "Top-2 accuracy = 0.603\n",
      "28\n",
      "normalizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5620 - val_loss: 1.5024\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4626 - val_loss: 1.4390\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4317 - val_loss: 1.4279\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4265 - val_loss: 1.4264\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.4251\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4234 - val_loss: 1.4265\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4232\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4261\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4230\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4209 - val_loss: 1.4241\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4195 - val_loss: 1.4232\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4193 - val_loss: 1.4220\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4194 - val_loss: 1.4225\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4193 - val_loss: 1.4341\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4201 - val_loss: 1.4219\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4182 - val_loss: 1.4226\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4188 - val_loss: 1.4243\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4194 - val_loss: 1.4249\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4191 - val_loss: 1.4230\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4175 - val_loss: 1.4243\n",
      "Top-2 accuracy = 0.606\n",
      "29\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6032 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5939 - val_loss: 1.5926\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5884 - val_loss: 1.5894\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5857 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "0\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5615 - val_loss: 1.5234\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4839 - val_loss: 1.4590\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4488 - val_loss: 1.4441\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4382\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4361 - val_loss: 1.4362\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4333 - val_loss: 1.4337\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4327\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4301\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4297\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4283\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4268\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4231 - val_loss: 1.4258\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4256\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4210 - val_loss: 1.4247\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4242\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4208 - val_loss: 1.4238\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.4235\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4190 - val_loss: 1.4232\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4212 - val_loss: 1.4240\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.4227\n",
      "Top-2 accuracy = 0.614\n",
      "1\n",
      "robusty|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6022 - val_loss: 1.5971\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5917 - val_loss: 1.5906\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5865 - val_loss: 1.5882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5845 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "2\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5689 - val_loss: 1.5170\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4760 - val_loss: 1.4590\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4495 - val_loss: 1.4443\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4449 - val_loss: 1.4459\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4424 - val_loss: 1.4387\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4401 - val_loss: 1.4382\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4393 - val_loss: 1.4389\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4396 - val_loss: 1.4364\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4359\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4364\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4382 - val_loss: 1.4350\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4361 - val_loss: 1.4426\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4377 - val_loss: 1.4348\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4345\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4359 - val_loss: 1.4336\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4358 - val_loss: 1.4339\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 1.4331\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4361\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4324\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4329\n",
      "Top-2 accuracy = 0.606\n",
      "3\n",
      "minmaxO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6033 - val_loss: 1.5988\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5939 - val_loss: 1.5927\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5886 - val_loss: 1.5895\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5857 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5842 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "4\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5732 - val_loss: 1.5389\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5067 - val_loss: 1.4823\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4667 - val_loss: 1.4577\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4467 - val_loss: 1.4428\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4378 - val_loss: 1.4370\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4327\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4312\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4306\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4313\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4292\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4302\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4287\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4297\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4282\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4264 - val_loss: 1.4283\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4271\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4266\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4253 - val_loss: 1.4264\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4261\n",
      "Top-2 accuracy = 0.607\n",
      "5\n",
      "normalizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5889 - val_loss: 1.5743\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5513 - val_loss: 1.5322\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5108 - val_loss: 1.4898\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4725 - val_loss: 1.4582\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4392\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4368 - val_loss: 1.4336\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4308\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4335\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4265\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4283\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4263\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4263\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4264 - val_loss: 1.4341\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4268\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4278\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4250\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4247 - val_loss: 1.4294\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4245\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4248\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4245\n",
      "Top-2 accuracy = 0.611\n",
      "6\n",
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5976 - val_loss: 1.5911\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5850 - val_loss: 1.5881\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5878\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "7\n",
      "robustX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.6020 - val_loss: 1.5959\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5883 - val_loss: 1.5879\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "8\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5702 - val_loss: 1.4918\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4635 - val_loss: 1.4453\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4329 - val_loss: 1.4279\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4291 - val_loss: 1.4349\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4264 - val_loss: 1.4358\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4266\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4232 - val_loss: 1.4239\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4221 - val_loss: 1.4235\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4237 - val_loss: 1.4238\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4211 - val_loss: 1.4280\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4228 - val_loss: 1.4231\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4203 - val_loss: 1.4222\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4205 - val_loss: 1.4212\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4206 - val_loss: 1.4210\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4192 - val_loss: 1.4226\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4214 - val_loss: 1.4203\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4186 - val_loss: 1.4213\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4196 - val_loss: 1.4232\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4199 - val_loss: 1.4256\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4198 - val_loss: 1.4203\n",
      "Top-2 accuracy = 0.612\n",
      "9\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5441 - val_loss: 1.4616\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4361 - val_loss: 1.4333\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4262 - val_loss: 1.4243\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4225 - val_loss: 1.4221\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4235 - val_loss: 1.4681\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4239 - val_loss: 1.4262\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4209 - val_loss: 1.4218\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4224 - val_loss: 1.4205\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4199 - val_loss: 1.4201\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4189 - val_loss: 1.4197\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4183 - val_loss: 1.4201\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4197 - val_loss: 1.4228\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4195 - val_loss: 1.4204\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4183 - val_loss: 1.4208\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4191 - val_loss: 1.4223\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4188 - val_loss: 1.4183\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4176 - val_loss: 1.4186\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4181 - val_loss: 1.4348\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4190 - val_loss: 1.4362\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4182 - val_loss: 1.4198\n",
      "Top-2 accuracy = 0.608\n",
      "10\n",
      "robustF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5795 - val_loss: 1.5532\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5313 - val_loss: 1.5092\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4891 - val_loss: 1.4738\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4633 - val_loss: 1.4563\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4502 - val_loss: 1.4477\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4380\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4353\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4333\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4320 - val_loss: 1.4328\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4338\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4302\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4313\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4297\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4305\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4301\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4297\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4293\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4290\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4284\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4290\n",
      "Top-2 accuracy = 0.606\n",
      "11\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5468 - val_loss: 1.4731\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4433 - val_loss: 1.4358\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4314 - val_loss: 1.4317\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4280\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4266\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4255\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4244\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4249\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4224 - val_loss: 1.4242\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4211 - val_loss: 1.4241\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4217\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4198 - val_loss: 1.4219\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 1.4210\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.4215\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4176 - val_loss: 1.4204\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4161 - val_loss: 1.4181\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4164 - val_loss: 1.4201\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4152 - val_loss: 1.4200\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4149 - val_loss: 1.4181\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4141 - val_loss: 1.4164\n",
      "Top-2 accuracy = 0.613\n",
      "12\n",
      "normalizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5884 - val_loss: 1.5502\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4993 - val_loss: 1.4571\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4334 - val_loss: 1.4270\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4230 - val_loss: 1.4234\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4205 - val_loss: 1.4239\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4202 - val_loss: 1.4223\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4185 - val_loss: 1.4233\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4201 - val_loss: 1.4226\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4181 - val_loss: 1.4246\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4175 - val_loss: 1.4224\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4171 - val_loss: 1.4242\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4168 - val_loss: 1.4231\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4176 - val_loss: 1.4247\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4173 - val_loss: 1.4238\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4164 - val_loss: 1.4207\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4162 - val_loss: 1.4254\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4169 - val_loss: 1.4218\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4158 - val_loss: 1.4217\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4168 - val_loss: 1.4256\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4162 - val_loss: 1.4211\n",
      "Top-2 accuracy = 0.605\n",
      "13\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5938 - val_loss: 1.5879\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5642 - val_loss: 1.5262\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5036 - val_loss: 1.4981\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5032 - val_loss: 1.5325\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5188 - val_loss: 1.5264\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5266 - val_loss: 1.5380\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5231 - val_loss: 1.5246\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5157 - val_loss: 1.5039\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5062 - val_loss: 1.5031\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4997 - val_loss: 1.5007\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4930 - val_loss: 1.4896\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4872 - val_loss: 1.4896\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4838 - val_loss: 1.4834\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4815 - val_loss: 1.4721\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4730 - val_loss: 1.4674\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4626 - val_loss: 1.4607\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4526 - val_loss: 1.4451\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4443 - val_loss: 1.4453\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4364 - val_loss: 1.4390\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4376 - val_loss: 1.4546\n",
      "Top-2 accuracy = 0.59\n",
      "14\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5824 - val_loss: 1.5325\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4844 - val_loss: 1.4579\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4419 - val_loss: 1.4375\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4334 - val_loss: 1.4354\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4312 - val_loss: 1.4337\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4301 - val_loss: 1.4319\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4293 - val_loss: 1.4352\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4290 - val_loss: 1.4307\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4291 - val_loss: 1.4386\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4279 - val_loss: 1.4287\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4260 - val_loss: 1.4284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4274 - val_loss: 1.4309\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4260 - val_loss: 1.4377\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4293 - val_loss: 1.4279\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4282\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4274 - val_loss: 1.4408\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4288 - val_loss: 1.4289\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4245 - val_loss: 1.4274\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4247 - val_loss: 1.4322\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4279 - val_loss: 1.4267\n",
      "Top-2 accuracy = 0.609\n",
      "15\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6030 - val_loss: 1.5985\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5938 - val_loss: 1.5926\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5886 - val_loss: 1.5896\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5858 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5844 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "16\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5786 - val_loss: 1.5439\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5222 - val_loss: 1.4939\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4650 - val_loss: 1.4522\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4422 - val_loss: 1.4492\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4347 - val_loss: 1.4388\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4305\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4341\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4343\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4301\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4279\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4276 - val_loss: 1.4272\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4281\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4253 - val_loss: 1.4287\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4239 - val_loss: 1.4328\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4274\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.4267\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4241 - val_loss: 1.4328\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4258\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.4278\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4302\n",
      "Top-2 accuracy = 0.607\n",
      "17\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5847 - val_loss: 1.5528\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5216 - val_loss: 1.4979\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4872 - val_loss: 1.4798\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4755 - val_loss: 1.4714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4698 - val_loss: 1.4676\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4663 - val_loss: 1.4655\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4621 - val_loss: 1.4610\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4605 - val_loss: 1.4580\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4564 - val_loss: 1.4553\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4545 - val_loss: 1.4545\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4531 - val_loss: 1.4522\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4518 - val_loss: 1.4521\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4503 - val_loss: 1.4499\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4500 - val_loss: 1.4494\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4494 - val_loss: 1.4489\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4484 - val_loss: 1.4488\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4480 - val_loss: 1.4482\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4471 - val_loss: 1.4472\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4466 - val_loss: 1.4468\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4460 - val_loss: 1.4465\n",
      "Top-2 accuracy = 0.603\n",
      "18\n",
      "normalizeG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5956 - val_loss: 1.5779\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5564 - val_loss: 1.5346\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5212 - val_loss: 1.5044\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4964 - val_loss: 1.4840\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4780 - val_loss: 1.4715\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4708 - val_loss: 1.4676\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4659 - val_loss: 1.4643\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4630 - val_loss: 1.4636\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4620 - val_loss: 1.4682\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4602 - val_loss: 1.4595\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4577 - val_loss: 1.4574\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4567 - val_loss: 1.4557\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4548 - val_loss: 1.4540\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4530 - val_loss: 1.4508\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4509 - val_loss: 1.4509\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4492 - val_loss: 1.4570\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4511 - val_loss: 1.4518\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4481 - val_loss: 1.4488\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4477 - val_loss: 1.4464\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4472 - val_loss: 1.4458\n",
      "Top-2 accuracy = 0.604\n",
      "19\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.6020 - val_loss: 1.5961\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5865 - val_loss: 1.5783\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5596 - val_loss: 1.5479\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5311 - val_loss: 1.5222\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5093 - val_loss: 1.5036\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4930 - val_loss: 1.4880\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4813 - val_loss: 1.4784\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4749 - val_loss: 1.4741\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4720 - val_loss: 1.4713\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4696 - val_loss: 1.4699\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4681 - val_loss: 1.4689\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4672 - val_loss: 1.4681\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4660 - val_loss: 1.4668\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4651 - val_loss: 1.4688\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4655 - val_loss: 1.4655\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4635 - val_loss: 1.4649\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4634 - val_loss: 1.4642\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4622 - val_loss: 1.4650\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4616 - val_loss: 1.4628\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4615 - val_loss: 1.4634\n",
      "Top-2 accuracy = 0.591\n",
      "20\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6031 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5938 - val_loss: 1.5925\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5884 - val_loss: 1.5894\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5856 - val_loss: 1.5880\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5842 - val_loss: 1.5875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5836 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "21\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5931 - val_loss: 1.5886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5876\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Top-2 accuracy = 0.492\n",
      "22\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5676 - val_loss: 1.5200\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4809 - val_loss: 1.4529\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4352\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4316\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4293\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4274 - val_loss: 1.4315\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4274\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4270\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4262\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4273\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4259\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4254\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4248\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4230 - val_loss: 1.4247\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4228 - val_loss: 1.4249\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4221 - val_loss: 1.4248\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4221 - val_loss: 1.4255\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4226 - val_loss: 1.4247\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4223 - val_loss: 1.4268\n",
      "Top-2 accuracy = 0.608\n",
      "23\n",
      "normalizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5559 - val_loss: 1.4864\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4504 - val_loss: 1.4378\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4304 - val_loss: 1.4279\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4278 - val_loss: 1.4325\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4236 - val_loss: 1.4256\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4216 - val_loss: 1.4283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4237 - val_loss: 1.4369\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4233 - val_loss: 1.4234\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4210 - val_loss: 1.4227\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4211 - val_loss: 1.4222\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4204 - val_loss: 1.4276\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4200 - val_loss: 1.4222\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4208 - val_loss: 1.4287\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4200 - val_loss: 1.4214\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4203 - val_loss: 1.4232\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4200 - val_loss: 1.4209\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4184 - val_loss: 1.4245\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4210 - val_loss: 1.4224\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4192 - val_loss: 1.4231\n",
      "Top-2 accuracy = 0.609\n",
      "24\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.6012 - val_loss: 1.5919\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5857 - val_loss: 1.5885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5838 - val_loss: 1.5880\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5880\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5880\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5880\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5879\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "25\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5536 - val_loss: 1.4796\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4665 - val_loss: 1.4678\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4620 - val_loss: 1.4718\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4579 - val_loss: 1.4606\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4504 - val_loss: 1.4579\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4479 - val_loss: 1.4511\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4376 - val_loss: 1.4422\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4361 - val_loss: 1.4412\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4363 - val_loss: 1.4397\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4331 - val_loss: 1.4325\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4313 - val_loss: 1.4313\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4321 - val_loss: 1.4316\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4307 - val_loss: 1.4348\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4306 - val_loss: 1.4427\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4293 - val_loss: 1.4306\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4306 - val_loss: 1.4450\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4323 - val_loss: 1.4304\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4278 - val_loss: 1.4299\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4282 - val_loss: 1.4263\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4303 - val_loss: 1.4333\n",
      "Top-2 accuracy = 0.602\n",
      "26\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5887 - val_loss: 1.5786\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5568 - val_loss: 1.5331\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5019 - val_loss: 1.4857\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4738 - val_loss: 1.4673\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4600 - val_loss: 1.4572\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4513 - val_loss: 1.4487\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 2s 20ms/step - loss: 1.4454 - val_loss: 1.4440\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4417 - val_loss: 1.4412\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4397 - val_loss: 1.4390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4380 - val_loss: 1.4379\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4370 - val_loss: 1.4369\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4364 - val_loss: 1.4368\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4353\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4346\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4338\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4337 - val_loss: 1.4333\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4329\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4325\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4339\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4314 - val_loss: 1.4317\n",
      "Top-2 accuracy = 0.605\n",
      "27\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5927 - val_loss: 1.5905\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5854 - val_loss: 1.5884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5839 - val_loss: 1.5877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5879\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5874\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5831 - val_loss: 1.5872\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5817 - val_loss: 1.5842\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5769 - val_loss: 1.5756\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5616 - val_loss: 1.5517\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5347 - val_loss: 1.5323\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5098 - val_loss: 1.4960\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4847 - val_loss: 1.4785\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4717 - val_loss: 1.4744\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4634 - val_loss: 1.4780\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4615 - val_loss: 1.4611\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4568 - val_loss: 1.4584\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4531 - val_loss: 1.4553\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4511 - val_loss: 1.4528\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4497 - val_loss: 1.4548\n",
      "Top-2 accuracy = 0.599\n",
      "28\n",
      "normalizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5955 - val_loss: 1.5892\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5845 - val_loss: 1.5877\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5879\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "29\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5923 - val_loss: 1.5840\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5395 - val_loss: 1.4986\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4589 - val_loss: 1.4396\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4382 - val_loss: 1.4340\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4350 - val_loss: 1.4321\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4326 - val_loss: 1.4305\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4333 - val_loss: 1.4296\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4296 - val_loss: 1.4304\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4298 - val_loss: 1.4352\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4311 - val_loss: 1.4363\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4303 - val_loss: 1.4326\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4327\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4312 - val_loss: 1.4276\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4282 - val_loss: 1.4309\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4284 - val_loss: 1.4294\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4282\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4268 - val_loss: 1.4270\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4262 - val_loss: 1.4252\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4264 - val_loss: 1.4263\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4297\n",
      "Top-2 accuracy = 0.603\n",
      "0\n",
      "robustN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5447 - val_loss: 1.4810\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4554 - val_loss: 1.4369\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4266 - val_loss: 1.4248\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4245 - val_loss: 1.4238\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4210 - val_loss: 1.4218\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4199 - val_loss: 1.4216\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4196 - val_loss: 1.4201\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4190 - val_loss: 1.4215\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4193 - val_loss: 1.4244\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4186 - val_loss: 1.4207\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4193 - val_loss: 1.4274\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4177 - val_loss: 1.4211\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4179 - val_loss: 1.4225\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4190 - val_loss: 1.4204\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4169 - val_loss: 1.4226\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4173 - val_loss: 1.4234\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4177 - val_loss: 1.4264\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4169 - val_loss: 1.4194\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4159 - val_loss: 1.4208\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4167 - val_loss: 1.4204\n",
      "Top-2 accuracy = 0.61\n",
      "1\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6004 - val_loss: 1.5945\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5893 - val_loss: 1.5890\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5847 - val_loss: 1.5875\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5836 - val_loss: 1.5875\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "2\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5971 - val_loss: 1.5901\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5847 - val_loss: 1.5879\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5878\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "3\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5810 - val_loss: 1.5464\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5095 - val_loss: 1.4738\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4538 - val_loss: 1.4422\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4366 - val_loss: 1.4359\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4356 - val_loss: 1.4408\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4310 - val_loss: 1.4285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4299 - val_loss: 1.4325\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4293 - val_loss: 1.4578\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4359 - val_loss: 1.4299\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4274 - val_loss: 1.4409\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4282 - val_loss: 1.4281\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4277 - val_loss: 1.4284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4261 - val_loss: 1.4319\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4275 - val_loss: 1.4325\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4271 - val_loss: 1.4309\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4251 - val_loss: 1.4270\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4243 - val_loss: 1.4314\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4275 - val_loss: 1.4253\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4234 - val_loss: 1.4257\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4247 - val_loss: 1.4372\n",
      "Top-2 accuracy = 0.599\n",
      "4\n",
      "maxabsg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.6006 - val_loss: 1.5937\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5864 - val_loss: 1.5879\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "5\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5991 - val_loss: 1.5903\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5843 - val_loss: 1.5877\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5882\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5880\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5880\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5878\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "6\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5916 - val_loss: 1.5723\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5456 - val_loss: 1.5246\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5196 - val_loss: 1.5432\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5105 - val_loss: 1.5102\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5049 - val_loss: 1.5003\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5005 - val_loss: 1.5049\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5043 - val_loss: 1.5038\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5117 - val_loss: 1.5055\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5047 - val_loss: 1.4991\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5012 - val_loss: 1.4889\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4916 - val_loss: 1.4933\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4933 - val_loss: 1.4936\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5525 - val_loss: 1.5882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5837 - val_loss: 1.5879\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5837 - val_loss: 1.5878\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5838 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5881\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5877\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5838 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "7\n",
      "robustB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5637 - val_loss: 1.6504\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5034 - val_loss: 1.4515\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4420 - val_loss: 1.4669\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4337 - val_loss: 1.4395\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4313 - val_loss: 1.4631\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4311 - val_loss: 1.4300\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4277 - val_loss: 1.4285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4283 - val_loss: 1.4282\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4321 - val_loss: 1.4273\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4257 - val_loss: 1.4254\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4283 - val_loss: 1.4368\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4305 - val_loss: 1.4323\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4268 - val_loss: 1.4361\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4260 - val_loss: 1.4406\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4256 - val_loss: 1.4252\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4264 - val_loss: 1.4240\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4243 - val_loss: 1.4276\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4228 - val_loss: 1.4261\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4235 - val_loss: 1.4241\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4226 - val_loss: 1.4227\n",
      "Top-2 accuracy = 0.608\n",
      "8\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5998 - val_loss: 1.5929\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5863 - val_loss: 1.5877\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.583 - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "9\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6008 - val_loss: 1.5906\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5613 - val_loss: 1.5258\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4945 - val_loss: 1.4718\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4617 - val_loss: 1.4565\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4479\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4416 - val_loss: 1.4415\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4381 - val_loss: 1.4383\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4384\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4363\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4344\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4330\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4327\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4329\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4324\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4316\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4317\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4328\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4316\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4306\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4290\n",
      "Top-2 accuracy = 0.608\n",
      "10\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5600 - val_loss: 1.5225\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4809 - val_loss: 1.4474\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 1.4287\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4256\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4241\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4231 - val_loss: 1.4249\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4214 - val_loss: 1.4271\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4240\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4194 - val_loss: 1.4216\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4182 - val_loss: 1.4204\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.4200\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4176 - val_loss: 1.4240\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4190 - val_loss: 1.4216\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4164 - val_loss: 1.4192\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4160 - val_loss: 1.4184\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4160 - val_loss: 1.4225\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4155 - val_loss: 1.4170\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4145 - val_loss: 1.4210\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4174 - val_loss: 1.4169\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4134 - val_loss: 1.4162\n",
      "Top-2 accuracy = 0.612\n",
      "11\n",
      "maxabsR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5915 - val_loss: 1.5876\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5884\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5875\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "12\n",
      "maxabsd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5592 - val_loss: 1.4983\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4595 - val_loss: 1.4469\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4395 - val_loss: 1.4393\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4374 - val_loss: 1.4362\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4331\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4304\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4299\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4282\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4266\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4312\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4261\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4300\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4248\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4260\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4223 - val_loss: 1.4237\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4215 - val_loss: 1.4217\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4214 - val_loss: 1.4207\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4207 - val_loss: 1.4257\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4210\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4186 - val_loss: 1.4222\n",
      "Top-2 accuracy = 0.608\n",
      "13\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5938 - val_loss: 1.5845\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5732 - val_loss: 1.5656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5497 - val_loss: 1.5363\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5209 - val_loss: 1.5091\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4937 - val_loss: 1.4822\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4718 - val_loss: 1.4635\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4577 - val_loss: 1.4522\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4448\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4430 - val_loss: 1.4413\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4408 - val_loss: 1.4388\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4381 - val_loss: 1.4381\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4366 - val_loss: 1.4360\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4358\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4346 - val_loss: 1.4351\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4349\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4328 - val_loss: 1.4340\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4335\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4312 - val_loss: 1.4335\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4307 - val_loss: 1.4325\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4317\n",
      "Top-2 accuracy = 0.605\n",
      "14\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5977 - val_loss: 1.5917\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5861 - val_loss: 1.5883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5839 - val_loss: 1.5878\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5879\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5879\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "15\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5571 - val_loss: 1.5108\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4845 - val_loss: 1.4662\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4555 - val_loss: 1.4483\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4426 - val_loss: 1.4407\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4377\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4356\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4347 - val_loss: 1.4369\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4347\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4334\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4331\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4334\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.4325\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4337\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4357\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4322\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4334\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4307 - val_loss: 1.4310\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4309\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4310\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4309\n",
      "Top-2 accuracy = 0.609\n",
      "16\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5894 - val_loss: 1.5879\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5838 - val_loss: 1.5877\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5881\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5881\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5878\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "17\n",
      "minmaxp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5930 - val_loss: 1.5877\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5836 - val_loss: 1.5879\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5836 - val_loss: 1.5878\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5836 - val_loss: 1.5874\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5879\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5837 - val_loss: 1.5877\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5836 - val_loss: 1.5875\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5879\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5882\n",
      "Top-2 accuracy = 0.492\n",
      "18\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.6033 - val_loss: 1.5988\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5939 - val_loss: 1.5927\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5886 - val_loss: 1.5895\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5856 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "19\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6010 - val_loss: 1.5948\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5874 - val_loss: 1.5856\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5479 - val_loss: 1.5099\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4893 - val_loss: 1.4797\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4651 - val_loss: 1.4599\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4495 - val_loss: 1.4473\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4400 - val_loss: 1.4410\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4349 - val_loss: 1.4369\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4344\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4332\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4322\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4287 - val_loss: 1.4317\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4316\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4306\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4299\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4305\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4297\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4289\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4287\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4285\n",
      "Top-2 accuracy = 0.609\n",
      "20\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.6096 - val_loss: 1.5980\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5930 - val_loss: 1.5918\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5874 - val_loss: 1.5888\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5846 - val_loss: 1.5877\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5878\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 2s 21ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "21\n",
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5749 - val_loss: 1.5429\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4977 - val_loss: 1.4729\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4508 - val_loss: 1.4400\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4337 - val_loss: 1.4295\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4338\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4300 - val_loss: 1.4277\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4247\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4241 - val_loss: 1.4250\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4242 - val_loss: 1.4263\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4236 - val_loss: 1.4236\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.4238\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4239 - val_loss: 1.4253\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4229 - val_loss: 1.4229\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4228 - val_loss: 1.4249\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4227 - val_loss: 1.4234\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4216 - val_loss: 1.4236\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4229 - val_loss: 1.4250\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4209 - val_loss: 1.4244\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4222 - val_loss: 1.4252\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4217 - val_loss: 1.4303\n",
      "Top-2 accuracy = 0.603\n",
      "22\n",
      "minmaxX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.6032 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5939 - val_loss: 1.5927\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5886 - val_loss: 1.5896\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5857 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "23\n",
      "maxabsm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5930 - val_loss: 1.5890\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5838 - val_loss: 1.5878\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5880\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "24\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5652 - val_loss: 1.5019\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4654 - val_loss: 1.4420\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4444 - val_loss: 1.4389\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4332 - val_loss: 1.4328\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4310 - val_loss: 1.4690\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4327 - val_loss: 1.4376\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4285 - val_loss: 1.4292\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4297 - val_loss: 1.4273\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4263 - val_loss: 1.4306\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4280 - val_loss: 1.4288\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4266 - val_loss: 1.4335\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4288 - val_loss: 1.4277\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4253 - val_loss: 1.4355\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4257 - val_loss: 1.4324\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4245 - val_loss: 1.4252\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4229 - val_loss: 1.4262\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4241 - val_loss: 1.4331\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4248 - val_loss: 1.4241\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4230 - val_loss: 1.4300\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4230 - val_loss: 1.4254\n",
      "Top-2 accuracy = 0.607\n",
      "25\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5928 - val_loss: 1.5895\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5848 - val_loss: 1.5878\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5836 - val_loss: 1.5877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "26\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5637 - val_loss: 1.5300\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5041 - val_loss: 1.4816\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4678 - val_loss: 1.4563\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4507 - val_loss: 1.4460\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4442 - val_loss: 1.4433\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4414 - val_loss: 1.4415\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4405 - val_loss: 1.4401\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4395 - val_loss: 1.4396\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4391 - val_loss: 1.4396\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4382 - val_loss: 1.4385\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4384\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4371\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4371 - val_loss: 1.4364\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4364 - val_loss: 1.4357\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4359\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4349\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4340 - val_loss: 1.4346\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 1.4344\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4352\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4328\n",
      "Top-2 accuracy = 0.606\n",
      "27\n",
      "robustV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5990 - val_loss: 1.5848\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5611 - val_loss: 1.5356\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5032 - val_loss: 1.4846\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4690 - val_loss: 1.4609\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4522 - val_loss: 1.4468\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4428 - val_loss: 1.4388\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4352 - val_loss: 1.4392\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4322 - val_loss: 1.4313\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4291 - val_loss: 1.4308\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4279 - val_loss: 1.4282\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4279 - val_loss: 1.4291\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4300\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4264 - val_loss: 1.4258\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4261 - val_loss: 1.4257\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4258 - val_loss: 1.4250\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4246 - val_loss: 1.4254\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4239 - val_loss: 1.4248\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4241 - val_loss: 1.4267\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.4256\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4232 - val_loss: 1.4267\n",
      "Top-2 accuracy = 0.607\n",
      "28\n",
      "normalizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5434 - val_loss: 1.4754\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4465 - val_loss: 1.4308\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4261 - val_loss: 1.4245\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4218 - val_loss: 1.4240\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4202 - val_loss: 1.4253\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4197 - val_loss: 1.4212\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4178 - val_loss: 1.4212\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4181 - val_loss: 1.4247\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4186 - val_loss: 1.4207\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4169 - val_loss: 1.4253\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4166 - val_loss: 1.4211\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4162 - val_loss: 1.4213\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4156 - val_loss: 1.4196\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4156 - val_loss: 1.4202\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4169 - val_loss: 1.4202\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4155 - val_loss: 1.4207\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4149 - val_loss: 1.4193\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4149 - val_loss: 1.4210\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4162 - val_loss: 1.4194\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4157 - val_loss: 1.4203\n",
      "Top-2 accuracy = 0.609\n",
      "29\n",
      "minmaxT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5993 - val_loss: 1.5917\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5860 - val_loss: 1.5879\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "0\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.6017 - val_loss: 1.5961\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5907 - val_loss: 1.5908\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5862 - val_loss: 1.5887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5845 - val_loss: 1.5879\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5877\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Top-2 accuracy = 0.492\n",
      "1\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.6032 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5940 - val_loss: 1.5928\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5886 - val_loss: 1.5895\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5856 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5842 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "2\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.5408 - val_loss: 1.4842\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4559 - val_loss: 1.4492\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4338 - val_loss: 1.4302\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4276 - val_loss: 1.4273\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4268 - val_loss: 1.4247\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4266 - val_loss: 1.4620\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4331 - val_loss: 1.4276\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4246 - val_loss: 1.4238\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4221 - val_loss: 1.4234\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4233 - val_loss: 1.4311\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4230 - val_loss: 1.4233\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4220 - val_loss: 1.4292\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4226 - val_loss: 1.4238\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4218 - val_loss: 1.4236\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4242 - val_loss: 1.4248\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4220 - val_loss: 1.4287\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4223 - val_loss: 1.4252\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4231 - val_loss: 1.4274\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4234 - val_loss: 1.4262\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4248 - val_loss: 1.4362\n",
      "Top-2 accuracy = 0.603\n",
      "3\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5920 - val_loss: 1.5752\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5454 - val_loss: 1.5078\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4733 - val_loss: 1.4538\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4451 - val_loss: 1.4379\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4364 - val_loss: 1.4375\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4325 - val_loss: 1.4305\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4291 - val_loss: 1.4286\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4272\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4261\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4249 - val_loss: 1.4266\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4249\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4245 - val_loss: 1.4254\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4254\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4236 - val_loss: 1.4240\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4235 - val_loss: 1.4255\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4239 - val_loss: 1.4245\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4232 - val_loss: 1.4230\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4223 - val_loss: 1.4234\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4223 - val_loss: 1.4275\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4236 - val_loss: 1.4232\n",
      "Top-2 accuracy = 0.608\n",
      "4\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5880 - val_loss: 1.5633\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5125 - val_loss: 1.4775\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4605 - val_loss: 1.4555\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4492\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4439 - val_loss: 1.4458\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4412 - val_loss: 1.4431\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4439\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4398\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4354 - val_loss: 1.4386\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4339 - val_loss: 1.4378\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4380\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4314 - val_loss: 1.4337\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4324\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4326\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4306\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4305\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4294\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4267 - val_loss: 1.4292\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4282\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4278\n",
      "Top-2 accuracy = 0.606\n",
      "5\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5804 - val_loss: 1.5386\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5053 - val_loss: 1.4800\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4639 - val_loss: 1.4517\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4455 - val_loss: 1.4426\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4410 - val_loss: 1.4400\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.4353\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4344 - val_loss: 1.4338\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4338\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4318\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4354\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4301 - val_loss: 1.4311\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4308\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4303\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4315\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4303\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4308\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4291\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4294\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.4281\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4292\n",
      "Top-2 accuracy = 0.606\n",
      "6\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.6030 - val_loss: 1.5986\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5937 - val_loss: 1.5925\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5883 - val_loss: 1.5893\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5855 - val_loss: 1.5880\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5842 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "7\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5456 - val_loss: 1.4986\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4587 - val_loss: 1.4411\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4347 - val_loss: 1.4367\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4293 - val_loss: 1.4383\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4291 - val_loss: 1.4333\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4274 - val_loss: 1.4331\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4267 - val_loss: 1.4278\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4254 - val_loss: 1.4273\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4255 - val_loss: 1.4322\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4248 - val_loss: 1.4297\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4288\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4253 - val_loss: 1.4259\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4234 - val_loss: 1.4269\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4229 - val_loss: 1.4324\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4247 - val_loss: 1.4303\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4242 - val_loss: 1.4299\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4232 - val_loss: 1.4263\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4253 - val_loss: 1.4292\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4233 - val_loss: 1.4334\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4226 - val_loss: 1.4268\n",
      "Top-2 accuracy = 0.607\n",
      "8\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5881 - val_loss: 1.5653\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5270 - val_loss: 1.4870\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4645 - val_loss: 1.4522\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4449 - val_loss: 1.4423\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4393 - val_loss: 1.4382\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4364 - val_loss: 1.4357\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4351\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4351\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4342\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4329\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4331\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4330\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4332\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4311 - val_loss: 1.4320\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4317\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4312\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4298 - val_loss: 1.4364\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4294 - val_loss: 1.4306\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4289 - val_loss: 1.4309\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4305\n",
      "Top-2 accuracy = 0.603\n",
      "9\n",
      "maxabsZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5657 - val_loss: 1.5343\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5113 - val_loss: 1.4928\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4783 - val_loss: 1.4714\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4651 - val_loss: 1.4618\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4567 - val_loss: 1.4543\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4511 - val_loss: 1.4501\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4484 - val_loss: 1.4469\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4455 - val_loss: 1.4443\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4436 - val_loss: 1.4425\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4420 - val_loss: 1.4406\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4406 - val_loss: 1.4397\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4392 - val_loss: 1.4387\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4388 - val_loss: 1.4380\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4385 - val_loss: 1.4373\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4392\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4386 - val_loss: 1.4355\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4341\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4343 - val_loss: 1.4339\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4339 - val_loss: 1.4327\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4321\n",
      "Top-2 accuracy = 0.605\n",
      "10\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5902 - val_loss: 1.5636\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5424 - val_loss: 1.5320\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5140 - val_loss: 1.5034\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4892 - val_loss: 1.4795\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4682 - val_loss: 1.4607\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4532 - val_loss: 1.4491\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4451 - val_loss: 1.4450\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4395 - val_loss: 1.4447\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.4360\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4339\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4325 - val_loss: 1.4342\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4321 - val_loss: 1.4317\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4303 - val_loss: 1.4326\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4317\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4325\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.4307\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4308\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4298\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4315\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4322\n",
      "Top-2 accuracy = 0.607\n",
      "11\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5564 - val_loss: 1.5124\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4662 - val_loss: 1.4523\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4380 - val_loss: 1.4288\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4250 - val_loss: 1.4269\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4235 - val_loss: 1.4263\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4242 - val_loss: 1.4275\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4243 - val_loss: 1.4253\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4223 - val_loss: 1.4292\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4235 - val_loss: 1.4439\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4230 - val_loss: 1.4235\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4197 - val_loss: 1.4237\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4191 - val_loss: 1.4298\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4191 - val_loss: 1.4249\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4184 - val_loss: 1.4269\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4201 - val_loss: 1.4258\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4193 - val_loss: 1.4503\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4242 - val_loss: 1.4254\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4177 - val_loss: 1.4240\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4178 - val_loss: 1.4261\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4189 - val_loss: 1.4267\n",
      "Top-2 accuracy = 0.603\n",
      "12\n",
      "maxabsv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5996 - val_loss: 1.5946\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5883 - val_loss: 1.5893\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5845 - val_loss: 1.5881\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5877\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5880\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5878\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5881\n",
      "Top-2 accuracy = 0.492\n",
      "13\n",
      "maxabsf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5735 - val_loss: 1.5227\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4781 - val_loss: 1.4481\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4427 - val_loss: 1.4381\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4336 - val_loss: 1.4330\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4289 - val_loss: 1.4454\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4318 - val_loss: 1.4282\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4274 - val_loss: 1.4287\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4270 - val_loss: 1.4374\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4274 - val_loss: 1.4312\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4247 - val_loss: 1.4364\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4253 - val_loss: 1.4295\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4294 - val_loss: 1.4255\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4249 - val_loss: 1.4265\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4268 - val_loss: 1.4260\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4257 - val_loss: 1.4249\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4240 - val_loss: 1.4314\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4249 - val_loss: 1.4285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4237 - val_loss: 1.4297\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4249 - val_loss: 1.4293\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4233 - val_loss: 1.4260\n",
      "Top-2 accuracy = 0.608\n",
      "14\n",
      "minmaxz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5798 - val_loss: 1.5543\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5172 - val_loss: 1.4879\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4674 - val_loss: 1.4573\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4512 - val_loss: 1.4490\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4448 - val_loss: 1.4455\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4419 - val_loss: 1.4576\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4425 - val_loss: 1.4413\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4390 - val_loss: 1.4393\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4390 - val_loss: 1.4390\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4386 - val_loss: 1.4394\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4370 - val_loss: 1.4402\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4373 - val_loss: 1.4386\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4378 - val_loss: 1.4384\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4361 - val_loss: 1.4428\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4365 - val_loss: 1.4392\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4442\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4368 - val_loss: 1.4438\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.4410\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4390 - val_loss: 1.4382\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4385\n",
      "Top-2 accuracy = 0.6\n",
      "15\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5934 - val_loss: 1.5895\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5844 - val_loss: 1.5877\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5832 - val_loss: 1.5867\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5718 - val_loss: 1.5472\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5052 - val_loss: 1.4818\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4715 - val_loss: 1.4640\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4612 - val_loss: 1.4568\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4557 - val_loss: 1.4536\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4519 - val_loss: 1.4490\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4470 - val_loss: 1.4460\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4441 - val_loss: 1.4453\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4423 - val_loss: 1.4433\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.4404\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4386 - val_loss: 1.4389\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4376\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4367 - val_loss: 1.4368\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4360\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4363\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4343 - val_loss: 1.4347\n",
      "Top-2 accuracy = 0.606\n",
      "16\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5666 - val_loss: 1.5288\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4917 - val_loss: 1.4710\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4514 - val_loss: 1.4462\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4392 - val_loss: 1.4440\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4363 - val_loss: 1.4363\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4392\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4337\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4355\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.4342\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4329\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4331\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4333\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4263 - val_loss: 1.4303\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4310\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4303\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4249 - val_loss: 1.4296\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4242 - val_loss: 1.4301\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4305\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4286\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4241 - val_loss: 1.4286\n",
      "Top-2 accuracy = 0.608\n",
      "17\n",
      "minmaxa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5961 - val_loss: 1.5897\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5767 - val_loss: 1.5534\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5054 - val_loss: 1.4789\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4653 - val_loss: 1.4620\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4569 - val_loss: 1.4635\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4554 - val_loss: 1.4554\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4514 - val_loss: 1.4531\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4504 - val_loss: 1.4534\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4488 - val_loss: 1.4478\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 1.4468\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4436 - val_loss: 1.4426\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4400 - val_loss: 1.4459\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4396 - val_loss: 1.4403\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4379 - val_loss: 1.4416\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4382 - val_loss: 1.4465\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4426\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4351 - val_loss: 1.4475\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4356 - val_loss: 1.4483\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4348 - val_loss: 1.4350\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4341 - val_loss: 1.4416\n",
      "Top-2 accuracy = 0.6\n",
      "18\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5869 - val_loss: 1.5802\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5478 - val_loss: 1.5274\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5023 - val_loss: 1.4900\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4741 - val_loss: 1.4692\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4657 - val_loss: 1.4650\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4615 - val_loss: 1.4643\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4615 - val_loss: 1.4605\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4601 - val_loss: 1.4627\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4593 - val_loss: 1.4589\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4571 - val_loss: 1.4581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4564 - val_loss: 1.4591\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4573 - val_loss: 1.4561\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4548 - val_loss: 1.4559\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4546 - val_loss: 1.4594\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4538 - val_loss: 1.4548\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4536 - val_loss: 1.4643\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4527 - val_loss: 1.4573\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4508 - val_loss: 1.4502\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4489 - val_loss: 1.4530\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4488 - val_loss: 1.4475\n",
      "Top-2 accuracy = 0.602\n",
      "19\n",
      "standardizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5912 - val_loss: 1.5877\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5881\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5885\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "20\n",
      "normalizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5734 - val_loss: 1.5185\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4710 - val_loss: 1.4441\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4369 - val_loss: 1.4333\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4350 - val_loss: 1.4326\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4323 - val_loss: 1.4317\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4304 - val_loss: 1.4275\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4285 - val_loss: 1.4278\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4273 - val_loss: 1.4268\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4259 - val_loss: 1.4260\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4259\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4245\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4248\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4242 - val_loss: 1.4246\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4238 - val_loss: 1.4313\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4348\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4245 - val_loss: 1.4247\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4240 - val_loss: 1.4238\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4226 - val_loss: 1.4234\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4227 - val_loss: 1.4255\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4231 - val_loss: 1.4244\n",
      "Top-2 accuracy = 0.608\n",
      "21\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5891 - val_loss: 1.5880\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5879\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5879\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Top-2 accuracy = 0.492\n",
      "22\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5736 - val_loss: 1.5525\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5363 - val_loss: 1.5183\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5041 - val_loss: 1.4857\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4727 - val_loss: 1.4612\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4529 - val_loss: 1.4421\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4381 - val_loss: 1.4354\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4331 - val_loss: 1.4350\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4304 - val_loss: 1.4338\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4325\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4297\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4287 - val_loss: 1.4302\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4293\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4284 - val_loss: 1.4295\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4315\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4356\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4279\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4281\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4258 - val_loss: 1.4294\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4278\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4277\n",
      "Top-2 accuracy = 0.61\n",
      "23\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.6030 - val_loss: 1.5985\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5939 - val_loss: 1.5928\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5887 - val_loss: 1.5897\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5859 - val_loss: 1.5882\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "24\n",
      "robustz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5522 - val_loss: 1.5155\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4925 - val_loss: 1.4724\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4605 - val_loss: 1.4502\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4479 - val_loss: 1.4466\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4429 - val_loss: 1.4411\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4381 - val_loss: 1.4378\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4365 - val_loss: 1.4389\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4364 - val_loss: 1.4377\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4342 - val_loss: 1.4372\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4338 - val_loss: 1.4397\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4332 - val_loss: 1.4350\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4319 - val_loss: 1.4329\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4301 - val_loss: 1.4332\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4298 - val_loss: 1.4337\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4296 - val_loss: 1.4337\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4287 - val_loss: 1.4325\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4282 - val_loss: 1.4345\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4274 - val_loss: 1.4330\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4277 - val_loss: 1.4313\n",
      "Top-2 accuracy = 0.604\n",
      "25\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5848 - val_loss: 1.5528\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5076 - val_loss: 1.4758\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4595 - val_loss: 1.4551\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4491 - val_loss: 1.4469\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4425 - val_loss: 1.4423\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4384 - val_loss: 1.4392\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 1.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4355 - val_loss: 1.4365\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4332 - val_loss: 1.4361\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4326 - val_loss: 1.4367\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4385\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4493\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4334 - val_loss: 1.4338\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4307 - val_loss: 1.4339\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4334\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4333\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4328\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4331\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.4330\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4292 - val_loss: 1.4340\n",
      "Top-2 accuracy = 0.604\n",
      "26\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5955 - val_loss: 1.5882\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5838 - val_loss: 1.5876\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5879\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5836 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Top-2 accuracy = 0.492\n",
      "27\n",
      "normalizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5806 - val_loss: 1.5108\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4580 - val_loss: 1.4349\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.429 - 0s 3ms/step - loss: 1.4291 - val_loss: 1.4307\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4325\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4330\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4251 - val_loss: 1.4260\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.4264\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4227 - val_loss: 1.4246\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4229 - val_loss: 1.4238\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4214 - val_loss: 1.4235\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4216 - val_loss: 1.4270\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4206 - val_loss: 1.4235\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4201 - val_loss: 1.4244\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4221 - val_loss: 1.4251\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4208 - val_loss: 1.4254\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4205 - val_loss: 1.4301\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4219 - val_loss: 1.4303\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4213 - val_loss: 1.4234\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4203 - val_loss: 1.4247\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4209 - val_loss: 1.4265\n",
      "Top-2 accuracy = 0.605\n",
      "28\n",
      "maxabsj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.6014 - val_loss: 1.5955\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5893 - val_loss: 1.5898\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5851 - val_loss: 1.5881\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5838 - val_loss: 1.5877\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "29\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 1.5761 - val_loss: 1.5321\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5016 - val_loss: 1.4847\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4834 - val_loss: 1.4805\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4895 - val_loss: 1.7149\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4810 - val_loss: 1.4745\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4668 - val_loss: 1.4564\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4577 - val_loss: 1.4472\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4483 - val_loss: 1.5001\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4645 - val_loss: 1.4520\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4463 - val_loss: 1.4545\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4452 - val_loss: 1.4447\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4361 - val_loss: 1.4335\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4315 - val_loss: 1.4305\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4316 - val_loss: 1.4337\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4305 - val_loss: 1.4313\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4315 - val_loss: 1.4304\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4315 - val_loss: 1.4295\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4299 - val_loss: 1.4566\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4347 - val_loss: 1.4394\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4301 - val_loss: 1.4290\n",
      "Top-2 accuracy = 0.607\n",
      "0\n",
      "standardizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5353 - val_loss: 1.4723\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 1.4357\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.4315\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4299\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4281\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4259\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4256\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4233\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4202 - val_loss: 1.4229\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4185 - val_loss: 1.4216\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4183 - val_loss: 1.4201\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4173 - val_loss: 1.4211\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4170 - val_loss: 1.4216\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4185 - val_loss: 1.4185\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4155 - val_loss: 1.4198\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4157 - val_loss: 1.4181\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4145 - val_loss: 1.4180\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4146 - val_loss: 1.4188\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4158 - val_loss: 1.4172\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4141 - val_loss: 1.4174\n",
      "Top-2 accuracy = 0.613\n",
      "1\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5504 - val_loss: 1.5017\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4789 - val_loss: 1.4642\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4536 - val_loss: 1.4471\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4439 - val_loss: 1.4484\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4381 - val_loss: 1.4314\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4278 - val_loss: 1.4281\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4266 - val_loss: 1.4292\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4260 - val_loss: 1.4296\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4246 - val_loss: 1.4222\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4241 - val_loss: 1.4228\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4240 - val_loss: 1.4318\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4299 - val_loss: 1.4265\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4217 - val_loss: 1.4232\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4211 - val_loss: 1.4218\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4210 - val_loss: 1.4231\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4209 - val_loss: 1.4216\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4207 - val_loss: 1.4200\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4198 - val_loss: 1.4316\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4209 - val_loss: 1.4246\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4204 - val_loss: 1.4204\n",
      "Top-2 accuracy = 0.609\n",
      "2\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5593 - val_loss: 1.4980\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4752 - val_loss: 1.4493\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4442 - val_loss: 1.4350\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4308 - val_loss: 1.4341\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4296 - val_loss: 1.4315\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4279 - val_loss: 1.4298\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4252 - val_loss: 1.4382\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4247 - val_loss: 1.4232\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4232 - val_loss: 1.4239\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4223 - val_loss: 1.4274\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4242 - val_loss: 1.4237\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4213 - val_loss: 1.4385\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4210 - val_loss: 1.4370\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4232 - val_loss: 1.4223\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4190 - val_loss: 1.4220\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4191 - val_loss: 1.4210\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4170 - val_loss: 1.4268\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4191 - val_loss: 1.4217\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4196 - val_loss: 1.4286\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4199 - val_loss: 1.4248\n",
      "Top-2 accuracy = 0.608\n",
      "3\n",
      "normalizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5713 - val_loss: 1.5238\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4772 - val_loss: 1.4491\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4407 - val_loss: 1.4371\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4339 - val_loss: 1.4338\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4318 - val_loss: 1.4325\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4303\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4308\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4280\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4278\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4253 - val_loss: 1.4267\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4241 - val_loss: 1.4338\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4262\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4236 - val_loss: 1.4249\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4231 - val_loss: 1.4257\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4221 - val_loss: 1.4247\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4215 - val_loss: 1.4247\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4209 - val_loss: 1.4238\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4236\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4204 - val_loss: 1.4235\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4201 - val_loss: 1.4241\n",
      "Top-2 accuracy = 0.608\n",
      "4\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5277 - val_loss: 1.4716\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4390 - val_loss: 1.4329\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4280 - val_loss: 1.4328\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4242 - val_loss: 1.4238\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4205 - val_loss: 1.4248\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4206 - val_loss: 1.4335\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4241 - val_loss: 1.4238\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4203 - val_loss: 1.4225\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4198 - val_loss: 1.4238\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4190 - val_loss: 1.4229\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4198 - val_loss: 1.4255\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4183 - val_loss: 1.4229\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4175 - val_loss: 1.4241\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4168 - val_loss: 1.4217\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4188 - val_loss: 1.4223\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4171 - val_loss: 1.4227\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4170 - val_loss: 1.4238\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4183 - val_loss: 1.4236\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4164 - val_loss: 1.4283\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4175 - val_loss: 1.4204\n",
      "Top-2 accuracy = 0.61\n",
      "5\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5483 - val_loss: 1.4955\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4552 - val_loss: 1.4337\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4294 - val_loss: 1.4289\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4249 - val_loss: 1.4493\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4260 - val_loss: 1.4336\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4235 - val_loss: 1.4247\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4218 - val_loss: 1.4229\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4207 - val_loss: 1.4252\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4212 - val_loss: 1.4360\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4221 - val_loss: 1.4397\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4228 - val_loss: 1.4241\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4207 - val_loss: 1.4238\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4216 - val_loss: 1.4243\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4195 - val_loss: 1.4254\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4192 - val_loss: 1.4263\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4185 - val_loss: 1.4222\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4182 - val_loss: 1.4229\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4201 - val_loss: 1.4216\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4185 - val_loss: 1.4212\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4191 - val_loss: 1.4240\n",
      "Top-2 accuracy = 0.606\n",
      "6\n",
      "maxabsf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6030 - val_loss: 1.5985\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5936 - val_loss: 1.5924\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5883 - val_loss: 1.5894\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5855 - val_loss: 1.5880\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5842 - val_loss: 1.5875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5837 - val_loss: 1.5874\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "7\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5953 - val_loss: 1.5913\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5863 - val_loss: 1.5880\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5839 - val_loss: 1.5874\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5883\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5879\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "8\n",
      "normalizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5537 - val_loss: 1.4970\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4857 - val_loss: 1.4801\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4473 - val_loss: 1.4286\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4285 - val_loss: 1.4425\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4276 - val_loss: 1.4303\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4254 - val_loss: 1.4266\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4265 - val_loss: 1.4524\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4273 - val_loss: 1.4288\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4244 - val_loss: 1.4230\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.4240 - val_loss: 1.4240\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4235 - val_loss: 1.4245\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4229 - val_loss: 1.4219\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4232 - val_loss: 1.4218\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4225 - val_loss: 1.4215\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4226 - val_loss: 1.4272\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4227 - val_loss: 1.4272\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4255 - val_loss: 1.4287\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4224 - val_loss: 1.4237\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4210 - val_loss: 1.4250\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4207 - val_loss: 1.4242\n",
      "Top-2 accuracy = 0.606\n",
      "9\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5599 - val_loss: 1.4999\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4999 - val_loss: 1.5022\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4859 - val_loss: 1.4858\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4763 - val_loss: 1.4830\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4856 - val_loss: 1.4916\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4834 - val_loss: 1.4719\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4807 - val_loss: 1.5026\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4750 - val_loss: 1.4687\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4682 - val_loss: 1.4694\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.4672 - val_loss: 1.4687\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4669 - val_loss: 1.4698\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5007 - val_loss: 1.5079\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5042 - val_loss: 1.4948\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5039 - val_loss: 1.5451\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5399 - val_loss: 1.5355\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5310 - val_loss: 1.5272\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5260 - val_loss: 1.5272\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5266 - val_loss: 1.5272\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5306 - val_loss: 1.5210\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5636 - val_loss: 1.5878\n",
      "Top-2 accuracy = 0.492\n",
      "10\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5666 - val_loss: 1.5347\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4991 - val_loss: 1.4804\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4604 - val_loss: 1.4525\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4429 - val_loss: 1.4524\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4336 - val_loss: 1.4345\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4294 - val_loss: 1.4292\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4283 - val_loss: 1.4318\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4286 - val_loss: 1.4286\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4307\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4268\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4259 - val_loss: 1.4269\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.4330\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4247 - val_loss: 1.4294\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4277\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4240 - val_loss: 1.4316\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4268\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4234 - val_loss: 1.4252\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4223 - val_loss: 1.4267\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4241 - val_loss: 1.4261\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4228 - val_loss: 1.4251\n",
      "Top-2 accuracy = 0.608\n",
      "11\n",
      "robustd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5865 - val_loss: 1.5708\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5477 - val_loss: 1.5307\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5144 - val_loss: 1.4995\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4888 - val_loss: 1.4784\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4676 - val_loss: 1.4615\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4519 - val_loss: 1.4468\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4413 - val_loss: 1.4381\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4341 - val_loss: 1.4388\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4317 - val_loss: 1.4313\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4293 - val_loss: 1.4309\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4266 - val_loss: 1.4341\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4299\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4247 - val_loss: 1.4274\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4242 - val_loss: 1.4274\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.4268\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4229 - val_loss: 1.4257\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4224 - val_loss: 1.4257\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4228 - val_loss: 1.4279\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4232 - val_loss: 1.4319\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4236 - val_loss: 1.4272\n",
      "Top-2 accuracy = 0.61\n",
      "12\n",
      "maxabsC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5837 - val_loss: 1.5612\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5085 - val_loss: 1.4591\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4408 - val_loss: 1.4380\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4290 - val_loss: 1.4282\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4264 - val_loss: 1.4299\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4248\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4243 - val_loss: 1.4275\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4238 - val_loss: 1.4236\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4213 - val_loss: 1.4256\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4216 - val_loss: 1.4296\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4257\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4203 - val_loss: 1.4225\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4198 - val_loss: 1.4226\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4186 - val_loss: 1.4214\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4188 - val_loss: 1.4197\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4170 - val_loss: 1.4200\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4160 - val_loss: 1.4207\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4157 - val_loss: 1.4175\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4155 - val_loss: 1.4165\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4154 - val_loss: 1.4203\n",
      "Top-2 accuracy = 0.612\n",
      "13\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5891 - val_loss: 1.5638\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5227 - val_loss: 1.4963\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4814 - val_loss: 1.4769\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4683 - val_loss: 1.4676\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4602 - val_loss: 1.4606\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4535 - val_loss: 1.4546\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4490 - val_loss: 1.4510\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4445 - val_loss: 1.4459\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4416 - val_loss: 1.4442\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4389 - val_loss: 1.4417\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4369 - val_loss: 1.4416\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4361 - val_loss: 1.4370\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4343 - val_loss: 1.4361\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4328 - val_loss: 1.4348\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4324 - val_loss: 1.4332\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4315 - val_loss: 1.4325\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4306 - val_loss: 1.4329\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4310\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4298 - val_loss: 1.4303\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4288 - val_loss: 1.4300\n",
      "Top-2 accuracy = 0.605\n",
      "14\n",
      "normalizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5842 - val_loss: 1.5548\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5281 - val_loss: 1.4946\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4699 - val_loss: 1.4458\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4407 - val_loss: 1.4350\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4342\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4321 - val_loss: 1.4300\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4308 - val_loss: 1.4303\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4310\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4283 - val_loss: 1.4281\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4296\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4296\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4265\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4268\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4275\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4275\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4257\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4258\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4282\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4266\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4256\n",
      "Top-2 accuracy = 0.607\n",
      "15\n",
      "standardizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5907 - val_loss: 1.5876\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5836 - val_loss: 1.5875\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5836 - val_loss: 1.5881\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5833 - val_loss: 1.5886\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5834 - val_loss: 1.5879\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5836 - val_loss: 1.5880\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5835 - val_loss: 1.5883\n",
      "Top-2 accuracy = 0.492\n",
      "16\n",
      "robustO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5888 - val_loss: 1.5687\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5536 - val_loss: 1.5407\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5286 - val_loss: 1.5170\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5020 - val_loss: 1.4838\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4688 - val_loss: 1.4629\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4477 - val_loss: 1.4421\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4381 - val_loss: 1.4417\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4353 - val_loss: 1.4364\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4340\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4316 - val_loss: 1.4325\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4299 - val_loss: 1.4308\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4305\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4300\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4275\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4271\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4288\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4292\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4254 - val_loss: 1.4277\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4266\n",
      "Top-2 accuracy = 0.607\n",
      "17\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5797 - val_loss: 1.5342\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5008 - val_loss: 1.4883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4680 - val_loss: 1.4686\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4596 - val_loss: 1.4647\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4541 - val_loss: 1.4577\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4531 - val_loss: 1.4566\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4536 - val_loss: 1.4692\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4538 - val_loss: 1.4588\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4524 - val_loss: 1.4563\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4523 - val_loss: 1.4562\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4520 - val_loss: 1.4655\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4527 - val_loss: 1.4584\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4517 - val_loss: 1.4557\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4521 - val_loss: 1.4587\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4525 - val_loss: 1.4558\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4505 - val_loss: 1.4558\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4502 - val_loss: 1.4536\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4499 - val_loss: 1.4555\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4490 - val_loss: 1.4516\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4482 - val_loss: 1.4514\n",
      "Top-2 accuracy = 0.593\n",
      "18\n",
      "robustk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5891 - val_loss: 1.5657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5372 - val_loss: 1.5063\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4792 - val_loss: 1.4651\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4535 - val_loss: 1.4509\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4453 - val_loss: 1.4508\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4419 - val_loss: 1.4529\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4411 - val_loss: 1.4400\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4367 - val_loss: 1.4406\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4352 - val_loss: 1.4414\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4370 - val_loss: 1.4457\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4393 - val_loss: 1.4360\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4344 - val_loss: 1.4371\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4316 - val_loss: 1.4331\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4319 - val_loss: 1.4321\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4306 - val_loss: 1.4315\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4318 - val_loss: 1.4295\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.4577\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4332 - val_loss: 1.4318\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4294 - val_loss: 1.4373\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.4292\n",
      "Top-2 accuracy = 0.604\n",
      "19\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5765 - val_loss: 1.5114\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4612 - val_loss: 1.4440\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4366 - val_loss: 1.4332\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4312 - val_loss: 1.4295\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4286 - val_loss: 1.4303\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4280 - val_loss: 1.4284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4274\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 1.4275\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4249 - val_loss: 1.4317\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4296\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4245 - val_loss: 1.4254\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4253\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4233 - val_loss: 1.4268\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4239 - val_loss: 1.4272\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4234 - val_loss: 1.4262\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4226 - val_loss: 1.4260\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4223 - val_loss: 1.4248\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4250\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4218 - val_loss: 1.4264\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4220 - val_loss: 1.4262\n",
      "Top-2 accuracy = 0.607\n",
      "20\n",
      "standardizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.6005 - val_loss: 1.5954\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5899 - val_loss: 1.5899\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5855 - val_loss: 1.5881\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5839 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "21\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.6005 - val_loss: 1.5947\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5876 - val_loss: 1.5881\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5754 - val_loss: 1.5465\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5195 - val_loss: 1.4989\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4912 - val_loss: 1.4786\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4734 - val_loss: 1.4653\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4613 - val_loss: 1.4563\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4593 - val_loss: 1.4540\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4524 - val_loss: 1.4548\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4517 - val_loss: 1.4499\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4489 - val_loss: 1.4508\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4484 - val_loss: 1.4489\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4473 - val_loss: 1.4458\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4456 - val_loss: 1.4520\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4467 - val_loss: 1.4435\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4449 - val_loss: 1.4437\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4450 - val_loss: 1.4428\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4436 - val_loss: 1.4469\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4426 - val_loss: 1.4418\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4429 - val_loss: 1.4411\n",
      "Top-2 accuracy = 0.599\n",
      "22\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5662 - val_loss: 1.5317\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4825 - val_loss: 1.4470\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4343 - val_loss: 1.4388\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4325\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4255\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4230 - val_loss: 1.4274\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4219 - val_loss: 1.4264\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4224 - val_loss: 1.4251\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4211 - val_loss: 1.4321\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4387\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4225 - val_loss: 1.4287\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4207 - val_loss: 1.4249\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4207 - val_loss: 1.4247\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4190 - val_loss: 1.4236\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4197 - val_loss: 1.4245\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4191 - val_loss: 1.4235\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4184 - val_loss: 1.4239\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4178 - val_loss: 1.4234\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4181 - val_loss: 1.4265\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4195 - val_loss: 1.4266\n",
      "Top-2 accuracy = 0.611\n",
      "23\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6024 - val_loss: 1.5940\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5770 - val_loss: 1.5484\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5124 - val_loss: 1.4804\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4648 - val_loss: 1.4538\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4477 - val_loss: 1.4436\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4387 - val_loss: 1.4370\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4338 - val_loss: 1.4337\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4310 - val_loss: 1.4323\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4296\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4306\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4279\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4269 - val_loss: 1.4289\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4288\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4260 - val_loss: 1.4281\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4270\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4249 - val_loss: 1.4281\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4248 - val_loss: 1.4254\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4250 - val_loss: 1.4260\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.4253\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4242 - val_loss: 1.4266\n",
      "Top-2 accuracy = 0.606\n",
      "24\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5762 - val_loss: 1.5259\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4840 - val_loss: 1.4587\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4439 - val_loss: 1.4363\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4321 - val_loss: 1.4339\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4281\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4304\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4312\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4278\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4259 - val_loss: 1.4260\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4266 - val_loss: 1.4240\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4254\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4257 - val_loss: 1.4241\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4252 - val_loss: 1.4244\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.4234\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4241\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4236 - val_loss: 1.4242\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4233 - val_loss: 1.4237\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4237 - val_loss: 1.4273\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4241 - val_loss: 1.4240\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4238 - val_loss: 1.4264\n",
      "Top-2 accuracy = 0.605\n",
      "25\n",
      "minmaxt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5995 - val_loss: 1.5837\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5661 - val_loss: 1.5463\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5266 - val_loss: 1.5032\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4848 - val_loss: 1.4913\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4579 - val_loss: 1.4479\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4425 - val_loss: 1.4399\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4361 - val_loss: 1.4334\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4318 - val_loss: 1.4312\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4314 - val_loss: 1.4282\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4282 - val_loss: 1.4292\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4286 - val_loss: 1.4363\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4260\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4270 - val_loss: 1.4308\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4258 - val_loss: 1.4317\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4259 - val_loss: 1.4248\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4248\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4246 - val_loss: 1.4307\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4254 - val_loss: 1.4249\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4265 - val_loss: 1.4274\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4257\n",
      "Top-2 accuracy = 0.608\n",
      "26\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5948 - val_loss: 1.5913\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5859 - val_loss: 1.5886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5840 - val_loss: 1.5877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "27\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5922 - val_loss: 1.5793\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5525 - val_loss: 1.5281\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5075 - val_loss: 1.4894\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4726 - val_loss: 1.4573\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4506 - val_loss: 1.4451\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4383 - val_loss: 1.4352\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4327 - val_loss: 1.4339\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4351\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4286 - val_loss: 1.4276\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4289\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4279 - val_loss: 1.4277\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4291\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4268 - val_loss: 1.4304\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4255 - val_loss: 1.4252\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4263\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4240 - val_loss: 1.4269\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4350\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4249 - val_loss: 1.4247\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4232 - val_loss: 1.4252\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4233 - val_loss: 1.4251\n",
      "Top-2 accuracy = 0.609\n",
      "28\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5424 - val_loss: 1.4639\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4400 - val_loss: 1.4396\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4246 - val_loss: 1.4253\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4227 - val_loss: 1.4257\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4194 - val_loss: 1.4240\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4197 - val_loss: 1.4339\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4217 - val_loss: 1.4226\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4186 - val_loss: 1.4243\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4180 - val_loss: 1.4233\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4190 - val_loss: 1.4258\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4183 - val_loss: 1.4249\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4189 - val_loss: 1.4259\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4175 - val_loss: 1.4250\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4174 - val_loss: 1.4265\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4173 - val_loss: 1.4224\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4176 - val_loss: 1.4244\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4161 - val_loss: 1.4231\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4162 - val_loss: 1.4236\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4169 - val_loss: 1.4219\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4171 - val_loss: 1.4316\n",
      "Top-2 accuracy = 0.604\n",
      "29\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.6011 - val_loss: 1.5945\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5883 - val_loss: 1.5884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5840 - val_loss: 1.5876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "0\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5421 - val_loss: 1.4862\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4479 - val_loss: 1.4351\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4305 - val_loss: 1.4289\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4295 - val_loss: 1.4273\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4254 - val_loss: 1.4259\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4230 - val_loss: 1.4316\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4221 - val_loss: 1.4239\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4217 - val_loss: 1.4350\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4248 - val_loss: 1.4228\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4209 - val_loss: 1.4540\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4343 - val_loss: 1.4283\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4231 - val_loss: 1.4232\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4193 - val_loss: 1.4297\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4208 - val_loss: 1.4225\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4200 - val_loss: 1.4277\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4211 - val_loss: 1.4214\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4198 - val_loss: 1.4211\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4190 - val_loss: 1.4208\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4202 - val_loss: 1.4219\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4205 - val_loss: 1.4203\n",
      "Top-2 accuracy = 0.61\n",
      "1\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5692 - val_loss: 1.5070\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4638 - val_loss: 1.4428\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4340 - val_loss: 1.4265\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4273 - val_loss: 1.4244\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 1.4235\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4222 - val_loss: 1.4222\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4212 - val_loss: 1.4233\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4205 - val_loss: 1.4268\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4194 - val_loss: 1.4216\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4190 - val_loss: 1.4219\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4177 - val_loss: 1.4185\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4165 - val_loss: 1.4230\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4168 - val_loss: 1.4170\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4146 - val_loss: 1.4165\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4138 - val_loss: 1.4163\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4142 - val_loss: 1.4164\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4151 - val_loss: 1.4177\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4139 - val_loss: 1.4162\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4127 - val_loss: 1.4158\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4116 - val_loss: 1.4175\n",
      "Top-2 accuracy = 0.614\n",
      "2\n",
      "normalizeQ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3083 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5854 - val_loss: 1.5451\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4971 - val_loss: 1.4677\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4608 - val_loss: 1.4558\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4519 - val_loss: 1.4496\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4465 - val_loss: 1.4453\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4427 - val_loss: 1.4423\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4400 - val_loss: 1.4386\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4375 - val_loss: 1.4362\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4351 - val_loss: 1.4344\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4336 - val_loss: 1.4323\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4315 - val_loss: 1.4312\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4302 - val_loss: 1.4288\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4287 - val_loss: 1.4274\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4269 - val_loss: 1.4255\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4259 - val_loss: 1.4243\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4245 - val_loss: 1.4237\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4235 - val_loss: 1.4225\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4229 - val_loss: 1.4220\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4219 - val_loss: 1.4220\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.4216 - val_loss: 1.4214\n",
      "Top-2 accuracy = 0.611\n",
      "3\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5376 - val_loss: 1.4751\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4600 - val_loss: 1.4493\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4376 - val_loss: 1.4317\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4303 - val_loss: 1.4299\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4261\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4260\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4255\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4259\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4252 - val_loss: 1.4409\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4348\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4256\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4233 - val_loss: 1.4255\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4238 - val_loss: 1.4239\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4224 - val_loss: 1.4276\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4228 - val_loss: 1.4233\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4233 - val_loss: 1.4244\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4236 - val_loss: 1.4234\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4226 - val_loss: 1.4243\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4222 - val_loss: 1.4239\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4232 - val_loss: 1.4233\n",
      "Top-2 accuracy = 0.607\n",
      "4\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5940 - val_loss: 1.5878\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5881\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5836 - val_loss: 1.5878\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5880\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5836 - val_loss: 1.5881\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5836 - val_loss: 1.5878\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5879\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "5\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 1.5573 - val_loss: 1.4891\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4733 - val_loss: 1.4768\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4850 - val_loss: 1.4862\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4800 - val_loss: 1.4814\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4799 - val_loss: 1.4811\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.4926 - val_loss: 1.5216\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5200 - val_loss: 1.5199\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5191 - val_loss: 1.5229\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5538 - val_loss: 1.5637\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5591 - val_loss: 1.5638\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5580 - val_loss: 1.5612\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5574 - val_loss: 1.5610\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5576 - val_loss: 1.5617\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5579 - val_loss: 1.5613\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5574 - val_loss: 1.5618\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5516 - val_loss: 1.5553\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5507 - val_loss: 1.5552\n",
      "Top-2 accuracy = 0.522\n",
      "6\n",
      "maxabsr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.6032 - val_loss: 1.5987\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5938 - val_loss: 1.5926\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5884 - val_loss: 1.5894\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5856 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5842 - val_loss: 1.5875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "7\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6001 - val_loss: 1.5922\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5788 - val_loss: 1.5650\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5426 - val_loss: 1.5268\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5082 - val_loss: 1.4952\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4819 - val_loss: 1.4722\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4642 - val_loss: 1.4575\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4512 - val_loss: 1.4479\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4428 - val_loss: 1.4434\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.4410\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4338 - val_loss: 1.4397\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4320 - val_loss: 1.4301\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4298 - val_loss: 1.4290\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4369\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4307 - val_loss: 1.4332\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4286 - val_loss: 1.4313\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 1.4294\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4262 - val_loss: 1.4268\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4261 - val_loss: 1.4269\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4259 - val_loss: 1.4308\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4260 - val_loss: 1.4351\n",
      "Top-2 accuracy = 0.598\n",
      "8\n",
      "maxabsU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5878 - val_loss: 1.5577\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5223 - val_loss: 1.5097\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4898 - val_loss: 1.4799\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4694 - val_loss: 1.4642\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4571 - val_loss: 1.4552\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4496 - val_loss: 1.4516\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4459 - val_loss: 1.4464\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4425 - val_loss: 1.4473\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4381 - val_loss: 1.4411\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4346 - val_loss: 1.4363\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4333 - val_loss: 1.4355\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4328 - val_loss: 1.4330\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4313 - val_loss: 1.4346\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4308 - val_loss: 1.4323\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.4300\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.4292\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4300\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4284\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4269 - val_loss: 1.4295\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4291 - val_loss: 1.4306\n",
      "Top-2 accuracy = 0.606\n",
      "9\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5499 - val_loss: 1.4799\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4431 - val_loss: 1.4330\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4290 - val_loss: 1.4400\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4260 - val_loss: 1.4267\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4240 - val_loss: 1.4242\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4208 - val_loss: 1.4262\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4233 - val_loss: 1.4345\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4212 - val_loss: 1.4204\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4200 - val_loss: 1.4232\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4215 - val_loss: 1.4221\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4205 - val_loss: 1.4220\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4212 - val_loss: 1.4226\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4212 - val_loss: 1.4298\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4202 - val_loss: 1.4246\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4208 - val_loss: 1.4225\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4188 - val_loss: 1.4245\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4198 - val_loss: 1.4193\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4180 - val_loss: 1.4209\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4192 - val_loss: 1.4214\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4206 - val_loss: 1.4194\n",
      "Top-2 accuracy = 0.61\n",
      "10\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5795 - val_loss: 1.5526\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5180 - val_loss: 1.4831\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4595 - val_loss: 1.4470\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4401 - val_loss: 1.4350\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4350 - val_loss: 1.4347\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4320 - val_loss: 1.4330\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4308 - val_loss: 1.4312\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4303 - val_loss: 1.4303\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4292 - val_loss: 1.4273\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4280 - val_loss: 1.4260\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4278\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4270 - val_loss: 1.4257\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4266 - val_loss: 1.4255\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4258 - val_loss: 1.4249\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4259 - val_loss: 1.4279\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4256 - val_loss: 1.4247\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4251 - val_loss: 1.4269\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4261 - val_loss: 1.4321\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.4237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4241\n",
      "Top-2 accuracy = 0.608\n",
      "11\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5867 - val_loss: 1.5573\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5182 - val_loss: 1.4822\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4691 - val_loss: 1.4565\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4488 - val_loss: 1.4666\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4427 - val_loss: 1.4443\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4347 - val_loss: 1.4346\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4314 - val_loss: 1.4423\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4313 - val_loss: 1.4276\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4260 - val_loss: 1.4270\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4261\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4254 - val_loss: 1.4295\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4248 - val_loss: 1.4363\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4253 - val_loss: 1.4244\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4232 - val_loss: 1.4263\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4257 - val_loss: 1.4257\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4245 - val_loss: 1.4246\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4239 - val_loss: 1.4255\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4271 - val_loss: 1.4471\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4245 - val_loss: 1.4261\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4237 - val_loss: 1.4336\n",
      "Top-2 accuracy = 0.599\n",
      "12\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.6032 - val_loss: 1.5986\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5939 - val_loss: 1.5927\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5885 - val_loss: 1.5895\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5857 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Top-2 accuracy = 0.492\n",
      "13\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5569 - val_loss: 1.4942\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4612 - val_loss: 1.4394\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4344 - val_loss: 1.4309\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4263 - val_loss: 1.4280\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4239 - val_loss: 1.4246\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4216 - val_loss: 1.4268\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4230 - val_loss: 1.4299\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4210 - val_loss: 1.4228\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4200 - val_loss: 1.4315\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4240 - val_loss: 1.4258\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4210 - val_loss: 1.4242\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4212 - val_loss: 1.4211\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4199 - val_loss: 1.4203\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4188 - val_loss: 1.4264\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4191 - val_loss: 1.4211\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4198 - val_loss: 1.4245\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4181 - val_loss: 1.4212\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4183 - val_loss: 1.4208\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4174 - val_loss: 1.4206\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4171 - val_loss: 1.4210\n",
      "Top-2 accuracy = 0.612\n",
      "14\n",
      "standardizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5609 - val_loss: 1.4949\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4613 - val_loss: 1.4440\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4402 - val_loss: 1.4364\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4342 - val_loss: 1.4333\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4305 - val_loss: 1.4294\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4290 - val_loss: 1.4429\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4332 - val_loss: 1.4296\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4270 - val_loss: 1.4265\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4273 - val_loss: 1.4395\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4261 - val_loss: 1.4265\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4245 - val_loss: 1.4261\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4232 - val_loss: 1.4248\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4236 - val_loss: 1.4251\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4224 - val_loss: 1.4241\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4217 - val_loss: 1.4240\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4217 - val_loss: 1.4236\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4210 - val_loss: 1.4266\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4218 - val_loss: 1.4274\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4221 - val_loss: 1.4232\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4200 - val_loss: 1.4225\n",
      "Top-2 accuracy = 0.609\n",
      "15\n",
      "robusth|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5922 - val_loss: 1.5867\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5429 - val_loss: 1.5059\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5005 - val_loss: 1.5016\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5564 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5882\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5880\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5835 - val_loss: 1.5879\n",
      "Top-2 accuracy = 0.492\n",
      "16\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5884 - val_loss: 1.5889\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5835 - val_loss: 1.5880\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5834 - val_loss: 1.5882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5836 - val_loss: 1.5883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5836 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5836 - val_loss: 1.5878\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5835 - val_loss: 1.5879\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5835 - val_loss: 1.5883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5835 - val_loss: 1.5879\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5834 - val_loss: 1.5882\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.5835 - val_loss: 1.5882\n",
      "Top-2 accuracy = 0.492\n",
      "17\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.5481 - val_loss: 1.4674\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4377 - val_loss: 1.4288\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4272 - val_loss: 1.4253\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4251 - val_loss: 1.4257\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4228 - val_loss: 1.4237\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4228 - val_loss: 1.4291\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4226 - val_loss: 1.4216\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4212 - val_loss: 1.4224\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4209 - val_loss: 1.4212\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4200 - val_loss: 1.4223\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4194 - val_loss: 1.4275\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4225 - val_loss: 1.4200\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4185 - val_loss: 1.4256\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4205 - val_loss: 1.4213\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4180 - val_loss: 1.4212\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4180 - val_loss: 1.4201\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4173 - val_loss: 1.4194\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4190 - val_loss: 1.4200\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4176 - val_loss: 1.4330\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4228 - val_loss: 1.4207\n",
      "Top-2 accuracy = 0.609\n",
      "18\n",
      "standardizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 19ms/step - loss: 1.5719 - val_loss: 1.5426\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5100 - val_loss: 1.4973\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.4957 - val_loss: 1.5031\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5019 - val_loss: 1.5031\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5036 - val_loss: 1.5026\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4989 - val_loss: 1.4983\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4965 - val_loss: 1.4968\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4958 - val_loss: 1.4963\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4926 - val_loss: 1.4927\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4915 - val_loss: 1.4936\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4917 - val_loss: 1.4949\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4929 - val_loss: 1.4939\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4913 - val_loss: 1.4920\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.4907 - val_loss: 1.4920\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.4880 - val_loss: 1.4822\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.4812 - val_loss: 1.4813\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.4788 - val_loss: 1.4793\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.4777 - val_loss: 1.4761\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5407 - val_loss: 1.5881\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.5839 - val_loss: 1.5875\n",
      "Top-2 accuracy = 0.492\n",
      "19\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5348 - val_loss: 1.4798\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4524 - val_loss: 1.4371\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4345 - val_loss: 1.4321\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4283 - val_loss: 1.4290\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4275 - val_loss: 1.4249\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4265 - val_loss: 1.4357\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4259 - val_loss: 1.4268\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4256 - val_loss: 1.4262\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4243 - val_loss: 1.4241\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4244 - val_loss: 1.4355\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4251 - val_loss: 1.4248\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4232 - val_loss: 1.4250\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4234 - val_loss: 1.4248\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4221 - val_loss: 1.4247\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4223 - val_loss: 1.4251\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4221 - val_loss: 1.4244\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4219 - val_loss: 1.4291\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4225 - val_loss: 1.4264\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4222 - val_loss: 1.4252\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4208 - val_loss: 1.4271\n",
      "Top-2 accuracy = 0.605\n",
      "20\n",
      "robustw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.6031 - val_loss: 1.5986\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5939 - val_loss: 1.5926\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5886 - val_loss: 1.5895\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5857 - val_loss: 1.5881\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5843 - val_loss: 1.5876\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5875\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5833 - val_loss: 1.5877\n",
      "Top-2 accuracy = 0.492\n",
      "21\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5803 - val_loss: 1.5626\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5366 - val_loss: 1.5095\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4842 - val_loss: 1.4706\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4607 - val_loss: 1.4546\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4480 - val_loss: 1.4450\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4413 - val_loss: 1.4387\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4375 - val_loss: 1.4364\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4350 - val_loss: 1.4361\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4337 - val_loss: 1.4342\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4319 - val_loss: 1.4316\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4313 - val_loss: 1.4302\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4305 - val_loss: 1.4304\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4297 - val_loss: 1.4298\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4296 - val_loss: 1.4295\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4288 - val_loss: 1.4296\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4292\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4295\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4282 - val_loss: 1.4285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4285 - val_loss: 1.4287\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4273 - val_loss: 1.4281\n",
      "Top-2 accuracy = 0.606\n",
      "22\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5810 - val_loss: 1.5493\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5274 - val_loss: 1.5006\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4752 - val_loss: 1.4572\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4470 - val_loss: 1.4391\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4342 - val_loss: 1.4374\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.4282\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4275\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4275 - val_loss: 1.4266\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4255 - val_loss: 1.4281\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4243 - val_loss: 1.4304\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4242 - val_loss: 1.4396\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4240 - val_loss: 1.4284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4243 - val_loss: 1.4259\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4229 - val_loss: 1.4237\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4222 - val_loss: 1.4235\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4224 - val_loss: 1.4256\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4230 - val_loss: 1.4230\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4218 - val_loss: 1.4242\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4226 - val_loss: 1.4239\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4221 - val_loss: 1.4264\n",
      "Top-2 accuracy = 0.61\n",
      "23\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 20ms/step - loss: 1.5883 - val_loss: 1.5879\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5836 - val_loss: 1.5882\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5836 - val_loss: 1.5878\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5836 - val_loss: 1.5876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5836 - val_loss: 1.5878\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5835 - val_loss: 1.5879\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5835 - val_loss: 1.5880\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.5837 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5834 - val_loss: 1.5881\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5836 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5835 - val_loss: 1.5882\n",
      "Top-2 accuracy = 0.492\n",
      "24\n",
      "standardizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5655 - val_loss: 1.5473\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.5250 - val_loss: 1.5112\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4930 - val_loss: 1.4823\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4688 - val_loss: 1.4622\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4525 - val_loss: 1.4499\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4420 - val_loss: 1.4407\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4353 - val_loss: 1.4400\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4323 - val_loss: 1.4323\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4300 - val_loss: 1.4324\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4309 - val_loss: 1.4318\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4291 - val_loss: 1.4292\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4281 - val_loss: 1.4292\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4278 - val_loss: 1.4389\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4329 - val_loss: 1.4292\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4277 - val_loss: 1.4308\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4272 - val_loss: 1.4284\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4264 - val_loss: 1.4273\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4265 - val_loss: 1.4281\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4270 - val_loss: 1.4284\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.4271 - val_loss: 1.4280\n",
      "Top-2 accuracy = 0.607\n",
      "25\n",
      "minmaxY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.5970 - val_loss: 1.5881\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5821 - val_loss: 1.5607\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4828 - val_loss: 1.4579\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4370 - val_loss: 1.4369\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4299 - val_loss: 1.4339\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4291 - val_loss: 1.4425\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.4309\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4262 - val_loss: 1.4271\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4258 - val_loss: 1.4283\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4253 - val_loss: 1.4308\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4265 - val_loss: 1.4408\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4366 - val_loss: 1.4291\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4244 - val_loss: 1.4258\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4237 - val_loss: 1.4268\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4231 - val_loss: 1.4275\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4214 - val_loss: 1.4263\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4223 - val_loss: 1.4302\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4231 - val_loss: 1.4272\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4222 - val_loss: 1.4254\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4232 - val_loss: 1.4265\n",
      "Top-2 accuracy = 0.606\n",
      "26\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.6027 - val_loss: 1.5977\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5890 - val_loss: 1.5883\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5841 - val_loss: 1.5875\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5878\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5834 - val_loss: 1.5876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Top-2 accuracy = 0.492\n",
      "27\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 22ms/step - loss: 1.5964 - val_loss: 1.5898\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 1.5843 - val_loss: 1.5879\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 1.5835 - val_loss: 1.5881\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 1.5836 - val_loss: 1.5875\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 1.5837 - val_loss: 1.5875\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5835 - val_loss: 1.5880\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5836 - val_loss: 1.5878\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5835 - val_loss: 1.5876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.5835 - val_loss: 1.5878\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.5835 - val_loss: 1.5877\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.5835 - val_loss: 1.5875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.5834 - val_loss: 1.5874\n",
      "Top-2 accuracy = 0.492\n",
      "28\n",
      "maxabsR|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 10ms/step - loss: 1.5958 - val_loss: 1.5865\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5495 - val_loss: 1.5096\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5238 - val_loss: 1.4917\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4707 - val_loss: 1.4600\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4501 - val_loss: 1.4561\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4455 - val_loss: 1.4431\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4441 - val_loss: 1.4467\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4398 - val_loss: 1.4400\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4375 - val_loss: 1.4380\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4343 - val_loss: 1.4332\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4313 - val_loss: 1.4291\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4286 - val_loss: 1.4289\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4272 - val_loss: 1.4410\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4319 - val_loss: 1.4302\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.4268 - val_loss: 1.4428\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4298 - val_loss: 1.4302\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4278 - val_loss: 1.4297\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.4262 - val_loss: 1.4261\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.4266 - val_loss: 1.4250\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4251 - val_loss: 1.4285\n",
      "Top-2 accuracy = 0.61\n",
      "29\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 1.5833 - val_loss: 1.5568\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.5293 - val_loss: 1.5060\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4904 - val_loss: 1.4773\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.4685 - val_loss: 1.4620\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4540 - val_loss: 1.4483\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4441 - val_loss: 1.4431\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4392 - val_loss: 1.4378\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4325 - val_loss: 1.4310\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4310 - val_loss: 1.4401\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4292 - val_loss: 1.4285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4259 - val_loss: 1.4296\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4253 - val_loss: 1.4268\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4250 - val_loss: 1.4275\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4231 - val_loss: 1.4243\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4229 - val_loss: 1.4237\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4230 - val_loss: 1.4286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4254 - val_loss: 1.4264\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4222 - val_loss: 1.4234\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4215 - val_loss: 1.4238\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.4221 - val_loss: 1.4225\n",
      "Top-2 accuracy = 0.613\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"accuracy\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [MulticlassDL(n_classes=5, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20)],\n",
    "    \"post_train_hooks\": [top2_hook],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"chromium-5class\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        MulticlassDL(n_classes=5, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.35783669504599736\n",
      "Top-2 Accuracy: 0.6135077995543112\n"
     ]
    }
   ],
   "source": [
    "interp = DODGEInterpreter(files=['./chromium-5class.txt'], max_by=0, \n",
    "                          metrics=['accuracy'])\n",
    "results = interp.interpret()['chromium-5class.txt']\n",
    "print('Top-1 Accuracy:', np.median(results['accuracy']))\n",
    "print('Top-2 Accuracy:', np.median(np.amax(np.array(top2).reshape(11,30), axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = np.where(data.y_train < 1, 0, np.where(data.y_train < 2, 1, np.where(data.y_train < 3, 2, np.where(data.y_train < 6, 3, np.where(data.y_train < 11, 4, np.where(data.y_train < 21, 5, 6))))))\n",
    "data.y_test = np.where(data.y_test < 1, 0, np.where(data.y_test < 2, 1, np.where(data.y_test < 3, 2, np.where(data.y_test < 6, 3, np.where(data.y_test < 11, 4, np.where(data.y_test < 21, 5, 6))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y_train = to_categorical(data.y_train, num_classes=7)\n",
    "data.y_test = to_categorical(data.y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170bde670>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170bde340>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741196d0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741199a0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x164a72040>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740a0b80>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174119b20>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174119490>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741191c0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174119460>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174119eb0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17401cd00>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x15a0fba90>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162598520>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162598eb0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162598190>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x162598850>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x16a798f10>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x170ba8850>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17408f520>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17408f9d0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17408fd90>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17408f0a0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17408f280>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17408fbe0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17408f100>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741210a0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174121a00>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741219a0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174121730>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174121d30>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1741218b0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174121160>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x161f491c0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17411d3d0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17411d040>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17411dfa0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17411d2b0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17411d640>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17411d160>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x17411dd60>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 2, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740893a0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174089790>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x174089b80>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740892e0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740f5d00>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740f5d30>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740f54c0>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740f5b80>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 5, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740f5b20>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 3, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x1740f5c40>, 'loss': 'categorical_crossentropy', 'n_classes': 7, 'n_epochs': 20, 'n_layers': 4, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robustf|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3233 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9502 - val_loss: 1.9098\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8851 - val_loss: 1.8638\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8419 - val_loss: 1.8261\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8101 - val_loss: 1.8045\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7927 - val_loss: 1.7931\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7827 - val_loss: 1.7863\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7767 - val_loss: 1.7815\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7717 - val_loss: 1.7770\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7678 - val_loss: 1.7740\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7649 - val_loss: 1.7716\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7625 - val_loss: 1.7695\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7605 - val_loss: 1.7683\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7586 - val_loss: 1.7667\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7651\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7559 - val_loss: 1.7640\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7546 - val_loss: 1.7638\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7536 - val_loss: 1.7626\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7526 - val_loss: 1.7618\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7518 - val_loss: 1.7610\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7511 - val_loss: 1.7599\n",
      "Top-2 accuracy = 0.468\n",
      "1\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3236 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9258 - val_loss: 1.9054\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8903 - val_loss: 1.8735\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8656 - val_loss: 1.8541\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8498 - val_loss: 1.8413\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8386 - val_loss: 1.8329\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8310 - val_loss: 1.8270\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8251 - val_loss: 1.8222\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8199 - val_loss: 1.8183\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8157 - val_loss: 1.8149\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8120 - val_loss: 1.8121\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8091 - val_loss: 1.8090\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8057 - val_loss: 1.8065\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8026 - val_loss: 1.8039\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7993 - val_loss: 1.8011\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7964 - val_loss: 1.7984\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7939 - val_loss: 1.7965\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7916 - val_loss: 1.7947\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7894 - val_loss: 1.7928\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7878 - val_loss: 1.7914\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7859 - val_loss: 1.7902\n",
      "Top-2 accuracy = 0.455\n",
      "2\n",
      "robusth|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3239 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9642 - val_loss: 1.8738\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8467 - val_loss: 1.8208\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8071 - val_loss: 1.7980\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7887 - val_loss: 1.7864\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7789 - val_loss: 1.7803\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7720 - val_loss: 1.7754\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7670 - val_loss: 1.7706\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7627 - val_loss: 1.7685\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7600 - val_loss: 1.7651\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7566 - val_loss: 1.7637\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7545 - val_loss: 1.7616\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7531 - val_loss: 1.7608\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7516 - val_loss: 1.7599\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7504 - val_loss: 1.7594\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7496 - val_loss: 1.7591\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7486 - val_loss: 1.7576\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7482 - val_loss: 1.7576\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7479 - val_loss: 1.7566\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7471 - val_loss: 1.7569\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7469 - val_loss: 1.7560\n",
      "Top-2 accuracy = 0.479\n",
      "3\n",
      "robustX|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3242 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9289 - val_loss: 1.9129\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8800 - val_loss: 1.8395\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8125 - val_loss: 1.8032\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7875\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7805\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7733 - val_loss: 1.7750\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7683 - val_loss: 1.7710\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7685\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7663\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7602 - val_loss: 1.7649\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7581 - val_loss: 1.7635\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7562 - val_loss: 1.7616\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7551 - val_loss: 1.7600\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7540 - val_loss: 1.7587\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7526 - val_loss: 1.7586\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7521 - val_loss: 1.7595\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7510 - val_loss: 1.7575\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7497 - val_loss: 1.7556\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7491 - val_loss: 1.7575\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7482 - val_loss: 1.7566\n",
      "Top-2 accuracy = 0.473\n",
      "4\n",
      "standardizej|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3249 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9369 - val_loss: 1.9257\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9079 - val_loss: 1.8872\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8752 - val_loss: 1.8653\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8569 - val_loss: 1.8502\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8435 - val_loss: 1.8386\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8325 - val_loss: 1.8295\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8242 - val_loss: 1.8232\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8177 - val_loss: 1.8174\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8128 - val_loss: 1.8140\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8091 - val_loss: 1.8103\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8058 - val_loss: 1.8077\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8031 - val_loss: 1.8055\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8006 - val_loss: 1.8032\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7982 - val_loss: 1.8013\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7960 - val_loss: 1.7992\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7938 - val_loss: 1.7969\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7914 - val_loss: 1.7946\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7891 - val_loss: 1.7922\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7868 - val_loss: 1.7901\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7847 - val_loss: 1.7880\n",
      "Top-2 accuracy = 0.46\n",
      "5\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3256 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9153 - val_loss: 1.8817\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8544 - val_loss: 1.8347\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8242 - val_loss: 1.8149\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8104 - val_loss: 1.8039\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7995 - val_loss: 1.7957\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7923 - val_loss: 1.7919\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7874 - val_loss: 1.7860\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7833 - val_loss: 1.7847\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7826\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7797 - val_loss: 1.7823\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7813\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7769 - val_loss: 1.7806\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7761 - val_loss: 1.7802\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7805\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7776\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7738 - val_loss: 1.7779\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7724 - val_loss: 1.7765\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7765\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7759\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7748\n",
      "Top-2 accuracy = 0.456\n",
      "6\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3263 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9594 - val_loss: 1.9180\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8974 - val_loss: 1.8824\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8701 - val_loss: 1.8611\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8520 - val_loss: 1.8467\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8399 - val_loss: 1.8382\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8320 - val_loss: 1.8316\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8258 - val_loss: 1.8242\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8178 - val_loss: 1.8176\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8129 - val_loss: 1.8140\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8097 - val_loss: 1.8114\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8070 - val_loss: 1.8094\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8048 - val_loss: 1.8072\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8030 - val_loss: 1.8058\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8012 - val_loss: 1.8044\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7994 - val_loss: 1.8028\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7978 - val_loss: 1.8016\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7962 - val_loss: 1.8003\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7949 - val_loss: 1.7989\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7935 - val_loss: 1.7981\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7921 - val_loss: 1.7964\n",
      "Top-2 accuracy = 0.449\n",
      "7\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9079 - val_loss: 1.8503\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8204 - val_loss: 1.7989\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7841 - val_loss: 1.7762\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7697 - val_loss: 1.7712\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7650 - val_loss: 1.7685\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7629 - val_loss: 1.7660\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7699\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7599 - val_loss: 1.7655\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7639\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7576 - val_loss: 1.7622\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7556 - val_loss: 1.7616\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7547 - val_loss: 1.7603\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7540 - val_loss: 1.7636\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7546 - val_loss: 1.7719\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7536 - val_loss: 1.7629\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7528 - val_loss: 1.7588\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7524 - val_loss: 1.7619\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7508 - val_loss: 1.7647\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7503 - val_loss: 1.7566\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7483 - val_loss: 1.7571\n",
      "Top-2 accuracy = 0.47\n",
      "8\n",
      "normalizeu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3273 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9242 - val_loss: 1.8890\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8464 - val_loss: 1.8128\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7994 - val_loss: 1.7924\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7848 - val_loss: 1.7855\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7792\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7767\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7687 - val_loss: 1.7732\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7659 - val_loss: 1.7716\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7638 - val_loss: 1.7699\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7681\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7606 - val_loss: 1.7672\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7591 - val_loss: 1.7658\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7586 - val_loss: 1.7651\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7572 - val_loss: 1.7640\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7561 - val_loss: 1.7632\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7555 - val_loss: 1.7634\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7547 - val_loss: 1.7629\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7543 - val_loss: 1.7622\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7542 - val_loss: 1.7618\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7528 - val_loss: 1.7613\n",
      "Top-2 accuracy = 0.473\n",
      "9\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3278 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9152 - val_loss: 1.8788\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8525 - val_loss: 1.8350\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8168 - val_loss: 1.8094\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7966 - val_loss: 1.7959\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7863 - val_loss: 1.7879\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7792 - val_loss: 1.7830\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7788\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7700 - val_loss: 1.7749\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7665 - val_loss: 1.7726\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7641 - val_loss: 1.7708\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7621 - val_loss: 1.7694\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7605 - val_loss: 1.7685\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7589 - val_loss: 1.7672\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7577 - val_loss: 1.7672\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7568 - val_loss: 1.7658\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7557 - val_loss: 1.7649\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7549 - val_loss: 1.7641\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7541 - val_loss: 1.7636\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7537 - val_loss: 1.7630\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7531 - val_loss: 1.7626\n",
      "Top-2 accuracy = 0.474\n",
      "10\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3282 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9023 - val_loss: 1.8550\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8276 - val_loss: 1.8237\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8074 - val_loss: 1.8055\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7983 - val_loss: 1.7959\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7955\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7894 - val_loss: 1.7915\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7881\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7824 - val_loss: 1.7833\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7790 - val_loss: 1.7811\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7771 - val_loss: 1.7796\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7746 - val_loss: 1.7773\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7774\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7704 - val_loss: 1.7749\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7671 - val_loss: 1.7718\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7661 - val_loss: 1.7707\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7700\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7681\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7604 - val_loss: 1.7756\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7666\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7591 - val_loss: 1.7659\n",
      "Top-2 accuracy = 0.468\n",
      "11\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3288 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9418 - val_loss: 1.8826\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8472 - val_loss: 1.8280\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8072 - val_loss: 1.8041\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7896 - val_loss: 1.7928\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7810 - val_loss: 1.7893\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7757 - val_loss: 1.7823\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7717 - val_loss: 1.7790\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7688 - val_loss: 1.7770\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7660 - val_loss: 1.7743\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7634 - val_loss: 1.7726\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7614 - val_loss: 1.7716\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7589 - val_loss: 1.7692\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7690\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7554 - val_loss: 1.7672\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7540 - val_loss: 1.7669\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7531 - val_loss: 1.7653\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7518 - val_loss: 1.7647\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7505 - val_loss: 1.7633\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7497 - val_loss: 1.7632\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7490 - val_loss: 1.7622\n",
      "Top-2 accuracy = 0.475\n",
      "12\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3292 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9073 - val_loss: 1.8682\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8335 - val_loss: 1.8134\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7997 - val_loss: 1.7964\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7876 - val_loss: 1.7874\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7816\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7725 - val_loss: 1.7767\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7745\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7717\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7617 - val_loss: 1.7691\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7594 - val_loss: 1.7674\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7579 - val_loss: 1.7661\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7569 - val_loss: 1.7655\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7557 - val_loss: 1.7653\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7547 - val_loss: 1.7656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7546 - val_loss: 1.7645\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7538 - val_loss: 1.7637\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7528 - val_loss: 1.7645\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7520 - val_loss: 1.7631\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7515 - val_loss: 1.7647\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7519 - val_loss: 1.7618\n",
      "Top-2 accuracy = 0.473\n",
      "13\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3298 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9367 - val_loss: 1.9336\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9279 - val_loss: 1.9281\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9218 - val_loss: 1.9184\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9066 - val_loss: 1.8985\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8850 - val_loss: 1.8748\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8637 - val_loss: 1.8556\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8485 - val_loss: 1.8433\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8354 - val_loss: 1.8305\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8243 - val_loss: 1.8204\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8150 - val_loss: 1.8127\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8079 - val_loss: 1.8069\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8018 - val_loss: 1.8019\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7967 - val_loss: 1.7972\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7918 - val_loss: 1.7935\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7885 - val_loss: 1.7916\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7868 - val_loss: 1.7902\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7855 - val_loss: 1.7905\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7850 - val_loss: 1.7885\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7844 - val_loss: 1.7888\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7843 - val_loss: 1.7879\n",
      "Top-2 accuracy = 0.456\n",
      "14\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9107 - val_loss: 1.8774\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8476 - val_loss: 1.8319\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8059 - val_loss: 1.7929\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7809 - val_loss: 1.7814\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7732 - val_loss: 1.7758\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7695 - val_loss: 1.7732\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7670 - val_loss: 1.7713\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7700\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7692\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7688\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7614 - val_loss: 1.7678\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7604 - val_loss: 1.7673\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7596 - val_loss: 1.7662\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7585 - val_loss: 1.7655\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7578 - val_loss: 1.7657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7573 - val_loss: 1.7647\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7568 - val_loss: 1.7644\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7558 - val_loss: 1.7626\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7546 - val_loss: 1.7634\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7545 - val_loss: 1.7619\n",
      "Top-2 accuracy = 0.473\n",
      "15\n",
      "maxabsf|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3308 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9046 - val_loss: 1.8526\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8139 - val_loss: 1.7923\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7824 - val_loss: 1.7796\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7723\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7667 - val_loss: 1.7690\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7626 - val_loss: 1.7664\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7601 - val_loss: 1.7647\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7576 - val_loss: 1.7631\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7558 - val_loss: 1.7613\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7544 - val_loss: 1.7605\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7536 - val_loss: 1.7600\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7525 - val_loss: 1.7603\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7515 - val_loss: 1.7591\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7505 - val_loss: 1.7595\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7499 - val_loss: 1.7572\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7497 - val_loss: 1.7569\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7487 - val_loss: 1.7576\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7482 - val_loss: 1.7563\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7472 - val_loss: 1.7568\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7469 - val_loss: 1.7569\n",
      "Top-2 accuracy = 0.472\n",
      "16\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3314 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9362 - val_loss: 1.9037\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8779 - val_loss: 1.8622\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8391 - val_loss: 1.8271\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8129 - val_loss: 1.8091\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8002 - val_loss: 1.7997\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7917 - val_loss: 1.7923\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7855 - val_loss: 1.7872\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7829\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7800\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7733 - val_loss: 1.7773\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7703 - val_loss: 1.7745\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7678 - val_loss: 1.7728\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7653 - val_loss: 1.7706\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7633 - val_loss: 1.7688\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7616 - val_loss: 1.7673\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7603 - val_loss: 1.7664\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7591 - val_loss: 1.7651\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7580 - val_loss: 1.7645\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7569 - val_loss: 1.7636\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7559 - val_loss: 1.7631\n",
      "Top-2 accuracy = 0.479\n",
      "17\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3317 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9405 - val_loss: 1.9322\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9278 - val_loss: 1.9249\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9076 - val_loss: 1.8877\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8588 - val_loss: 1.8384\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8178 - val_loss: 1.8046\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7959 - val_loss: 1.7902\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7850 - val_loss: 1.7827\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7787 - val_loss: 1.7788\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7753 - val_loss: 1.7766\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7730 - val_loss: 1.7753\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7713 - val_loss: 1.7747\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7702 - val_loss: 1.7733\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7688 - val_loss: 1.7726\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7686 - val_loss: 1.7724\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7672 - val_loss: 1.7718\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7666 - val_loss: 1.7704\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7655 - val_loss: 1.7701\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7645 - val_loss: 1.7708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7650 - val_loss: 1.7689\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7634 - val_loss: 1.7687\n",
      "Top-2 accuracy = 0.465\n",
      "18\n",
      "maxabsa|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3324 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9145 - val_loss: 1.8787\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8358 - val_loss: 1.8116\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7960 - val_loss: 1.7947\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7853 - val_loss: 1.7874\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7782 - val_loss: 1.7826\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7730 - val_loss: 1.7772\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7686 - val_loss: 1.7737\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7655 - val_loss: 1.7716\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7631 - val_loss: 1.7697\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7607 - val_loss: 1.7674\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7592 - val_loss: 1.7663\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7578 - val_loss: 1.7646\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7563 - val_loss: 1.7641\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7551 - val_loss: 1.7632\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7543 - val_loss: 1.7623\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7532 - val_loss: 1.7616\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7524 - val_loss: 1.7608\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7517 - val_loss: 1.7612\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7511 - val_loss: 1.7601\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7504 - val_loss: 1.7592\n",
      "Top-2 accuracy = 0.477\n",
      "19\n",
      "robustg|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3328 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9690 - val_loss: 1.9058\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8769 - val_loss: 1.8578\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8377 - val_loss: 1.8244\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8133 - val_loss: 1.8082\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8019 - val_loss: 1.7998\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7947 - val_loss: 1.7936\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7894 - val_loss: 1.7890\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7852 - val_loss: 1.7859\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7812 - val_loss: 1.7823\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7800\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7756 - val_loss: 1.7783\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7735 - val_loss: 1.7765\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7711 - val_loss: 1.7742\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7694 - val_loss: 1.7732\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7679 - val_loss: 1.7722\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7711\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7652 - val_loss: 1.7703\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7641 - val_loss: 1.7694\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7631 - val_loss: 1.7686\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7621 - val_loss: 1.7677\n",
      "Top-2 accuracy = 0.47\n",
      "20\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3331 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9555 - val_loss: 1.8824\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8432 - val_loss: 1.8163\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7986 - val_loss: 1.7920\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7825 - val_loss: 1.7823\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7769\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7738\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7656 - val_loss: 1.7709\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7626 - val_loss: 1.7692\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7605 - val_loss: 1.7678\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7588 - val_loss: 1.7661\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7567 - val_loss: 1.7657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7559 - val_loss: 1.7644\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7546 - val_loss: 1.7642\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7533 - val_loss: 1.7629\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7523 - val_loss: 1.7624\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7516 - val_loss: 1.7620\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7509 - val_loss: 1.7614\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7501 - val_loss: 1.7600\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7495 - val_loss: 1.7616\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7488 - val_loss: 1.7605\n",
      "Top-2 accuracy = 0.474\n",
      "21\n",
      "minmaxb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3335 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9391 - val_loss: 1.9303\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9188 - val_loss: 1.9056\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8923 - val_loss: 1.8799\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8680 - val_loss: 1.8594\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8502 - val_loss: 1.8450\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8384 - val_loss: 1.8357\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8299 - val_loss: 1.8304\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8245 - val_loss: 1.8251\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8174 - val_loss: 1.8158\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8092 - val_loss: 1.8103\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8047 - val_loss: 1.8069\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8012 - val_loss: 1.8047\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7995 - val_loss: 1.8036\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7972 - val_loss: 1.8020\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7961 - val_loss: 1.8009\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7948 - val_loss: 1.8002\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7939 - val_loss: 1.7994\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7930 - val_loss: 1.7986\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7926 - val_loss: 1.7983\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7922 - val_loss: 1.7982\n",
      "Top-2 accuracy = 0.451\n",
      "22\n",
      "normalizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9286 - val_loss: 1.9026\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8542 - val_loss: 1.8219\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8037 - val_loss: 1.8002\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7925\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7849 - val_loss: 1.7867\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7834\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7774 - val_loss: 1.7814\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7753 - val_loss: 1.7797\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7735 - val_loss: 1.7798\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7790\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7719 - val_loss: 1.7780\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7770\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7700 - val_loss: 1.7755\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7688 - val_loss: 1.7749\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7746\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7758\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7671 - val_loss: 1.7724\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7661 - val_loss: 1.7714\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7654 - val_loss: 1.7714\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7652 - val_loss: 1.7725\n",
      "Top-2 accuracy = 0.471\n",
      "23\n",
      "robustm|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3345 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9344 - val_loss: 1.9252\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9144 - val_loss: 1.9053\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8862 - val_loss: 1.8764\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8526 - val_loss: 1.8359\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8126 - val_loss: 1.8053\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7925 - val_loss: 1.7967\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7849 - val_loss: 1.7896\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7797 - val_loss: 1.7843\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7745 - val_loss: 1.7806\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7715 - val_loss: 1.7775\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7699 - val_loss: 1.7767\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7666 - val_loss: 1.7737\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7647 - val_loss: 1.7722\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7634 - val_loss: 1.7705\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7626 - val_loss: 1.7695\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7606 - val_loss: 1.7692\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7602 - val_loss: 1.7690\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7598 - val_loss: 1.7665\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7582 - val_loss: 1.7660\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7574 - val_loss: 1.7657\n",
      "Top-2 accuracy = 0.47\n",
      "24\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3351 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9165 - val_loss: 1.8837\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8409 - val_loss: 1.8098\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7959 - val_loss: 1.7879\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7805 - val_loss: 1.7792\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7724 - val_loss: 1.7749\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7681 - val_loss: 1.7707\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7643 - val_loss: 1.7683\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7614 - val_loss: 1.7661\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7596 - val_loss: 1.7651\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7573 - val_loss: 1.7647\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7561 - val_loss: 1.7627\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7548 - val_loss: 1.7624\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7539 - val_loss: 1.7617\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7530 - val_loss: 1.7607\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7520 - val_loss: 1.7599\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7516 - val_loss: 1.7594\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7507 - val_loss: 1.7586\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7497 - val_loss: 1.7603\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7492 - val_loss: 1.7593\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7492 - val_loss: 1.7589\n",
      "Top-2 accuracy = 0.473\n",
      "25\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3356 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9396 - val_loss: 1.9341\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9292 - val_loss: 1.9294\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9258 - val_loss: 1.9279\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9237 - val_loss: 1.9253\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9199 - val_loss: 1.9207\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9121 - val_loss: 1.9091\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8961 - val_loss: 1.8883\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8704 - val_loss: 1.8611\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8492 - val_loss: 1.8473\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8379 - val_loss: 1.8371\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8304 - val_loss: 1.8304\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8246 - val_loss: 1.8248\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8200 - val_loss: 1.8204\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8157 - val_loss: 1.8167\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8120 - val_loss: 1.8139\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8087 - val_loss: 1.8113\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8064 - val_loss: 1.8082\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8030 - val_loss: 1.8059\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8004 - val_loss: 1.8042\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7985 - val_loss: 1.8018\n",
      "Top-2 accuracy = 0.46\n",
      "26\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3363 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9034\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8699 - val_loss: 1.8410\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8210 - val_loss: 1.8148\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8026 - val_loss: 1.8025\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7938 - val_loss: 1.7963\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7884 - val_loss: 1.7918\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7839 - val_loss: 1.7879\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7804 - val_loss: 1.7861\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7775 - val_loss: 1.7829\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7748 - val_loss: 1.7810\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7724 - val_loss: 1.7791\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7703 - val_loss: 1.7775\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7766\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7755\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7746\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7652 - val_loss: 1.7731\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7646 - val_loss: 1.7724\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7633 - val_loss: 1.7721\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7628 - val_loss: 1.7712\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7622 - val_loss: 1.7706\n",
      "Top-2 accuracy = 0.466\n",
      "27\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3369 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9352 - val_loss: 1.9301\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9252 - val_loss: 1.9254\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9157 - val_loss: 1.9065\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8832 - val_loss: 1.8657\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8463 - val_loss: 1.8332\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8195 - val_loss: 1.8120\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8043 - val_loss: 1.8020\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7968 - val_loss: 1.7959\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7926 - val_loss: 1.7930\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7890 - val_loss: 1.7898\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7860 - val_loss: 1.7871\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7835 - val_loss: 1.7861\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7813 - val_loss: 1.7834\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7796 - val_loss: 1.7813\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7771 - val_loss: 1.7810\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7753 - val_loss: 1.7795\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7736 - val_loss: 1.7777\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7717 - val_loss: 1.7755\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7707 - val_loss: 1.7744\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7697 - val_loss: 1.7738\n",
      "Top-2 accuracy = 0.464\n",
      "28\n",
      "standardizeA|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3375 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9293 - val_loss: 1.9202\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8980 - val_loss: 1.8800\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8477 - val_loss: 1.8287\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8095 - val_loss: 1.8037\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7929 - val_loss: 1.7936\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7848 - val_loss: 1.7868\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7828\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7764 - val_loss: 1.7798\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7741 - val_loss: 1.7782\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7722 - val_loss: 1.7758\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7702 - val_loss: 1.7745\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7688 - val_loss: 1.7732\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7675 - val_loss: 1.7716\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7661 - val_loss: 1.7708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7653 - val_loss: 1.7697\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7642 - val_loss: 1.7688\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7634 - val_loss: 1.7681\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7626 - val_loss: 1.7680\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7616 - val_loss: 1.7670\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7608 - val_loss: 1.7670\n",
      "Top-2 accuracy = 0.469\n",
      "29\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9184 - val_loss: 1.8695\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8260 - val_loss: 1.8106\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7899\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7801 - val_loss: 1.7866\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7739 - val_loss: 1.7794\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7696 - val_loss: 1.7763\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7669 - val_loss: 1.7729\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7652 - val_loss: 1.7714\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7640 - val_loss: 1.7738\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7702\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7683\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7611 - val_loss: 1.7680\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7607 - val_loss: 1.7676\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7687\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7582 - val_loss: 1.7673\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7587 - val_loss: 1.7669\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7573 - val_loss: 1.7672\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7571 - val_loss: 1.7667\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7569 - val_loss: 1.7672\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7570 - val_loss: 1.7659\n",
      "Top-2 accuracy = 0.47\n",
      "0\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9307 - val_loss: 1.8982\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8579 - val_loss: 1.8218\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8024 - val_loss: 1.7897\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7807 - val_loss: 1.7796\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7747\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7688 - val_loss: 1.7734\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7715\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7698\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7643 - val_loss: 1.7693\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7683\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7676\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7611 - val_loss: 1.7675\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7604 - val_loss: 1.7668\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7602 - val_loss: 1.7656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7596 - val_loss: 1.7671\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7601 - val_loss: 1.7652\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7653\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7649\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7585 - val_loss: 1.7655\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7587 - val_loss: 1.7646\n",
      "Top-2 accuracy = 0.467\n",
      "1\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3392 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9052 - val_loss: 1.8617\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8316 - val_loss: 1.8205\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8075 - val_loss: 1.8068\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7976 - val_loss: 1.7992\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7921 - val_loss: 1.7948\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7884 - val_loss: 1.7923\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7855 - val_loss: 1.7896\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7829 - val_loss: 1.7874\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7810 - val_loss: 1.7856\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7791 - val_loss: 1.7838\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7775 - val_loss: 1.7836\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7757 - val_loss: 1.7813\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7740 - val_loss: 1.7794\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7729 - val_loss: 1.7784\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7700 - val_loss: 1.7757\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7691 - val_loss: 1.7746\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7678 - val_loss: 1.7736\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7674 - val_loss: 1.7733\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7661 - val_loss: 1.7723\n",
      "Top-2 accuracy = 0.466\n",
      "2\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3398 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.8894\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8551 - val_loss: 1.8286\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8158 - val_loss: 1.8082\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7984 - val_loss: 1.7960\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7874 - val_loss: 1.7882\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7852\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7769 - val_loss: 1.7816\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7737 - val_loss: 1.7791\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7713 - val_loss: 1.7772\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7756\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7667 - val_loss: 1.7737\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7653 - val_loss: 1.7720\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7641 - val_loss: 1.7716\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7695\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7675\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7597 - val_loss: 1.7660\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7650\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7575 - val_loss: 1.7644\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7564 - val_loss: 1.7639\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7558 - val_loss: 1.7629\n",
      "Top-2 accuracy = 0.473\n",
      "3\n",
      "normalizeV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3402 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9403 - val_loss: 1.9249\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9108 - val_loss: 1.8972\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8775 - val_loss: 1.8619\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8450 - val_loss: 1.8343\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8222 - val_loss: 1.8176\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8093 - val_loss: 1.8078\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8013 - val_loss: 1.8021\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7958 - val_loss: 1.7976\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7940\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7881 - val_loss: 1.7915\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7847 - val_loss: 1.7888\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7818 - val_loss: 1.7862\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7795 - val_loss: 1.7844\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7771 - val_loss: 1.7842\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7761 - val_loss: 1.7809\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7738 - val_loss: 1.7797\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7785\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7711 - val_loss: 1.7772\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7700 - val_loss: 1.7763\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7756\n",
      "Top-2 accuracy = 0.467\n",
      "4\n",
      "normalizeL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3406 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9035\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8711 - val_loss: 1.8502\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8295 - val_loss: 1.8225\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8109 - val_loss: 1.8100\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8034 - val_loss: 1.8043\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7987 - val_loss: 1.8002\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7950 - val_loss: 1.7970\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7915 - val_loss: 1.7924\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7886 - val_loss: 1.7892\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7848 - val_loss: 1.7855\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7820 - val_loss: 1.7828\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7797 - val_loss: 1.7807\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7776 - val_loss: 1.7801\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7759 - val_loss: 1.7779\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7744 - val_loss: 1.7760\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7732 - val_loss: 1.7747\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7716 - val_loss: 1.7744\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7703 - val_loss: 1.7735\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7700 - val_loss: 1.7721\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7687 - val_loss: 1.7709\n",
      "Top-2 accuracy = 0.468\n",
      "5\n",
      "maxabsZ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3413 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9357 - val_loss: 1.9204\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8981 - val_loss: 1.8718\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8499 - val_loss: 1.8322\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8213 - val_loss: 1.8171\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8104 - val_loss: 1.8101\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8046 - val_loss: 1.8064\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8005 - val_loss: 1.8030\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7975 - val_loss: 1.8009\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7949 - val_loss: 1.7990\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7929 - val_loss: 1.7977\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7908 - val_loss: 1.7962\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7892 - val_loss: 1.7947\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7874 - val_loss: 1.7934\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7858 - val_loss: 1.7924\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7844 - val_loss: 1.7910\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7831 - val_loss: 1.7893\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7813 - val_loss: 1.7885\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7801 - val_loss: 1.7864\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7790 - val_loss: 1.7852\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7778 - val_loss: 1.7851\n",
      "Top-2 accuracy = 0.458\n",
      "6\n",
      "standardizeY|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3419 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9573 - val_loss: 1.9349\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9267 - val_loss: 1.9200\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8964 - val_loss: 1.8653\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8412 - val_loss: 1.8228\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8134 - val_loss: 1.8079\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8024 - val_loss: 1.8011\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7962 - val_loss: 1.7964\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7918 - val_loss: 1.7927\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7881 - val_loss: 1.7901\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7849 - val_loss: 1.7874\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7816 - val_loss: 1.7850\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7782 - val_loss: 1.7814\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7752 - val_loss: 1.7796\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7727 - val_loss: 1.7774\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7702 - val_loss: 1.7763\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7681 - val_loss: 1.7741\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7661 - val_loss: 1.7726\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7643 - val_loss: 1.7712\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7627 - val_loss: 1.7695\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7611 - val_loss: 1.7688\n",
      "Top-2 accuracy = 0.469\n",
      "7\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9346 - val_loss: 1.9226\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8984 - val_loss: 1.8780\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8545 - val_loss: 1.8428\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8250 - val_loss: 1.8173\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8036 - val_loss: 1.7998\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7905 - val_loss: 1.7909\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7837 - val_loss: 1.7862\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7796 - val_loss: 1.7831\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7772 - val_loss: 1.7815\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7752 - val_loss: 1.7803\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7746 - val_loss: 1.7793\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7730 - val_loss: 1.7776\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7721 - val_loss: 1.7782\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7718 - val_loss: 1.7772\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7712 - val_loss: 1.7758\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7755\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7695 - val_loss: 1.7749\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7783\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7747\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7687 - val_loss: 1.7746\n",
      "Top-2 accuracy = 0.464\n",
      "8\n",
      "robustk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9318 - val_loss: 1.9190\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9041 - val_loss: 1.8920\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8722 - val_loss: 1.8544\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8303 - val_loss: 1.8172\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8080 - val_loss: 1.8083\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8019 - val_loss: 1.8047\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7985 - val_loss: 1.8018\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7962 - val_loss: 1.7994\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7934 - val_loss: 1.7968\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7911 - val_loss: 1.7946\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7892 - val_loss: 1.7923\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7867 - val_loss: 1.7898\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7847 - val_loss: 1.7879\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7830 - val_loss: 1.7865\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7853\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7810 - val_loss: 1.7839\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7794 - val_loss: 1.7831\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7786 - val_loss: 1.7823\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7776 - val_loss: 1.7813\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7768 - val_loss: 1.7807\n",
      "Top-2 accuracy = 0.46\n",
      "9\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9394 - val_loss: 1.9334\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9034 - val_loss: 1.8585\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8229 - val_loss: 1.8061\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7895\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7814\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7751 - val_loss: 1.7778\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7734 - val_loss: 1.7766\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7705 - val_loss: 1.7742\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7700 - val_loss: 1.7726\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7679 - val_loss: 1.7721\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7710\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7658 - val_loss: 1.7698\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7692\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7642 - val_loss: 1.7698\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7637 - val_loss: 1.7701\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7637 - val_loss: 1.7686\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7710\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7679\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7677\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7692\n",
      "Top-2 accuracy = 0.464\n",
      "10\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9384 - val_loss: 1.9334\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9011 - val_loss: 1.8377\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8038 - val_loss: 1.7838\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7762 - val_loss: 1.7805\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7699 - val_loss: 1.7713\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7680 - val_loss: 1.7772\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7661 - val_loss: 1.7694\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7650 - val_loss: 1.7684\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7637 - val_loss: 1.7679\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7627 - val_loss: 1.7677\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7625 - val_loss: 1.7661\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7613 - val_loss: 1.7645\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7611 - val_loss: 1.7674\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7596 - val_loss: 1.7640\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7592 - val_loss: 1.7641\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7591 - val_loss: 1.7654\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7593 - val_loss: 1.7644\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7584 - val_loss: 1.7637\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7577 - val_loss: 1.7662\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7583 - val_loss: 1.7658\n",
      "Top-2 accuracy = 0.461\n",
      "11\n",
      "normalizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9229 - val_loss: 1.9013\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8718 - val_loss: 1.8458\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8251 - val_loss: 1.8137\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8023 - val_loss: 1.7984\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7898 - val_loss: 1.7893\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7821 - val_loss: 1.7831\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7776 - val_loss: 1.7801\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7752 - val_loss: 1.7782\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7738 - val_loss: 1.7768\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7729 - val_loss: 1.7755\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7755\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7711 - val_loss: 1.7742\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7705 - val_loss: 1.7727\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7696 - val_loss: 1.7723\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7716\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7685 - val_loss: 1.7709\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7679 - val_loss: 1.7709\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7676 - val_loss: 1.7706\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7672 - val_loss: 1.7700\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7667 - val_loss: 1.7693\n",
      "Top-2 accuracy = 0.467\n",
      "12\n",
      "standardizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9129 - val_loss: 1.8611\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8173 - val_loss: 1.7850\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7748 - val_loss: 1.7740\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7676 - val_loss: 1.7762\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7669 - val_loss: 1.7731\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7681\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7624 - val_loss: 1.7716\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7617 - val_loss: 1.7686\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7606 - val_loss: 1.7684\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7601 - val_loss: 1.7678\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7594 - val_loss: 1.7665\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7586 - val_loss: 1.7679\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7590 - val_loss: 1.7675\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7581 - val_loss: 1.7653\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7580 - val_loss: 1.7651\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7576 - val_loss: 1.7655\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7571 - val_loss: 1.7698\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7594 - val_loss: 1.7640\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7569 - val_loss: 1.7664\n",
      "Top-2 accuracy = 0.468\n",
      "13\n",
      "robustf|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3453 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9046 - val_loss: 1.8642\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8309 - val_loss: 1.8144\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7994 - val_loss: 1.7975\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7883 - val_loss: 1.7906\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7828 - val_loss: 1.7860\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7787 - val_loss: 1.7836\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7757 - val_loss: 1.7805\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7731 - val_loss: 1.7789\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7708 - val_loss: 1.7776\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7691 - val_loss: 1.7758\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7671 - val_loss: 1.7752\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7657 - val_loss: 1.7734\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7644 - val_loss: 1.7724\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7634 - val_loss: 1.7713\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7718\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7614 - val_loss: 1.7702\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7602 - val_loss: 1.7689\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7589 - val_loss: 1.7695\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7678\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7577 - val_loss: 1.7673\n",
      "Top-2 accuracy = 0.47\n",
      "14\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9319 - val_loss: 1.9282\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9022 - val_loss: 1.8600\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8284 - val_loss: 1.8132\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7976 - val_loss: 1.7928\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7865 - val_loss: 1.7889\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7840\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7792 - val_loss: 1.7819\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7762 - val_loss: 1.7793\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7746 - val_loss: 1.7810\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7762\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7720 - val_loss: 1.7747\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7752\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7704 - val_loss: 1.7757\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7697 - val_loss: 1.7735\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7691 - val_loss: 1.7732\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7721\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7679 - val_loss: 1.7717\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7675 - val_loss: 1.7720\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7706\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7665 - val_loss: 1.7710\n",
      "Top-2 accuracy = 0.466\n",
      "15\n",
      "maxabsq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9387 - val_loss: 1.9322\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9177 - val_loss: 1.9033\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8724 - val_loss: 1.8526\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8361 - val_loss: 1.8323\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8239 - val_loss: 1.8246\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8179 - val_loss: 1.8216\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8144 - val_loss: 1.8175\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8117 - val_loss: 1.8145\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8091 - val_loss: 1.8125\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8072 - val_loss: 1.8111\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8055 - val_loss: 1.8093\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8037 - val_loss: 1.8078\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8019 - val_loss: 1.8062\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8007 - val_loss: 1.8050\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7992 - val_loss: 1.8034\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7975 - val_loss: 1.8023\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7962 - val_loss: 1.8010\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7946 - val_loss: 1.7997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7935 - val_loss: 1.7982\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7916 - val_loss: 1.7977\n",
      "Top-2 accuracy = 0.454\n",
      "16\n",
      "normalizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9376 - val_loss: 1.9329\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9290 - val_loss: 1.9294\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9264 - val_loss: 1.9284\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9253 - val_loss: 1.9283\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9253 - val_loss: 1.9283\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9252 - val_loss: 1.9280\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9245 - val_loss: 1.9278\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9233 - val_loss: 1.9246\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9183 - val_loss: 1.9169\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9048 - val_loss: 1.8979\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8847 - val_loss: 1.8774\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8641 - val_loss: 1.8625\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8531 - val_loss: 1.8570\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8474 - val_loss: 1.8504\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8433 - val_loss: 1.8478\n",
      "Top-2 accuracy = 0.439\n",
      "17\n",
      "normalizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9193 - val_loss: 1.8932\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8461 - val_loss: 1.8192\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8025 - val_loss: 1.7995\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7902 - val_loss: 1.8008\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7845 - val_loss: 1.8043\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7826 - val_loss: 1.7836\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7796 - val_loss: 1.7837\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7775 - val_loss: 1.7802\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7753 - val_loss: 1.7795\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.7772\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.7792\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7737 - val_loss: 1.7866\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7740 - val_loss: 1.7939\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7751 - val_loss: 1.7742\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7715 - val_loss: 1.7741\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7705 - val_loss: 1.7743\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7715 - val_loss: 1.7751\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7724 - val_loss: 1.7904\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7713 - val_loss: 1.7741\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7700 - val_loss: 1.7731\n",
      "Top-2 accuracy = 0.466\n",
      "18\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3473 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9232 - val_loss: 1.8994\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8757 - val_loss: 1.8587\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8415 - val_loss: 1.8330\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8233 - val_loss: 1.8207\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8142 - val_loss: 1.8146\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8086 - val_loss: 1.8108\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8044 - val_loss: 1.8071\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8015 - val_loss: 1.8051\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7989 - val_loss: 1.8044\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7978 - val_loss: 1.8006\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7959 - val_loss: 1.7994\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7943 - val_loss: 1.7992\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7939 - val_loss: 1.7980\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7918 - val_loss: 1.7960\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7904 - val_loss: 1.7952\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7895 - val_loss: 1.7943\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7885 - val_loss: 1.7929\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7877 - val_loss: 1.7916\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7862 - val_loss: 1.7908\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7853 - val_loss: 1.7898\n",
      "Top-2 accuracy = 0.465\n",
      "19\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9026 - val_loss: 1.8550\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8224 - val_loss: 1.7977\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7860 - val_loss: 1.7829\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7752 - val_loss: 1.7768\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7699 - val_loss: 1.7726\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7672 - val_loss: 1.7760\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7713\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7646 - val_loss: 1.7722\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7628 - val_loss: 1.7704\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7632 - val_loss: 1.7704\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7627 - val_loss: 1.7683\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7675\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7600 - val_loss: 1.7678\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7593 - val_loss: 1.7679\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7673\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7587 - val_loss: 1.7665\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7573 - val_loss: 1.7677\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7566 - val_loss: 1.7661\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7556 - val_loss: 1.7663\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7555 - val_loss: 1.7657\n",
      "Top-2 accuracy = 0.465\n",
      "20\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9242 - val_loss: 1.8883\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8585 - val_loss: 1.8384\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8231 - val_loss: 1.8156\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8051 - val_loss: 1.8044\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7956 - val_loss: 1.7970\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7894 - val_loss: 1.7912\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7854 - val_loss: 1.7885\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7821 - val_loss: 1.7853\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7814 - val_loss: 1.7850\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7794 - val_loss: 1.7876\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7793 - val_loss: 1.7819\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7783 - val_loss: 1.7821\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7776 - val_loss: 1.7800\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7759 - val_loss: 1.7795\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7798\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7737 - val_loss: 1.7783\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7736 - val_loss: 1.7781\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7730 - val_loss: 1.7770\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7730 - val_loss: 1.7779\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7721 - val_loss: 1.7766\n",
      "Top-2 accuracy = 0.466\n",
      "21\n",
      "robustw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9051 - val_loss: 1.8714\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8336 - val_loss: 1.8172\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7995 - val_loss: 1.7981\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7863 - val_loss: 1.7878\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7794 - val_loss: 1.7842\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7816\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7782\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7755\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7744\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7673 - val_loss: 1.7724\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7646 - val_loss: 1.7720\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7628 - val_loss: 1.7695\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7696\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7604 - val_loss: 1.7689\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7596 - val_loss: 1.7692\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7587 - val_loss: 1.7672\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7580 - val_loss: 1.7664\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7570 - val_loss: 1.7665\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7558 - val_loss: 1.7662\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7552 - val_loss: 1.7664\n",
      "Top-2 accuracy = 0.467\n",
      "22\n",
      "maxabsa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9146 - val_loss: 1.8711\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8336 - val_loss: 1.8121\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7954 - val_loss: 1.7887\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7815 - val_loss: 1.7840\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7757 - val_loss: 1.7767\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7717 - val_loss: 1.7758\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7711 - val_loss: 1.7725\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7688 - val_loss: 1.7720\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7670 - val_loss: 1.7712\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7664 - val_loss: 1.7712\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7643 - val_loss: 1.7698\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7641 - val_loss: 1.7704\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7681\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7730\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7655 - val_loss: 1.7669\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7621 - val_loss: 1.7672\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7612 - val_loss: 1.7661\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7601 - val_loss: 1.7662\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7600 - val_loss: 1.7670\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7597 - val_loss: 1.7667\n",
      "Top-2 accuracy = 0.463\n",
      "23\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9251 - val_loss: 1.8946\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8564 - val_loss: 1.8252\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8012 - val_loss: 1.7934\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7832 - val_loss: 1.7857\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7774 - val_loss: 1.7822\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.7797\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7777\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7758\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7676 - val_loss: 1.7746\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7737\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7652 - val_loss: 1.7731\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7640 - val_loss: 1.7716\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7633 - val_loss: 1.7712\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7704\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7690\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7604 - val_loss: 1.7690\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7599 - val_loss: 1.7675\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7590 - val_loss: 1.7665\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7578 - val_loss: 1.7669\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7574 - val_loss: 1.7651\n",
      "Top-2 accuracy = 0.473\n",
      "24\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8995 - val_loss: 1.8222\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7947 - val_loss: 1.7863\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7774 - val_loss: 1.7801\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7721 - val_loss: 1.7760\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7673 - val_loss: 1.7724\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7642 - val_loss: 1.7695\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7686\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7654\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7589 - val_loss: 1.7668\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7583 - val_loss: 1.7701\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7643\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7563 - val_loss: 1.7652\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7574 - val_loss: 1.7654\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7560 - val_loss: 1.7636\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7544 - val_loss: 1.7626\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7537 - val_loss: 1.7655\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7542 - val_loss: 1.7620\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7533 - val_loss: 1.7614\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7521 - val_loss: 1.7650\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7522 - val_loss: 1.7610\n",
      "Top-2 accuracy = 0.476\n",
      "25\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9332 - val_loss: 1.9207\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8968 - val_loss: 1.8722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8313 - val_loss: 1.8109\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7924 - val_loss: 1.7890\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7800 - val_loss: 1.7826\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7754 - val_loss: 1.7822\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7740 - val_loss: 1.7801\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7722 - val_loss: 1.7781\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7720 - val_loss: 1.7770\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7764\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7690 - val_loss: 1.7750\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7748\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7680 - val_loss: 1.7761\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7684 - val_loss: 1.7746\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7739\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7665 - val_loss: 1.7733\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7729\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7658 - val_loss: 1.7744\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7665 - val_loss: 1.7726\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7656 - val_loss: 1.7724\n",
      "Top-2 accuracy = 0.467\n",
      "26\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9227 - val_loss: 1.8713\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8097 - val_loss: 1.7889\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7810\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.7767\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7748\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7727\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7665 - val_loss: 1.7713\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7655 - val_loss: 1.7691\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7633 - val_loss: 1.7698\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7687\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7691\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7673\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7596 - val_loss: 1.7670\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7583 - val_loss: 1.7644\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7575 - val_loss: 1.7663\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7567 - val_loss: 1.7628\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7551 - val_loss: 1.7622\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7533 - val_loss: 1.7608\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7535 - val_loss: 1.7610\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7517 - val_loss: 1.7601\n",
      "Top-2 accuracy = 0.472\n",
      "27\n",
      "normalizeJ|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3516 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9234 - val_loss: 1.8952\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8705 - val_loss: 1.8514\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8295 - val_loss: 1.8165\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8023 - val_loss: 1.7986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7882 - val_loss: 1.7894\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7811 - val_loss: 1.7831\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7762 - val_loss: 1.7795\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7726 - val_loss: 1.7766\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7714 - val_loss: 1.7753\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7700 - val_loss: 1.7744\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7723\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7665 - val_loss: 1.7718\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7660 - val_loss: 1.7714\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7705\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7743\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7640 - val_loss: 1.7695\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7624 - val_loss: 1.7691\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7674\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7612 - val_loss: 1.7666\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7666\n",
      "Top-2 accuracy = 0.467\n",
      "28\n",
      "maxabsf|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3523 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9084 - val_loss: 1.8772\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8490 - val_loss: 1.8293\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8150 - val_loss: 1.8112\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8018 - val_loss: 1.8030\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7952 - val_loss: 1.7972\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7899 - val_loss: 1.7923\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7856 - val_loss: 1.7892\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7822 - val_loss: 1.7861\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7789 - val_loss: 1.7840\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7764 - val_loss: 1.7810\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7741 - val_loss: 1.7801\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7723 - val_loss: 1.7772\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7756\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7686 - val_loss: 1.7745\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7672 - val_loss: 1.7725\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7655 - val_loss: 1.7712\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7641 - val_loss: 1.7705\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7634 - val_loss: 1.7688\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7623 - val_loss: 1.7677\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7666\n",
      "Top-2 accuracy = 0.473\n",
      "29\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3527 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9259 - val_loss: 1.8924\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8586 - val_loss: 1.8277\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8148 - val_loss: 1.8081\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8035 - val_loss: 1.8036\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7997 - val_loss: 1.8029\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7975 - val_loss: 1.7979\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7928 - val_loss: 1.7948\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7903 - val_loss: 1.7937\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7871 - val_loss: 1.7897\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7838 - val_loss: 1.7864\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7808 - val_loss: 1.7837\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7794 - val_loss: 1.7841\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7787 - val_loss: 1.7849\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7813\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7742 - val_loss: 1.7840\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.7800\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7714 - val_loss: 1.7829\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7765\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7691 - val_loss: 1.7749\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7672 - val_loss: 1.7744\n",
      "Top-2 accuracy = 0.466\n",
      "0\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9363 - val_loss: 1.9221\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9009 - val_loss: 1.8765\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8506 - val_loss: 1.8340\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8188 - val_loss: 1.8148\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8015 - val_loss: 1.8048\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7988 - val_loss: 1.8028\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7994\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7886 - val_loss: 1.7994\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7916 - val_loss: 1.7967\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7873 - val_loss: 1.7953\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7852 - val_loss: 1.7937\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7846 - val_loss: 1.7936\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7841 - val_loss: 1.7945\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7832 - val_loss: 1.7939\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7834 - val_loss: 1.7915\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7826 - val_loss: 1.7914\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7828 - val_loss: 1.7911\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7917\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7854 - val_loss: 1.7931\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7881\n",
      "Top-2 accuracy = 0.46\n",
      "1\n",
      "robustj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9397 - val_loss: 1.9355\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9314 - val_loss: 1.9312\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9280 - val_loss: 1.9295\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9265 - val_loss: 1.9287\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9258 - val_loss: 1.9286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9256 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "2\n",
      "minmaxD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9325 - val_loss: 1.9293\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9249 - val_loss: 1.9258\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9029 - val_loss: 1.8735\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8417 - val_loss: 1.8267\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8090 - val_loss: 1.8080\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7985 - val_loss: 1.8005\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7930 - val_loss: 1.7976\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7898 - val_loss: 1.7954\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7893 - val_loss: 1.7973\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7872 - val_loss: 1.7937\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7848 - val_loss: 1.7922\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7902\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7829 - val_loss: 1.7896\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7823 - val_loss: 1.7888\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7808 - val_loss: 1.7874\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7790 - val_loss: 1.7858\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7767 - val_loss: 1.7830\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7757 - val_loss: 1.7819\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7745 - val_loss: 1.7831\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7736 - val_loss: 1.7828\n",
      "Top-2 accuracy = 0.462\n",
      "3\n",
      "normalizei|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3549 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9146 - val_loss: 1.8821\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8652 - val_loss: 1.8514\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8340 - val_loss: 1.8219\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8124 - val_loss: 1.8111\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8039 - val_loss: 1.8042\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8000 - val_loss: 1.8012\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7955 - val_loss: 1.8000\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7922 - val_loss: 1.7935\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7888 - val_loss: 1.7908\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7868 - val_loss: 1.7889\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7847 - val_loss: 1.7921\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7835 - val_loss: 1.7866\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7804 - val_loss: 1.7841\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7797 - val_loss: 1.7835\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7775 - val_loss: 1.7831\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7763 - val_loss: 1.7818\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7742 - val_loss: 1.7806\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7744 - val_loss: 1.7775\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7720 - val_loss: 1.7764\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7709 - val_loss: 1.7774\n",
      "Top-2 accuracy = 0.467\n",
      "4\n",
      "robustI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9199 - val_loss: 1.8850\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8633 - val_loss: 1.8553\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8432 - val_loss: 1.8396\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8240 - val_loss: 1.8223\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8042 - val_loss: 1.8014\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7858 - val_loss: 1.7888\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7772\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7730\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7646 - val_loss: 1.7691\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7679\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7662\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7586 - val_loss: 1.7660\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7570 - val_loss: 1.7649\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7562 - val_loss: 1.7647\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7553 - val_loss: 1.7650\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7547 - val_loss: 1.7633\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7537 - val_loss: 1.7628\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7537 - val_loss: 1.7629\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7524 - val_loss: 1.7640\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7524 - val_loss: 1.7629\n",
      "Top-2 accuracy = 0.472\n",
      "5\n",
      "minmaxO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9371 - val_loss: 1.9311\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9257 - val_loss: 1.9251\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9144 - val_loss: 1.9069\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8887 - val_loss: 1.8825\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8688 - val_loss: 1.8670\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8561 - val_loss: 1.8564\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8472 - val_loss: 1.8489\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8409 - val_loss: 1.8439\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8356 - val_loss: 1.8392\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8316 - val_loss: 1.8358\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8285 - val_loss: 1.8328\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8258 - val_loss: 1.8316\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8237 - val_loss: 1.8288\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8216 - val_loss: 1.8267\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8200 - val_loss: 1.8253\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8184 - val_loss: 1.8237\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8169 - val_loss: 1.8226\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8159 - val_loss: 1.8216\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8147 - val_loss: 1.8209\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8139 - val_loss: 1.8196\n",
      "Top-2 accuracy = 0.449\n",
      "6\n",
      "minmaxW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9295 - val_loss: 1.9286\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9250 - val_loss: 1.9271\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9082 - val_loss: 1.8641\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8212 - val_loss: 1.8065\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8031 - val_loss: 1.8031\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7973 - val_loss: 1.8007\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7947 - val_loss: 1.7982\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7921 - val_loss: 1.7946\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7896 - val_loss: 1.7927\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7865 - val_loss: 1.7894\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7837 - val_loss: 1.7889\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7823 - val_loss: 1.7843\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7822\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7765 - val_loss: 1.7824\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7745 - val_loss: 1.7785\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7747 - val_loss: 1.7858\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7759\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7748\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7679 - val_loss: 1.7751\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7748\n",
      "Top-2 accuracy = 0.466\n",
      "7\n",
      "normalizec|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3570 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9083 - val_loss: 1.8645\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8428 - val_loss: 1.8288\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8193 - val_loss: 1.8124\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8074 - val_loss: 1.8043\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7996 - val_loss: 1.7992\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7947 - val_loss: 1.7953\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7908 - val_loss: 1.7943\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7878 - val_loss: 1.7909\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7849 - val_loss: 1.7885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7826 - val_loss: 1.7877\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7802 - val_loss: 1.7855\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7796 - val_loss: 1.7852\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7765 - val_loss: 1.7814\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7746 - val_loss: 1.7807\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7721 - val_loss: 1.7782\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7705 - val_loss: 1.7775\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7690 - val_loss: 1.7770\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7682 - val_loss: 1.7770\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7669 - val_loss: 1.7742\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7656 - val_loss: 1.7744\n",
      "Top-2 accuracy = 0.469\n",
      "8\n",
      "minmaxF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9218 - val_loss: 1.8889\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8404 - val_loss: 1.8114\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7971 - val_loss: 1.8041\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7884 - val_loss: 1.7954\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7849 - val_loss: 1.7889\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7814 - val_loss: 1.7868\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7792 - val_loss: 1.7833\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7765 - val_loss: 1.7806\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7807\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7754 - val_loss: 1.7797\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7726 - val_loss: 1.7803\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7731 - val_loss: 1.7779\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7712 - val_loss: 1.7764\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7791\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7731 - val_loss: 1.7748\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7691 - val_loss: 1.7754\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7684 - val_loss: 1.7734\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7755\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7673 - val_loss: 1.7733\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7672 - val_loss: 1.7716\n",
      "Top-2 accuracy = 0.466\n",
      "9\n",
      "maxabsV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9401 - val_loss: 1.9342\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9137 - val_loss: 1.8810\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8413 - val_loss: 1.8193\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8037 - val_loss: 1.8003\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7915\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7866\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7796 - val_loss: 1.7826\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7774 - val_loss: 1.7809\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7763 - val_loss: 1.7812\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7747 - val_loss: 1.7799\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.7802\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7732 - val_loss: 1.7778\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7721 - val_loss: 1.7780\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7720 - val_loss: 1.7785\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7786\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7708 - val_loss: 1.7763\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7696 - val_loss: 1.7737\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7691 - val_loss: 1.7740\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7691 - val_loss: 1.7745\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7758\n",
      "Top-2 accuracy = 0.468\n",
      "10\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8888 - val_loss: 1.8388\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7982 - val_loss: 1.7791\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7841\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7699 - val_loss: 1.7759\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7684 - val_loss: 1.7724\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7739\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7715\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7712\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7645 - val_loss: 1.7695\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7643 - val_loss: 1.7711\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7645 - val_loss: 1.7686\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7645 - val_loss: 1.7703\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7644 - val_loss: 1.7679\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7628 - val_loss: 1.7682\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7719\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7813\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7630 - val_loss: 1.7675\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7679\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7614 - val_loss: 1.7678\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7615 - val_loss: 1.7674\n",
      "Top-2 accuracy = 0.463\n",
      "11\n",
      "robustF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9337 - val_loss: 1.9073\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8843 - val_loss: 1.8659\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8497 - val_loss: 1.8442\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8314 - val_loss: 1.8303\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8186 - val_loss: 1.8191\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8090 - val_loss: 1.8084\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7990 - val_loss: 1.7998\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7932 - val_loss: 1.7949\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7878 - val_loss: 1.7915\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7842 - val_loss: 1.7895\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7870\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7854\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7778 - val_loss: 1.7829\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7760 - val_loss: 1.7820\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7744 - val_loss: 1.7798\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7729 - val_loss: 1.7808\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7724 - val_loss: 1.7797\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7725 - val_loss: 1.7788\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7771\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7771\n",
      "Top-2 accuracy = 0.465\n",
      "12\n",
      "maxabsd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9295 - val_loss: 1.9165\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8967 - val_loss: 1.8852\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8710 - val_loss: 1.8657\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8521 - val_loss: 1.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8362 - val_loss: 1.8326\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8239 - val_loss: 1.8214\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8137 - val_loss: 1.8132\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8063 - val_loss: 1.8068\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8009 - val_loss: 1.8029\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7972 - val_loss: 1.8009\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7947 - val_loss: 1.7980\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7924 - val_loss: 1.7967\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7904 - val_loss: 1.7946\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7887 - val_loss: 1.7936\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7880 - val_loss: 1.7919\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7911\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7858 - val_loss: 1.7905\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7891\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7842 - val_loss: 1.7884\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7834 - val_loss: 1.7878\n",
      "Top-2 accuracy = 0.458\n",
      "13\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9037 - val_loss: 1.8382\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7974 - val_loss: 1.7812\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7717\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7654 - val_loss: 1.7798\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7642 - val_loss: 1.7679\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7669\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7604 - val_loss: 1.7651\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7592 - val_loss: 1.7659\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7668\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7665\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7579 - val_loss: 1.7647\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7624\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7565 - val_loss: 1.7649\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7570 - val_loss: 1.7626\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7554 - val_loss: 1.7649\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7586 - val_loss: 1.7624\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7556 - val_loss: 1.7642\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7552 - val_loss: 1.7690\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7573 - val_loss: 1.7619\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7542 - val_loss: 1.7638\n",
      "Top-2 accuracy = 0.47\n",
      "14\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3606 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9302 - val_loss: 1.9034\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8902 - val_loss: 1.8769\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8580 - val_loss: 1.8436\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8299 - val_loss: 1.8247\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8174 - val_loss: 1.8165\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8111 - val_loss: 1.8123\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8073 - val_loss: 1.8099\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8049 - val_loss: 1.8069\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8028 - val_loss: 1.8054\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8004 - val_loss: 1.8038\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7989 - val_loss: 1.8024\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7973 - val_loss: 1.8007\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7961 - val_loss: 1.8017\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7949 - val_loss: 1.7982\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7932 - val_loss: 1.7980\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7918 - val_loss: 1.7965\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7905 - val_loss: 1.7966\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7892 - val_loss: 1.7939\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7879 - val_loss: 1.7940\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7926\n",
      "Top-2 accuracy = 0.46\n",
      "15\n",
      "standardizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9293 - val_loss: 1.8972\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8508 - val_loss: 1.8116\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7917 - val_loss: 1.7855\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7740 - val_loss: 1.7763\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7685 - val_loss: 1.7735\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7654 - val_loss: 1.7717\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7641 - val_loss: 1.7715\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7629 - val_loss: 1.7699\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7687\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7612 - val_loss: 1.7694\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7676\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7602 - val_loss: 1.7683\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7600 - val_loss: 1.7670\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7595 - val_loss: 1.7673\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7595 - val_loss: 1.7674\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7587 - val_loss: 1.7661\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7654\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7576 - val_loss: 1.7651\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7574 - val_loss: 1.7670\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7575 - val_loss: 1.7650\n",
      "Top-2 accuracy = 0.465\n",
      "16\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3612 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9351 - val_loss: 1.9304\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9178 - val_loss: 1.9098\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8895 - val_loss: 1.8757\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8595 - val_loss: 1.8508\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8417 - val_loss: 1.8375\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8322 - val_loss: 1.8304\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8263 - val_loss: 1.8255\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8223 - val_loss: 1.8221\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8195 - val_loss: 1.8195\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8173 - val_loss: 1.8188\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8154 - val_loss: 1.8169\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8140 - val_loss: 1.8162\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8129 - val_loss: 1.8155\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8121 - val_loss: 1.8155\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8117 - val_loss: 1.8146\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8113 - val_loss: 1.8147\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8108 - val_loss: 1.8148\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8104 - val_loss: 1.8141\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8101 - val_loss: 1.8147\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8098 - val_loss: 1.8140\n",
      "Top-2 accuracy = 0.446\n",
      "17\n",
      "normalizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9368 - val_loss: 1.9292\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9070 - val_loss: 1.8764\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8498 - val_loss: 1.8365\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8305 - val_loss: 1.8261\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8210 - val_loss: 1.8147\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8131 - val_loss: 1.8113\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8092 - val_loss: 1.8069\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8041 - val_loss: 1.8029\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7998 - val_loss: 1.8026\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7971 - val_loss: 1.7980\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7984 - val_loss: 1.8350\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8054 - val_loss: 1.7952\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7909 - val_loss: 1.8112\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7922 - val_loss: 1.7926\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7883 - val_loss: 1.8078\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.8013\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7878 - val_loss: 1.7933\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7860 - val_loss: 1.7886\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7845 - val_loss: 1.7947\n",
      "Top-2 accuracy = 0.456\n",
      "18\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9200 - val_loss: 1.8755\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8295 - val_loss: 1.8133\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7965 - val_loss: 1.7970\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7892 - val_loss: 1.7936\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7847 - val_loss: 1.7897\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7818 - val_loss: 1.7864\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7794 - val_loss: 1.7851\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7776 - val_loss: 1.7841\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7825\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7753 - val_loss: 1.7817\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7807\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7733 - val_loss: 1.7809\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7725 - val_loss: 1.7803\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7794\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7719 - val_loss: 1.7786\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7720 - val_loss: 1.7786\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7722 - val_loss: 1.7777\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7714 - val_loss: 1.7863\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7720 - val_loss: 1.7771\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7761\n",
      "Top-2 accuracy = 0.464\n",
      "19\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9392 - val_loss: 1.9344\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9249 - val_loss: 1.8979\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8712 - val_loss: 1.8491\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8364 - val_loss: 1.8311\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8229 - val_loss: 1.8222\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8156 - val_loss: 1.8175\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8098 - val_loss: 1.8120\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8057 - val_loss: 1.8089\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8029 - val_loss: 1.8063\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8002 - val_loss: 1.8042\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7982 - val_loss: 1.8021\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7964 - val_loss: 1.8009\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7941 - val_loss: 1.7993\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7924 - val_loss: 1.7963\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7910 - val_loss: 1.7971\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7898 - val_loss: 1.7946\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7892 - val_loss: 1.7941\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7887 - val_loss: 1.7958\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7889 - val_loss: 1.7940\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7876 - val_loss: 1.7925\n",
      "Top-2 accuracy = 0.46\n",
      "20\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9205 - val_loss: 1.9019\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8698 - val_loss: 1.8410\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8074 - val_loss: 1.7965\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7850 - val_loss: 1.7880\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7768 - val_loss: 1.7806\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.7812\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7720 - val_loss: 1.7854\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7726 - val_loss: 1.7764\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7760\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7699 - val_loss: 1.7756\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7750\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7754\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7694 - val_loss: 1.7757\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7694 - val_loss: 1.7766\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7686 - val_loss: 1.7772\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7771\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7752\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7683 - val_loss: 1.7803\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7744\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7741\n",
      "Top-2 accuracy = 0.466\n",
      "21\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8922 - val_loss: 1.8393\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7982 - val_loss: 1.7851\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7674 - val_loss: 1.7717\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7610 - val_loss: 1.7712\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7607 - val_loss: 1.7660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7567 - val_loss: 1.7668\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7571 - val_loss: 1.7658\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7559 - val_loss: 1.7658\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7562 - val_loss: 1.7652\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7548 - val_loss: 1.7652\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7565 - val_loss: 1.7640\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7542 - val_loss: 1.7636\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7550 - val_loss: 1.7631\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7546 - val_loss: 1.7634\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7532 - val_loss: 1.7667\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7549 - val_loss: 1.7732\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7596 - val_loss: 1.7631\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7536 - val_loss: 1.7621\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7539 - val_loss: 1.7670\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7536 - val_loss: 1.7631\n",
      "Top-2 accuracy = 0.466\n",
      "22\n",
      "standardizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9157 - val_loss: 1.8659\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8340 - val_loss: 1.8129\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7973 - val_loss: 1.7941\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7836 - val_loss: 1.7851\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7762 - val_loss: 1.7800\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7722 - val_loss: 1.7768\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7794\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7720 - val_loss: 1.7731\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7676 - val_loss: 1.7715\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7711\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7654 - val_loss: 1.7706\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7697\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7640 - val_loss: 1.7695\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7635 - val_loss: 1.7713\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7687\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7691\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7626 - val_loss: 1.7681\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7617 - val_loss: 1.7684\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7683\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7694\n",
      "Top-2 accuracy = 0.467\n",
      "23\n",
      "minmaxo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9303 - val_loss: 1.9289\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9256 - val_loss: 1.9287\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9286\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9257 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9288\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9259 - val_loss: 1.9287\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9289\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9290\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "24\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9079 - val_loss: 1.8536\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8205 - val_loss: 1.8035\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7878 - val_loss: 1.7876\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7767 - val_loss: 1.7812\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7713 - val_loss: 1.7791\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7686 - val_loss: 1.7739\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7666 - val_loss: 1.7717\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7651 - val_loss: 1.7720\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7649 - val_loss: 1.7700\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7644 - val_loss: 1.7705\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7631 - val_loss: 1.7693\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7629 - val_loss: 1.7686\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7616 - val_loss: 1.7701\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7624 - val_loss: 1.7704\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7618 - val_loss: 1.7691\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7612 - val_loss: 1.7703\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7613 - val_loss: 1.7682\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7614 - val_loss: 1.7728\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7601 - val_loss: 1.7675\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7602 - val_loss: 1.7672\n",
      "Top-2 accuracy = 0.466\n",
      "25\n",
      "robustw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9318 - val_loss: 1.9129\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8756 - val_loss: 1.8565\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8425 - val_loss: 1.8419\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8278 - val_loss: 1.8205\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8052 - val_loss: 1.8088\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7886 - val_loss: 1.7941\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7803 - val_loss: 1.7879\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7789 - val_loss: 1.7844\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7731 - val_loss: 1.7814\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7705 - val_loss: 1.7743\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7695 - val_loss: 1.7773\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7682 - val_loss: 1.7770\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7675 - val_loss: 1.7740\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7675 - val_loss: 1.7737\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7650 - val_loss: 1.7762\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7646 - val_loss: 1.7751\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7638 - val_loss: 1.7709\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7629 - val_loss: 1.7750\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7680 - val_loss: 1.7718\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7616 - val_loss: 1.7703\n",
      "Top-2 accuracy = 0.465\n",
      "26\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3669 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9225 - val_loss: 1.9101\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8930 - val_loss: 1.8722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8432 - val_loss: 1.8220\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8139 - val_loss: 1.8113\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8072 - val_loss: 1.8098\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8036 - val_loss: 1.8044\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8022 - val_loss: 1.8019\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8004 - val_loss: 1.8019\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7994 - val_loss: 1.7991\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7969 - val_loss: 1.8030\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7965 - val_loss: 1.7983\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7954 - val_loss: 1.7968\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7947 - val_loss: 1.7961\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7930 - val_loss: 1.7939\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7916 - val_loss: 1.7926\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7911 - val_loss: 1.7977\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7904 - val_loss: 1.7997\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7918 - val_loss: 1.7929\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7887 - val_loss: 1.7955\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7874 - val_loss: 1.7934\n",
      "Top-2 accuracy = 0.456\n",
      "27\n",
      "standardizev|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3676 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9151 - val_loss: 1.8754\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8496 - val_loss: 1.8283\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8183 - val_loss: 1.8116\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8059 - val_loss: 1.8041\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7984 - val_loss: 1.7990\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7922 - val_loss: 1.7939\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7864 - val_loss: 1.7891\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7821 - val_loss: 1.7887\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7785 - val_loss: 1.7834\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7753 - val_loss: 1.7815\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7725 - val_loss: 1.7796\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7785\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7767\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7744\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7644 - val_loss: 1.7741\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7630 - val_loss: 1.7722\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7716\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7598 - val_loss: 1.7708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7589 - val_loss: 1.7693\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7576 - val_loss: 1.7684\n",
      "Top-2 accuracy = 0.47\n",
      "28\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8966 - val_loss: 1.8662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8355 - val_loss: 1.8161\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8000 - val_loss: 1.7940\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7864\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7794 - val_loss: 1.7824\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7796\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7730 - val_loss: 1.7785\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7708 - val_loss: 1.7767\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7742\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7669 - val_loss: 1.7731\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7653 - val_loss: 1.7722\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7640 - val_loss: 1.7705\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7697\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7616 - val_loss: 1.7693\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7606 - val_loss: 1.7686\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7601 - val_loss: 1.7678\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7590 - val_loss: 1.7672\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7586 - val_loss: 1.7666\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7659\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7568 - val_loss: 1.7668\n",
      "Top-2 accuracy = 0.476\n",
      "29\n",
      "minmaxf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8887 - val_loss: 1.8154\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7918 - val_loss: 1.7884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7855\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7776 - val_loss: 1.7812\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7760 - val_loss: 1.7853\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7795\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7888\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7789\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7710 - val_loss: 1.7837\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7718 - val_loss: 1.7755\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7696 - val_loss: 1.7735\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7722\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7690 - val_loss: 1.7822\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7716\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7667 - val_loss: 1.7707\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7670 - val_loss: 1.7770\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7658 - val_loss: 1.7708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7634 - val_loss: 1.7695\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7626 - val_loss: 1.7684\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7717\n",
      "Top-2 accuracy = 0.47\n",
      "0\n",
      "minmaxP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9261 - val_loss: 1.9198\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8904 - val_loss: 1.8742\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8588 - val_loss: 1.8546\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8377 - val_loss: 1.8427\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8243 - val_loss: 1.8173\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8024 - val_loss: 1.7998\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7904 - val_loss: 1.7939\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7871 - val_loss: 1.7865\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7823 - val_loss: 1.7917\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7805 - val_loss: 1.7830\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7782 - val_loss: 1.7815\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7766 - val_loss: 1.7806\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7753 - val_loss: 1.7810\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7756 - val_loss: 1.7788\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7721 - val_loss: 1.7827\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7745 - val_loss: 1.7781\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7719 - val_loss: 1.7799\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7708 - val_loss: 1.7765\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7698 - val_loss: 1.7881\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7740 - val_loss: 1.7850\n",
      "Top-2 accuracy = 0.463\n",
      "1\n",
      "robustV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9409 - val_loss: 1.9373\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9338 - val_loss: 1.9328\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9300 - val_loss: 1.9305\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9278 - val_loss: 1.9293\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9267 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9260 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Top-2 accuracy = 0.348\n",
      "2\n",
      "standardizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9406 - val_loss: 1.9317\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9155 - val_loss: 1.9020\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8892 - val_loss: 1.8810\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8717 - val_loss: 1.8675\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8600 - val_loss: 1.8569\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8450 - val_loss: 1.8392\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8296 - val_loss: 1.8285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8189 - val_loss: 1.8194\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8108 - val_loss: 1.8126\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8043 - val_loss: 1.8084\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7997 - val_loss: 1.8040\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7958 - val_loss: 1.8003\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7927 - val_loss: 1.7972\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7899 - val_loss: 1.7951\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7879 - val_loss: 1.7935\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7862 - val_loss: 1.7918\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7906\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7840 - val_loss: 1.7899\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7830 - val_loss: 1.7900\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7830 - val_loss: 1.7890\n",
      "Top-2 accuracy = 0.458\n",
      "3\n",
      "robustd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9408 - val_loss: 1.9371\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9337 - val_loss: 1.9327\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9297 - val_loss: 1.9303\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9276 - val_loss: 1.9291\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9265 - val_loss: 1.9286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9259 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9256 - val_loss: 1.9283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "4\n",
      "minmaxh|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3712 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9319 - val_loss: 1.9088\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8730 - val_loss: 1.8442\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8221 - val_loss: 1.8157\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8057 - val_loss: 1.8070\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8011 - val_loss: 1.8026\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7980 - val_loss: 1.8028\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7966 - val_loss: 1.7993\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7938 - val_loss: 1.7959\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7906 - val_loss: 1.7954\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7881 - val_loss: 1.7916\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7852 - val_loss: 1.7899\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7837 - val_loss: 1.7881\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7819 - val_loss: 1.7877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7808 - val_loss: 1.7873\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7797 - val_loss: 1.7868\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7850\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7764 - val_loss: 1.7830\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7759 - val_loss: 1.7814\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7740 - val_loss: 1.7816\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7729 - val_loss: 1.7800\n",
      "Top-2 accuracy = 0.463\n",
      "5\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9376 - val_loss: 1.9325\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9278 - val_loss: 1.9289\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 62s 749ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Top-2 accuracy = 0.348\n",
      "6\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9329 - val_loss: 1.9173\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8943 - val_loss: 1.8783\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8543 - val_loss: 1.8431\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8251 - val_loss: 1.8202\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8074 - val_loss: 1.8093\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7969 - val_loss: 1.7977\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7884 - val_loss: 1.7913\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7836 - val_loss: 1.7879\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7806 - val_loss: 1.7857\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7790 - val_loss: 1.7847\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7772 - val_loss: 1.7831\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7765 - val_loss: 1.7823\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 1.7818\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7747 - val_loss: 1.7812\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7803\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7800\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7735 - val_loss: 1.7806\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7730 - val_loss: 1.7793\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7787\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7719 - val_loss: 1.7781\n",
      "Top-2 accuracy = 0.462\n",
      "7\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9237 - val_loss: 1.8837\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8536 - val_loss: 1.8302\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8061 - val_loss: 1.7981\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7868 - val_loss: 1.7973\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7782 - val_loss: 1.7759\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7737\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7650 - val_loss: 1.7692\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7632 - val_loss: 1.7695\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7627 - val_loss: 1.7751\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7629 - val_loss: 1.7695\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7619 - val_loss: 1.7667\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7615 - val_loss: 1.7670\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7609 - val_loss: 1.7664\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7632 - val_loss: 1.7674\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7600 - val_loss: 1.7700\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7604 - val_loss: 1.7656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7616 - val_loss: 1.7654\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7618 - val_loss: 1.7696\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7613 - val_loss: 1.7811\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7642 - val_loss: 1.7691\n",
      "Top-2 accuracy = 0.466\n",
      "8\n",
      "minmaxQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9014 - val_loss: 1.8680\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8314 - val_loss: 1.8009\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7839\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7740 - val_loss: 1.7776\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7695 - val_loss: 1.7748\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7680 - val_loss: 1.7774\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7706\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7646 - val_loss: 1.7704\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7630 - val_loss: 1.7723\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7643 - val_loss: 1.7709\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7605 - val_loss: 1.7674\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7599 - val_loss: 1.7675\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7590 - val_loss: 1.7656\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7582 - val_loss: 1.7708\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7679\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7566 - val_loss: 1.7657\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7561 - val_loss: 1.7644\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7556 - val_loss: 1.7624\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7563 - val_loss: 1.7633\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7544 - val_loss: 1.7667\n",
      "Top-2 accuracy = 0.471\n",
      "9\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9406 - val_loss: 1.9371\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9334 - val_loss: 1.9325\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9295 - val_loss: 1.9302\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9275 - val_loss: 1.9291\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9265 - val_loss: 1.9286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9259 - val_loss: 1.9284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9256 - val_loss: 1.9283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "10\n",
      "maxabsi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9144 - val_loss: 1.8694\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8329 - val_loss: 1.8087\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7897 - val_loss: 1.7861\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7759 - val_loss: 1.7836\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7727\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7673 - val_loss: 1.7762\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7730\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7638 - val_loss: 1.7701\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7708\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7616 - val_loss: 1.7685\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7597 - val_loss: 1.7675\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7598 - val_loss: 1.7686\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7600 - val_loss: 1.7666\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7590 - val_loss: 1.7675\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7582 - val_loss: 1.7663\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7574 - val_loss: 1.7664\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7573 - val_loss: 1.7693\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7598 - val_loss: 1.7654\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7579 - val_loss: 1.7647\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7561 - val_loss: 1.7637\n",
      "Top-2 accuracy = 0.47\n",
      "11\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9274 - val_loss: 1.9032\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8687 - val_loss: 1.8437\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8150 - val_loss: 1.8025\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7872 - val_loss: 1.7852\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7770 - val_loss: 1.7805\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7728 - val_loss: 1.7818\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7717 - val_loss: 1.7751\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7682 - val_loss: 1.7731\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7669 - val_loss: 1.7717\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7660 - val_loss: 1.7728\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7733\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7645 - val_loss: 1.7707\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7799\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7756\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7706\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7707\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7695\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7722\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7618 - val_loss: 1.7689\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7612 - val_loss: 1.7693\n",
      "Top-2 accuracy = 0.467\n",
      "12\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9408 - val_loss: 1.9372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9337 - val_loss: 1.9328\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9305\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9277 - val_loss: 1.9293\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9265 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9259 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "13\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9410 - val_loss: 1.9375\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9339 - val_loss: 1.9328\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9299 - val_loss: 1.9304\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9278 - val_loss: 1.9293\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9267 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9260 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9257 - val_loss: 1.9283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Top-2 accuracy = 0.348\n",
      "14\n",
      "minmaxo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9293 - val_loss: 1.9000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8614 - val_loss: 1.8318\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8129 - val_loss: 1.8069\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7940 - val_loss: 1.7903\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7831 - val_loss: 1.7992\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7800 - val_loss: 1.7918\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7757 - val_loss: 1.7790\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7735 - val_loss: 1.7775\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7710 - val_loss: 1.7771\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7694 - val_loss: 1.7754\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7695 - val_loss: 1.7730\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7677 - val_loss: 1.7748\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7678 - val_loss: 1.7740\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7671 - val_loss: 1.7741\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7664 - val_loss: 1.7719\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7654 - val_loss: 1.7925\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7678 - val_loss: 1.7722\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7729\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7720\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7653 - val_loss: 1.7686\n",
      "Top-2 accuracy = 0.468\n",
      "15\n",
      "standardizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9267 - val_loss: 1.9102\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8669 - val_loss: 1.8398\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8185 - val_loss: 1.8076\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7941 - val_loss: 1.7938\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7853 - val_loss: 1.7854\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7792 - val_loss: 1.7811\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7763 - val_loss: 1.7797\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7775\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7777\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7696 - val_loss: 1.7732\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7682 - val_loss: 1.7733\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7663 - val_loss: 1.7729\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7646 - val_loss: 1.7717\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7640 - val_loss: 1.7703\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7693\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7618 - val_loss: 1.7692\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7612 - val_loss: 1.7696\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7599 - val_loss: 1.7698\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7678\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7589 - val_loss: 1.7671\n",
      "Top-2 accuracy = 0.469\n",
      "16\n",
      "standardizeF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9310 - val_loss: 1.9194\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8992 - val_loss: 1.8783\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8580 - val_loss: 1.8508\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8365 - val_loss: 1.8359\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8219 - val_loss: 1.8190\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8045 - val_loss: 1.8210\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7912 - val_loss: 1.7971\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7822 - val_loss: 1.7839\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7729 - val_loss: 1.7793\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7698 - val_loss: 1.7757\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7670 - val_loss: 1.7738\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7651 - val_loss: 1.7726\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7731\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7636 - val_loss: 1.7800\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7648 - val_loss: 1.7698\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7626 - val_loss: 1.7758\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7618 - val_loss: 1.7674\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7617 - val_loss: 1.7704\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7605 - val_loss: 1.7668\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7609 - val_loss: 1.7676\n",
      "Top-2 accuracy = 0.465\n",
      "17\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9087 - val_loss: 1.8808\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8586 - val_loss: 1.8432\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8265 - val_loss: 1.8208\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8056 - val_loss: 1.8035\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7919 - val_loss: 1.7946\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7914\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7822 - val_loss: 1.7890\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7800 - val_loss: 1.7884\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7781 - val_loss: 1.7862\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7769 - val_loss: 1.7851\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7843\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7745 - val_loss: 1.7832\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7736 - val_loss: 1.7822\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7725 - val_loss: 1.7811\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7721 - val_loss: 1.7799\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7794\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7701 - val_loss: 1.7791\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7695 - val_loss: 1.7780\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7690 - val_loss: 1.7777\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7684 - val_loss: 1.7766\n",
      "Top-2 accuracy = 0.466\n",
      "18\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8945 - val_loss: 1.8453\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8066 - val_loss: 1.7925\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7827 - val_loss: 1.7873\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7775 - val_loss: 1.7864\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7829\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7779\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7770\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7695 - val_loss: 1.7774\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7765\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7771\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7748\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7646 - val_loss: 1.7735\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7641 - val_loss: 1.7728\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7733\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7714\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7612 - val_loss: 1.7723\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7618 - val_loss: 1.7706\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7606 - val_loss: 1.7732\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7607 - val_loss: 1.7696\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7729\n",
      "Top-2 accuracy = 0.464\n",
      "19\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9409 - val_loss: 1.9373\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.9328\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9300 - val_loss: 1.9304\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9278 - val_loss: 1.9293\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9266 - val_loss: 1.9286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9260 - val_loss: 1.9285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9283\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9283\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "20\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8842 - val_loss: 1.8000\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7728\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7625 - val_loss: 1.7694\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7709\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7579 - val_loss: 1.7673\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7563 - val_loss: 1.7685\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7556 - val_loss: 1.7666\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7550 - val_loss: 1.7654\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7546 - val_loss: 1.7653\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7538 - val_loss: 1.7647\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7530 - val_loss: 1.7650\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7532 - val_loss: 1.7662\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7533 - val_loss: 1.7639\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7523 - val_loss: 1.7634\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7522 - val_loss: 1.7665\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7517 - val_loss: 1.7660\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7521 - val_loss: 1.7672\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7511 - val_loss: 1.7656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7513 - val_loss: 1.7644\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7517 - val_loss: 1.7655\n",
      "Top-2 accuracy = 0.472\n",
      "21\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3811 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9345 - val_loss: 1.9278\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9224 - val_loss: 1.9186\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9047 - val_loss: 1.8854\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8534 - val_loss: 1.8254\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8092 - val_loss: 1.8048\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7947 - val_loss: 1.7939\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7860 - val_loss: 1.7895\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7868\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7786 - val_loss: 1.7850\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7763 - val_loss: 1.7833\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7745 - val_loss: 1.7818\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7724 - val_loss: 1.7799\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7703 - val_loss: 1.7788\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7688 - val_loss: 1.7769\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7670 - val_loss: 1.7757\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7657 - val_loss: 1.7745\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7645 - val_loss: 1.7730\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7635 - val_loss: 1.7721\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7625 - val_loss: 1.7721\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7616 - val_loss: 1.7709\n",
      "Top-2 accuracy = 0.471\n",
      "22\n",
      "minmaxa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9320 - val_loss: 1.9285\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9286\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9284\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9289\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9251 - val_loss: 1.9237\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8874 - val_loss: 1.8544\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8309 - val_loss: 1.8078\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7928 - val_loss: 1.7885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7823 - val_loss: 1.7813\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7770 - val_loss: 1.7783\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7727 - val_loss: 1.7731\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7695 - val_loss: 1.7748\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7676 - val_loss: 1.7811\n",
      "Top-2 accuracy = 0.461\n",
      "23\n",
      "standardizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9038 - val_loss: 1.8566\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8306 - val_loss: 1.8222\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8023 - val_loss: 1.7985\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7896 - val_loss: 1.7888\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7842 - val_loss: 1.7861\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7796 - val_loss: 1.7811\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7733 - val_loss: 1.7760\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7689 - val_loss: 1.7726\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7645 - val_loss: 1.7694\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7643 - val_loss: 1.7695\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7618 - val_loss: 1.7686\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7685\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7596 - val_loss: 1.7697\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7589 - val_loss: 1.7697\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7583 - val_loss: 1.7664\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7574 - val_loss: 1.7668\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7582 - val_loss: 1.7677\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7561 - val_loss: 1.7654\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7550 - val_loss: 1.7681\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7566 - val_loss: 1.7659\n",
      "Top-2 accuracy = 0.47\n",
      "24\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9006 - val_loss: 1.8559\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8181 - val_loss: 1.8013\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7855 - val_loss: 1.7857\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7747 - val_loss: 1.7771\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7725\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7717\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7667 - val_loss: 1.7715\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7655 - val_loss: 1.7686\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7682\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7630 - val_loss: 1.7675\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7672\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7672\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7617 - val_loss: 1.7673\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7606 - val_loss: 1.7660\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7603 - val_loss: 1.7667\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7600 - val_loss: 1.7669\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7598 - val_loss: 1.7657\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7595 - val_loss: 1.7650\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7587 - val_loss: 1.7654\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7591 - val_loss: 1.7643\n",
      "Top-2 accuracy = 0.469\n",
      "25\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 20ms/step - loss: 1.9299 - val_loss: 1.9265\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8990 - val_loss: 1.8680\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8486 - val_loss: 1.8369\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8217 - val_loss: 1.8183\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8056 - val_loss: 1.8059\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7956 - val_loss: 1.8011\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7875 - val_loss: 1.7956\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7826 - val_loss: 1.7874\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7791 - val_loss: 1.7943\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7789 - val_loss: 1.7904\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7772 - val_loss: 1.7831\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7825\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7781\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7769\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7720 - val_loss: 1.7835\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7740 - val_loss: 1.7762\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7757\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7745\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7706 - val_loss: 1.7742\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7700 - val_loss: 1.7759\n",
      "Top-2 accuracy = 0.462\n",
      "26\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3839 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9346 - val_loss: 1.9174\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8839 - val_loss: 1.8520\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8313 - val_loss: 1.8214\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8134 - val_loss: 1.8108\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8059 - val_loss: 1.8063\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8016 - val_loss: 1.8046\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7986 - val_loss: 1.8010\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7962 - val_loss: 1.7989\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7940 - val_loss: 1.7973\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7925 - val_loss: 1.7957\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7901 - val_loss: 1.7940\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7881 - val_loss: 1.7920\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7862 - val_loss: 1.7905\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7842 - val_loss: 1.7888\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7825 - val_loss: 1.7875\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7813 - val_loss: 1.7849\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7799 - val_loss: 1.7839\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7832\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7768 - val_loss: 1.7822\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 1.7812\n",
      "Top-2 accuracy = 0.467\n",
      "27\n",
      "normalizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8954 - val_loss: 1.8313\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7946 - val_loss: 1.7809\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7716 - val_loss: 1.7801\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7690 - val_loss: 1.7710\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7641 - val_loss: 1.7719\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7651 - val_loss: 1.7690\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7620 - val_loss: 1.7751\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7635 - val_loss: 1.7697\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7622 - val_loss: 1.7679\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7606 - val_loss: 1.7680\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7606 - val_loss: 1.7687\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7600 - val_loss: 1.7690\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7607 - val_loss: 1.7669\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7594 - val_loss: 1.7662\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7586 - val_loss: 1.7656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7585 - val_loss: 1.7650\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7579 - val_loss: 1.7677\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7597 - val_loss: 1.7653\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7581 - val_loss: 1.7660\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7574 - val_loss: 1.7669\n",
      "Top-2 accuracy = 0.467\n",
      "28\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9271 - val_loss: 1.8968\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8655 - val_loss: 1.8459\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8205 - val_loss: 1.8157\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8009 - val_loss: 1.8003\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7906 - val_loss: 1.7951\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7851 - val_loss: 1.7922\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7821 - val_loss: 1.7904\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7873\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7785 - val_loss: 1.7877\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7767 - val_loss: 1.7820\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7775 - val_loss: 1.7832\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7849\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7760 - val_loss: 1.7810\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7809\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7729 - val_loss: 1.7821\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7737 - val_loss: 1.7771\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7718 - val_loss: 1.7780\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7716 - val_loss: 1.7864\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7863\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7719 - val_loss: 1.7756\n",
      "Top-2 accuracy = 0.469\n",
      "29\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9192 - val_loss: 1.8809\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8499 - val_loss: 1.8300\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8080 - val_loss: 1.7976\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7844 - val_loss: 1.7817\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.7776\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7711 - val_loss: 1.7768\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7861\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7699 - val_loss: 1.7721\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7676 - val_loss: 1.7733\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7683 - val_loss: 1.7752\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7719\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7739\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7652 - val_loss: 1.7697\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7646 - val_loss: 1.7714\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7648 - val_loss: 1.7808\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7668 - val_loss: 1.7740\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7657 - val_loss: 1.7825\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7667 - val_loss: 1.7703\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7633 - val_loss: 1.7687\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7634 - val_loss: 1.7677\n",
      "Top-2 accuracy = 0.467\n",
      "0\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3859 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8999 - val_loss: 1.8672\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8353 - val_loss: 1.8140\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8054 - val_loss: 1.8019\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7962 - val_loss: 1.7975\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7932\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7873\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7793 - val_loss: 1.7836\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7846\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7732 - val_loss: 1.7870\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7709 - val_loss: 1.7780\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7673 - val_loss: 1.7752\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7653 - val_loss: 1.7754\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7652 - val_loss: 1.7721\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7716\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7626 - val_loss: 1.7718\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7702\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7608 - val_loss: 1.7708\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7596 - val_loss: 1.7677\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7582 - val_loss: 1.7679\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7583 - val_loss: 1.7744\n",
      "Top-2 accuracy = 0.47\n",
      "1\n",
      "minmaxr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8947 - val_loss: 1.8479\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8104 - val_loss: 1.7981\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7867 - val_loss: 1.7874\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7796 - val_loss: 1.7873\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7759 - val_loss: 1.7783\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7777\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7706 - val_loss: 1.7747\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7685 - val_loss: 1.7735\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7671 - val_loss: 1.7725\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7721\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7658 - val_loss: 1.7716\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7645 - val_loss: 1.7705\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7637 - val_loss: 1.7702\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7637 - val_loss: 1.7694\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7628 - val_loss: 1.7688\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7695\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7694\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7608 - val_loss: 1.7684\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7602 - val_loss: 1.7671\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7602 - val_loss: 1.7668\n",
      "Top-2 accuracy = 0.467\n",
      "2\n",
      "robustd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9223 - val_loss: 1.8944\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8675 - val_loss: 1.8507\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8268 - val_loss: 1.8144\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8007 - val_loss: 1.7987\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7874 - val_loss: 1.7905\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 1.7845\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.7819\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7711 - val_loss: 1.7761\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7666 - val_loss: 1.7739\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7642 - val_loss: 1.7723\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7621 - val_loss: 1.7704\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7693\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7600 - val_loss: 1.7696\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7586 - val_loss: 1.7691\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7573 - val_loss: 1.7678\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7568 - val_loss: 1.7688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7563 - val_loss: 1.7666\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7551 - val_loss: 1.7671\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7544 - val_loss: 1.7667\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7538 - val_loss: 1.7655\n",
      "Top-2 accuracy = 0.475\n",
      "3\n",
      "maxabsh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9407 - val_loss: 1.9351\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9287 - val_loss: 1.9235\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9133 - val_loss: 1.9050\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8926 - val_loss: 1.8839\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8690 - val_loss: 1.8636\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8514 - val_loss: 1.8502\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8395 - val_loss: 1.8402\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8310 - val_loss: 1.8326\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8243 - val_loss: 1.8273\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8192 - val_loss: 1.8230\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8154 - val_loss: 1.8193\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8121 - val_loss: 1.8159\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8090 - val_loss: 1.8132\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8061 - val_loss: 1.8109\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8035 - val_loss: 1.8087\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8018 - val_loss: 1.8073\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8000 - val_loss: 1.8059\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7984 - val_loss: 1.8047\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7969 - val_loss: 1.8037\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7959 - val_loss: 1.8026\n",
      "Top-2 accuracy = 0.458\n",
      "4\n",
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8685 - val_loss: 1.8185\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7852 - val_loss: 1.7778\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7680 - val_loss: 1.7693\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7619 - val_loss: 1.7767\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7596 - val_loss: 1.7697\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7577 - val_loss: 1.7674\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7591 - val_loss: 1.7655\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7549 - val_loss: 1.7661\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7544 - val_loss: 1.7653\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7539 - val_loss: 1.7637\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7542 - val_loss: 1.7639\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7534 - val_loss: 1.7683\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7542 - val_loss: 1.7659\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7534 - val_loss: 1.7641\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7527 - val_loss: 1.7630\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7522 - val_loss: 1.7646\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7529 - val_loss: 1.7619\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7508 - val_loss: 1.7628\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7505 - val_loss: 1.7612\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7508 - val_loss: 1.7647\n",
      "Top-2 accuracy = 0.47\n",
      "5\n",
      "normalizeD|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3879 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9367 - val_loss: 1.9166\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8998 - val_loss: 1.8814\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8582 - val_loss: 1.8395\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8230 - val_loss: 1.8146\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8064 - val_loss: 1.8042\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7981 - val_loss: 1.7976\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7919 - val_loss: 1.7928\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7871 - val_loss: 1.7894\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7830 - val_loss: 1.7861\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7801 - val_loss: 1.7840\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7779 - val_loss: 1.7824\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7758 - val_loss: 1.7805\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7741 - val_loss: 1.7795\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7728 - val_loss: 1.7790\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7716 - val_loss: 1.7775\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7704 - val_loss: 1.7765\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7756\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7683 - val_loss: 1.7750\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7673 - val_loss: 1.7738\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7663 - val_loss: 1.7736\n",
      "Top-2 accuracy = 0.467\n",
      "6\n",
      "normalizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9350 - val_loss: 1.9194\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8935 - val_loss: 1.8639\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8362 - val_loss: 1.8169\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8039 - val_loss: 1.7986\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7902 - val_loss: 1.7902\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7830 - val_loss: 1.7866\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7804 - val_loss: 1.7824\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7765 - val_loss: 1.7802\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7805\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7734 - val_loss: 1.7784\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7718 - val_loss: 1.7771\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7710 - val_loss: 1.7752\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7701 - val_loss: 1.7754\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7699 - val_loss: 1.7738\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7683 - val_loss: 1.7737\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7680 - val_loss: 1.7728\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7672 - val_loss: 1.7727\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7667 - val_loss: 1.7722\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 1.7734\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 1.7709\n",
      "Top-2 accuracy = 0.464\n",
      "7\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3885 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8971 - val_loss: 1.8631\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8355 - val_loss: 1.8122\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7963 - val_loss: 1.7910\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7834 - val_loss: 1.7828\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7760 - val_loss: 1.7787\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7716 - val_loss: 1.7752\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7671 - val_loss: 1.7757\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7643 - val_loss: 1.7701\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7618 - val_loss: 1.7691\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7594 - val_loss: 1.7673\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7595 - val_loss: 1.7663\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7568 - val_loss: 1.7644\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7543 - val_loss: 1.7631\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7541 - val_loss: 1.7633\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7520 - val_loss: 1.7633\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7508 - val_loss: 1.7607\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7494 - val_loss: 1.7626\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7496 - val_loss: 1.7607\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7493 - val_loss: 1.7617\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7475 - val_loss: 1.7611\n",
      "Top-2 accuracy = 0.473\n",
      "8\n",
      "maxabsW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9070 - val_loss: 1.8636\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8280 - val_loss: 1.8112\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7949 - val_loss: 1.7946\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7864 - val_loss: 1.7918\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7795 - val_loss: 1.7851\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7762 - val_loss: 1.7777\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7728 - val_loss: 1.7778\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7712 - val_loss: 1.7745\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7689 - val_loss: 1.7714\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7689 - val_loss: 1.7738\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7672 - val_loss: 1.7700\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7760\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7671 - val_loss: 1.7711\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7735\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7642 - val_loss: 1.7738\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7634 - val_loss: 1.7676\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7619 - val_loss: 1.7679\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7614 - val_loss: 1.7700\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7635 - val_loss: 1.7703\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7608 - val_loss: 1.7683\n",
      "Top-2 accuracy = 0.466\n",
      "9\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9290 - val_loss: 1.9002\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8589 - val_loss: 1.8249\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8058 - val_loss: 1.8003\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7897 - val_loss: 1.7877\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7791 - val_loss: 1.7800\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7761\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7701 - val_loss: 1.7746\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7676 - val_loss: 1.7738\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7673 - val_loss: 1.7718\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7655 - val_loss: 1.7703\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7648 - val_loss: 1.7704\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7696\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7631 - val_loss: 1.7699\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7629 - val_loss: 1.7691\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7621 - val_loss: 1.7679\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7672\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7611 - val_loss: 1.7668\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7615 - val_loss: 1.7669\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7606 - val_loss: 1.7664\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7602 - val_loss: 1.7683\n",
      "Top-2 accuracy = 0.467\n",
      "10\n",
      "minmaxF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9301 - val_loss: 1.9182\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8875 - val_loss: 1.8691\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8435 - val_loss: 1.8379\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8193 - val_loss: 1.8176\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8038 - val_loss: 1.8131\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7970 - val_loss: 1.8020\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7878 - val_loss: 1.7915\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7836 - val_loss: 1.7977\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7806 - val_loss: 1.7883\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7763 - val_loss: 1.7808\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7728 - val_loss: 1.7794\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7733 - val_loss: 1.7780\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7698 - val_loss: 1.7775\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7680 - val_loss: 1.7731\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7677 - val_loss: 1.7735\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7694 - val_loss: 1.7752\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7671 - val_loss: 1.7723\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7670 - val_loss: 1.7722\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7675 - val_loss: 1.7819\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7672 - val_loss: 1.7777\n",
      "Top-2 accuracy = 0.465\n",
      "11\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9054 - val_loss: 1.8544\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8156 - val_loss: 1.7986\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7893 - val_loss: 1.7905\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7832 - val_loss: 1.7853\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7786 - val_loss: 1.7886\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7797\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 1.7811\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7771\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7715 - val_loss: 1.7756\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7710 - val_loss: 1.7787\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7699 - val_loss: 1.7772\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7744\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7683 - val_loss: 1.7735\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7723\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7667 - val_loss: 1.7732\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7718\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 1.7715\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7669 - val_loss: 1.7768\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7670 - val_loss: 1.7725\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7656 - val_loss: 1.7785\n",
      "Top-2 accuracy = 0.465\n",
      "12\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9101 - val_loss: 1.8575\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8168 - val_loss: 1.7921\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7757 - val_loss: 1.7761\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7696\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7633 - val_loss: 1.7689\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7679\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7587 - val_loss: 1.7666\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7576 - val_loss: 1.7656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7562 - val_loss: 1.7665\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7556 - val_loss: 1.7642\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7539 - val_loss: 1.7637\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7549 - val_loss: 1.7636\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7523 - val_loss: 1.7626\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7510 - val_loss: 1.7633\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7511 - val_loss: 1.7636\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7520 - val_loss: 1.7631\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7500 - val_loss: 1.7629\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7495 - val_loss: 1.7632\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7494 - val_loss: 1.7638\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7491 - val_loss: 1.7650\n",
      "Top-2 accuracy = 0.474\n",
      "13\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9190 - val_loss: 1.8721\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8188 - val_loss: 1.7932\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7773 - val_loss: 1.7780\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7690 - val_loss: 1.7727\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7700\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7641 - val_loss: 1.7699\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7633 - val_loss: 1.7672\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7617 - val_loss: 1.7663\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7659\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7602 - val_loss: 1.7655\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7596 - val_loss: 1.7660\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7671\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7652\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7579 - val_loss: 1.7659\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7575 - val_loss: 1.7663\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7586 - val_loss: 1.7659\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7581 - val_loss: 1.7635\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7569 - val_loss: 1.7634\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7564 - val_loss: 1.7648\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7568 - val_loss: 1.7655\n",
      "Top-2 accuracy = 0.468\n",
      "14\n",
      "maxabsM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9385 - val_loss: 1.9251\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9029 - val_loss: 1.8813\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8495 - val_loss: 1.8331\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8094 - val_loss: 1.8016\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7862 - val_loss: 1.7867\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 1.7808\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7710 - val_loss: 1.7781\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7767\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7669 - val_loss: 1.7759\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 1.7743\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7650 - val_loss: 1.7751\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7727\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7729\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7729\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7633 - val_loss: 1.7714\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7628 - val_loss: 1.7730\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7626 - val_loss: 1.7718\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7625 - val_loss: 1.7710\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7625 - val_loss: 1.7715\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7700\n",
      "Top-2 accuracy = 0.466\n",
      "15\n",
      "maxabsv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9369 - val_loss: 1.9261\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9086 - val_loss: 1.8879\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8499 - val_loss: 1.8229\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7998 - val_loss: 1.7880\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7773 - val_loss: 1.7767\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7728\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7673 - val_loss: 1.7773\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7669 - val_loss: 1.7690\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7637 - val_loss: 1.7685\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7626 - val_loss: 1.7681\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7614 - val_loss: 1.7674\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7606 - val_loss: 1.7663\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7608 - val_loss: 1.7658\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7597 - val_loss: 1.7649\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7592 - val_loss: 1.7654\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7645\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7586 - val_loss: 1.7685\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7641\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7574 - val_loss: 1.7649\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7638\n",
      "Top-2 accuracy = 0.469\n",
      "16\n",
      "standardizec|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8811 - val_loss: 1.8188\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7818 - val_loss: 1.7777\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7636 - val_loss: 1.7688\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7569 - val_loss: 1.7659\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7551 - val_loss: 1.7655\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7540 - val_loss: 1.7657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7545 - val_loss: 1.7700\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7528 - val_loss: 1.7697\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7541 - val_loss: 1.7630\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7514 - val_loss: 1.7689\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7519 - val_loss: 1.7648\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7512 - val_loss: 1.7645\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7517 - val_loss: 1.7623\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7508 - val_loss: 1.7672\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7515 - val_loss: 1.7698\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7550 - val_loss: 1.7620\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7510 - val_loss: 1.7659\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7502 - val_loss: 1.7711\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7517 - val_loss: 1.7635\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7500 - val_loss: 1.7620\n",
      "Top-2 accuracy = 0.467\n",
      "17\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9283 - val_loss: 1.9131\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8548 - val_loss: 1.8166\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7941 - val_loss: 1.7818\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7747 - val_loss: 1.7754\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7703 - val_loss: 1.7710\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7705\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7636 - val_loss: 1.7688\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7643 - val_loss: 1.7674\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7621 - val_loss: 1.7724\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7616 - val_loss: 1.7662\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7594 - val_loss: 1.7669\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7589 - val_loss: 1.7661\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7581 - val_loss: 1.7673\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7591 - val_loss: 1.7819\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7612 - val_loss: 1.7686\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7567 - val_loss: 1.7692\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7582 - val_loss: 1.7643\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7556 - val_loss: 1.7638\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7565 - val_loss: 1.7699\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7562 - val_loss: 1.7640\n",
      "Top-2 accuracy = 0.466\n",
      "18\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9409 - val_loss: 1.9372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9337 - val_loss: 1.9327\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9298 - val_loss: 1.9303\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9278 - val_loss: 1.9291\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9267 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9260 - val_loss: 1.9284\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9257 - val_loss: 1.9283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9283\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Top-2 accuracy = 0.348\n",
      "19\n",
      "robustX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8873 - val_loss: 1.8172\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7919 - val_loss: 1.7812\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7731 - val_loss: 1.7752\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7725\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7649 - val_loss: 1.7708\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7633 - val_loss: 1.7699\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7690\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7616 - val_loss: 1.7695\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7608 - val_loss: 1.7682\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7594 - val_loss: 1.7672\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7592 - val_loss: 1.7680\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7575 - val_loss: 1.7674\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7582 - val_loss: 1.7651\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7570 - val_loss: 1.7659\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7568 - val_loss: 1.7659\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7569 - val_loss: 1.7650\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7556 - val_loss: 1.7650\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7550 - val_loss: 1.7663\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7552 - val_loss: 1.7637\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7543 - val_loss: 1.7635\n",
      "Top-2 accuracy = 0.468\n",
      "20\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9408 - val_loss: 1.9372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9337 - val_loss: 1.9328\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9298 - val_loss: 1.9304\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9277 - val_loss: 1.9292\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9266 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9260 - val_loss: 1.9285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9283\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9253 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "21\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9148 - val_loss: 1.8366\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8013 - val_loss: 1.7912\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7803 - val_loss: 1.7818\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7726 - val_loss: 1.7737\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7689 - val_loss: 1.7720\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7666 - val_loss: 1.7718\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7646 - val_loss: 1.7875\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7665 - val_loss: 1.7685\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7645 - val_loss: 1.7677\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7624 - val_loss: 1.7679\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7607 - val_loss: 1.7682\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7611 - val_loss: 1.7695\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7604 - val_loss: 1.7687\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7596 - val_loss: 1.7669\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7596 - val_loss: 1.7671\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7582 - val_loss: 1.7653\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7585 - val_loss: 1.7868\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7616 - val_loss: 1.7643\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7585 - val_loss: 1.7651\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7573 - val_loss: 1.7699\n",
      "Top-2 accuracy = 0.469\n",
      "22\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9212 - val_loss: 1.8977\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8645 - val_loss: 1.8367\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8174 - val_loss: 1.8066\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7940 - val_loss: 1.7922\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7824 - val_loss: 1.7846\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7755 - val_loss: 1.7791\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7714 - val_loss: 1.7753\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7687 - val_loss: 1.7749\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7663 - val_loss: 1.7723\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7710\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7646 - val_loss: 1.7706\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7684\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7675\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7617 - val_loss: 1.7676\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7615 - val_loss: 1.7702\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7616 - val_loss: 1.7674\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7603 - val_loss: 1.7668\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7605 - val_loss: 1.7660\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7601 - val_loss: 1.7676\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7615 - val_loss: 1.7664\n",
      "Top-2 accuracy = 0.47\n",
      "23\n",
      "minmaxg|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3963 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9397 - val_loss: 1.9213\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9014 - val_loss: 1.8754\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8496 - val_loss: 1.8317\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8198 - val_loss: 1.8151\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8089 - val_loss: 1.8079\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8038 - val_loss: 1.8034\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.8000 - val_loss: 1.8005\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7968 - val_loss: 1.7994\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7946 - val_loss: 1.7961\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7919 - val_loss: 1.7938\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7897 - val_loss: 1.7919\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7878 - val_loss: 1.7904\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7865 - val_loss: 1.7886\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7845 - val_loss: 1.7879\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7829 - val_loss: 1.7868\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7820 - val_loss: 1.7857\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7806 - val_loss: 1.7848\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7795 - val_loss: 1.7859\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7789 - val_loss: 1.7837\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.7783 - val_loss: 1.7842\n",
      "Top-2 accuracy = 0.466\n",
      "24\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_3966 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9107 - val_loss: 1.8625\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8159 - val_loss: 1.7959\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7845 - val_loss: 1.7823\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7744 - val_loss: 1.7763\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7687 - val_loss: 1.7728\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7642 - val_loss: 1.7705\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7671\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7592 - val_loss: 1.7665\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7566 - val_loss: 1.7679\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7568 - val_loss: 1.7680\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7550 - val_loss: 1.7650\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7537 - val_loss: 1.7635\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7522 - val_loss: 1.7627\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7507 - val_loss: 1.7620\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7503 - val_loss: 1.7618\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7492 - val_loss: 1.7625\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7483 - val_loss: 1.7599\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7478 - val_loss: 1.7603\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7479 - val_loss: 1.7601\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7476 - val_loss: 1.7596\n",
      "Top-2 accuracy = 0.478\n",
      "25\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9365 - val_loss: 1.9255\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9013 - val_loss: 1.8853\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8658 - val_loss: 1.8615\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8468 - val_loss: 1.8470\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8348 - val_loss: 1.8360\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8256 - val_loss: 1.8287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8176 - val_loss: 1.8199\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8123 - val_loss: 1.8183\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8061 - val_loss: 1.8119\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8019 - val_loss: 1.8073\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7981 - val_loss: 1.8046\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7947 - val_loss: 1.8009\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7921 - val_loss: 1.7987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7906 - val_loss: 1.7955\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7875 - val_loss: 1.7946\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7859 - val_loss: 1.7913\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7839 - val_loss: 1.7907\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7822 - val_loss: 1.7898\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7881\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7796 - val_loss: 1.7861\n",
      "Top-2 accuracy = 0.463\n",
      "26\n",
      "maxabsG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9390 - val_loss: 1.9355\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9311 - val_loss: 1.9311\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9274 - val_loss: 1.9290\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9262 - val_loss: 1.9285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9256 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9288\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9288\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9283\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.925 - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "27\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9064 - val_loss: 1.8618\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8332 - val_loss: 1.8160\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7981 - val_loss: 1.7915\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 1.7812\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7767\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7672 - val_loss: 1.7729\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7644 - val_loss: 1.7716\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7625 - val_loss: 1.7710\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7695\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7602 - val_loss: 1.7692\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7594 - val_loss: 1.7679\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7589 - val_loss: 1.7670\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7582 - val_loss: 1.7668\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7576 - val_loss: 1.7663\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7576 - val_loss: 1.7656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7567 - val_loss: 1.7646\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7563 - val_loss: 1.7649\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7558 - val_loss: 1.7652\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7559 - val_loss: 1.7640\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7549 - val_loss: 1.7643\n",
      "Top-2 accuracy = 0.468\n",
      "28\n",
      "standardizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9376 - val_loss: 1.9310\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9269 - val_loss: 1.9287\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9288\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9288\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "29\n",
      "robustq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9119 - val_loss: 1.8823\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8543 - val_loss: 1.8403\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8214 - val_loss: 1.8190\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8036 - val_loss: 1.8046\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7923 - val_loss: 1.7960\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7896\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7811 - val_loss: 1.7863\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7830\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7757 - val_loss: 1.7805\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7729 - val_loss: 1.7788\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7777\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7760\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7680 - val_loss: 1.7750\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7667 - val_loss: 1.7735\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7654 - val_loss: 1.7724\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7642 - val_loss: 1.7720\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7629 - val_loss: 1.7702\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7695\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7690\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7604 - val_loss: 1.7681\n",
      "Top-2 accuracy = 0.468\n",
      "0\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8965 - val_loss: 1.8345\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7898 - val_loss: 1.7749\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7648 - val_loss: 1.7694\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7610 - val_loss: 1.7693\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7600 - val_loss: 1.7695\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7591 - val_loss: 1.7679\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7578 - val_loss: 1.7638\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7575 - val_loss: 1.7650\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7566 - val_loss: 1.7668\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7563 - val_loss: 1.7647\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7567 - val_loss: 1.7637\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7556 - val_loss: 1.7635\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7546 - val_loss: 1.7641\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7548 - val_loss: 1.7668\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7546 - val_loss: 1.7689\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7563 - val_loss: 1.7642\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7540 - val_loss: 1.7630\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7536 - val_loss: 1.7616\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7528 - val_loss: 1.7632\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7533 - val_loss: 1.7649\n",
      "Top-2 accuracy = 0.468\n",
      "1\n",
      "standardizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8772 - val_loss: 1.8176\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7792 - val_loss: 1.7736\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7601 - val_loss: 1.7745\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7579 - val_loss: 1.7721\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7549 - val_loss: 1.7656\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7547 - val_loss: 1.7658\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7530 - val_loss: 1.7694\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7520 - val_loss: 1.7645\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7512 - val_loss: 1.7673\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7528 - val_loss: 1.7665\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7513 - val_loss: 1.7694\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7523 - val_loss: 1.7666\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7504 - val_loss: 1.7660\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7520 - val_loss: 1.7648\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7492 - val_loss: 1.7693\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7498 - val_loss: 1.7649\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.7496 - val_loss: 1.7653\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7496 - val_loss: 1.7679\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7506 - val_loss: 1.7638\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7518 - val_loss: 1.7659\n",
      "Top-2 accuracy = 0.471\n",
      "2\n",
      "normalizei|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9181 - val_loss: 1.8793\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8555 - val_loss: 1.8383\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8118 - val_loss: 1.8009\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7828 - val_loss: 1.7861\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7746 - val_loss: 1.7763\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7666 - val_loss: 1.7705\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7645 - val_loss: 1.7698\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7611 - val_loss: 1.7675\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7609 - val_loss: 1.7658\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7601 - val_loss: 1.7816\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7648 - val_loss: 1.7662\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7577 - val_loss: 1.7677\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7583 - val_loss: 1.7642\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7577 - val_loss: 1.7669\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7600 - val_loss: 1.7656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7574 - val_loss: 1.7643\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7565 - val_loss: 1.7644\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7565 - val_loss: 1.7653\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7567 - val_loss: 1.7694\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7568 - val_loss: 1.7651\n",
      "Top-2 accuracy = 0.466\n",
      "3\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9212 - val_loss: 1.8808\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8388 - val_loss: 1.8151\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7985 - val_loss: 1.7949\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7850 - val_loss: 1.7872\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7785 - val_loss: 1.7819\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7790\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7760\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7733\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7666 - val_loss: 1.7713\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7649 - val_loss: 1.7701\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7626 - val_loss: 1.7682\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7612 - val_loss: 1.7673\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7598 - val_loss: 1.7666\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7592 - val_loss: 1.7666\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7578 - val_loss: 1.7656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7566 - val_loss: 1.7646\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7559 - val_loss: 1.7639\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7549 - val_loss: 1.7643\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7542 - val_loss: 1.7629\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7537 - val_loss: 1.7623\n",
      "Top-2 accuracy = 0.471\n",
      "4\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9384 - val_loss: 1.9322\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9173 - val_loss: 1.8917\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8554 - val_loss: 1.8355\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8157 - val_loss: 1.8079\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7939 - val_loss: 1.7923\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7816 - val_loss: 1.7845\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7814\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7786\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7774\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7694 - val_loss: 1.7767\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7762\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7681 - val_loss: 1.7756\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7679 - val_loss: 1.7763\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7820\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7672 - val_loss: 1.7757\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7667 - val_loss: 1.7771\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7752\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7660 - val_loss: 1.7757\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7752\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7660 - val_loss: 1.7776\n",
      "Top-2 accuracy = 0.464\n",
      "5\n",
      "maxabsj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9094 - val_loss: 1.8246\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7809 - val_loss: 1.7741\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7635 - val_loss: 1.7695\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7604 - val_loss: 1.7684\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7574 - val_loss: 1.7659\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7562 - val_loss: 1.7671\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7557 - val_loss: 1.7642\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7544 - val_loss: 1.7648\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7543 - val_loss: 1.7655\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7548 - val_loss: 1.7679\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7560 - val_loss: 1.7624\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7515 - val_loss: 1.7622\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7511 - val_loss: 1.7611\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7496 - val_loss: 1.7617\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7484 - val_loss: 1.7607\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7475 - val_loss: 1.7627\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7478 - val_loss: 1.7582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7453 - val_loss: 1.7605\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7451 - val_loss: 1.7598\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7435 - val_loss: 1.7598\n",
      "Top-2 accuracy = 0.474\n",
      "6\n",
      "minmaxv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9172 - val_loss: 1.8800\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8478 - val_loss: 1.8244\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8030 - val_loss: 1.7996\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7884 - val_loss: 1.7924\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7810 - val_loss: 1.7861\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7812 - val_loss: 1.7840\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7770 - val_loss: 1.7814\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7811\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7834\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7754 - val_loss: 1.7801\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7757 - val_loss: 1.7850\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7762 - val_loss: 1.7787\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7727 - val_loss: 1.7776\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7723 - val_loss: 1.7809\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7794\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7724 - val_loss: 1.7774\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7708 - val_loss: 1.7777\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7718 - val_loss: 1.7756\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7709 - val_loss: 1.7783\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7706 - val_loss: 1.8003\n",
      "Top-2 accuracy = 0.459\n",
      "7\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9421 - val_loss: 1.9369\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9321 - val_loss: 1.9299\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9170 - val_loss: 1.9009\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8738 - val_loss: 1.8463\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8197 - val_loss: 1.8269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7885 - val_loss: 1.7855\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7781 - val_loss: 1.7789\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7732 - val_loss: 1.7832\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7696 - val_loss: 1.7866\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 1.7744\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7663 - val_loss: 1.7751\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7659 - val_loss: 1.7920\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7663 - val_loss: 1.7733\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7653 - val_loss: 1.7727\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7662 - val_loss: 1.7770\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7642 - val_loss: 1.7720\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7641 - val_loss: 1.7712\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7633 - val_loss: 1.7713\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7632 - val_loss: 1.7703\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7620 - val_loss: 1.7782\n",
      "Top-2 accuracy = 0.464\n",
      "8\n",
      "normalizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9086 - val_loss: 1.8640\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8206 - val_loss: 1.7964\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7821 - val_loss: 1.7820\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7725 - val_loss: 1.7819\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7710 - val_loss: 1.7759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7693 - val_loss: 1.7770\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7705 - val_loss: 1.7779\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7703 - val_loss: 1.7802\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7680 - val_loss: 1.7939\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7731 - val_loss: 1.7780\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7666 - val_loss: 1.7898\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7679 - val_loss: 1.7730\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7656 - val_loss: 1.7753\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7643 - val_loss: 1.7730\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7654 - val_loss: 1.7727\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7639 - val_loss: 1.7724\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7641 - val_loss: 1.7731\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7640 - val_loss: 1.7783\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7639 - val_loss: 1.7721\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7630 - val_loss: 1.7709\n",
      "Top-2 accuracy = 0.467\n",
      "9\n",
      "normalizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9293 - val_loss: 1.8993\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8559 - val_loss: 1.8284\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8070 - val_loss: 1.8059\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7904 - val_loss: 1.7914\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7831 - val_loss: 1.7855\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7767 - val_loss: 1.7856\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7744 - val_loss: 1.7793\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7727 - val_loss: 1.7870\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7715 - val_loss: 1.7761\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7706 - val_loss: 1.7751\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7711 - val_loss: 1.7760\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7742\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7761\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7731\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7683 - val_loss: 1.7737\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7684 - val_loss: 1.7725\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7673 - val_loss: 1.7852\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7717\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 1.7783\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7690 - val_loss: 1.7834\n",
      "Top-2 accuracy = 0.459\n",
      "10\n",
      "normalizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9043 - val_loss: 1.8498\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8172 - val_loss: 1.7975\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7770 - val_loss: 1.7750\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7670 - val_loss: 1.7700\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7686\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7619 - val_loss: 1.7690\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7605 - val_loss: 1.7850\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7631 - val_loss: 1.7655\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7598 - val_loss: 1.7648\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7586 - val_loss: 1.7688\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7612 - val_loss: 1.7645\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7579 - val_loss: 1.7673\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7584 - val_loss: 1.7646\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7581 - val_loss: 1.7672\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7575 - val_loss: 1.7692\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7573 - val_loss: 1.7667\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7579 - val_loss: 1.7649\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7582 - val_loss: 1.7640\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7576 - val_loss: 1.7884\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7730 - val_loss: 1.7649\n",
      "Top-2 accuracy = 0.468\n",
      "11\n",
      "minmaxW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9346 - val_loss: 1.9279\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9286\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9220 - val_loss: 1.9101\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8665 - val_loss: 1.8360\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8039 - val_loss: 1.7976\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7885 - val_loss: 1.7956\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7828 - val_loss: 1.7897\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7800 - val_loss: 1.7866\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7785 - val_loss: 1.7862\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7778 - val_loss: 1.7849\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7776 - val_loss: 1.7822\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7835\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7748 - val_loss: 1.7830\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7751 - val_loss: 1.7811\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7747 - val_loss: 1.7814\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7720 - val_loss: 1.7879\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7721 - val_loss: 1.7813\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7712 - val_loss: 1.7799\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7790\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7688 - val_loss: 1.7860\n",
      "Top-2 accuracy = 0.454\n",
      "12\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9152 - val_loss: 1.8720\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8229 - val_loss: 1.7970\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7835 - val_loss: 1.7833\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7807 - val_loss: 1.7876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7780 - val_loss: 1.8057\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7773 - val_loss: 1.8002\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7743 - val_loss: 1.8012\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7755 - val_loss: 1.7760\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7713 - val_loss: 1.7743\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7701 - val_loss: 1.7805\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7694 - val_loss: 1.7745\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7674 - val_loss: 1.8474\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7787 - val_loss: 1.7882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7680 - val_loss: 1.7741\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7666 - val_loss: 1.7714\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7643 - val_loss: 1.7727\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7650 - val_loss: 1.7699\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7652 - val_loss: 1.7729\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7659 - val_loss: 1.7721\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7624 - val_loss: 1.8004\n",
      "Top-2 accuracy = 0.451\n",
      "13\n",
      "minmaxt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9407 - val_loss: 1.9372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9338 - val_loss: 1.9329\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9299 - val_loss: 1.9305\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9279 - val_loss: 1.9294\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9268 - val_loss: 1.9288\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9261 - val_loss: 1.9285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Top-2 accuracy = 0.348\n",
      "14\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9405 - val_loss: 1.9364\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9319 - val_loss: 1.9310\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9275 - val_loss: 1.9290\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9260 - val_loss: 1.9285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "15\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9235 - val_loss: 1.9090\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8867 - val_loss: 1.8730\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8505 - val_loss: 1.8403\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8228 - val_loss: 1.8215\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8042 - val_loss: 1.8073\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7956 - val_loss: 1.8010\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7906 - val_loss: 1.7951\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7872 - val_loss: 1.7938\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7856 - val_loss: 1.7947\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7848 - val_loss: 1.7905\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7832 - val_loss: 1.7893\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7824 - val_loss: 1.7886\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7821 - val_loss: 1.7895\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7805 - val_loss: 1.7886\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7802 - val_loss: 1.7871\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7794 - val_loss: 1.7899\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7799 - val_loss: 1.7867\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7786 - val_loss: 1.7853\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7784 - val_loss: 1.7849\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7910\n",
      "Top-2 accuracy = 0.456\n",
      "16\n",
      "robustc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8851 - val_loss: 1.8361\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8061 - val_loss: 1.7963\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7829\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7726 - val_loss: 1.7791\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7683 - val_loss: 1.7759\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7654 - val_loss: 1.7726\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7633 - val_loss: 1.7710\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7615 - val_loss: 1.7701\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7604 - val_loss: 1.7692\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7591 - val_loss: 1.7686\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7572 - val_loss: 1.7706\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7572 - val_loss: 1.7656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7557 - val_loss: 1.7646\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7555 - val_loss: 1.7662\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7547 - val_loss: 1.7646\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7541 - val_loss: 1.7648\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7530 - val_loss: 1.7634\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7526 - val_loss: 1.7631\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7527 - val_loss: 1.7622\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7511 - val_loss: 1.7618\n",
      "Top-2 accuracy = 0.475\n",
      "17\n",
      "normalizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9110 - val_loss: 1.8649\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8170 - val_loss: 1.7960\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7832 - val_loss: 1.7848\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7764 - val_loss: 1.7809\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7729 - val_loss: 1.7760\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7701 - val_loss: 1.7735\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7723\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7711\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7649 - val_loss: 1.7696\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7685\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7631 - val_loss: 1.7686\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7622 - val_loss: 1.7682\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7605 - val_loss: 1.7670\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7598 - val_loss: 1.7667\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7593 - val_loss: 1.7664\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7590 - val_loss: 1.7652\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7582 - val_loss: 1.7659\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7581 - val_loss: 1.7660\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7572 - val_loss: 1.7644\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7647\n",
      "Top-2 accuracy = 0.466\n",
      "18\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9213 - val_loss: 1.8888\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8518 - val_loss: 1.8291\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8081 - val_loss: 1.8021\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7884 - val_loss: 1.7891\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7822\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7780\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7760\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7678 - val_loss: 1.7737\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7662 - val_loss: 1.7729\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7659 - val_loss: 1.7721\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7703\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7702\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7686\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7611 - val_loss: 1.7674\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7677\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7598 - val_loss: 1.7669\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7598 - val_loss: 1.7667\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7589 - val_loss: 1.7662\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7592 - val_loss: 1.7650\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7580 - val_loss: 1.7645\n",
      "Top-2 accuracy = 0.47\n",
      "19\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9300 - val_loss: 1.9100\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8846 - val_loss: 1.8669\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8471 - val_loss: 1.8432\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8298 - val_loss: 1.8317\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8147 - val_loss: 1.8087\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7886 - val_loss: 1.7856\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7729 - val_loss: 1.7769\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7734\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7633 - val_loss: 1.7721\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7615 - val_loss: 1.7694\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7598 - val_loss: 1.7681\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7592 - val_loss: 1.7680\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7677\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7574 - val_loss: 1.7656\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7568 - val_loss: 1.7662\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7561 - val_loss: 1.7657\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7574 - val_loss: 1.7656\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7557 - val_loss: 1.7661\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7554 - val_loss: 1.7655\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7553 - val_loss: 1.7649\n",
      "Top-2 accuracy = 0.466\n",
      "20\n",
      "robustv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9144 - val_loss: 1.8748\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8379 - val_loss: 1.8193\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7915 - val_loss: 1.7852\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7826\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7749 - val_loss: 1.7787\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7708 - val_loss: 1.7742\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7665 - val_loss: 1.7737\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7642 - val_loss: 1.7713\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7699\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7695\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7603 - val_loss: 1.7708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7600 - val_loss: 1.7674\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7573 - val_loss: 1.7664\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7563 - val_loss: 1.7652\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7564 - val_loss: 1.7647\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7553 - val_loss: 1.7643\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7544 - val_loss: 1.7640\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7540 - val_loss: 1.7643\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7539 - val_loss: 1.7629\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7529 - val_loss: 1.7638\n",
      "Top-2 accuracy = 0.472\n",
      "21\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9188 - val_loss: 1.8774\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8423 - val_loss: 1.8237\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7984 - val_loss: 1.7936\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7733 - val_loss: 1.7748\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7649 - val_loss: 1.7719\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7657\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7592 - val_loss: 1.7686\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7591 - val_loss: 1.7663\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7581 - val_loss: 1.7648\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7578 - val_loss: 1.7645\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7568 - val_loss: 1.7654\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7572 - val_loss: 1.7667\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7563 - val_loss: 1.7649\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7560 - val_loss: 1.7635\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7562 - val_loss: 1.7717\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7563 - val_loss: 1.7627\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7550 - val_loss: 1.7629\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7553 - val_loss: 1.7627\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7540 - val_loss: 1.7641\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7545 - val_loss: 1.7629\n",
      "Top-2 accuracy = 0.47\n",
      "22\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9173 - val_loss: 1.8731\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8272 - val_loss: 1.8093\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7863 - val_loss: 1.7865\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7719 - val_loss: 1.7766\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7665 - val_loss: 1.7717\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7626 - val_loss: 1.7694\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7701\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7606 - val_loss: 1.7706\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7595 - val_loss: 1.7669\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7582 - val_loss: 1.7677\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7580 - val_loss: 1.7662\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7576 - val_loss: 1.7675\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7566 - val_loss: 1.7664\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7577 - val_loss: 1.7669\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7562 - val_loss: 1.7656\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7554 - val_loss: 1.7642\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7552 - val_loss: 1.7655\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7558 - val_loss: 1.7643\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7556 - val_loss: 1.7670\n",
      "Top-2 accuracy = 0.469\n",
      "23\n",
      "normalizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8721 - val_loss: 1.8090\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7854 - val_loss: 1.7823\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7688 - val_loss: 1.7742\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7656 - val_loss: 1.7686\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7609 - val_loss: 1.7678\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7587 - val_loss: 1.7722\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7576 - val_loss: 1.7665\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7568 - val_loss: 1.7689\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7558 - val_loss: 1.7710\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7559 - val_loss: 1.7635\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7557 - val_loss: 1.7647\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7556 - val_loss: 1.7654\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7555 - val_loss: 1.7660\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7547 - val_loss: 1.7648\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7540 - val_loss: 1.7646\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7540 - val_loss: 1.7632\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7534 - val_loss: 1.7670\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7532 - val_loss: 1.7639\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7526 - val_loss: 1.7658\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7559 - val_loss: 1.7676\n",
      "Top-2 accuracy = 0.464\n",
      "24\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8871 - val_loss: 1.8179\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7898 - val_loss: 1.7853\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7694 - val_loss: 1.7728\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7748\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7615 - val_loss: 1.7698\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7597 - val_loss: 1.7686\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7591 - val_loss: 1.7665\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7579 - val_loss: 1.7657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7567 - val_loss: 1.7667\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7569 - val_loss: 1.7660\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7557 - val_loss: 1.7654\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7547 - val_loss: 1.7648\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7549 - val_loss: 1.7648\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7550 - val_loss: 1.7635\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7544 - val_loss: 1.7639\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7544 - val_loss: 1.7642\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7546 - val_loss: 1.7655\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7536 - val_loss: 1.7649\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7531 - val_loss: 1.7636\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7537 - val_loss: 1.7678\n",
      "Top-2 accuracy = 0.467\n",
      "25\n",
      "standardizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9070 - val_loss: 1.8662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8347 - val_loss: 1.8166\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8003 - val_loss: 1.7965\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7865 - val_loss: 1.7850\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7783 - val_loss: 1.7786\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7719 - val_loss: 1.7785\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7717 - val_loss: 1.7703\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7670 - val_loss: 1.7798\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7681 - val_loss: 1.7686\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7641 - val_loss: 1.7687\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7658 - val_loss: 1.7732\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7627 - val_loss: 1.7720\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7641 - val_loss: 1.7813\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7654 - val_loss: 1.7671\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7610 - val_loss: 1.7643\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7603 - val_loss: 1.7723\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7607 - val_loss: 1.7680\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7598 - val_loss: 1.7647\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7586 - val_loss: 1.7675\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7589 - val_loss: 1.7709\n",
      "Top-2 accuracy = 0.464\n",
      "26\n",
      "robustQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9264 - val_loss: 1.9073\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8670 - val_loss: 1.8210\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7887 - val_loss: 1.7789\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7684 - val_loss: 1.7739\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7669 - val_loss: 1.7759\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7616 - val_loss: 1.7663\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7634 - val_loss: 1.7721\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7608 - val_loss: 1.7661\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7601 - val_loss: 1.7647\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7615 - val_loss: 1.7667\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7587 - val_loss: 1.7732\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7572 - val_loss: 1.7641\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7576 - val_loss: 1.7698\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7592 - val_loss: 1.7661\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7575 - val_loss: 1.7640\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7572 - val_loss: 1.7645\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7580 - val_loss: 1.7690\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7584 - val_loss: 1.7640\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7573 - val_loss: 1.7670\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7572 - val_loss: 1.7643\n",
      "Top-2 accuracy = 0.466\n",
      "27\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9354 - val_loss: 1.9218\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8984 - val_loss: 1.8735\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8520 - val_loss: 1.8408\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8261 - val_loss: 1.8220\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8120 - val_loss: 1.8119\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8023 - val_loss: 1.8035\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7947 - val_loss: 1.7977\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7891 - val_loss: 1.7943\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7848 - val_loss: 1.7915\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7829 - val_loss: 1.7890\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7809 - val_loss: 1.7875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7799 - val_loss: 1.7867\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7791 - val_loss: 1.7868\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7784 - val_loss: 1.7867\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7775 - val_loss: 1.7850\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7771 - val_loss: 1.7847\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7766 - val_loss: 1.7840\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7761 - val_loss: 1.7834\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7754 - val_loss: 1.7831\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7753 - val_loss: 1.7837\n",
      "Top-2 accuracy = 0.46\n",
      "28\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8840 - val_loss: 1.8313\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7903 - val_loss: 1.7811\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7610 - val_loss: 1.7671\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7569 - val_loss: 1.7656\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7542 - val_loss: 1.7645\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7541 - val_loss: 1.7636\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7534 - val_loss: 1.7647\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7523 - val_loss: 1.7638\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7521 - val_loss: 1.7684\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7515 - val_loss: 1.7628\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7514 - val_loss: 1.7626\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7519 - val_loss: 1.7669\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7514 - val_loss: 1.7683\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7504 - val_loss: 1.7636\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7495 - val_loss: 1.7648\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7493 - val_loss: 1.7664\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7502 - val_loss: 1.7647\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7493 - val_loss: 1.7729\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7535 - val_loss: 1.7643\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7486 - val_loss: 1.7655\n",
      "Top-2 accuracy = 0.468\n",
      "29\n",
      "robustK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9174 - val_loss: 1.8878\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8466 - val_loss: 1.8291\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7955 - val_loss: 1.7854\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7719 - val_loss: 1.7752\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7650 - val_loss: 1.7689\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7626 - val_loss: 1.7679\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7605 - val_loss: 1.7665\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7600 - val_loss: 1.7687\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7638 - val_loss: 1.7847\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7593 - val_loss: 1.7637\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7567 - val_loss: 1.7634\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7577 - val_loss: 1.7649\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7566 - val_loss: 1.7636\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7576 - val_loss: 1.7631\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7571 - val_loss: 1.7761\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7599 - val_loss: 1.7757\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7579 - val_loss: 1.7649\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7551 - val_loss: 1.7635\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7567 - val_loss: 1.7635\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7563 - val_loss: 1.7679\n",
      "Top-2 accuracy = 0.465\n",
      "0\n",
      "standardizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9394 - val_loss: 1.9340\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9314 - val_loss: 1.9298\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9278 - val_loss: 1.9285\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9264 - val_loss: 1.9281\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9258 - val_loss: 1.9282\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9282\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "1\n",
      "normalizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9304 - val_loss: 1.9119\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8831 - val_loss: 1.8615\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8390 - val_loss: 1.8327\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8125 - val_loss: 1.8130\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7976 - val_loss: 1.8006\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7877 - val_loss: 1.7965\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7819 - val_loss: 1.7835\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7756 - val_loss: 1.7882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7720 - val_loss: 1.7800\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7686 - val_loss: 1.7771\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7670 - val_loss: 1.7724\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7686 - val_loss: 1.7777\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7668 - val_loss: 1.7728\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7644 - val_loss: 1.7693\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7700\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7633 - val_loss: 1.7684\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7618 - val_loss: 1.7685\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7629 - val_loss: 1.7691\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7615 - val_loss: 1.7680\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7700\n",
      "Top-2 accuracy = 0.469\n",
      "2\n",
      "robustv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9010 - val_loss: 1.8688\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8356 - val_loss: 1.8071\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7815 - val_loss: 1.7780\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7633 - val_loss: 1.7672\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7607 - val_loss: 1.7642\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7582 - val_loss: 1.7650\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7579 - val_loss: 1.7773\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7615 - val_loss: 1.7728\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7600 - val_loss: 1.7660\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7577 - val_loss: 1.7634\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7560 - val_loss: 1.7796\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7571 - val_loss: 1.7650\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7573 - val_loss: 1.7633\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7551 - val_loss: 1.7633\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7565 - val_loss: 1.7633\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7550 - val_loss: 1.7706\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7550 - val_loss: 1.7803\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7631 - val_loss: 1.7634\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7558 - val_loss: 1.7639\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7546 - val_loss: 1.7665\n",
      "Top-2 accuracy = 0.466\n",
      "3\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9354 - val_loss: 1.9303\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9275 - val_loss: 1.9259\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9048 - val_loss: 1.8724\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8380 - val_loss: 1.8139\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8011 - val_loss: 1.7961\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7858 - val_loss: 1.7886\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7784 - val_loss: 1.7813\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.7777\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7715 - val_loss: 1.7769\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7694 - val_loss: 1.7745\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7739\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7675 - val_loss: 1.7719\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7656 - val_loss: 1.7723\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7713\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7644 - val_loss: 1.7706\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7655 - val_loss: 1.7703\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7634 - val_loss: 1.7694\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7642 - val_loss: 1.7695\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7630 - val_loss: 1.7725\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7692\n",
      "Top-2 accuracy = 0.468\n",
      "4\n",
      "robustd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8926 - val_loss: 1.8475\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8178 - val_loss: 1.8029\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7852 - val_loss: 1.7775\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7699 - val_loss: 1.7778\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7662 - val_loss: 1.7693\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7611 - val_loss: 1.7683\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7587 - val_loss: 1.7783\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7622 - val_loss: 1.7657\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7581 - val_loss: 1.7684\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7586 - val_loss: 1.7657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7571 - val_loss: 1.7652\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7567 - val_loss: 1.7672\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7548 - val_loss: 1.7651\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7546 - val_loss: 1.7658\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7589 - val_loss: 1.7654\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7549 - val_loss: 1.7633\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7536 - val_loss: 1.7648\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7529 - val_loss: 1.7726\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7542 - val_loss: 1.7650\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7530 - val_loss: 1.7690\n",
      "Top-2 accuracy = 0.47\n",
      "5\n",
      "maxabsV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9348 - val_loss: 1.9168\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8849 - val_loss: 1.8618\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8425 - val_loss: 1.8333\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8188 - val_loss: 1.8151\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8044 - val_loss: 1.8036\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7952 - val_loss: 1.7968\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7899 - val_loss: 1.7925\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7894\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7826 - val_loss: 1.7866\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7800 - val_loss: 1.7844\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7826\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7769 - val_loss: 1.7804\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7805\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7726 - val_loss: 1.7777\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7715 - val_loss: 1.7771\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7704 - val_loss: 1.7779\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7695 - val_loss: 1.7766\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7683 - val_loss: 1.7759\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7687 - val_loss: 1.7743\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7737\n",
      "Top-2 accuracy = 0.465\n",
      "6\n",
      "normalized|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9273 - val_loss: 1.9083\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8839 - val_loss: 1.8634\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8393 - val_loss: 1.8230\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8064 - val_loss: 1.8090\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7903 - val_loss: 1.7906\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7807 - val_loss: 1.7861\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7763 - val_loss: 1.7803\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7724 - val_loss: 1.7902\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7721 - val_loss: 1.7770\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7690 - val_loss: 1.7733\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7668 - val_loss: 1.7722\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7647 - val_loss: 1.7720\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7650 - val_loss: 1.7723\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7632 - val_loss: 1.7692\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7630 - val_loss: 1.7704\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7615 - val_loss: 1.7684\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7613 - val_loss: 1.7670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7623 - val_loss: 1.7694\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7608 - val_loss: 1.7666\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7606 - val_loss: 1.7679\n",
      "Top-2 accuracy = 0.472\n",
      "7\n",
      "minmaxG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8959 - val_loss: 1.8464\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8115 - val_loss: 1.7953\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7826 - val_loss: 1.7831\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7750 - val_loss: 1.7844\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7725 - val_loss: 1.7749\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7694 - val_loss: 1.7746\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7734\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7672 - val_loss: 1.7726\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7722\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7666 - val_loss: 1.7724\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7654 - val_loss: 1.7717\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7649 - val_loss: 1.7712\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7649 - val_loss: 1.7707\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7701\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7629 - val_loss: 1.7701\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7629 - val_loss: 1.7686\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7693\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7616 - val_loss: 1.7706\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7629 - val_loss: 1.7688\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7716\n",
      "Top-2 accuracy = 0.466\n",
      "8\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9092 - val_loss: 1.8641\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8232 - val_loss: 1.7953\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7804 - val_loss: 1.7789\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7694 - val_loss: 1.7798\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7668 - val_loss: 1.7726\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7642 - val_loss: 1.7708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7636 - val_loss: 1.7714\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7619 - val_loss: 1.7696\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7618 - val_loss: 1.7721\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7612 - val_loss: 1.7711\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7712\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7598 - val_loss: 1.7683\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7598 - val_loss: 1.7681\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7590 - val_loss: 1.7703\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7700\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7572 - val_loss: 1.7698\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7571 - val_loss: 1.7667\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7567 - val_loss: 1.7715\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7570 - val_loss: 1.7713\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7568 - val_loss: 1.7676\n",
      "Top-2 accuracy = 0.469\n",
      "9\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8796 - val_loss: 1.8230\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7951 - val_loss: 1.7886\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7769 - val_loss: 1.7826\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7724 - val_loss: 1.7833\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7703 - val_loss: 1.7763\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7664 - val_loss: 1.7754\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7643 - val_loss: 1.7752\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7638 - val_loss: 1.7780\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7654 - val_loss: 1.7833\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7638 - val_loss: 1.7721\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7623 - val_loss: 1.7720\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7595 - val_loss: 1.7734\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7633 - val_loss: 1.7704\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7586 - val_loss: 1.7698\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7593 - val_loss: 1.7720\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7581 - val_loss: 1.7701\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7569 - val_loss: 1.7692\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7569 - val_loss: 1.7697\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7565 - val_loss: 1.7817\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7582 - val_loss: 1.7740\n",
      "Top-2 accuracy = 0.473\n",
      "10\n",
      "normalizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9409 - val_loss: 1.9372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9333 - val_loss: 1.9326\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9291 - val_loss: 1.9302\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9269 - val_loss: 1.9290\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9259 - val_loss: 1.9286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 2s 22ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Top-2 accuracy = 0.348\n",
      "11\n",
      "minmaxK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9368 - val_loss: 1.9331\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9293 - val_loss: 1.9297\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9265 - val_loss: 1.9286\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9257 - val_loss: 1.9287\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Top-2 accuracy = 0.348\n",
      "12\n",
      "maxabsg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8697 - val_loss: 1.8439\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8223 - val_loss: 1.8086\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7924 - val_loss: 1.7903\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7797 - val_loss: 1.7841\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7764 - val_loss: 1.7820\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7758 - val_loss: 1.7810\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7741 - val_loss: 1.7819\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7728 - val_loss: 1.7797\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7717 - val_loss: 1.7769\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7713 - val_loss: 1.7769\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7685 - val_loss: 1.7781\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7690 - val_loss: 1.7760\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7686 - val_loss: 1.7750\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7666 - val_loss: 1.7743\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7745\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7659 - val_loss: 1.7744\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7653 - val_loss: 1.7752\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7768\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7641 - val_loss: 1.7749\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7649 - val_loss: 1.7724\n",
      "Top-2 accuracy = 0.467\n",
      "13\n",
      "robustz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9328 - val_loss: 1.9118\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8656 - val_loss: 1.8247\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8003 - val_loss: 1.7914\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7787 - val_loss: 1.7819\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7734 - val_loss: 1.7768\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7753\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7677 - val_loss: 1.7734\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7742\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7655 - val_loss: 1.7721\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7655 - val_loss: 1.7707\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7637 - val_loss: 1.7698\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7625 - val_loss: 1.7733\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7628 - val_loss: 1.7717\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7610 - val_loss: 1.7689\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7614 - val_loss: 1.7680\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7599 - val_loss: 1.7692\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7599 - val_loss: 1.7661\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7592 - val_loss: 1.7680\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7591 - val_loss: 1.7674\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7586 - val_loss: 1.7671\n",
      "Top-2 accuracy = 0.463\n",
      "14\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8949 - val_loss: 1.8332\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7992 - val_loss: 1.7950\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7750 - val_loss: 1.7744\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7654 - val_loss: 1.7790\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7627 - val_loss: 1.7740\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7632 - val_loss: 1.7674\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7596 - val_loss: 1.7906\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7643 - val_loss: 1.7670\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7587 - val_loss: 1.7649\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7568 - val_loss: 1.7675\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7566 - val_loss: 1.7664\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7565 - val_loss: 1.7656\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7554 - val_loss: 1.7696\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7568 - val_loss: 1.7648\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7567 - val_loss: 1.7644\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7552 - val_loss: 1.7744\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7567 - val_loss: 1.7665\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7548 - val_loss: 1.7655\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7548 - val_loss: 1.7650\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7535 - val_loss: 1.7673\n",
      "Top-2 accuracy = 0.471\n",
      "15\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9140 - val_loss: 1.8772\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8456 - val_loss: 1.8273\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8037 - val_loss: 1.7892\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7779 - val_loss: 1.7792\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7709 - val_loss: 1.7821\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7679 - val_loss: 1.7747\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7686 - val_loss: 1.7764\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7641 - val_loss: 1.7810\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7656 - val_loss: 1.7746\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7638 - val_loss: 1.7742\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7628 - val_loss: 1.7719\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7621 - val_loss: 1.7717\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7612 - val_loss: 1.7717\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7614 - val_loss: 1.7701\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7597 - val_loss: 1.7827\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7617 - val_loss: 1.7751\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7597 - val_loss: 1.7786\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7619 - val_loss: 1.7711\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7598 - val_loss: 1.7705\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7583 - val_loss: 1.7682\n",
      "Top-2 accuracy = 0.468\n",
      "16\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9394 - val_loss: 1.9342\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9296 - val_loss: 1.9287\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9218 - val_loss: 1.9132\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8872 - val_loss: 1.8729\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8622 - val_loss: 1.8581\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8507 - val_loss: 1.8483\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8421 - val_loss: 1.8412\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8353 - val_loss: 1.8341\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8291 - val_loss: 1.8307\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8236 - val_loss: 1.8242\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8185 - val_loss: 1.8201\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8144 - val_loss: 1.8162\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8105 - val_loss: 1.8143\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8074 - val_loss: 1.8105\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8043 - val_loss: 1.8086\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8024 - val_loss: 1.8090\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8018 - val_loss: 1.8055\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7986 - val_loss: 1.8034\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7974 - val_loss: 1.8055\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7970 - val_loss: 1.8018\n",
      "Top-2 accuracy = 0.456\n",
      "17\n",
      "standardizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9408 - val_loss: 1.9372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9335 - val_loss: 1.9326\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9297 - val_loss: 1.9302\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9277 - val_loss: 1.9291\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9266 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9260 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Top-2 accuracy = 0.348\n",
      "18\n",
      "normalizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9186 - val_loss: 1.8722\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8282 - val_loss: 1.7959\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7786 - val_loss: 1.7783\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7721 - val_loss: 1.7786\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7801\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7680 - val_loss: 1.7765\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7689 - val_loss: 1.7733\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7731\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7654 - val_loss: 1.7721\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7649 - val_loss: 1.7716\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7646 - val_loss: 1.7717\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7709\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7721\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7731\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7714\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7644 - val_loss: 1.7818\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7742\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7625 - val_loss: 1.7699\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7701\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7620 - val_loss: 1.7701\n",
      "Top-2 accuracy = 0.467\n",
      "19\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9181 - val_loss: 1.8836\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8468 - val_loss: 1.8267\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8054 - val_loss: 1.8013\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7877 - val_loss: 1.7954\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7802 - val_loss: 1.7848\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7774 - val_loss: 1.7809\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7732 - val_loss: 1.7783\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7708 - val_loss: 1.7778\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7693 - val_loss: 1.7761\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7675 - val_loss: 1.7754\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7669 - val_loss: 1.7731\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7663 - val_loss: 1.7768\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7652 - val_loss: 1.7706\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7635 - val_loss: 1.7725\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7631 - val_loss: 1.7734\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7634 - val_loss: 1.7693\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7622 - val_loss: 1.7682\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7615 - val_loss: 1.7718\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7627 - val_loss: 1.7671\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7605 - val_loss: 1.7672\n",
      "Top-2 accuracy = 0.47\n",
      "20\n",
      "normalizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9361 - val_loss: 1.9329\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9268 - val_loss: 1.9291\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9289\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9289\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9288\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Top-2 accuracy = 0.348\n",
      "21\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9222 - val_loss: 1.8768\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8443 - val_loss: 1.8156\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8009 - val_loss: 1.7907\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7812 - val_loss: 1.7800\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7725 - val_loss: 1.7769\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7681 - val_loss: 1.7727\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7668 - val_loss: 1.7724\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7642 - val_loss: 1.7701\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7647 - val_loss: 1.7864\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7688 - val_loss: 1.7675\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7615 - val_loss: 1.7659\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7599 - val_loss: 1.7766\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7617 - val_loss: 1.7696\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7595 - val_loss: 1.7767\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7619 - val_loss: 1.7660\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7584 - val_loss: 1.7653\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7590 - val_loss: 1.7646\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7586 - val_loss: 1.7666\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7604 - val_loss: 1.7871\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7612 - val_loss: 1.7658\n",
      "Top-2 accuracy = 0.466\n",
      "22\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9265 - val_loss: 1.8934\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8552 - val_loss: 1.8321\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8128 - val_loss: 1.8060\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7922 - val_loss: 1.7920\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7779 - val_loss: 1.7827\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7727 - val_loss: 1.7776\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7703 - val_loss: 1.7747\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7748 - val_loss: 1.7720\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7681 - val_loss: 1.7778\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7732 - val_loss: 1.7855\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7683 - val_loss: 1.7750\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7683 - val_loss: 1.7697\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7645 - val_loss: 1.7723\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7629 - val_loss: 1.7680\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7643 - val_loss: 1.7743\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7645 - val_loss: 1.7715\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7631 - val_loss: 1.7737\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7631 - val_loss: 1.7693\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7632 - val_loss: 1.7737\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7617 - val_loss: 1.7706\n",
      "Top-2 accuracy = 0.46\n",
      "23\n",
      "maxabsr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9250 - val_loss: 1.8922\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8502 - val_loss: 1.8155\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7959 - val_loss: 1.7865\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7762 - val_loss: 1.7796\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7743\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7658 - val_loss: 1.7722\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7651 - val_loss: 1.7699\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7641 - val_loss: 1.7683\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7624 - val_loss: 1.7681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7617 - val_loss: 1.7681\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7672\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7605 - val_loss: 1.7666\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7601 - val_loss: 1.7662\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7603 - val_loss: 1.7663\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7594 - val_loss: 1.7680\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7607 - val_loss: 1.7651\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7593 - val_loss: 1.7658\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7585 - val_loss: 1.7656\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7583 - val_loss: 1.7648\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7583 - val_loss: 1.7646\n",
      "Top-2 accuracy = 0.469\n",
      "24\n",
      "normalizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9276 - val_loss: 1.8936\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8398 - val_loss: 1.7950\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7804 - val_loss: 1.7807\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.7758\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7705 - val_loss: 1.7797\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7694 - val_loss: 1.7724\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7672 - val_loss: 1.7804\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7679 - val_loss: 1.7700\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7652 - val_loss: 1.7703\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7642 - val_loss: 1.7689\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7685\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7679\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7636 - val_loss: 1.7675\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7627 - val_loss: 1.7689\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7623 - val_loss: 1.7715\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7618 - val_loss: 1.7663\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7665\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7608 - val_loss: 1.7655\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7599 - val_loss: 1.7663\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7598 - val_loss: 1.7651\n",
      "Top-2 accuracy = 0.467\n",
      "25\n",
      "minmaxX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9320 - val_loss: 1.9225\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9018 - val_loss: 1.8803\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8577 - val_loss: 1.8442\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8237 - val_loss: 1.8160\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7998 - val_loss: 1.7969\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7874 - val_loss: 1.7920\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7815 - val_loss: 1.7851\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7762 - val_loss: 1.7849\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7746 - val_loss: 1.7821\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7735 - val_loss: 1.7919\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7746 - val_loss: 1.7799\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7722 - val_loss: 1.7776\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7708 - val_loss: 1.7774\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7706 - val_loss: 1.7824\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7714 - val_loss: 1.7776\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7768\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7694 - val_loss: 1.7790\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.7807\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7692 - val_loss: 1.7760\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7687 - val_loss: 1.7759\n",
      "Top-2 accuracy = 0.46\n",
      "26\n",
      "minmaxQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9075 - val_loss: 1.8543\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8122 - val_loss: 1.7922\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7785 - val_loss: 1.7777\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7689 - val_loss: 1.7732\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7657 - val_loss: 1.7703\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7631 - val_loss: 1.7689\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7611 - val_loss: 1.7677\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7668\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7606 - val_loss: 1.7729\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7667\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7604 - val_loss: 1.7659\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7589 - val_loss: 1.7659\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7589 - val_loss: 1.7663\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7586 - val_loss: 1.7663\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7582 - val_loss: 1.7646\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7582 - val_loss: 1.7645\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7573 - val_loss: 1.7646\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7644\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7574 - val_loss: 1.7639\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7575 - val_loss: 1.7659\n",
      "Top-2 accuracy = 0.473\n",
      "27\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9190 - val_loss: 1.8823\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8500 - val_loss: 1.8300\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8169 - val_loss: 1.8082\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7953 - val_loss: 1.7911\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7765 - val_loss: 1.7762\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7678 - val_loss: 1.7724\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7667 - val_loss: 1.7701\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7639 - val_loss: 1.7697\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7632 - val_loss: 1.7740\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7625 - val_loss: 1.7691\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7633 - val_loss: 1.7732\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7638 - val_loss: 1.7718\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7653 - val_loss: 1.7689\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7626 - val_loss: 1.7712\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7608 - val_loss: 1.7665\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7610 - val_loss: 1.7691\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7610 - val_loss: 1.7663\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7600 - val_loss: 1.7755\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7684\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7594 - val_loss: 1.7664\n",
      "Top-2 accuracy = 0.467\n",
      "28\n",
      "robustc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9356 - val_loss: 1.9304\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9263 - val_loss: 1.9285\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9288\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9288\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9256 - val_loss: 1.9287\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Top-2 accuracy = 0.348\n",
      "29\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9409 - val_loss: 1.9374\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9339 - val_loss: 1.9328\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9300 - val_loss: 1.9304\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9279 - val_loss: 1.9292\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9267 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9260 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Top-2 accuracy = 0.348\n",
      "0\n",
      "minmaxO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9391 - val_loss: 1.9340\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9302 - val_loss: 1.9297\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9268 - val_loss: 1.9286\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9258 - val_loss: 1.9283\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9288\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Top-2 accuracy = 0.348\n",
      "1\n",
      "standardizep|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9319 - val_loss: 1.9154\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8798 - val_loss: 1.8470\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8138 - val_loss: 1.8057\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7851 - val_loss: 1.7815\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7748\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7673 - val_loss: 1.7719\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7639 - val_loss: 1.7694\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7616 - val_loss: 1.7689\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7611 - val_loss: 1.7693\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7607 - val_loss: 1.7656\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7601 - val_loss: 1.7660\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7598 - val_loss: 1.7677\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7591 - val_loss: 1.7666\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7579 - val_loss: 1.7647\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7578 - val_loss: 1.7668\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7577 - val_loss: 1.7677\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7568 - val_loss: 1.7736\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7569 - val_loss: 1.7648\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7567 - val_loss: 1.7651\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7560 - val_loss: 1.7645\n",
      "Top-2 accuracy = 0.468\n",
      "2\n",
      "robustl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9123 - val_loss: 1.8701\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8484 - val_loss: 1.8338\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8109 - val_loss: 1.7934\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7802 - val_loss: 1.7776\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7699 - val_loss: 1.7730\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7663 - val_loss: 1.7761\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7653 - val_loss: 1.7693\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7620 - val_loss: 1.7682\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7607 - val_loss: 1.7679\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7607 - val_loss: 1.7681\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7592 - val_loss: 1.7685\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7663\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7583 - val_loss: 1.7667\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7578 - val_loss: 1.7655\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7579 - val_loss: 1.7651\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7576 - val_loss: 1.7647\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7569 - val_loss: 1.7652\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7571 - val_loss: 1.7654\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7562 - val_loss: 1.7636\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7563 - val_loss: 1.7662\n",
      "Top-2 accuracy = 0.471\n",
      "3\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8965 - val_loss: 1.8580\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8308 - val_loss: 1.8153\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7969 - val_loss: 1.7891\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7787 - val_loss: 1.7802\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7718 - val_loss: 1.7781\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7689 - val_loss: 1.7868\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7682 - val_loss: 1.7741\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7661 - val_loss: 1.7713\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7665 - val_loss: 1.7717\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7645 - val_loss: 1.7711\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7638 - val_loss: 1.7728\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7634 - val_loss: 1.7717\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7629 - val_loss: 1.7702\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7627 - val_loss: 1.7689\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7625 - val_loss: 1.7724\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7618 - val_loss: 1.7704\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7619 - val_loss: 1.7678\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7622 - val_loss: 1.7681\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7620 - val_loss: 1.7679\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7611 - val_loss: 1.7714\n",
      "Top-2 accuracy = 0.468\n",
      "4\n",
      "maxabsA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9338 - val_loss: 1.9070\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8622 - val_loss: 1.8238\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7967 - val_loss: 1.7826\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7721 - val_loss: 1.7729\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7647 - val_loss: 1.7783\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7674\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7614 - val_loss: 1.7659\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7602 - val_loss: 1.7688\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7607 - val_loss: 1.7655\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7601 - val_loss: 1.7658\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7583 - val_loss: 1.7653\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7646\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7590 - val_loss: 1.7646\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7575 - val_loss: 1.7643\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7590 - val_loss: 1.7667\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7581 - val_loss: 1.7647\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7573 - val_loss: 1.7648\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7566 - val_loss: 1.7639\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7563 - val_loss: 1.7644\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7564 - val_loss: 1.7653\n",
      "Top-2 accuracy = 0.466\n",
      "5\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9245 - val_loss: 1.8910\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8600 - val_loss: 1.8423\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8197 - val_loss: 1.8110\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7939 - val_loss: 1.7942\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7815 - val_loss: 1.7827\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7725 - val_loss: 1.7782\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7674 - val_loss: 1.7750\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7651 - val_loss: 1.7739\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7638 - val_loss: 1.7717\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7625 - val_loss: 1.7711\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7618 - val_loss: 1.7695\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7600 - val_loss: 1.7689\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7595 - val_loss: 1.7690\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7595 - val_loss: 1.7679\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7583 - val_loss: 1.7666\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7576 - val_loss: 1.7669\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7570 - val_loss: 1.7668\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7571 - val_loss: 1.7670\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7563 - val_loss: 1.7660\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7563 - val_loss: 1.7675\n",
      "Top-2 accuracy = 0.47\n",
      "6\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9314 - val_loss: 1.9114\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8858 - val_loss: 1.8646\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8422 - val_loss: 1.8280\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8113 - val_loss: 1.8041\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7921 - val_loss: 1.7900\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7808 - val_loss: 1.7831\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7787\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7700 - val_loss: 1.7746\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7675 - val_loss: 1.7743\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7661 - val_loss: 1.7724\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7656 - val_loss: 1.7713\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7640 - val_loss: 1.7709\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7709\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7629 - val_loss: 1.7697\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7621 - val_loss: 1.7709\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7617 - val_loss: 1.7687\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7611 - val_loss: 1.7689\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7685\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7609 - val_loss: 1.7683\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 1.7678\n",
      "Top-2 accuracy = 0.466\n",
      "7\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9062 - val_loss: 1.8516\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8146 - val_loss: 1.7932\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7801 - val_loss: 1.7788\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7707 - val_loss: 1.7741\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7689 - val_loss: 1.7787\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7670 - val_loss: 1.7702\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7636 - val_loss: 1.7691\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7624 - val_loss: 1.7701\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7614 - val_loss: 1.7677\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7609 - val_loss: 1.7698\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7600 - val_loss: 1.7726\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7599 - val_loss: 1.7659\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7583 - val_loss: 1.7680\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7576 - val_loss: 1.7673\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7586 - val_loss: 1.7687\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7568 - val_loss: 1.7685\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7571 - val_loss: 1.7694\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7559 - val_loss: 1.7673\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7554 - val_loss: 1.7694\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7561 - val_loss: 1.7672\n",
      "Top-2 accuracy = 0.466\n",
      "8\n",
      "robustg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.8886\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8671 - val_loss: 1.8399\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8167 - val_loss: 1.8029\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7816 - val_loss: 1.7762\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7687 - val_loss: 1.7731\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7647 - val_loss: 1.7736\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7640 - val_loss: 1.7920\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7649 - val_loss: 1.7695\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7714\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7608 - val_loss: 1.7699\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7609 - val_loss: 1.7720\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7594 - val_loss: 1.7687\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7605 - val_loss: 1.7691\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7600 - val_loss: 1.7744\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7643 - val_loss: 1.7692\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7592 - val_loss: 1.7671\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7578 - val_loss: 1.7670\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7578 - val_loss: 1.7675\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7577 - val_loss: 1.7668\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7566 - val_loss: 1.7679\n",
      "Top-2 accuracy = 0.469\n",
      "9\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9041 - val_loss: 1.8576\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8324 - val_loss: 1.8188\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8038 - val_loss: 1.8012\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7890 - val_loss: 1.7902\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7816 - val_loss: 1.7862\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7783 - val_loss: 1.7849\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7753 - val_loss: 1.7801\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7740 - val_loss: 1.7781\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7732 - val_loss: 1.7775\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7707 - val_loss: 1.7756\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7702 - val_loss: 1.7750\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7697 - val_loss: 1.7735\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7681 - val_loss: 1.7741\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.7761\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7675 - val_loss: 1.7726\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7667 - val_loss: 1.7725\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7718\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7654 - val_loss: 1.7719\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7648 - val_loss: 1.7710\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7649 - val_loss: 1.7725\n",
      "Top-2 accuracy = 0.465\n",
      "10\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9110 - val_loss: 1.8668\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8246 - val_loss: 1.7984\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7818 - val_loss: 1.7771\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7681 - val_loss: 1.7712\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7694\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 2s 23ms/step - loss: 1.7612 - val_loss: 1.7671\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7608 - val_loss: 1.7667\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7591 - val_loss: 1.7667\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7588 - val_loss: 1.7662\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7590 - val_loss: 1.7651\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7575 - val_loss: 1.7648\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7655\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7642\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7567 - val_loss: 1.7650\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7569 - val_loss: 1.7645\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7571 - val_loss: 1.7639\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7565 - val_loss: 1.7645\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7557 - val_loss: 1.7643\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7556 - val_loss: 1.7641\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7564 - val_loss: 1.7642\n",
      "Top-2 accuracy = 0.468\n",
      "11\n",
      "standardizen|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9220 - val_loss: 1.8831\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8539 - val_loss: 1.8332\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8198 - val_loss: 1.8146\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8035 - val_loss: 1.8009\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7931 - val_loss: 1.7919\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7855 - val_loss: 1.7871\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7783 - val_loss: 1.7789\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7713 - val_loss: 1.7733\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7646 - val_loss: 1.7694\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7613 - val_loss: 1.7749\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7597 - val_loss: 1.7675\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7587 - val_loss: 1.7701\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7576 - val_loss: 1.7680\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7573 - val_loss: 1.7685\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7565 - val_loss: 1.7672\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7562 - val_loss: 1.7656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7556 - val_loss: 1.7664\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7557 - val_loss: 1.7660\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7553 - val_loss: 1.7662\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7547 - val_loss: 1.7649\n",
      "Top-2 accuracy = 0.468\n",
      "12\n",
      "standardizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8836 - val_loss: 1.8210\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7872 - val_loss: 1.7749\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7620 - val_loss: 1.7693\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7581 - val_loss: 1.7673\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7558 - val_loss: 1.7655\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7566 - val_loss: 1.7639\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7535 - val_loss: 1.7636\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7553 - val_loss: 1.7655\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7536 - val_loss: 1.7661\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7547 - val_loss: 1.7630\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7538 - val_loss: 1.7641\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7525 - val_loss: 1.7635\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7526 - val_loss: 1.7659\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7518 - val_loss: 1.7663\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7518 - val_loss: 1.7617\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7519 - val_loss: 1.7678\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7508 - val_loss: 1.7631\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7508 - val_loss: 1.7626\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7500 - val_loss: 1.7630\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7520 - val_loss: 1.7652\n",
      "Top-2 accuracy = 0.47\n",
      "13\n",
      "minmaxk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9410 - val_loss: 1.9374\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9338 - val_loss: 1.9328\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9300 - val_loss: 1.9304\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9278 - val_loss: 1.9292\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9267 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9260 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9256 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "14\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9213 - val_loss: 1.8774\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8203 - val_loss: 1.7957\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7822 - val_loss: 1.7834\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7739 - val_loss: 1.7747\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7701 - val_loss: 1.7773\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7699 - val_loss: 1.7739\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7674 - val_loss: 1.7741\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7675 - val_loss: 1.7829\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7698 - val_loss: 1.7701\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7651 - val_loss: 1.7712\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7650 - val_loss: 1.7716\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7649 - val_loss: 1.7749\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7651 - val_loss: 1.7694\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7651 - val_loss: 1.7925\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7721 - val_loss: 1.7695\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7644 - val_loss: 1.7701\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7653 - val_loss: 1.7698\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7641 - val_loss: 1.7689\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7630 - val_loss: 1.7679\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7626 - val_loss: 1.7710\n",
      "Top-2 accuracy = 0.468\n",
      "15\n",
      "maxabsM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9294 - val_loss: 1.9290\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9252 - val_loss: 1.9257\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8804 - val_loss: 1.8293\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7991 - val_loss: 1.7900\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7801 - val_loss: 1.7788\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7728 - val_loss: 1.7763\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7869\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7722 - val_loss: 1.7780\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7678 - val_loss: 1.7727\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7664 - val_loss: 1.7753\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7673 - val_loss: 1.7770\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7662 - val_loss: 1.7738\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7642 - val_loss: 1.7704\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7695\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7636 - val_loss: 1.7688\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7622 - val_loss: 1.7715\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7685\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7621 - val_loss: 1.7698\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7714\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7655 - val_loss: 1.7679\n",
      "Top-2 accuracy = 0.467\n",
      "16\n",
      "robustq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.9349 - val_loss: 1.9303\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9257 - val_loss: 1.9286\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9290\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9256 - val_loss: 1.9289\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9256 - val_loss: 1.9282\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9283\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9288\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Top-2 accuracy = 0.348\n",
      "17\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9056 - val_loss: 1.8631\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8299 - val_loss: 1.8079\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7858 - val_loss: 1.7805\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7709 - val_loss: 1.7748\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7659 - val_loss: 1.7897\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7653 - val_loss: 1.7698\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7634 - val_loss: 1.7697\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7627 - val_loss: 1.7688\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7616 - val_loss: 1.7674\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7603 - val_loss: 1.7672\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.7605 - val_loss: 1.7680\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7611 - val_loss: 1.7718\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7596 - val_loss: 1.7670\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7604 - val_loss: 1.7675\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7590 - val_loss: 1.7685\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7614 - val_loss: 1.7679\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7599 - val_loss: 1.7658\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7597 - val_loss: 1.7653\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7585 - val_loss: 1.7686\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7586 - val_loss: 1.7671\n",
      "Top-2 accuracy = 0.47\n",
      "18\n",
      "robustw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9397 - val_loss: 1.9354\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9305 - val_loss: 1.9301\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9268 - val_loss: 1.9288\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9257 - val_loss: 1.9286\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9283\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "19\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9361 - val_loss: 1.9287\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8990 - val_loss: 1.8774\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8385 - val_loss: 1.8084\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7886 - val_loss: 1.7873\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7777 - val_loss: 1.7826\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7746 - val_loss: 1.7773\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7777\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7730 - val_loss: 1.7754\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7710 - val_loss: 1.7760\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7707 - val_loss: 1.7773\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7684 - val_loss: 1.7797\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7704 - val_loss: 1.7739\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7675 - val_loss: 1.7735\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7667 - val_loss: 1.7738\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7673 - val_loss: 1.7727\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7670 - val_loss: 1.7723\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7656 - val_loss: 1.7726\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7653 - val_loss: 1.7752\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7669 - val_loss: 1.7725\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7650 - val_loss: 1.7723\n",
      "Top-2 accuracy = 0.466\n",
      "20\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9398 - val_loss: 1.9328\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9049 - val_loss: 1.8759\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8534 - val_loss: 1.8390\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8202 - val_loss: 1.8173\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8032 - val_loss: 1.8005\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7905 - val_loss: 1.7927\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7811 - val_loss: 1.7920\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7745 - val_loss: 1.7779\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7712 - val_loss: 1.7744\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7684 - val_loss: 1.7736\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7672 - val_loss: 1.7709\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7652 - val_loss: 1.7764\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7647 - val_loss: 1.7742\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7646 - val_loss: 1.7720\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7644 - val_loss: 1.7696\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7634 - val_loss: 1.7694\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7636 - val_loss: 1.7759\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7630 - val_loss: 1.7683\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7618 - val_loss: 1.7709\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7626 - val_loss: 1.7700\n",
      "Top-2 accuracy = 0.469\n",
      "21\n",
      "maxabsL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8994 - val_loss: 1.8461\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8096 - val_loss: 1.7988\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7759 - val_loss: 1.7752\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7669 - val_loss: 1.8056\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7709 - val_loss: 1.7707\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7616 - val_loss: 1.7686\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7614 - val_loss: 1.7691\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7612 - val_loss: 1.7675\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7600 - val_loss: 1.7678\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7595 - val_loss: 1.7680\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7596 - val_loss: 1.7720\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7589 - val_loss: 1.7676\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7575 - val_loss: 1.7784\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7589 - val_loss: 1.7663\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7593 - val_loss: 1.7660\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7568 - val_loss: 1.7731\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7617 - val_loss: 1.7660\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7563 - val_loss: 1.7642\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7566 - val_loss: 1.7649\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7561 - val_loss: 1.7639\n",
      "Top-2 accuracy = 0.468\n",
      "22\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8819 - val_loss: 1.8273\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7973 - val_loss: 1.7807\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7683 - val_loss: 1.7739\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7666 - val_loss: 1.7729\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7609 - val_loss: 1.7757\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7614 - val_loss: 1.7679\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7588 - val_loss: 1.7664\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7578 - val_loss: 1.7765\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7580 - val_loss: 1.7717\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7579 - val_loss: 1.7659\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7575 - val_loss: 1.7707\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7602 - val_loss: 1.7659\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7555 - val_loss: 1.7684\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7563 - val_loss: 1.7662\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7561 - val_loss: 1.7719\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7568 - val_loss: 1.7774\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7550 - val_loss: 1.7737\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7583 - val_loss: 1.7683\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7590 - val_loss: 1.7659\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7551 - val_loss: 1.7660\n",
      "Top-2 accuracy = 0.469\n",
      "23\n",
      "normalizei|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9408 - val_loss: 1.9372\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9337 - val_loss: 1.9326\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9298 - val_loss: 1.9303\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9277 - val_loss: 1.9291\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9265 - val_loss: 1.9286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9260 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9283\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Top-2 accuracy = 0.348\n",
      "24\n",
      "standardizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9303 - val_loss: 1.9082\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8659 - val_loss: 1.8385\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8178 - val_loss: 1.8103\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7966 - val_loss: 1.8011\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7813 - val_loss: 1.7812\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7725 - val_loss: 1.7786\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7712 - val_loss: 1.7918\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7702 - val_loss: 1.7760\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7674 - val_loss: 1.7761\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7661 - val_loss: 1.7727\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7641 - val_loss: 1.7732\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7625 - val_loss: 1.7722\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7620 - val_loss: 1.7702\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7622 - val_loss: 1.7709\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7625 - val_loss: 1.7693\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7618 - val_loss: 1.7696\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7603 - val_loss: 1.7725\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7611 - val_loss: 1.7684\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7598 - val_loss: 1.7677\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7590 - val_loss: 1.7763\n",
      "Top-2 accuracy = 0.462\n",
      "25\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9241 - val_loss: 1.9086\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8787 - val_loss: 1.8610\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8443 - val_loss: 1.8428\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8305 - val_loss: 1.8283\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8150 - val_loss: 1.8158\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8017 - val_loss: 1.8025\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7910 - val_loss: 1.7964\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7855 - val_loss: 1.7957\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7826 - val_loss: 1.8010\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7817 - val_loss: 1.7935\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7775 - val_loss: 1.7869\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7743 - val_loss: 1.7807\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7730 - val_loss: 1.7789\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7700 - val_loss: 1.7772\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7707 - val_loss: 1.7800\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7713 - val_loss: 1.7813\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7693 - val_loss: 1.7737\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7696 - val_loss: 1.7777\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7680 - val_loss: 1.7732\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7663 - val_loss: 1.7717\n",
      "Top-2 accuracy = 0.467\n",
      "26\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9005 - val_loss: 1.8687\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8478 - val_loss: 1.8418\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8151 - val_loss: 1.8079\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7932 - val_loss: 1.7940\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7813 - val_loss: 1.7831\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7739 - val_loss: 1.7769\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7670 - val_loss: 1.7755\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7715 - val_loss: 1.7867\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7633 - val_loss: 1.7691\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7633 - val_loss: 1.7666\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7614 - val_loss: 1.7670\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7590 - val_loss: 1.7675\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7597 - val_loss: 1.7717\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7610 - val_loss: 1.7672\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7591 - val_loss: 1.7661\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7579 - val_loss: 1.7671\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7586 - val_loss: 1.7749\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7595 - val_loss: 1.7707\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7582 - val_loss: 1.7664\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7568 - val_loss: 1.7755\n",
      "Top-2 accuracy = 0.463\n",
      "27\n",
      "minmaxR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9154 - val_loss: 1.8573\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8117 - val_loss: 1.7945\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7739 - val_loss: 1.7797\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7665 - val_loss: 1.7727\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7657 - val_loss: 1.7693\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7612 - val_loss: 1.7798\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7614 - val_loss: 1.7687\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7596 - val_loss: 1.7694\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7577 - val_loss: 1.7692\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7590 - val_loss: 1.7661\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7573 - val_loss: 1.7652\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7570 - val_loss: 1.7657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7581 - val_loss: 1.7665\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7567 - val_loss: 1.7726\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7572 - val_loss: 1.7658\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7557 - val_loss: 1.7637\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7556 - val_loss: 1.7776\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7600 - val_loss: 1.7718\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7570 - val_loss: 1.7639\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7558 - val_loss: 1.7656\n",
      "Top-2 accuracy = 0.466\n",
      "28\n",
      "minmaxo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9178 - val_loss: 1.8576\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8053 - val_loss: 1.7822\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7710 - val_loss: 1.7727\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7653 - val_loss: 1.7718\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7738\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7639 - val_loss: 1.7687\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7622 - val_loss: 1.7713\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7629 - val_loss: 1.7665\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7615 - val_loss: 1.7700\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7604 - val_loss: 1.7653\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7591 - val_loss: 1.7686\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7680\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7583 - val_loss: 1.7662\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7593 - val_loss: 1.7694\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7593 - val_loss: 1.7644\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7595 - val_loss: 1.7745\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7609 - val_loss: 1.7663\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7566 - val_loss: 1.7639\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7576 - val_loss: 1.7658\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7583 - val_loss: 1.7634\n",
      "Top-2 accuracy = 0.471\n",
      "29\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9036 - val_loss: 1.8670\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8451 - val_loss: 1.8285\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8081 - val_loss: 1.7975\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7787 - val_loss: 1.7739\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7654 - val_loss: 1.7694\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7614 - val_loss: 1.7723\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7596 - val_loss: 1.7687\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7586 - val_loss: 1.7662\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7594 - val_loss: 1.7755\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7595 - val_loss: 1.7668\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7588 - val_loss: 1.7666\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7586 - val_loss: 1.7658\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7576 - val_loss: 1.7728\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7577 - val_loss: 1.7672\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7575 - val_loss: 1.7713\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7576 - val_loss: 1.7649\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7566 - val_loss: 1.7651\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7565 - val_loss: 1.7688\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7575 - val_loss: 1.7670\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7576 - val_loss: 1.7679\n",
      "Top-2 accuracy = 0.465\n",
      "0\n",
      "normalizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9345 - val_loss: 1.9128\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8607 - val_loss: 1.8367\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8071 - val_loss: 1.7922\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7789 - val_loss: 1.7819\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7697 - val_loss: 1.7783\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7697 - val_loss: 1.7703\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7681 - val_loss: 1.7719\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7656 - val_loss: 1.7701\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7637 - val_loss: 1.7800\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7646 - val_loss: 1.7686\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7626 - val_loss: 1.7698\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7627 - val_loss: 1.7678\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7603 - val_loss: 1.7658\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7613 - val_loss: 1.7663\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7617 - val_loss: 1.7658\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7615 - val_loss: 1.7671\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7609 - val_loss: 1.7702\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7594 - val_loss: 1.7646\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7594 - val_loss: 1.7681\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7594 - val_loss: 1.7651\n",
      "Top-2 accuracy = 0.468\n",
      "1\n",
      "normalizeG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9344 - val_loss: 1.9294\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9261 - val_loss: 1.9285\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9206 - val_loss: 1.8899\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8425 - val_loss: 1.8312\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7956 - val_loss: 1.7864\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7683 - val_loss: 1.7711\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7640 - val_loss: 1.7688\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7599 - val_loss: 1.7681\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7576 - val_loss: 1.7651\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7595 - val_loss: 1.7649\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7571 - val_loss: 1.7735\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7564 - val_loss: 1.7729\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7569 - val_loss: 1.7654\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7558 - val_loss: 1.7657\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7569 - val_loss: 1.7905\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7597 - val_loss: 1.7649\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7554 - val_loss: 1.7630\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7536 - val_loss: 1.7640\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7539 - val_loss: 1.7680\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7543 - val_loss: 1.7722\n",
      "Top-2 accuracy = 0.461\n",
      "2\n",
      "normalizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9230 - val_loss: 1.8854\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8486 - val_loss: 1.8242\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8066 - val_loss: 1.7968\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7843 - val_loss: 1.7964\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7752 - val_loss: 1.7717\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7647 - val_loss: 1.7682\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7624 - val_loss: 1.7670\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7604 - val_loss: 1.7725\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7598 - val_loss: 1.7657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7584 - val_loss: 1.7735\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7588 - val_loss: 1.7659\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7599 - val_loss: 1.7653\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7575 - val_loss: 1.7744\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7591 - val_loss: 1.7698\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7594 - val_loss: 1.7653\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7560 - val_loss: 1.7643\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7567 - val_loss: 1.7701\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7569 - val_loss: 1.7645\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7553 - val_loss: 1.7636\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7559 - val_loss: 1.7655\n",
      "Top-2 accuracy = 0.468\n",
      "3\n",
      "robustD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9378 - val_loss: 1.9319\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9271 - val_loss: 1.9290\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9253 - val_loss: 1.9283\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9222 - val_loss: 1.9181\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8908 - val_loss: 1.8614\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8205 - val_loss: 1.8000\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7870 - val_loss: 1.7856\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7780 - val_loss: 1.7796\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7742 - val_loss: 1.7765\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7706 - val_loss: 1.7753\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7693 - val_loss: 1.7741\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7687 - val_loss: 1.7738\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7674 - val_loss: 1.7733\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7671 - val_loss: 1.7731\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7664 - val_loss: 1.7721\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7663 - val_loss: 1.7723\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7665 - val_loss: 1.7719\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7652 - val_loss: 1.7711\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7659 - val_loss: 1.7699\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7650 - val_loss: 1.7699\n",
      "Top-2 accuracy = 0.467\n",
      "4\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9382 - val_loss: 1.9308\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9162 - val_loss: 1.9037\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8838 - val_loss: 1.8751\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8578 - val_loss: 1.8535\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8381 - val_loss: 1.8374\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8250 - val_loss: 1.8272\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8165 - val_loss: 1.8181\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8090 - val_loss: 1.8124\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8044 - val_loss: 1.8080\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7996 - val_loss: 1.8045\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7967 - val_loss: 1.8011\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7938 - val_loss: 1.7984\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7909 - val_loss: 1.7958\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7892 - val_loss: 1.7943\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7872 - val_loss: 1.7918\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7860 - val_loss: 1.7923\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7840 - val_loss: 1.7911\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7845 - val_loss: 1.7898\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7821 - val_loss: 1.7872\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7808 - val_loss: 1.7864\n",
      "Top-2 accuracy = 0.465\n",
      "5\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9173 - val_loss: 1.8809\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8293 - val_loss: 1.8007\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7787 - val_loss: 1.7775\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7674 - val_loss: 1.7732\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7611 - val_loss: 1.7690\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7585 - val_loss: 1.7714\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7584 - val_loss: 1.7682\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7582 - val_loss: 1.7665\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7563 - val_loss: 1.7785\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7586 - val_loss: 1.7688\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7558 - val_loss: 1.7700\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7573 - val_loss: 1.7655\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7548 - val_loss: 1.7684\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7567 - val_loss: 1.7648\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7557 - val_loss: 1.7646\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7544 - val_loss: 1.7642\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7547 - val_loss: 1.7646\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7547 - val_loss: 1.7671\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7538 - val_loss: 1.7736\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7534 - val_loss: 1.7659\n",
      "Top-2 accuracy = 0.465\n",
      "6\n",
      "standardizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.8898 - val_loss: 1.8323\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8045 - val_loss: 1.7923\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7777 - val_loss: 1.7806\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7700 - val_loss: 1.7776\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7684 - val_loss: 1.7729\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7659 - val_loss: 1.7761\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7641 - val_loss: 1.7743\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7649 - val_loss: 1.7719\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7617 - val_loss: 1.7692\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7603 - val_loss: 1.7682\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7608 - val_loss: 1.7817\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7603 - val_loss: 1.7680\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7599 - val_loss: 1.7699\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7589 - val_loss: 1.7758\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7576 - val_loss: 1.7696\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7598 - val_loss: 1.7665\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7587 - val_loss: 1.7786\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7578 - val_loss: 1.7694\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7572 - val_loss: 1.7774\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7572 - val_loss: 1.7759\n",
      "Top-2 accuracy = 0.461\n",
      "7\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.9349 - val_loss: 1.9286\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9256 - val_loss: 1.9286\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9256 - val_loss: 1.9288\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9256 - val_loss: 1.9286\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9256 - val_loss: 1.9286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9256 - val_loss: 1.9286\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9256 - val_loss: 1.9288\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Top-2 accuracy = 0.348\n",
      "8\n",
      "normalizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8850 - val_loss: 1.8334\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7998 - val_loss: 1.7877\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7736 - val_loss: 1.7761\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7679 - val_loss: 1.7725\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7635 - val_loss: 1.7722\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7624 - val_loss: 1.7707\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7631 - val_loss: 1.7772\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7639 - val_loss: 1.7693\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7600 - val_loss: 1.7709\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7606 - val_loss: 1.7760\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7604 - val_loss: 1.7752\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7630 - val_loss: 1.7670\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7577 - val_loss: 1.7727\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7579 - val_loss: 1.7717\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7576 - val_loss: 1.7688\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7571 - val_loss: 1.7656\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7566 - val_loss: 1.7691\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7576 - val_loss: 1.7670\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7563 - val_loss: 1.7679\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7584 - val_loss: 1.7661\n",
      "Top-2 accuracy = 0.471\n",
      "9\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9127 - val_loss: 1.8816\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8640 - val_loss: 1.8574\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8430 - val_loss: 1.8420\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8276 - val_loss: 1.8302\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8177 - val_loss: 1.8220\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8113 - val_loss: 1.8154\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8052 - val_loss: 1.8122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8004 - val_loss: 1.8065\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7964 - val_loss: 1.8030\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7935 - val_loss: 1.8007\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7910 - val_loss: 1.7984\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7883 - val_loss: 1.7962\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7856 - val_loss: 1.7932\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7840 - val_loss: 1.7916\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7818 - val_loss: 1.7905\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7802 - val_loss: 1.7884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7791 - val_loss: 1.7872\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7769 - val_loss: 1.7857\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7756 - val_loss: 1.7853\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7745 - val_loss: 1.7835\n",
      "Top-2 accuracy = 0.472\n",
      "10\n",
      "robustA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9281 - val_loss: 1.9027\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8466 - val_loss: 1.8056\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7813 - val_loss: 1.7817\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7670 - val_loss: 1.7704\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7622 - val_loss: 1.7701\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7604 - val_loss: 1.7698\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7591 - val_loss: 1.7805\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7628 - val_loss: 1.7678\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7596 - val_loss: 1.7689\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7586 - val_loss: 1.7710\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7575 - val_loss: 1.7707\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7576 - val_loss: 1.7709\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7576 - val_loss: 1.7663\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7551 - val_loss: 1.7662\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7559 - val_loss: 1.7659\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7550 - val_loss: 1.7661\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7545 - val_loss: 1.7657\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7556 - val_loss: 1.7643\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7539 - val_loss: 1.7670\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7545 - val_loss: 1.7653\n",
      "Top-2 accuracy = 0.474\n",
      "11\n",
      "standardizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9262 - val_loss: 1.9158\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8881 - val_loss: 1.8566\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8290 - val_loss: 1.8125\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7956 - val_loss: 1.7925\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7805 - val_loss: 1.7846\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7745 - val_loss: 1.7827\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7702 - val_loss: 1.7779\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7690 - val_loss: 1.7791\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7688 - val_loss: 1.7761\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7663 - val_loss: 1.7745\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7652 - val_loss: 1.7724\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7639 - val_loss: 1.7717\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7634 - val_loss: 1.7738\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7636 - val_loss: 1.7711\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7624 - val_loss: 1.7686\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7613 - val_loss: 1.7685\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7610 - val_loss: 1.7675\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7608 - val_loss: 1.7665\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7683\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7604 - val_loss: 1.7659\n",
      "Top-2 accuracy = 0.469\n",
      "12\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9111 - val_loss: 1.8764\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8558 - val_loss: 1.8450\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8306 - val_loss: 1.8261\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8068 - val_loss: 1.8009\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7920 - val_loss: 1.7932\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7865 - val_loss: 1.7895\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7842 - val_loss: 1.7879\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7818 - val_loss: 1.7867\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7812 - val_loss: 1.7906\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7796 - val_loss: 1.7847\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7792 - val_loss: 1.7851\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7772 - val_loss: 1.7814\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7763 - val_loss: 1.7897\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7755 - val_loss: 1.7792\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7732 - val_loss: 1.7816\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7722 - val_loss: 1.7801\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7715 - val_loss: 1.7827\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7737 - val_loss: 1.7763\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7700 - val_loss: 1.7840\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 1.7773\n",
      "Top-2 accuracy = 0.464\n",
      "13\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9379 - val_loss: 1.9321\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9286 - val_loss: 1.9288\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9261 - val_loss: 1.9283\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9283\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Top-2 accuracy = 0.348\n",
      "14\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9370 - val_loss: 1.9318\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9273 - val_loss: 1.9288\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "15\n",
      "maxabsr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.9344 - val_loss: 1.9307\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9265 - val_loss: 1.9290\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9256 - val_loss: 1.9288\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9282\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9290\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9288\n",
      "Top-2 accuracy = 0.348\n",
      "16\n",
      "robustf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8729 - val_loss: 1.8001\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7769 - val_loss: 1.7793\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7697 - val_loss: 1.7715\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7655 - val_loss: 1.7706\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7629 - val_loss: 1.7699\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7607 - val_loss: 1.7747\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7609 - val_loss: 1.7688\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7597 - val_loss: 1.7659\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7581 - val_loss: 1.7666\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7573 - val_loss: 1.7653\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7569 - val_loss: 1.7665\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7571 - val_loss: 1.7637\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7561 - val_loss: 1.7635\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7549 - val_loss: 1.7655\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7560 - val_loss: 1.7631\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7549 - val_loss: 1.7662\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7539 - val_loss: 1.7626\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7557 - val_loss: 1.7668\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7556 - val_loss: 1.7649\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7526 - val_loss: 1.7647\n",
      "Top-2 accuracy = 0.466\n",
      "17\n",
      "normalizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9407 - val_loss: 1.9370\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9331 - val_loss: 1.9322\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9289 - val_loss: 1.9298\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9268 - val_loss: 1.9289\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9260 - val_loss: 1.9285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Top-2 accuracy = 0.348\n",
      "18\n",
      "maxabsm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9018 - val_loss: 1.8574\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8171 - val_loss: 1.7939\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7773 - val_loss: 1.7780\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7684 - val_loss: 1.7714\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7636 - val_loss: 1.7683\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7609 - val_loss: 1.7685\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7603 - val_loss: 1.7677\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7593 - val_loss: 1.7647\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7584 - val_loss: 1.7650\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7577 - val_loss: 1.7657\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7572 - val_loss: 1.7646\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7572 - val_loss: 1.7716\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7588 - val_loss: 1.7649\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7571 - val_loss: 1.7639\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7557 - val_loss: 1.7639\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7561 - val_loss: 1.7632\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7552 - val_loss: 1.7673\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7562 - val_loss: 1.7632\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7555 - val_loss: 1.7627\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7551 - val_loss: 1.7640\n",
      "Top-2 accuracy = 0.467\n",
      "19\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 1.8956 - val_loss: 1.8447\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8270 - val_loss: 1.8142\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.8001 - val_loss: 1.8015\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7945 - val_loss: 1.7995\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7926 - val_loss: 1.7982\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7902 - val_loss: 1.7973\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7881 - val_loss: 1.7912\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7818 - val_loss: 1.7893\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7830 - val_loss: 1.7862\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7798 - val_loss: 1.7870\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7778 - val_loss: 1.7874\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7772 - val_loss: 1.7817\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7740 - val_loss: 1.7865\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7748 - val_loss: 1.7869\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7728 - val_loss: 1.7813\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7701 - val_loss: 1.7797\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7692 - val_loss: 1.7752\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.7679 - val_loss: 1.7768\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7688 - val_loss: 1.7817\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7762 - val_loss: 1.7978\n",
      "Top-2 accuracy = 0.463\n",
      "20\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8960 - val_loss: 1.8457\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8108 - val_loss: 1.7931\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7762 - val_loss: 1.7776\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7660 - val_loss: 1.7732\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7635 - val_loss: 1.7703\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7609 - val_loss: 1.7684\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7594 - val_loss: 1.7700\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7594 - val_loss: 1.7738\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7587 - val_loss: 1.7669\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7573 - val_loss: 1.7698\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7585 - val_loss: 1.7657\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7577 - val_loss: 1.7664\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7580 - val_loss: 1.7683\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7578 - val_loss: 1.7658\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7564 - val_loss: 1.7644\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7562 - val_loss: 1.7646\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7557 - val_loss: 1.7702\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7567 - val_loss: 1.7644\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7550 - val_loss: 1.7653\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7557 - val_loss: 1.7700\n",
      "Top-2 accuracy = 0.466\n",
      "21\n",
      "robustj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9263 - val_loss: 1.8994\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8766 - val_loss: 1.8524\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8383 - val_loss: 1.8264\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8168 - val_loss: 1.8103\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7948 - val_loss: 1.7879\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7756 - val_loss: 1.7758\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7683 - val_loss: 1.7744\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7676 - val_loss: 1.7728\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7657 - val_loss: 1.7734\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7639 - val_loss: 1.7690\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7628 - val_loss: 1.7726\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7645 - val_loss: 1.7687\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7613 - val_loss: 1.7723\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7617 - val_loss: 1.7670\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7620 - val_loss: 1.7675\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7607 - val_loss: 1.7677\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7601 - val_loss: 1.7672\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7605 - val_loss: 1.7666\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7600 - val_loss: 1.7682\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7629 - val_loss: 1.7689\n",
      "Top-2 accuracy = 0.465\n",
      "22\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9209 - val_loss: 1.8906\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8519 - val_loss: 1.8259\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8048 - val_loss: 1.7981\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7895 - val_loss: 1.7892\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7817 - val_loss: 1.7834\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7763 - val_loss: 1.7806\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7725 - val_loss: 1.7765\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7693 - val_loss: 1.7735\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7709\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7638 - val_loss: 1.7702\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7619 - val_loss: 1.7673\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7601 - val_loss: 1.7657\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7584 - val_loss: 1.7648\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7569 - val_loss: 1.7635\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7557 - val_loss: 1.7637\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7549 - val_loss: 1.7623\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7535 - val_loss: 1.7615\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7530 - val_loss: 1.7613\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7526 - val_loss: 1.7608\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7515 - val_loss: 1.7606\n",
      "Top-2 accuracy = 0.475\n",
      "23\n",
      "minmaxT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9165 - val_loss: 1.8868\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8458 - val_loss: 1.8205\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7998 - val_loss: 1.7918\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7813 - val_loss: 1.7825\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7749 - val_loss: 1.7823\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7730 - val_loss: 1.7861\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7737 - val_loss: 1.7760\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7684 - val_loss: 1.7739\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7682 - val_loss: 1.7761\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7669 - val_loss: 1.7751\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7664 - val_loss: 1.7718\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7656 - val_loss: 1.7708\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7647 - val_loss: 1.7726\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7644 - val_loss: 1.7704\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7643 - val_loss: 1.7706\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7763\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.7702\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7631 - val_loss: 1.7700\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7623 - val_loss: 1.7698\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7627 - val_loss: 1.7675\n",
      "Top-2 accuracy = 0.471\n",
      "24\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9251 - val_loss: 1.8965\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8746 - val_loss: 1.8653\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8445 - val_loss: 1.8356\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8171 - val_loss: 1.8120\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8042 - val_loss: 1.7983\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7889 - val_loss: 1.7890\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7786 - val_loss: 1.7814\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7760 - val_loss: 1.7808\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7718 - val_loss: 1.7808\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7702 - val_loss: 1.7734\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7693 - val_loss: 1.7732\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7672 - val_loss: 1.7776\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7667 - val_loss: 1.7697\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7637 - val_loss: 1.7702\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7637 - val_loss: 1.7787\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7635 - val_loss: 1.7692\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7632 - val_loss: 1.7685\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7634 - val_loss: 1.7705\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7638 - val_loss: 1.7668\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7621 - val_loss: 1.7705\n",
      "Top-2 accuracy = 0.465\n",
      "25\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9116 - val_loss: 1.8532\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8106 - val_loss: 1.7931\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7781 - val_loss: 1.7798\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7685 - val_loss: 1.7736\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7646 - val_loss: 1.7739\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7638 - val_loss: 1.7704\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7629 - val_loss: 1.7725\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7628 - val_loss: 1.7743\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7626 - val_loss: 1.7731\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7595 - val_loss: 1.7697\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7602 - val_loss: 1.7731\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7594 - val_loss: 1.7698\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7592 - val_loss: 1.7689\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7581 - val_loss: 1.7696\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7584 - val_loss: 1.7699\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7585 - val_loss: 1.7706\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7612 - val_loss: 1.7725\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7612 - val_loss: 1.7686\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7589 - val_loss: 1.7714\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7584 - val_loss: 1.7754\n",
      "Top-2 accuracy = 0.464\n",
      "26\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8900 - val_loss: 1.8295\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7820 - val_loss: 1.7738\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7624 - val_loss: 1.7679\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7589 - val_loss: 1.7734\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7563 - val_loss: 1.7640\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7549 - val_loss: 1.7689\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7549 - val_loss: 1.7674\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7538 - val_loss: 1.7656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7533 - val_loss: 1.7627\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7521 - val_loss: 1.7652\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7527 - val_loss: 1.7656\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7528 - val_loss: 1.7687\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7516 - val_loss: 1.7669\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7525 - val_loss: 1.7627\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7508 - val_loss: 1.7669\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7522 - val_loss: 1.7629\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7506 - val_loss: 1.7700\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7534 - val_loss: 1.7686\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7513 - val_loss: 1.7624\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7527 - val_loss: 1.7617\n",
      "Top-2 accuracy = 0.47\n",
      "27\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9004 - val_loss: 1.8438\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8049 - val_loss: 1.7801\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7623 - val_loss: 1.7770\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7576 - val_loss: 1.7667\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7541 - val_loss: 1.7662\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7544 - val_loss: 1.7625\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7520 - val_loss: 1.7711\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7525 - val_loss: 1.7676\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7508 - val_loss: 1.7636\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7499 - val_loss: 1.7625\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7519 - val_loss: 1.7682\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.7527 - val_loss: 1.7697\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7501 - val_loss: 1.7726\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7496 - val_loss: 1.7616\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7498 - val_loss: 1.7618\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7494 - val_loss: 1.7650\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7485 - val_loss: 1.7639\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7498 - val_loss: 1.7636\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7526 - val_loss: 1.7682\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7506 - val_loss: 1.7708\n",
      "Top-2 accuracy = 0.467\n",
      "28\n",
      "normalizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9269 - val_loss: 1.9072\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8697 - val_loss: 1.8455\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8048 - val_loss: 1.7931\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7789 - val_loss: 1.7804\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7713 - val_loss: 1.7754\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7688 - val_loss: 1.7740\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7666 - val_loss: 1.7753\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7660 - val_loss: 1.7742\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7656 - val_loss: 1.7784\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7642 - val_loss: 1.7704\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7652 - val_loss: 1.7708\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7629 - val_loss: 1.7727\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7633 - val_loss: 1.7698\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7617 - val_loss: 1.7689\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7630 - val_loss: 1.7703\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7611 - val_loss: 1.7693\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7615 - val_loss: 1.7723\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7616 - val_loss: 1.7703\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7611 - val_loss: 1.7677\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7606 - val_loss: 1.7807\n",
      "Top-2 accuracy = 0.461\n",
      "29\n",
      "normalizes|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.8816 - val_loss: 1.8309\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7965 - val_loss: 1.7957\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7713 - val_loss: 1.7862\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7647 - val_loss: 1.7705\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7629 - val_loss: 1.7662\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7587 - val_loss: 1.7656\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7571 - val_loss: 1.7710\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7572 - val_loss: 1.7667\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7547 - val_loss: 1.7639\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7548 - val_loss: 1.7686\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7559 - val_loss: 1.7639\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7542 - val_loss: 1.7632\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7545 - val_loss: 1.7645\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7526 - val_loss: 1.7748\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7571 - val_loss: 1.7675\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7533 - val_loss: 1.7701\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7562 - val_loss: 1.7636\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7528 - val_loss: 1.7633\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7518 - val_loss: 1.7666\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7533 - val_loss: 1.7624\n",
      "Top-2 accuracy = 0.472\n",
      "0\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.8957 - val_loss: 1.8518\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8157 - val_loss: 1.8037\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7827 - val_loss: 1.7839\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7717 - val_loss: 1.7768\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7652 - val_loss: 1.7726\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7605 - val_loss: 1.7707\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7586 - val_loss: 1.7682\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7586 - val_loss: 1.7656\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7563 - val_loss: 1.7652\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7562 - val_loss: 1.7674\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7552 - val_loss: 1.7655\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7536 - val_loss: 1.7672\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7543 - val_loss: 1.7675\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7537 - val_loss: 1.7641\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7537 - val_loss: 1.7634\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7535 - val_loss: 1.7639\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7525 - val_loss: 1.7640\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7539 - val_loss: 1.7631\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7516 - val_loss: 1.7670\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7547 - val_loss: 1.7649\n",
      "Top-2 accuracy = 0.471\n",
      "1\n",
      "robustI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.9376 - val_loss: 1.9317\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9275 - val_loss: 1.9288\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9259 - val_loss: 1.9285\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9256 - val_loss: 1.9284\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Top-2 accuracy = 0.348\n",
      "2\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9201 - val_loss: 1.8897\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8567 - val_loss: 1.8365\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8180 - val_loss: 1.8099\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7952 - val_loss: 1.7932\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7830 - val_loss: 1.7851\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7757 - val_loss: 1.7805\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7713 - val_loss: 1.7756\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7675 - val_loss: 1.7731\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7657 - val_loss: 1.7715\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7699\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7635 - val_loss: 1.7686\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7623 - val_loss: 1.7680\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7611 - val_loss: 1.7689\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7607 - val_loss: 1.7677\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7596 - val_loss: 1.7667\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7593 - val_loss: 1.7684\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7614 - val_loss: 1.7657\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7585 - val_loss: 1.7650\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7581 - val_loss: 1.7653\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7578 - val_loss: 1.7655\n",
      "Top-2 accuracy = 0.468\n",
      "3\n",
      "robusth|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9382 - val_loss: 1.9290\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9100 - val_loss: 1.8896\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8735 - val_loss: 1.8599\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8506 - val_loss: 1.8443\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8409 - val_loss: 1.8386\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8419 - val_loss: 1.8469\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8439 - val_loss: 1.8463\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8431 - val_loss: 1.8448\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8427 - val_loss: 1.8487\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8409 - val_loss: 1.8407\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8360 - val_loss: 1.8338\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8351 - val_loss: 1.8330\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8341 - val_loss: 1.8346\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8336 - val_loss: 1.8347\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8437 - val_loss: 1.8526\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8481 - val_loss: 1.8510\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8496 - val_loss: 1.8550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8705 - val_loss: 1.8741\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8607 - val_loss: 1.8485\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8427 - val_loss: 1.8462\n",
      "Top-2 accuracy = 0.443\n",
      "4\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9319 - val_loss: 1.9284\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9256 - val_loss: 1.9287\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9257 - val_loss: 1.9286\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9254 - val_loss: 1.9288\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Top-2 accuracy = 0.348\n",
      "5\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9344 - val_loss: 1.9264\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8835 - val_loss: 1.8491\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8121 - val_loss: 1.7950\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7820 - val_loss: 1.7801\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7734 - val_loss: 1.7776\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7690 - val_loss: 1.7723\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7687 - val_loss: 1.7733\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7672 - val_loss: 1.7720\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7669 - val_loss: 1.7722\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7643 - val_loss: 1.7706\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7656 - val_loss: 1.7707\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7626 - val_loss: 1.7715\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7642 - val_loss: 1.7694\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7645 - val_loss: 1.7687\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7614 - val_loss: 1.7683\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7612 - val_loss: 1.7678\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7615 - val_loss: 1.7712\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7625 - val_loss: 1.7676\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7618 - val_loss: 1.7680\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7607 - val_loss: 1.7674\n",
      "Top-2 accuracy = 0.471\n",
      "6\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9048 - val_loss: 1.8614\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8320 - val_loss: 1.8195\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7987 - val_loss: 1.7924\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7750 - val_loss: 1.7770\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7691 - val_loss: 1.7771\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7669 - val_loss: 1.7754\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7646 - val_loss: 1.7915\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7657 - val_loss: 1.7736\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7620 - val_loss: 1.7702\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7604 - val_loss: 1.7717\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7611 - val_loss: 1.7687\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7596 - val_loss: 1.7674\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7611 - val_loss: 1.7754\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7620 - val_loss: 1.7723\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7595 - val_loss: 1.7692\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7591 - val_loss: 1.7844\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7612 - val_loss: 1.7673\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7580 - val_loss: 1.7679\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7568 - val_loss: 1.7681\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7577 - val_loss: 1.7683\n",
      "Top-2 accuracy = 0.466\n",
      "7\n",
      "standardizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9261 - val_loss: 1.8893\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8597 - val_loss: 1.8476\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8275 - val_loss: 1.8230\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8076 - val_loss: 1.8082\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7948 - val_loss: 1.7968\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 1.7894\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7792 - val_loss: 1.7840\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7755 - val_loss: 1.7825\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7796\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7705 - val_loss: 1.7780\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7687 - val_loss: 1.7755\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7671 - val_loss: 1.7751\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7668 - val_loss: 1.7731\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7656 - val_loss: 1.7724\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7639 - val_loss: 1.7716\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7640 - val_loss: 1.7707\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7752\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7632 - val_loss: 1.7708\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7621 - val_loss: 1.7719\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7622 - val_loss: 1.7705\n",
      "Top-2 accuracy = 0.466\n",
      "8\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9130 - val_loss: 1.8770\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8310 - val_loss: 1.8046\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7786 - val_loss: 1.7791\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7663 - val_loss: 1.7726\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7629 - val_loss: 1.7750\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7612 - val_loss: 1.7691\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7594 - val_loss: 1.7715\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7597 - val_loss: 1.7676\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7583 - val_loss: 1.7685\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7595 - val_loss: 1.7695\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7569 - val_loss: 1.7683\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7577 - val_loss: 1.7694\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7567 - val_loss: 1.7670\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7568 - val_loss: 1.7659\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7564 - val_loss: 1.7659\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7559 - val_loss: 1.7659\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7556 - val_loss: 1.7654\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7561 - val_loss: 1.7673\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7562 - val_loss: 1.7654\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7546 - val_loss: 1.7664\n",
      "Top-2 accuracy = 0.469\n",
      "9\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9044 - val_loss: 1.8523\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8324 - val_loss: 1.8192\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8051 - val_loss: 1.7974\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7846 - val_loss: 1.7857\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7710 - val_loss: 1.7774\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7665 - val_loss: 1.7747\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7617 - val_loss: 1.7691\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7597 - val_loss: 1.7690\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7588 - val_loss: 1.7657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7567 - val_loss: 1.7643\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7557 - val_loss: 1.7649\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7566 - val_loss: 1.7675\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7549 - val_loss: 1.7682\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7560 - val_loss: 1.7654\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7537 - val_loss: 1.7657\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7541 - val_loss: 1.7650\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7543 - val_loss: 1.7642\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7525 - val_loss: 1.7633\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7530 - val_loss: 1.7631\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7524 - val_loss: 1.7633\n",
      "Top-2 accuracy = 0.468\n",
      "10\n",
      "standardizeU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9171 - val_loss: 1.8661\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8273 - val_loss: 1.8062\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7875 - val_loss: 1.7884\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7771 - val_loss: 1.7839\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7753 - val_loss: 1.7812\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7742 - val_loss: 1.7860\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7734 - val_loss: 1.7802\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7723 - val_loss: 1.7821\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7724 - val_loss: 1.7810\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7717 - val_loss: 1.7780\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7703 - val_loss: 1.7789\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7702 - val_loss: 1.7768\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7692 - val_loss: 1.7788\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7696 - val_loss: 1.7778\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7701 - val_loss: 1.7766\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7679 - val_loss: 1.7766\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7697 - val_loss: 1.7759\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7677 - val_loss: 1.7781\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7682 - val_loss: 1.7772\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7683 - val_loss: 1.7751\n",
      "Top-2 accuracy = 0.465\n",
      "11\n",
      "minmaxQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9374 - val_loss: 1.9319\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9240 - val_loss: 1.9141\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8857 - val_loss: 1.8688\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8478 - val_loss: 1.8407\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8249 - val_loss: 1.8276\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8109 - val_loss: 1.8124\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8022 - val_loss: 1.8054\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7965 - val_loss: 1.8032\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7913 - val_loss: 1.7967\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7876 - val_loss: 1.7919\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7845 - val_loss: 1.7904\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7820 - val_loss: 1.7906\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7810 - val_loss: 1.7859\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7788 - val_loss: 1.7866\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7779 - val_loss: 1.7839\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7773 - val_loss: 1.7838\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7770 - val_loss: 1.7825\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7768 - val_loss: 1.7836\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7759 - val_loss: 1.7815\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 1.7827\n",
      "Top-2 accuracy = 0.464\n",
      "12\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9393 - val_loss: 1.9323\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9140 - val_loss: 1.8924\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8648 - val_loss: 1.8509\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8288 - val_loss: 1.8254\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.8092 - val_loss: 1.8129\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7997 - val_loss: 1.8065\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7955 - val_loss: 1.8020\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7920 - val_loss: 1.7997\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7890 - val_loss: 1.7972\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7869 - val_loss: 1.7940\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7857 - val_loss: 1.7940\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7844 - val_loss: 1.7923\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7831 - val_loss: 1.7906\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7824 - val_loss: 1.7895\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7816 - val_loss: 1.7920\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7811 - val_loss: 1.7878\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7808 - val_loss: 1.7890\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7801 - val_loss: 1.7873\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7791 - val_loss: 1.7867\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7798 - val_loss: 1.7863\n",
      "Top-2 accuracy = 0.463\n",
      "13\n",
      "minmaxa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9327 - val_loss: 1.9302\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9266 - val_loss: 1.9289\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9256 - val_loss: 1.9288\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9288\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9256 - val_loss: 1.9286\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9288\n",
      "Top-2 accuracy = 0.348\n",
      "14\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9344 - val_loss: 1.9133\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8744 - val_loss: 1.8436\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8267 - val_loss: 1.8201\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8088 - val_loss: 1.8121\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8018 - val_loss: 1.8100\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7957 - val_loss: 1.7994\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7921 - val_loss: 1.7956\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7893 - val_loss: 1.7966\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7899 - val_loss: 1.8013\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7880 - val_loss: 1.7925\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7864 - val_loss: 1.7937\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7868 - val_loss: 1.7906\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7874 - val_loss: 1.7899\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7852 - val_loss: 1.7932\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7843 - val_loss: 1.7894\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7839 - val_loss: 1.7899\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7823 - val_loss: 1.7901\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7818 - val_loss: 1.7863\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7804 - val_loss: 1.7892\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7803 - val_loss: 1.7849\n",
      "Top-2 accuracy = 0.465\n",
      "15\n",
      "maxabsj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9091 - val_loss: 1.8617\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8172 - val_loss: 1.7932\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7814 - val_loss: 1.7910\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7715 - val_loss: 1.7740\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7684 - val_loss: 1.7720\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7646 - val_loss: 1.7741\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7637 - val_loss: 1.7685\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7628 - val_loss: 1.7753\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7616 - val_loss: 1.7690\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7604 - val_loss: 1.7719\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7616 - val_loss: 1.7650\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7603 - val_loss: 1.7661\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7598 - val_loss: 1.7667\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7580 - val_loss: 1.7666\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7578 - val_loss: 1.7643\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7569 - val_loss: 1.7673\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7576 - val_loss: 1.7678\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7571 - val_loss: 1.7695\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7589 - val_loss: 1.7707\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7590 - val_loss: 1.7641\n",
      "Top-2 accuracy = 0.471\n",
      "16\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9123 - val_loss: 1.8583\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8173 - val_loss: 1.8016\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7882 - val_loss: 1.7900\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7846 - val_loss: 1.7911\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7768 - val_loss: 1.7764\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7709 - val_loss: 1.7944\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7679 - val_loss: 1.7795\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7662 - val_loss: 1.7768\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7671 - val_loss: 1.7770\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7652 - val_loss: 1.8054\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7636 - val_loss: 1.7787\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7652 - val_loss: 1.7678\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7604 - val_loss: 1.7736\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7588 - val_loss: 1.7700\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7584 - val_loss: 1.7666\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7576 - val_loss: 1.7702\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7592 - val_loss: 1.7675\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7593 - val_loss: 1.7655\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7581 - val_loss: 1.7790\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7588 - val_loss: 1.7706\n",
      "Top-2 accuracy = 0.464\n",
      "17\n",
      "normalizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 1.9391 - val_loss: 1.9353\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9303 - val_loss: 1.9303\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9267 - val_loss: 1.9287\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9258 - val_loss: 1.9285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9289\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9287\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9254 - val_loss: 1.9287\n",
      "Top-2 accuracy = 0.348\n",
      "18\n",
      "robustY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 1.9348 - val_loss: 1.9286\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9257 - val_loss: 1.9286\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9256 - val_loss: 1.9287\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9256 - val_loss: 1.9284\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9257 - val_loss: 1.9284\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9256 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9256 - val_loss: 1.9288\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9256 - val_loss: 1.9286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9256 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9289\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9291\n",
      "Top-2 accuracy = 0.348\n",
      "19\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9156 - val_loss: 1.8847\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8664 - val_loss: 1.8589\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.8472 - val_loss: 1.8397\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8230 - val_loss: 1.8121\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7946 - val_loss: 1.7867\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7789 - val_loss: 1.7818\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7748 - val_loss: 1.7757\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7716 - val_loss: 1.7778\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7696 - val_loss: 1.7734\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7672 - val_loss: 1.7730\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7668 - val_loss: 1.7696\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7657 - val_loss: 1.7714\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7647 - val_loss: 1.7691\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7634 - val_loss: 1.7717\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7633 - val_loss: 1.7694\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7622 - val_loss: 1.7674\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7615 - val_loss: 1.7666\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7610 - val_loss: 1.7662\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7609 - val_loss: 1.7667\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7600 - val_loss: 1.7665\n",
      "Top-2 accuracy = 0.465\n",
      "20\n",
      "robustf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9393 - val_loss: 1.9261\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8834 - val_loss: 1.8289\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8029 - val_loss: 1.7881\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7780 - val_loss: 1.7953\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7763 - val_loss: 1.7784\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7689 - val_loss: 1.7735\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7671 - val_loss: 1.7722\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7668 - val_loss: 1.7776\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7655 - val_loss: 1.7723\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7634 - val_loss: 1.7988\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7667 - val_loss: 1.7692\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7647 - val_loss: 1.7697\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7629 - val_loss: 1.7698\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7615 - val_loss: 1.7683\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7609 - val_loss: 1.7733\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7611 - val_loss: 1.8010\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7672 - val_loss: 1.7668\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7598 - val_loss: 1.7701\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7617 - val_loss: 1.7657\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7594 - val_loss: 1.7691\n",
      "Top-2 accuracy = 0.472\n",
      "21\n",
      "maxabsO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 1.9375 - val_loss: 1.9328\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9290 - val_loss: 1.9290\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9262 - val_loss: 1.9284\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9256 - val_loss: 1.9284\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9284\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9255 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9254 - val_loss: 1.9288\n",
      "Top-2 accuracy = 0.348\n",
      "22\n",
      "standardizeL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.9077 - val_loss: 1.8718\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.8363 - val_loss: 1.8229\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7956 - val_loss: 1.7904\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7761 - val_loss: 1.7778\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7659 - val_loss: 1.7805\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7625 - val_loss: 1.7748\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7608 - val_loss: 1.7759\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7599 - val_loss: 1.7704\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7600 - val_loss: 1.7694\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7585 - val_loss: 1.7701\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7577 - val_loss: 1.7706\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7609 - val_loss: 1.7741\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7564 - val_loss: 1.7698\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7599 - val_loss: 1.7792\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7571 - val_loss: 1.7687\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7560 - val_loss: 1.7682\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7545 - val_loss: 1.7674\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7546 - val_loss: 1.7737\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7561 - val_loss: 1.7684\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7567 - val_loss: 1.7766\n",
      "Top-2 accuracy = 0.467\n",
      "23\n",
      "robustR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 15ms/step - loss: 1.9391 - val_loss: 1.9339\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9294 - val_loss: 1.9288\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9261 - val_loss: 1.9282\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9256 - val_loss: 1.9283\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9283\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9255 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Top-2 accuracy = 0.348\n",
      "24\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9392 - val_loss: 1.9350\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9313 - val_loss: 1.9305\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9275 - val_loss: 1.9287\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9260 - val_loss: 1.9283\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9257 - val_loss: 1.9283\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9283\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9285\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9254 - val_loss: 1.9286\n",
      "Top-2 accuracy = 0.348\n",
      "25\n",
      "normalizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 1.8983 - val_loss: 1.8552\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8248 - val_loss: 1.8143\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7811 - val_loss: 1.7728\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7674 - val_loss: 1.7838\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7666 - val_loss: 1.7714\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7638 - val_loss: 1.7670\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7620 - val_loss: 1.7662\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7614 - val_loss: 1.7671\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7617 - val_loss: 1.7659\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7597 - val_loss: 1.7654\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7593 - val_loss: 1.7694\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7592 - val_loss: 1.7643\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7590 - val_loss: 1.7641\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7585 - val_loss: 1.7670\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7596 - val_loss: 1.7793\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7607 - val_loss: 1.7643\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7577 - val_loss: 1.7641\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7575 - val_loss: 1.7714\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7596 - val_loss: 1.7704\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7576 - val_loss: 1.7631\n",
      "Top-2 accuracy = 0.467\n",
      "26\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.9182 - val_loss: 1.8684\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.8443 - val_loss: 1.8201\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7949 - val_loss: 1.7880\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7753 - val_loss: 1.7782\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7733 - val_loss: 1.7719\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7664 - val_loss: 1.7802\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7660 - val_loss: 1.7934\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.7668 - val_loss: 1.7700\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7626 - val_loss: 1.7725\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7635 - val_loss: 1.7689\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7630 - val_loss: 1.7741\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7619 - val_loss: 1.7730\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7638 - val_loss: 1.7692\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7624 - val_loss: 1.7683\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7604 - val_loss: 1.7677\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7607 - val_loss: 1.7671\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7595 - val_loss: 1.7668\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.7593 - val_loss: 1.7685\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7631 - val_loss: 1.7722\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.7623 - val_loss: 1.7684\n",
      "Top-2 accuracy = 0.465\n",
      "27\n",
      "maxabsB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9409 - val_loss: 1.9362\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9325 - val_loss: 1.9303\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9274 - val_loss: 1.9273\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9202 - val_loss: 1.9055\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8838 - val_loss: 1.8696\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8557 - val_loss: 1.8500\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8348 - val_loss: 1.8286\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8146 - val_loss: 1.8098\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7981 - val_loss: 1.8075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7891 - val_loss: 1.7909\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7818 - val_loss: 1.7859\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7788 - val_loss: 1.7853\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7765 - val_loss: 1.7848\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.7804\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7726 - val_loss: 1.7783\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7722 - val_loss: 1.7771\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7715 - val_loss: 1.7770\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7762\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7703 - val_loss: 1.7767\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7701 - val_loss: 1.7815\n",
      "Top-2 accuracy = 0.465\n",
      "28\n",
      "normalizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9377 - val_loss: 1.9296\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9108 - val_loss: 1.8921\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8727 - val_loss: 1.8578\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8427 - val_loss: 1.8307\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8185 - val_loss: 1.8110\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8029 - val_loss: 1.8006\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7923 - val_loss: 1.7903\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7854 - val_loss: 1.7857\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7819 - val_loss: 1.7830\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7799 - val_loss: 1.7814\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7769 - val_loss: 1.7832\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7765 - val_loss: 1.7816\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7756 - val_loss: 1.7796\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7746 - val_loss: 1.7785\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.7743 - val_loss: 1.7783\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7729 - val_loss: 1.7785\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7735 - val_loss: 1.7772\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7723 - val_loss: 1.7773\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7722 - val_loss: 1.7776\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7731 - val_loss: 1.7765\n",
      "Top-2 accuracy = 0.467\n",
      "29\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9301 - val_loss: 1.9189\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8890 - val_loss: 1.8672\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8483 - val_loss: 1.8424\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8290 - val_loss: 1.8274\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8167 - val_loss: 1.8173\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8075 - val_loss: 1.8103\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8011 - val_loss: 1.8107\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7980 - val_loss: 1.8011\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7928 - val_loss: 1.7989\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7908 - val_loss: 1.7955\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7881 - val_loss: 1.7942\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7852 - val_loss: 1.7927\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7841 - val_loss: 1.7896\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7833 - val_loss: 1.7894\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7819 - val_loss: 1.7874\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7807 - val_loss: 1.7873\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7796 - val_loss: 1.7870\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7782 - val_loss: 1.7840\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7781 - val_loss: 1.7844\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7773 - val_loss: 1.7833\n",
      "Top-2 accuracy = 0.466\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"accuracy\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [MulticlassDL(n_classes=7, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20)],\n",
    "    \"post_train_hooks\": [top2_hook],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"chromium-5class\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        MulticlassDL(n_classes=7, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv chromium-5class.txt chromium-7class.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 2004.4163217544556 seconds.\n",
      "Top-1 Accuracy: 0.2921547340151991\n",
      "Top-2 Accuracy: 0.47457288154962574\n"
     ]
    }
   ],
   "source": [
    "print('Completed in', end - start, 'seconds.')\n",
    "interp = DODGEInterpreter(files=['./chromium-7class.txt'], max_by=0, \n",
    "                          metrics=['accuracy'])\n",
    "results = interp.interpret()['chromium-7class.txt']\n",
    "print('Top-1 Accuracy:', np.median(results['accuracy']))\n",
    "print('Top-2 Accuracy:', np.median(np.amax(np.array(top2).reshape(10,30), axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = np.where(data.y_train < 1, 0, np.where(data.y_train < 2, 1, np.where(data.y_train < 3, 2, np.where(data.y_train < 4, 3, np.where(data.y_train < 6, 4, np.where(data.y_train < 8, 5, np.where(data.y_train < 11, 6, np.where(data.y_train < 21, 7, 8))))))))\n",
    "data.y_test = np.where(data.y_test < 1, 0, np.where(data.y_test < 2, 1, np.where(data.y_test < 3, 2, np.where(data.y_test < 4, 3, np.where(data.y_test < 6, 4, np.where(data.y_test < 8, 5, np.where(data.y_test < 11, 6, np.where(data.y_test < 21, 7, 8))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y_train = to_categorical(data.y_train, num_classes=9)\n",
    "data.y_test = to_categorical(data.y_test, num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x103f91460>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142cd85b0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142cf0580>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e092b0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e09550>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x103f919a0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142cf0400>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e09ca0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e09f40>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e0d250>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e0d550>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e0d850>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e0daf0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e0ddc0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e0dfd0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e15250>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e154f0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e157f0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e15a30>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e15c10>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e15eb0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e1c190>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e1c430>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e1c6d0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e1c970>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e1cc10>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e1ceb0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e23190>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e23430>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e236d0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e23970>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e23c10>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e23eb0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e2a190>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e2a490>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 5, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e2a670>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e2a910>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e2aac0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e2ad30>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e2af40>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e312b0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e31550>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e317f0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 4, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e31a90>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e31d30>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e31f40>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e392b0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e39550>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 2, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e397f0>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e39a90>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 6, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.multiclassdl.MulticlassDL object at 0x142e39d30>, 'loss': 'categorical_crossentropy', 'n_classes': 9, 'n_epochs': 20, 'n_layers': 3, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 20)}, 'verbose': 1, 'wfo': False, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1657 - val_loss: 2.1321\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1149 - val_loss: 2.0944\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0853 - val_loss: 2.0652\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0606 - val_loss: 2.0446\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0459 - val_loss: 2.0336\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0361 - val_loss: 2.0259\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0282 - val_loss: 2.0216\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0230 - val_loss: 2.0178\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0195 - val_loss: 2.0144\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0181 - val_loss: 2.0122\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0152 - val_loss: 2.0108\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0131 - val_loss: 2.0087\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0116 - val_loss: 2.0069\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0096 - val_loss: 2.0056\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0087 - val_loss: 2.0039\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0070 - val_loss: 2.0024\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0061 - val_loss: 2.0021\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0048 - val_loss: 2.0016\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0040 - val_loss: 2.0034\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 1.9992\n",
      "Top-2 accuracy = 0.44\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/raise_utils/learners/multiclassdl.py:84: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "1\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1751 - val_loss: 2.1537\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1321 - val_loss: 2.1053\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0889 - val_loss: 2.0694\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0669 - val_loss: 2.0567\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0573 - val_loss: 2.0491\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0515 - val_loss: 2.0444\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0477 - val_loss: 2.0408\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0443 - val_loss: 2.0380\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0416 - val_loss: 2.0347\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0392 - val_loss: 2.0328\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0369 - val_loss: 2.0305\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0346 - val_loss: 2.0282\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0326 - val_loss: 2.0261\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0306 - val_loss: 2.0244\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0287 - val_loss: 2.0229\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0270 - val_loss: 2.0214\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0255 - val_loss: 2.0202\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0242 - val_loss: 2.0189\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0229 - val_loss: 2.0178\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0217 - val_loss: 2.0170\n",
      "Top-2 accuracy = 0.437\n",
      "2\n",
      "maxabsl|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1747 - val_loss: 2.1551\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1426 - val_loss: 2.1215\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1131 - val_loss: 2.0966\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0867 - val_loss: 2.0692\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0645 - val_loss: 2.0527\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0519 - val_loss: 2.0434\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0433 - val_loss: 2.0360\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0367 - val_loss: 2.0334\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0327 - val_loss: 2.0266\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0273 - val_loss: 2.0228\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0237 - val_loss: 2.0205\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0213 - val_loss: 2.0180\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0184 - val_loss: 2.0150\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0161 - val_loss: 2.0128\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0137 - val_loss: 2.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0131 - val_loss: 2.0096\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0116 - val_loss: 2.0082\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0098 - val_loss: 2.0077\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0079 - val_loss: 2.0064\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0066 - val_loss: 2.0040\n",
      "Top-2 accuracy = 0.444\n",
      "3\n",
      "minmaxC|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_16 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1788 - val_loss: 2.1516\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1305 - val_loss: 2.1095\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1039 - val_loss: 2.0912\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0900 - val_loss: 2.0795\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0798 - val_loss: 2.0722\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0707 - val_loss: 2.0587\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0558 - val_loss: 2.0404\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0414 - val_loss: 2.0299\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0335 - val_loss: 2.0240\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0282 - val_loss: 2.0217\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0255 - val_loss: 2.0183\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0230 - val_loss: 2.0173\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0209 - val_loss: 2.0151\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0195 - val_loss: 2.0145\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0168 - val_loss: 2.0115\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0153 - val_loss: 2.0101\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0139 - val_loss: 2.0093\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0122 - val_loss: 2.0078\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0108 - val_loss: 2.0063\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0093 - val_loss: 2.0053\n",
      "Top-2 accuracy = 0.439\n",
      "4\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_21 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1865 - val_loss: 2.1718\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1500 - val_loss: 2.1179\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1007 - val_loss: 2.0803\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0777 - val_loss: 2.0629\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0643 - val_loss: 2.0519\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0552 - val_loss: 2.0448\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0487 - val_loss: 2.0402\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0444 - val_loss: 2.0359\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0399 - val_loss: 2.0333\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0373 - val_loss: 2.0312\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0355 - val_loss: 2.0307\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0339 - val_loss: 2.0276\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0320 - val_loss: 2.0278\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0308 - val_loss: 2.0255\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0294 - val_loss: 2.0252\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0287 - val_loss: 2.0241\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0279 - val_loss: 2.0234\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0269 - val_loss: 2.0230\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0260 - val_loss: 2.0221\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0255 - val_loss: 2.0217\n",
      "Top-2 accuracy = 0.437\n",
      "5\n",
      "robustL|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_28 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1558 - val_loss: 2.0894\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0498 - val_loss: 2.0210\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0151 - val_loss: 2.0027\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 1.9962\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9939 - val_loss: 1.9895\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9863\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9867 - val_loss: 1.9844\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9848 - val_loss: 1.9824\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9830 - val_loss: 1.9807\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9822 - val_loss: 1.9797\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9806 - val_loss: 1.9780\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9793 - val_loss: 1.9776\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9787 - val_loss: 1.9756\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9781 - val_loss: 1.9748\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9778 - val_loss: 1.9753\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9763 - val_loss: 1.9732\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9759 - val_loss: 1.9744\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9750 - val_loss: 1.9723\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9737 - val_loss: 1.9718\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9735 - val_loss: 1.9714\n",
      "Top-2 accuracy = 0.453\n",
      "6\n",
      "maxabsS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_35 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1674 - val_loss: 2.1338\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1088 - val_loss: 2.0799\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0670 - val_loss: 2.0503\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0481 - val_loss: 2.0366\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0370 - val_loss: 2.0276\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0295 - val_loss: 2.0210\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0237 - val_loss: 2.0163\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0188 - val_loss: 2.0117\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0145 - val_loss: 2.0080\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0115 - val_loss: 2.0054\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0091 - val_loss: 2.0035\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0069 - val_loss: 2.0017\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0052 - val_loss: 2.0005\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0034 - val_loss: 1.9989\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0022 - val_loss: 1.9975\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0010 - val_loss: 1.9968\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0000 - val_loss: 1.9967\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9995 - val_loss: 1.9951\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9989 - val_loss: 1.9942\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9981 - val_loss: 1.9945\n",
      "Top-2 accuracy = 0.44\n",
      "7\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_39 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1690 - val_loss: 2.1102\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0806 - val_loss: 2.0577\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0506 - val_loss: 2.0397\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0376 - val_loss: 2.0287\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0278 - val_loss: 2.0203\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0207 - val_loss: 2.0144\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0154 - val_loss: 2.0091\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0101 - val_loss: 2.0044\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0055 - val_loss: 2.0005\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0020 - val_loss: 1.9973\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9983 - val_loss: 1.9939\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9953 - val_loss: 1.9915\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9925 - val_loss: 1.9890\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9911 - val_loss: 1.9873\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9889 - val_loss: 1.9862\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9874 - val_loss: 1.9839\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9861 - val_loss: 1.9832\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9848 - val_loss: 1.9820\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9839 - val_loss: 1.9811\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9830 - val_loss: 1.9806\n",
      "Top-2 accuracy = 0.452\n",
      "8\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_42 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1451 - val_loss: 2.0877\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0602 - val_loss: 2.0331\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0306 - val_loss: 2.0165\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0188 - val_loss: 2.0080\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0115 - val_loss: 2.0011\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0056 - val_loss: 1.9969\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 1.9944\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9984 - val_loss: 1.9918\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9965 - val_loss: 1.9898\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9942 - val_loss: 1.9888\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9928 - val_loss: 1.9869\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9910 - val_loss: 1.9858\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9848\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9888 - val_loss: 1.9837\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9877 - val_loss: 1.9844\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9873 - val_loss: 1.9833\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9875 - val_loss: 1.9830\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9859 - val_loss: 1.9820\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9849 - val_loss: 1.9802\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9836 - val_loss: 1.9796\n",
      "Top-2 accuracy = 0.452\n",
      "9\n",
      "maxabsU|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_48 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.2097 - val_loss: 2.1884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1808 - val_loss: 2.1721\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1691 - val_loss: 2.1630\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1611 - val_loss: 2.1545\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1518 - val_loss: 2.1423\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1366 - val_loss: 2.1196\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1094 - val_loss: 2.0877\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0818 - val_loss: 2.0627\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0613 - val_loss: 2.0461\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0489 - val_loss: 2.0376\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0422 - val_loss: 2.0328\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0379 - val_loss: 2.0293\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0346 - val_loss: 2.0270\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0320 - val_loss: 2.0247\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0293 - val_loss: 2.0222\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0265 - val_loss: 2.0198\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0242 - val_loss: 2.0177\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0222 - val_loss: 2.0157\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0198 - val_loss: 2.0134\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0169 - val_loss: 2.0108\n",
      "Top-2 accuracy = 0.44\n",
      "10\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_51 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1638 - val_loss: 2.1214\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0755 - val_loss: 2.0389\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0353 - val_loss: 2.0238\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0246 - val_loss: 2.0162\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0179 - val_loss: 2.0115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 2.0064\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0075 - val_loss: 2.0027\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 1.9969\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9989 - val_loss: 1.9942\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9967 - val_loss: 1.9917\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9941 - val_loss: 1.9916\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9888\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9906 - val_loss: 1.9866\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9864\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9889 - val_loss: 1.9854\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9883 - val_loss: 1.9859\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9872 - val_loss: 1.9845\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9866 - val_loss: 1.9836\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9858 - val_loss: 1.9837\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9861 - val_loss: 1.9818\n",
      "Top-2 accuracy = 0.452\n",
      "11\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_58 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1884 - val_loss: 2.1505\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1218 - val_loss: 2.0819\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0611 - val_loss: 2.0356\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0318 - val_loss: 2.0196\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0214 - val_loss: 2.0128\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0156 - val_loss: 2.0087\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0117 - val_loss: 2.0053\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0087 - val_loss: 2.0034\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0062 - val_loss: 2.0007\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0041 - val_loss: 1.9991\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0022 - val_loss: 1.9974\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0004 - val_loss: 1.9960\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9990 - val_loss: 1.9943\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9978 - val_loss: 1.9930\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9966 - val_loss: 1.9923\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9957 - val_loss: 1.9912\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9947 - val_loss: 1.9904\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9939 - val_loss: 1.9893\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9932 - val_loss: 1.9888\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9924 - val_loss: 1.9874\n",
      "Top-2 accuracy = 0.451\n",
      "12\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_61 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1967 - val_loss: 2.1744\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1572 - val_loss: 2.1334\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1122 - val_loss: 2.0848\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0706 - val_loss: 2.0534\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0491 - val_loss: 2.0389\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0384 - val_loss: 2.0309\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0314 - val_loss: 2.0246\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0262 - val_loss: 2.0205\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0224 - val_loss: 2.0169\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0188 - val_loss: 2.0135\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0161 - val_loss: 2.0106\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0139 - val_loss: 2.0086\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0118 - val_loss: 2.0063\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0104 - val_loss: 2.0047\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0087 - val_loss: 2.0034\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0072 - val_loss: 2.0018\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0059 - val_loss: 2.0004\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0049 - val_loss: 1.9995\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0039 - val_loss: 1.9985\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0028 - val_loss: 1.9974\n",
      "Top-2 accuracy = 0.447\n",
      "13\n",
      "robustr|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_65 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1357 - val_loss: 2.0857\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0604 - val_loss: 2.0324\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0319 - val_loss: 2.0199\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0237 - val_loss: 2.0136\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0179 - val_loss: 2.0075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0127 - val_loss: 2.0028\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0082 - val_loss: 1.9989\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0039 - val_loss: 1.9948\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9929\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9984 - val_loss: 1.9898\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9953 - val_loss: 1.9875\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9938 - val_loss: 1.9861\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9915 - val_loss: 1.9851\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9900 - val_loss: 1.9856\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9891 - val_loss: 1.9827\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9878 - val_loss: 1.9821\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9864 - val_loss: 1.9814\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9858 - val_loss: 1.9802\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9851 - val_loss: 1.9795\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9840 - val_loss: 1.9787\n",
      "Top-2 accuracy = 0.451\n",
      "14\n",
      "robustN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1468 - val_loss: 2.1017\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0700 - val_loss: 2.0402\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0293 - val_loss: 2.0184\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0156 - val_loss: 2.0099\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0100 - val_loss: 2.0050\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0071 - val_loss: 2.0029\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0047 - val_loss: 2.0006\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 1.9988\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0015 - val_loss: 1.9981\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0004 - val_loss: 1.9963\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9994 - val_loss: 1.9963\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9984 - val_loss: 1.9964\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9945\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9937\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9965 - val_loss: 1.9943\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9963 - val_loss: 1.9937\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9923\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9951 - val_loss: 1.9914\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9945 - val_loss: 1.9911\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9941 - val_loss: 1.9914\n",
      "Top-2 accuracy = 0.451\n",
      "15\n",
      "normalizei|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_75 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1819 - val_loss: 2.1670\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1618 - val_loss: 2.1549\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1524 - val_loss: 2.1434\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1384 - val_loss: 2.1255\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1180 - val_loss: 2.1036\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0960 - val_loss: 2.0783\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0764 - val_loss: 2.0624\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0628 - val_loss: 2.0506\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0525 - val_loss: 2.0438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0459 - val_loss: 2.0369\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0402 - val_loss: 2.0319\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0361 - val_loss: 2.0277\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0324 - val_loss: 2.0234\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0284 - val_loss: 2.0201\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0254 - val_loss: 2.0200\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0232 - val_loss: 2.0154\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0213 - val_loss: 2.0138\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0198 - val_loss: 2.0118\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0181 - val_loss: 2.0101\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0165 - val_loss: 2.0080\n",
      "Top-2 accuracy = 0.446\n",
      "16\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_82 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1690 - val_loss: 2.1140\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0822 - val_loss: 2.0514\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0435 - val_loss: 2.0278\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0269 - val_loss: 2.0169\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0190 - val_loss: 2.0107\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0138 - val_loss: 2.0069\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0101 - val_loss: 2.0037\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0070 - val_loss: 2.0010\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0048 - val_loss: 1.9993\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0028 - val_loss: 1.9974\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0011 - val_loss: 1.9962\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9999 - val_loss: 1.9949\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9986 - val_loss: 1.9935\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9975 - val_loss: 1.9924\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9961 - val_loss: 1.9916\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9958 - val_loss: 1.9904\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9941 - val_loss: 1.9901\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9932 - val_loss: 1.9893\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9927 - val_loss: 1.9884\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9923 - val_loss: 1.9878\n",
      "Top-2 accuracy = 0.447\n",
      "17\n",
      "minmaxY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1775 - val_loss: 2.1610\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1564\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1519 - val_loss: 2.1404\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1144 - val_loss: 2.0809\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0634 - val_loss: 2.0444\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0442 - val_loss: 2.0341\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0351 - val_loss: 2.0260\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0300 - val_loss: 2.0228\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0274 - val_loss: 2.0204\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0250 - val_loss: 2.0195\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0235 - val_loss: 2.0180\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0224 - val_loss: 2.0174\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0216 - val_loss: 2.0156\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0195 - val_loss: 2.0147\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0186 - val_loss: 2.0140\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0174 - val_loss: 2.0132\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0168 - val_loss: 2.0134\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0163 - val_loss: 2.0128\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0152 - val_loss: 2.0122\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0152 - val_loss: 2.0113\n",
      "Top-2 accuracy = 0.443\n",
      "18\n",
      "robustM|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_89 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1829 - val_loss: 2.1730\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1682 - val_loss: 2.1637\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1624 - val_loss: 2.1599\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1599 - val_loss: 2.1582\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1585 - val_loss: 2.1565\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1572 - val_loss: 2.1555\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1559 - val_loss: 2.1543\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1538 - val_loss: 2.1511\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1489 - val_loss: 2.1438\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1379 - val_loss: 2.1286\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1186 - val_loss: 2.1081\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0997 - val_loss: 2.0886\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0815 - val_loss: 2.0715\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0661 - val_loss: 2.0571\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0548 - val_loss: 2.0476\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0473 - val_loss: 2.0413\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0419 - val_loss: 2.0371\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0380 - val_loss: 2.0336\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0352 - val_loss: 2.0311\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0332 - val_loss: 2.0292\n",
      "Top-2 accuracy = 0.437\n",
      "19\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1730 - val_loss: 2.1326\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1126 - val_loss: 2.0900\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0874 - val_loss: 2.0738\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0752 - val_loss: 2.0643\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0673 - val_loss: 2.0573\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0621 - val_loss: 2.0519\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0548 - val_loss: 2.0454\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0501 - val_loss: 2.0407\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0461 - val_loss: 2.0368\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0430 - val_loss: 2.0346\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0403 - val_loss: 2.0316\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0380 - val_loss: 2.0298\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0360 - val_loss: 2.0284\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0339 - val_loss: 2.0272\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0325 - val_loss: 2.0254\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0308 - val_loss: 2.0229\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0294 - val_loss: 2.0215\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0284 - val_loss: 2.0204\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0270 - val_loss: 2.0195\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0259 - val_loss: 2.0185\n",
      "Top-2 accuracy = 0.449\n",
      "20\n",
      "standardizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1857 - val_loss: 2.1642\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1380 - val_loss: 2.1039\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0809 - val_loss: 2.0518\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0435 - val_loss: 2.0249\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0237 - val_loss: 2.0126\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0148 - val_loss: 2.0062\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0092 - val_loss: 2.0019\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0061 - val_loss: 1.9994\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0037 - val_loss: 1.9982\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0023 - val_loss: 1.9965\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9960\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9998 - val_loss: 1.9946\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9987 - val_loss: 1.9943\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9982 - val_loss: 1.9933\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9969 - val_loss: 1.9924\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9962 - val_loss: 1.9921\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9952 - val_loss: 1.9911\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9946 - val_loss: 1.9909\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9938 - val_loss: 1.9901\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9934 - val_loss: 1.9900\n",
      "Top-2 accuracy = 0.452\n",
      "21\n",
      "maxabsb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_106 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1932 - val_loss: 2.1755\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1567 - val_loss: 2.1225\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0862 - val_loss: 2.0482\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0412 - val_loss: 2.0245\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0257 - val_loss: 2.0155\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0186 - val_loss: 2.0103\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0138 - val_loss: 2.0068\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0106 - val_loss: 2.0039\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0075 - val_loss: 2.0010\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0050 - val_loss: 1.9991\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0027 - val_loss: 1.9974\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0010 - val_loss: 1.9952\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9990 - val_loss: 1.9931\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9975 - val_loss: 1.9920\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9960 - val_loss: 1.9912\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9950 - val_loss: 1.9899\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9938 - val_loss: 1.9891\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9930 - val_loss: 1.9880\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9921 - val_loss: 1.9875\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9913 - val_loss: 1.9872\n",
      "Top-2 accuracy = 0.451\n",
      "22\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1876 - val_loss: 2.1748\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1633 - val_loss: 2.1343\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1177 - val_loss: 2.0925\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0836 - val_loss: 2.0669\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0585 - val_loss: 2.0461\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0393 - val_loss: 2.0299\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0253 - val_loss: 2.0200\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0171 - val_loss: 2.0111\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0116 - val_loss: 2.0061\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0080 - val_loss: 2.0042\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0064 - val_loss: 2.0013\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0044 - val_loss: 1.9995\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0029 - val_loss: 1.9990\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 1.9968\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 1.9981\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9960\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9993 - val_loss: 1.9971\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9942\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9977 - val_loss: 1.9995\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9993 - val_loss: 1.9933\n",
      "Top-2 accuracy = 0.449\n",
      "23\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1805 - val_loss: 2.1464\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1128 - val_loss: 2.0826\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0793 - val_loss: 2.0634\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0648 - val_loss: 2.0515\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0530 - val_loss: 2.0407\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0409 - val_loss: 2.0292\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0314 - val_loss: 2.0219\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0250 - val_loss: 2.0164\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0204 - val_loss: 2.0126\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0162 - val_loss: 2.0123\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0143 - val_loss: 2.0066\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0109 - val_loss: 2.0043\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0090 - val_loss: 2.0026\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0074 - val_loss: 2.0020\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0065 - val_loss: 2.0004\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 1.9990\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0040 - val_loss: 1.9983\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0030 - val_loss: 1.9968\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0014 - val_loss: 1.9955\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0004 - val_loss: 1.9952\n",
      "Top-2 accuracy = 0.45\n",
      "24\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_121 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1892 - val_loss: 2.1800\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1736 - val_loss: 2.1631\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1531 - val_loss: 2.1340\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1196 - val_loss: 2.0988\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0889 - val_loss: 2.0736\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0664 - val_loss: 2.0549\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0508 - val_loss: 2.0418\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0399 - val_loss: 2.0333\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0327 - val_loss: 2.0277\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0274 - val_loss: 2.0229\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0231 - val_loss: 2.0190\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0190 - val_loss: 2.0152\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0159 - val_loss: 2.0127\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0133 - val_loss: 2.0098\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0112 - val_loss: 2.0078\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0091 - val_loss: 2.0056\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0074 - val_loss: 2.0037\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0061 - val_loss: 2.0024\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0049 - val_loss: 2.0009\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0038 - val_loss: 2.0001\n",
      "Top-2 accuracy = 0.447\n",
      "25\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_127 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1893 - val_loss: 2.1811\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1753 - val_loss: 2.1698\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1654 - val_loss: 2.1610\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1561 - val_loss: 2.1506\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1452 - val_loss: 2.1396\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1319 - val_loss: 2.1202\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1076 - val_loss: 2.0955\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0856 - val_loss: 2.0750\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0689 - val_loss: 2.0606\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0573 - val_loss: 2.0505\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0487 - val_loss: 2.0427\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0432 - val_loss: 2.0373\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0388 - val_loss: 2.0334\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0351 - val_loss: 2.0305\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0327 - val_loss: 2.0277\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0309 - val_loss: 2.0258\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0292 - val_loss: 2.0242\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0280 - val_loss: 2.0233\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0270 - val_loss: 2.0225\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0259 - val_loss: 2.0217\n",
      "Top-2 accuracy = 0.435\n",
      "26\n",
      "maxabsz|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_130 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1885 - val_loss: 2.1767\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1684 - val_loss: 2.1555\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1366 - val_loss: 2.1062\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0849 - val_loss: 2.0581\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0548 - val_loss: 2.0415\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0450 - val_loss: 2.0360\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0414 - val_loss: 2.0338\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0398 - val_loss: 2.0324\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0383 - val_loss: 2.0320\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0372 - val_loss: 2.0307\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0366 - val_loss: 2.0296\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0351 - val_loss: 2.0289\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0340 - val_loss: 2.0278\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0325 - val_loss: 2.0269\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0311 - val_loss: 2.0247\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0300 - val_loss: 2.0242\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0287 - val_loss: 2.0226\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0274 - val_loss: 2.0215\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0265 - val_loss: 2.0204\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0254 - val_loss: 2.0193\n",
      "Top-2 accuracy = 0.435\n",
      "27\n",
      "maxabsO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1834 - val_loss: 2.1622\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1269 - val_loss: 2.0783\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0525 - val_loss: 2.0304\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0243 - val_loss: 2.0159\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0182 - val_loss: 2.0131\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0157 - val_loss: 2.0112\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0147 - val_loss: 2.0102\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0135 - val_loss: 2.0097\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0141 - val_loss: 2.0124\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0123 - val_loss: 2.0096\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0113 - val_loss: 2.0085\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0107 - val_loss: 2.0095\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 2.0079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0113 - val_loss: 2.0059\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0093 - val_loss: 2.0057\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0089 - val_loss: 2.0049\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0083 - val_loss: 2.0049\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0082 - val_loss: 2.0040\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0071 - val_loss: 2.0039\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0067 - val_loss: 2.0034\n",
      "Top-2 accuracy = 0.446\n",
      "28\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1735 - val_loss: 2.1409\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1129 - val_loss: 2.0802\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0690 - val_loss: 2.0488\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0441 - val_loss: 2.0321\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0338 - val_loss: 2.0266\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0308 - val_loss: 2.0241\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0274 - val_loss: 2.0219\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0258 - val_loss: 2.0204\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0233 - val_loss: 2.0186\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0221 - val_loss: 2.0169\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0211 - val_loss: 2.0180\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0202 - val_loss: 2.0149\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0184 - val_loss: 2.0146\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0181 - val_loss: 2.0143\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0168 - val_loss: 2.0107\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0156 - val_loss: 2.0112\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0153 - val_loss: 2.0105\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0142 - val_loss: 2.0101\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0143 - val_loss: 2.0076\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0132 - val_loss: 2.0069\n",
      "Top-2 accuracy = 0.439\n",
      "29\n",
      "standardizeF|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_142 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1911 - val_loss: 2.1451\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1142 - val_loss: 2.0828\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0679 - val_loss: 2.0508\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0463 - val_loss: 2.0357\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0339 - val_loss: 2.0257\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0251 - val_loss: 2.0182\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0182 - val_loss: 2.0125\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0130 - val_loss: 2.0079\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0087 - val_loss: 2.0044\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0056 - val_loss: 2.0016\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0026 - val_loss: 1.9989\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0003 - val_loss: 1.9970\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9982 - val_loss: 1.9947\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9962 - val_loss: 1.9931\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9947 - val_loss: 1.9914\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9936 - val_loss: 1.9902\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9923 - val_loss: 1.9889\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9912 - val_loss: 1.9877\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9903 - val_loss: 1.9871\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9895 - val_loss: 1.9862\n",
      "Top-2 accuracy = 0.449\n",
      "0\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1815 - val_loss: 2.1603\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1265 - val_loss: 2.0674\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0500 - val_loss: 2.0400\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0368 - val_loss: 2.0268\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0304 - val_loss: 2.0249\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0260 - val_loss: 2.0217\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0226 - val_loss: 2.0142\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0198 - val_loss: 2.0141\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0179 - val_loss: 2.0130\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0163 - val_loss: 2.0096\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0147 - val_loss: 2.0080\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0139 - val_loss: 2.0079\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0126 - val_loss: 2.0060\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0118 - val_loss: 2.0055\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0108 - val_loss: 2.0048\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0104 - val_loss: 2.0071\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0104 - val_loss: 2.0034\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0099 - val_loss: 2.0041\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0081 - val_loss: 2.0028\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0084 - val_loss: 2.0018\n",
      "Top-2 accuracy = 0.445\n",
      "1\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_152 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1704 - val_loss: 2.1338\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1048 - val_loss: 2.0727\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0616 - val_loss: 2.0419\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0431 - val_loss: 2.0332\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0351 - val_loss: 2.0275\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0312 - val_loss: 2.0226\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0287 - val_loss: 2.0196\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0250 - val_loss: 2.0182\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0226 - val_loss: 2.0157\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0205 - val_loss: 2.0133\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0191 - val_loss: 2.0117\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0170 - val_loss: 2.0108\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0161 - val_loss: 2.0122\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0144 - val_loss: 2.0086\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0128 - val_loss: 2.0079\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0116 - val_loss: 2.0066\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0105 - val_loss: 2.0047\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0092 - val_loss: 2.0041\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0084 - val_loss: 2.0030\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0074 - val_loss: 2.0017\n",
      "Top-2 accuracy = 0.445\n",
      "2\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1734 - val_loss: 2.1486\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1308 - val_loss: 2.1004\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0917 - val_loss: 2.0708\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0683 - val_loss: 2.0501\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0508 - val_loss: 2.0357\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0385 - val_loss: 2.0282\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0305 - val_loss: 2.0220\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0247 - val_loss: 2.0191\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0214 - val_loss: 2.0149\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0181 - val_loss: 2.0131\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0164 - val_loss: 2.0135\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0150 - val_loss: 2.0089\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0138 - val_loss: 2.0077\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0119 - val_loss: 2.0072\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0107 - val_loss: 2.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 2.0078\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0093 - val_loss: 2.0039\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0088 - val_loss: 2.0030\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0075 - val_loss: 2.0048\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0076 - val_loss: 2.0026\n",
      "Top-2 accuracy = 0.446\n",
      "3\n",
      "standardizeD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1650 - val_loss: 2.1385\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1146 - val_loss: 2.0928\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0712 - val_loss: 2.0489\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0338 - val_loss: 2.0180\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0131 - val_loss: 2.0031\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0037 - val_loss: 1.9974\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0001 - val_loss: 1.9950\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9942\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9976 - val_loss: 1.9931\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9967 - val_loss: 1.9930\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9964 - val_loss: 1.9925\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9922\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9957 - val_loss: 1.9921\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9953 - val_loss: 1.9911\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9946 - val_loss: 1.9922\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9951 - val_loss: 1.9905\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9946 - val_loss: 1.9903\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9935 - val_loss: 1.9905\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9934 - val_loss: 1.9893\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9931 - val_loss: 1.9887\n",
      "Top-2 accuracy = 0.451\n",
      "4\n",
      "normalizeK|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_163 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1527 - val_loss: 2.0852\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0483 - val_loss: 2.0229\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0190 - val_loss: 2.0076\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0075 - val_loss: 1.9994\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0009 - val_loss: 1.9941\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9966 - val_loss: 1.9911\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9933 - val_loss: 1.9870\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9899 - val_loss: 1.9851\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9885 - val_loss: 1.9831\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9866 - val_loss: 1.9817\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9856 - val_loss: 1.9803\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9841 - val_loss: 1.9804\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9823 - val_loss: 1.9801\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9818 - val_loss: 1.9801\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9810 - val_loss: 1.9843\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9809 - val_loss: 1.9783\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9806 - val_loss: 1.9769\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9798 - val_loss: 1.9785\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9784 - val_loss: 1.9776\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9788 - val_loss: 1.9757\n",
      "Top-2 accuracy = 0.451\n",
      "5\n",
      "robusto|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1731 - val_loss: 2.1421\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0849 - val_loss: 2.0298\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0183 - val_loss: 2.0063\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0062 - val_loss: 2.0008\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0013 - val_loss: 1.9971\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0003 - val_loss: 1.9951\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9984 - val_loss: 1.9948\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9942\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9962 - val_loss: 1.9964\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9963 - val_loss: 1.9934\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9950 - val_loss: 1.9924\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9944 - val_loss: 1.9924\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9941 - val_loss: 1.9914\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9915\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9937 - val_loss: 1.9917\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9939 - val_loss: 1.9909\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9925 - val_loss: 1.9907\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9927 - val_loss: 1.9911\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9936 - val_loss: 1.9921\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9927 - val_loss: 1.9923\n",
      "Top-2 accuracy = 0.45\n",
      "6\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1730 - val_loss: 2.1538\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1384 - val_loss: 2.1161\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1018 - val_loss: 2.0774\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0676 - val_loss: 2.0547\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0458 - val_loss: 2.0343\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0316 - val_loss: 2.0246\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0239 - val_loss: 2.0168\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0186 - val_loss: 2.0148\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0151 - val_loss: 2.0096\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0121 - val_loss: 2.0090\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0106 - val_loss: 2.0068\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0088 - val_loss: 2.0045\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0072 - val_loss: 2.0045\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0060 - val_loss: 2.0024\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0047 - val_loss: 2.0015\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0042 - val_loss: 2.0013\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0035 - val_loss: 2.0004\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 1.9996\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0021 - val_loss: 1.9990\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0018 - val_loss: 1.9993\n",
      "Top-2 accuracy = 0.447\n",
      "7\n",
      "maxabsr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1877 - val_loss: 2.1763\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1649 - val_loss: 2.1460\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1305 - val_loss: 2.1109\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1040 - val_loss: 2.0897\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0865 - val_loss: 2.0742\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0720 - val_loss: 2.0613\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0607 - val_loss: 2.0515\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0521 - val_loss: 2.0435\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0456 - val_loss: 2.0396\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0408 - val_loss: 2.0340\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0368 - val_loss: 2.0305\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0334 - val_loss: 2.0273\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0307 - val_loss: 2.0249\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0289 - val_loss: 2.0228\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0265 - val_loss: 2.0224\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0254 - val_loss: 2.0186\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0233 - val_loss: 2.0186\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0221 - val_loss: 2.0163\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0208 - val_loss: 2.0146\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0201 - val_loss: 2.0140\n",
      "Top-2 accuracy = 0.449\n",
      "8\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_185 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1613 - val_loss: 2.1213\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0888 - val_loss: 2.0554\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0449 - val_loss: 2.0296\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0290 - val_loss: 2.0199\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0208 - val_loss: 2.0141\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0158 - val_loss: 2.0086\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0125 - val_loss: 2.0058\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0099 - val_loss: 2.0036\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0078 - val_loss: 2.0011\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0062 - val_loss: 1.9995\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 1.9985\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0033 - val_loss: 1.9972\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0019 - val_loss: 1.9978\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0021 - val_loss: 1.9963\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0011 - val_loss: 1.9947\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9934\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9986 - val_loss: 1.9925\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9985 - val_loss: 1.9912\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9975 - val_loss: 1.9910\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9968 - val_loss: 1.9912\n",
      "Top-2 accuracy = 0.447\n",
      "9\n",
      "robustA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1405 - val_loss: 2.0523\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0381 - val_loss: 2.0099\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0106 - val_loss: 1.9971\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0023 - val_loss: 1.9920\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9968 - val_loss: 1.9908\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9947 - val_loss: 1.9870\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9932 - val_loss: 1.9858\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9921 - val_loss: 1.9860\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9909 - val_loss: 1.9887\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9935 - val_loss: 1.9840\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9896 - val_loss: 1.9847\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9839\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9885 - val_loss: 1.9902\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9896 - val_loss: 1.9855\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9879 - val_loss: 1.9858\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9880 - val_loss: 1.9822\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9882 - val_loss: 1.9826\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9872 - val_loss: 1.9843\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9873 - val_loss: 1.9834\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9865 - val_loss: 1.9838\n",
      "Top-2 accuracy = 0.45\n",
      "10\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_198 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.2485 - val_loss: 2.1284\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0997 - val_loss: 2.0695\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0567 - val_loss: 2.0388\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0360 - val_loss: 2.0264\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0260 - val_loss: 2.0200\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0197 - val_loss: 2.0136\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0150 - val_loss: 2.0101\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0106 - val_loss: 2.0076\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0074 - val_loss: 2.0041\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0043 - val_loss: 2.0020\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0019 - val_loss: 2.0001\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9999 - val_loss: 1.9985\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9973 - val_loss: 1.9972\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9957 - val_loss: 1.9951\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9937 - val_loss: 1.9940\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9931 - val_loss: 1.9929\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9913 - val_loss: 1.9927\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9907 - val_loss: 1.9917\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9896 - val_loss: 1.9902\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9878 - val_loss: 1.9900\n",
      "Top-2 accuracy = 0.45\n",
      "11\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_202 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1437 - val_loss: 2.0807\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0552 - val_loss: 2.0381\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0360 - val_loss: 2.0290\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0302 - val_loss: 2.0309\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0262 - val_loss: 2.0215\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0236 - val_loss: 2.0147\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0187 - val_loss: 2.0130\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0155 - val_loss: 2.0084\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0122 - val_loss: 2.0070\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0094 - val_loss: 2.0031\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0080 - val_loss: 2.0000\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0050 - val_loss: 2.0015\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0038 - val_loss: 1.9972\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0024 - val_loss: 2.0015\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 1.9953\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9989 - val_loss: 1.9928\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9980 - val_loss: 1.9936\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9954\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9904\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9961 - val_loss: 2.0202\n",
      "Top-2 accuracy = 0.437\n",
      "12\n",
      "standardizeX|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_209 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.2111 - val_loss: 2.1377\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1012 - val_loss: 2.0648\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0552 - val_loss: 2.0395\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0385 - val_loss: 2.0292\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0299 - val_loss: 2.0229\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0238 - val_loss: 2.0184\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0193 - val_loss: 2.0146\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0157 - val_loss: 2.0115\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0129 - val_loss: 2.0088\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0103 - val_loss: 2.0068\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0081 - val_loss: 2.0042\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0060 - val_loss: 2.0022\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0040 - val_loss: 2.0005\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0023 - val_loss: 1.9985\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0008 - val_loss: 1.9969\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9992 - val_loss: 1.9957\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9979 - val_loss: 1.9939\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9968 - val_loss: 1.9931\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9956 - val_loss: 1.9923\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9948 - val_loss: 1.9911\n",
      "Top-2 accuracy = 0.451\n",
      "13\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1525 - val_loss: 2.0694\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0389 - val_loss: 2.0151\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0137 - val_loss: 2.0033\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 1.9979\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0018 - val_loss: 1.9949\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9988 - val_loss: 1.9931\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9969 - val_loss: 1.9917\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9953 - val_loss: 1.9910\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9935 - val_loss: 1.9887\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9928 - val_loss: 1.9902\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9922 - val_loss: 1.9885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9916 - val_loss: 1.9865\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9872\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9867\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9899 - val_loss: 1.9858\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9884 - val_loss: 1.9888\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9883 - val_loss: 1.9894\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9884 - val_loss: 1.9841\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9880 - val_loss: 1.9854\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9869 - val_loss: 1.9845\n",
      "Top-2 accuracy = 0.45\n",
      "14\n",
      "robustY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1560 - val_loss: 2.1149\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0786 - val_loss: 2.0462\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0346 - val_loss: 2.0227\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0184 - val_loss: 2.0119\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0108 - val_loss: 2.0067\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0062 - val_loss: 2.0028\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0031 - val_loss: 1.9995\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0003 - val_loss: 1.9970\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9955\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9966 - val_loss: 1.9936\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9953 - val_loss: 1.9927\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9938 - val_loss: 1.9914\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9927 - val_loss: 1.9897\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9915 - val_loss: 1.9908\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9908 - val_loss: 1.9878\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9893 - val_loss: 1.9875\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9889 - val_loss: 1.9862\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9878 - val_loss: 1.9852\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9871 - val_loss: 1.9846\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9860 - val_loss: 1.9841\n",
      "Top-2 accuracy = 0.451\n",
      "15\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1577 - val_loss: 2.1072\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0763 - val_loss: 2.0436\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0348 - val_loss: 2.0178\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0172 - val_loss: 2.0062\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0086 - val_loss: 2.0006\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0039 - val_loss: 1.9967\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0014 - val_loss: 1.9943\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9992 - val_loss: 1.9931\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9975 - val_loss: 1.9921\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9910\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9959 - val_loss: 1.9905\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9951 - val_loss: 1.9898\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9942 - val_loss: 1.9899\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9939 - val_loss: 1.9895\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9936 - val_loss: 1.9889\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9928 - val_loss: 1.9882\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9923 - val_loss: 1.9880\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9868\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9915 - val_loss: 1.9872\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9914 - val_loss: 1.9879\n",
      "Top-2 accuracy = 0.448\n",
      "16\n",
      "standardizeo|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_222 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1677 - val_loss: 2.1154\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0606 - val_loss: 2.0221\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0180 - val_loss: 2.0052\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0057 - val_loss: 1.9989\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9926\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9949 - val_loss: 1.9885\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9923 - val_loss: 1.9870\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9895 - val_loss: 1.9868\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9884 - val_loss: 1.9834\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9866 - val_loss: 1.9845\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9862 - val_loss: 1.9817\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9843 - val_loss: 1.9813\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9827 - val_loss: 1.9805\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9829 - val_loss: 1.9813\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9816 - val_loss: 1.9792\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9804 - val_loss: 1.9794\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9802 - val_loss: 1.9781\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9793 - val_loss: 1.9784\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9788 - val_loss: 1.9783\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9776 - val_loss: 1.9775\n",
      "Top-2 accuracy = 0.451\n",
      "17\n",
      "normalizeG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1113 - val_loss: 2.0138\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0059 - val_loss: 1.9931\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9961 - val_loss: 1.9902\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9922 - val_loss: 1.9894\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9900 - val_loss: 1.9861\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9883 - val_loss: 1.9857\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9882 - val_loss: 1.9852\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9877 - val_loss: 1.9882\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9877 - val_loss: 1.9849\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9868 - val_loss: 1.9839\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9859 - val_loss: 1.9841\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9860 - val_loss: 1.9856\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9847 - val_loss: 1.9830\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9850 - val_loss: 1.9836\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9842 - val_loss: 1.9841\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9844 - val_loss: 1.9844\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9842 - val_loss: 1.9852\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9835 - val_loss: 1.9840\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9845 - val_loss: 1.9860\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9837 - val_loss: 1.9849\n",
      "Top-2 accuracy = 0.45\n",
      "18\n",
      "maxabsW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1383 - val_loss: 2.0797\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0456 - val_loss: 2.0150\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0085 - val_loss: 1.9969\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9988 - val_loss: 1.9918\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9964 - val_loss: 1.9899\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9944 - val_loss: 1.9892\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9935 - val_loss: 1.9879\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9925 - val_loss: 1.9871\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9917 - val_loss: 1.9871\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9915 - val_loss: 1.9870\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9909 - val_loss: 1.9859\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9910 - val_loss: 1.9901\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9917 - val_loss: 1.9865\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9858\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9901 - val_loss: 1.9863\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9896 - val_loss: 1.9853\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9860\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9895 - val_loss: 1.9850\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9892 - val_loss: 1.9854\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9891 - val_loss: 1.9847\n",
      "Top-2 accuracy = 0.449\n",
      "19\n",
      "robustF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1601 - val_loss: 2.1324\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0955 - val_loss: 2.0542\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0367 - val_loss: 2.0213\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0167 - val_loss: 2.0091\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0083 - val_loss: 2.0021\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 1.9976\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0000 - val_loss: 1.9950\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9982 - val_loss: 1.9929\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9965 - val_loss: 1.9914\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9953 - val_loss: 1.9910\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9944 - val_loss: 1.9890\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9937 - val_loss: 1.9879\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9918 - val_loss: 1.9876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9912 - val_loss: 1.9869\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9904 - val_loss: 1.9851\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9895 - val_loss: 1.9851\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9889 - val_loss: 1.9837\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9880 - val_loss: 1.9830\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9874 - val_loss: 1.9819\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9871 - val_loss: 1.9811\n",
      "Top-2 accuracy = 0.448\n",
      "20\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1277 - val_loss: 2.0398\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0238 - val_loss: 2.0115\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0077 - val_loss: 1.9998\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0018 - val_loss: 1.9964\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0002 - val_loss: 1.9945\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9973 - val_loss: 1.9948\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9902\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9942 - val_loss: 1.9895\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9934 - val_loss: 1.9895\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9933 - val_loss: 1.9897\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9912 - val_loss: 1.9896\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9909 - val_loss: 1.9870\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9869\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9889 - val_loss: 1.9890\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9904 - val_loss: 1.9872\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9889 - val_loss: 1.9894\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9916 - val_loss: 1.9837\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9870 - val_loss: 1.9846\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9853 - val_loss: 1.9819\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9863 - val_loss: 1.9808\n",
      "Top-2 accuracy = 0.452\n",
      "21\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1558 - val_loss: 2.1086\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0797 - val_loss: 2.0494\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0441 - val_loss: 2.0329\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0307 - val_loss: 2.0233\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0247 - val_loss: 2.0205\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0205 - val_loss: 2.0174\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0167 - val_loss: 2.0134\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0136 - val_loss: 2.0116\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0121 - val_loss: 2.0103\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0115 - val_loss: 2.0174\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0111 - val_loss: 2.0088\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0112 - val_loss: 2.0073\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0087 - val_loss: 2.0061\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0083 - val_loss: 2.0079\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0076 - val_loss: 2.0081\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0066 - val_loss: 2.0092\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0086 - val_loss: 2.0053\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0067 - val_loss: 2.0061\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0055 - val_loss: 2.0068\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0073 - val_loss: 2.0098\n",
      "Top-2 accuracy = 0.447\n",
      "22\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_253 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1703 - val_loss: 2.1407\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1158 - val_loss: 2.0898\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0785 - val_loss: 2.0607\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0574 - val_loss: 2.0472\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0459 - val_loss: 2.0371\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0371 - val_loss: 2.0305\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0307 - val_loss: 2.0245\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0260 - val_loss: 2.0195\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0217 - val_loss: 2.0163\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0184 - val_loss: 2.0134\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0156 - val_loss: 2.0123\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0135 - val_loss: 2.0093\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0115 - val_loss: 2.0064\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0090 - val_loss: 2.0050\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0072 - val_loss: 2.0036\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0052 - val_loss: 2.0023\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0044 - val_loss: 2.0010\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0027 - val_loss: 2.0000\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0013 - val_loss: 1.9978\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9998 - val_loss: 1.9966\n",
      "Top-2 accuracy = 0.448\n",
      "23\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1115 - val_loss: 2.0195\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0081 - val_loss: 1.9940\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9967 - val_loss: 1.9945\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9934 - val_loss: 1.9895\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9908 - val_loss: 1.9895\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9891 - val_loss: 1.9874\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9913 - val_loss: 1.9863\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9879 - val_loss: 1.9860\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9869 - val_loss: 1.9935\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9889 - val_loss: 1.9845\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9861 - val_loss: 1.9916\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9912 - val_loss: 1.9876\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9853 - val_loss: 1.9851\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9862 - val_loss: 1.9849\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9850 - val_loss: 1.9853\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9848 - val_loss: 1.9835\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9848 - val_loss: 1.9849\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9835 - val_loss: 1.9844\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9838 - val_loss: 1.9868\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9833 - val_loss: 1.9823\n",
      "Top-2 accuracy = 0.449\n",
      "24\n",
      "minmaxW|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_267 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1778 - val_loss: 2.1538\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1443 - val_loss: 2.1316\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1263 - val_loss: 2.1135\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1063 - val_loss: 2.0890\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0854 - val_loss: 2.0719\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0720 - val_loss: 2.0622\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0638 - val_loss: 2.0557\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0589 - val_loss: 2.0517\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0555 - val_loss: 2.0493\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0533 - val_loss: 2.0476\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0515 - val_loss: 2.0464\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0501 - val_loss: 2.0447\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0484 - val_loss: 2.0436\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0469 - val_loss: 2.0424\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0459 - val_loss: 2.0406\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0439 - val_loss: 2.0396\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0429 - val_loss: 2.0379\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0412 - val_loss: 2.0368\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0399 - val_loss: 2.0351\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0387 - val_loss: 2.0338\n",
      "Top-2 accuracy = 0.431\n",
      "25\n",
      "normalizep|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_270 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1781 - val_loss: 2.1650\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1598 - val_loss: 2.1537\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1496 - val_loss: 2.1430\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1362 - val_loss: 2.1255\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1154 - val_loss: 2.1025\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0943 - val_loss: 2.0829\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0785 - val_loss: 2.0691\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0676 - val_loss: 2.0594\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0602 - val_loss: 2.0528\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0538 - val_loss: 2.0477\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0495 - val_loss: 2.0435\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0461 - val_loss: 2.0408\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0439 - val_loss: 2.0394\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0419 - val_loss: 2.0368\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0403 - val_loss: 2.0362\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0389 - val_loss: 2.0334\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0371 - val_loss: 2.0319\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0358 - val_loss: 2.0311\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0348 - val_loss: 2.0297\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0338 - val_loss: 2.0286\n",
      "Top-2 accuracy = 0.431\n",
      "26\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_273 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1800 - val_loss: 2.1674\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1536 - val_loss: 2.1416\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1261 - val_loss: 2.1125\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0978 - val_loss: 2.0809\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0704 - val_loss: 2.0560\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0540 - val_loss: 2.0449\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0452 - val_loss: 2.0379\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0412 - val_loss: 2.0348\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0387 - val_loss: 2.0328\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0364 - val_loss: 2.0305\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0345 - val_loss: 2.0294\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0330 - val_loss: 2.0281\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0327 - val_loss: 2.0271\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0306 - val_loss: 2.0260\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0300 - val_loss: 2.0248\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0292 - val_loss: 2.0240\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0286 - val_loss: 2.0248\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0278 - val_loss: 2.0224\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0267 - val_loss: 2.0216\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0265 - val_loss: 2.0210\n",
      "Top-2 accuracy = 0.438\n",
      "27\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1766 - val_loss: 2.1503\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1080 - val_loss: 2.0618\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0475 - val_loss: 2.0297\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0290 - val_loss: 2.0185\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0209 - val_loss: 2.0120\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0160 - val_loss: 2.0081\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0125 - val_loss: 2.0067\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0100 - val_loss: 2.0047\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0088 - val_loss: 2.0036\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0074 - val_loss: 2.0014\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0063 - val_loss: 2.0012\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0055 - val_loss: 2.0031\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0050 - val_loss: 1.9992\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0029 - val_loss: 1.9980\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0027 - val_loss: 1.9977\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0019 - val_loss: 1.9974\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0011 - val_loss: 1.9963\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0010 - val_loss: 1.9962\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0001 - val_loss: 1.9954\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9998 - val_loss: 1.9948\n",
      "Top-2 accuracy = 0.447\n",
      "28\n",
      "normalizeH|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_282 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1900 - val_loss: 2.1807\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1722 - val_loss: 2.1610\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1484 - val_loss: 2.1316\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1222 - val_loss: 2.1088\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1049 - val_loss: 2.0949\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0936 - val_loss: 2.0856\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0854 - val_loss: 2.0779\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0794 - val_loss: 2.0723\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0744 - val_loss: 2.0668\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0693 - val_loss: 2.0615\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0636 - val_loss: 2.0552\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0567 - val_loss: 2.0476\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0494 - val_loss: 2.0398\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0427 - val_loss: 2.0329\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0369 - val_loss: 2.0271\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0323 - val_loss: 2.0229\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0288 - val_loss: 2.0200\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0261 - val_loss: 2.0177\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0241 - val_loss: 2.0160\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0226 - val_loss: 2.0146\n",
      "Top-2 accuracy = 0.442\n",
      "29\n",
      "maxabsU|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_287 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1803 - val_loss: 2.1549\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1321 - val_loss: 2.1060\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0910 - val_loss: 2.0715\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0650 - val_loss: 2.0534\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0518 - val_loss: 2.0436\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0433 - val_loss: 2.0356\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0364 - val_loss: 2.0306\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0325 - val_loss: 2.0278\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0298 - val_loss: 2.0255\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0278 - val_loss: 2.0237\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0262 - val_loss: 2.0222\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0246 - val_loss: 2.0208\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0229 - val_loss: 2.0194\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0217 - val_loss: 2.0179\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0204 - val_loss: 2.0167\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0192 - val_loss: 2.0156\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0181 - val_loss: 2.0145\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0171 - val_loss: 2.0133\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0163 - val_loss: 2.0124\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0151 - val_loss: 2.0114\n",
      "Top-2 accuracy = 0.436\n",
      "0\n",
      "maxabsD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1641 - val_loss: 2.1161\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0748 - val_loss: 2.0425\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0364 - val_loss: 2.0209\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0200 - val_loss: 2.0122\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0130 - val_loss: 2.0067\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0084 - val_loss: 2.0019\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0059 - val_loss: 1.9990\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0039 - val_loss: 1.9982\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0025 - val_loss: 1.9970\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0014 - val_loss: 1.9965\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9998 - val_loss: 1.9953\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9984 - val_loss: 1.9935\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9973 - val_loss: 1.9935\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9967 - val_loss: 1.9953\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9966 - val_loss: 1.9936\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9958 - val_loss: 1.9910\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9945 - val_loss: 1.9902\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9937 - val_loss: 1.9904\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9892\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9932 - val_loss: 1.9898\n",
      "Top-2 accuracy = 0.447\n",
      "1\n",
      "minmaxt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1554 - val_loss: 2.0928\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0593 - val_loss: 2.0759\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0336 - val_loss: 2.0239\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0251 - val_loss: 2.0117\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0159 - val_loss: 2.0081\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0125 - val_loss: 2.0063\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0120 - val_loss: 2.0237\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0115 - val_loss: 2.0035\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0071 - val_loss: 2.0030\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0062 - val_loss: 2.0018\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0042 - val_loss: 1.9991\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0063 - val_loss: 2.0007\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0036 - val_loss: 2.0084\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0059 - val_loss: 2.0009\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0023 - val_loss: 2.0465\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0066 - val_loss: 2.0080\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0012 - val_loss: 2.0000\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0025 - val_loss: 1.9953\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0011 - val_loss: 2.0333\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0103 - val_loss: 2.0123\n",
      "Top-2 accuracy = 0.438\n",
      "2\n",
      "robusts|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1784 - val_loss: 2.1419\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1112 - val_loss: 2.0749\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0582 - val_loss: 2.0350\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0316 - val_loss: 2.0180\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0202 - val_loss: 2.0103\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0145 - val_loss: 2.0059\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0112 - val_loss: 2.0041\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0088 - val_loss: 2.0022\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0069 - val_loss: 2.0006\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0055 - val_loss: 1.9994\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0040 - val_loss: 1.9981\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0027 - val_loss: 1.9970\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0020 - val_loss: 1.9964\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0010 - val_loss: 1.9953\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9997 - val_loss: 1.9940\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9988 - val_loss: 1.9939\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9981 - val_loss: 1.9928\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9973 - val_loss: 1.9918\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9966 - val_loss: 1.9907\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9956 - val_loss: 1.9910\n",
      "Top-2 accuracy = 0.448\n",
      "3\n",
      "standardizes|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_304 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1835 - val_loss: 2.1644\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1429 - val_loss: 2.1109\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0798 - val_loss: 2.0520\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0418 - val_loss: 2.0305\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0273 - val_loss: 2.0204\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0200 - val_loss: 2.0154\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0151 - val_loss: 2.0109\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0110 - val_loss: 2.0070\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0080 - val_loss: 2.0042\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0052 - val_loss: 2.0019\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0033 - val_loss: 1.9997\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0016 - val_loss: 1.9980\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0000 - val_loss: 1.9965\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9988 - val_loss: 1.9971\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9984 - val_loss: 1.9946\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9970 - val_loss: 1.9939\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9958 - val_loss: 1.9931\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9955 - val_loss: 1.9926\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9945 - val_loss: 1.9918\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9935 - val_loss: 1.9910\n",
      "Top-2 accuracy = 0.45\n",
      "4\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1899 - val_loss: 2.1822\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1775 - val_loss: 2.1725\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1700 - val_loss: 2.1664\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1652 - val_loss: 2.1627\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1624 - val_loss: 2.1606\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1608 - val_loss: 2.1594\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1600 - val_loss: 2.1588\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1594 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1590 - val_loss: 2.1582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "5\n",
      "minmaxj|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_312 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1860 - val_loss: 2.1633\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1269 - val_loss: 2.0807\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0585 - val_loss: 2.0361\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0413 - val_loss: 2.0359\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0361 - val_loss: 2.0258\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0295 - val_loss: 2.0197\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0242 - val_loss: 2.0163\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0198 - val_loss: 2.0103\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0153 - val_loss: 2.0075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0133 - val_loss: 2.0027\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0092 - val_loss: 2.0001\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0064 - val_loss: 1.9980\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0044 - val_loss: 1.9952\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0026 - val_loss: 1.9967\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0024 - val_loss: 1.9926\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 1.9947\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9909\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9980 - val_loss: 1.9894\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9958 - val_loss: 1.9884\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9956 - val_loss: 1.9886\n",
      "Top-2 accuracy = 0.445\n",
      "6\n",
      "normalizeV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_317 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1837 - val_loss: 2.1713\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1648 - val_loss: 2.1605\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1560 - val_loss: 2.1485\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1364 - val_loss: 2.1150\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1020 - val_loss: 2.0815\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0753 - val_loss: 2.0600\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0586 - val_loss: 2.0450\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0476 - val_loss: 2.0376\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0428 - val_loss: 2.0347\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0402 - val_loss: 2.0324\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0385 - val_loss: 2.0316\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0370 - val_loss: 2.0302\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0361 - val_loss: 2.0290\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0353 - val_loss: 2.0293\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0350 - val_loss: 2.0276\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0336 - val_loss: 2.0269\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0329 - val_loss: 2.0264\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0323 - val_loss: 2.0256\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0319 - val_loss: 2.0251\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0312 - val_loss: 2.0250\n",
      "Top-2 accuracy = 0.433\n",
      "7\n",
      "normalizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1892 - val_loss: 2.1816\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1770 - val_loss: 2.1719\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1694 - val_loss: 2.1659\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1648 - val_loss: 2.1623\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1621 - val_loss: 2.1603\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1605 - val_loss: 2.1591\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1597 - val_loss: 2.1585\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1594 - val_loss: 2.1583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "8\n",
      "minmaxd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1889 - val_loss: 2.1788\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1656 - val_loss: 2.1465\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1293 - val_loss: 2.1076\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0984 - val_loss: 2.0828\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0805 - val_loss: 2.0695\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0694 - val_loss: 2.0603\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0614 - val_loss: 2.0531\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0547 - val_loss: 2.0477\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0498 - val_loss: 2.0436\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0466 - val_loss: 2.0399\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0429 - val_loss: 2.0375\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0407 - val_loss: 2.0343\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0380 - val_loss: 2.0320\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0356 - val_loss: 2.0300\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0340 - val_loss: 2.0284\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0324 - val_loss: 2.0267\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0312 - val_loss: 2.0260\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0295 - val_loss: 2.0240\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0282 - val_loss: 2.0229\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0272 - val_loss: 2.0219\n",
      "Top-2 accuracy = 0.44\n",
      "9\n",
      "minmaxT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1871 - val_loss: 2.1734\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1528 - val_loss: 2.1221\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0933 - val_loss: 2.0624\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0463 - val_loss: 2.0319\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0235 - val_loss: 2.0131\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0140 - val_loss: 2.0072\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0105 - val_loss: 2.0040\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0080 - val_loss: 2.0011\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0065 - val_loss: 2.0005\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0055 - val_loss: 2.0010\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0047 - val_loss: 2.0057\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0047 - val_loss: 1.9963\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0028 - val_loss: 1.9958\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0020 - val_loss: 1.9950\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9958\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0007 - val_loss: 1.9947\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9957\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 1.9947\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0001 - val_loss: 1.9940\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9989 - val_loss: 1.9938\n",
      "Top-2 accuracy = 0.447\n",
      "10\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1575 - val_loss: 2.1237\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0995 - val_loss: 2.0702\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0550 - val_loss: 2.0351\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0282 - val_loss: 2.0143\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0130 - val_loss: 2.0027\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0055 - val_loss: 1.9969\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0015 - val_loss: 1.9939\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9985 - val_loss: 1.9919\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9966 - val_loss: 1.9897\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9890\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9944 - val_loss: 1.9884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9936 - val_loss: 1.9877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9927 - val_loss: 1.9886\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9860\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9914 - val_loss: 1.9862\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9911 - val_loss: 1.9851\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9904 - val_loss: 1.9847\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9900 - val_loss: 1.9850\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9857\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9891 - val_loss: 1.9835\n",
      "Top-2 accuracy = 0.451\n",
      "11\n",
      "standardizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1698 - val_loss: 2.1409\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1187 - val_loss: 2.0927\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0772 - val_loss: 2.0608\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0480 - val_loss: 2.0320\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0277 - val_loss: 2.0186\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0182 - val_loss: 2.0127\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0131 - val_loss: 2.0067\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0097 - val_loss: 2.0042\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0086 - val_loss: 2.0028\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0072 - val_loss: 2.0015\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0058 - val_loss: 2.0000\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0046 - val_loss: 2.0005\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0041 - val_loss: 2.0028\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0049 - val_loss: 1.9997\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 1.9987\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0021 - val_loss: 1.9972\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0014 - val_loss: 1.9977\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0018 - val_loss: 1.9963\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0003 - val_loss: 1.9978\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9969\n",
      "Top-2 accuracy = 0.447\n",
      "12\n",
      "minmaxS|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_340 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1658 - val_loss: 2.1296\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0930 - val_loss: 2.0585\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0523 - val_loss: 2.0380\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0380 - val_loss: 2.0287\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0307 - val_loss: 2.0227\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0258 - val_loss: 2.0191\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0233 - val_loss: 2.0159\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0182 - val_loss: 2.0124\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0155 - val_loss: 2.0099\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0135 - val_loss: 2.0130\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0123 - val_loss: 2.0056\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0092 - val_loss: 2.0044\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0083 - val_loss: 2.0023\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0069 - val_loss: 2.0039\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0053 - val_loss: 1.9994\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0049 - val_loss: 1.9989\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0023 - val_loss: 2.0037\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0017 - val_loss: 2.0053\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0038 - val_loss: 1.9975\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0003 - val_loss: 1.9989\n",
      "Top-2 accuracy = 0.443\n",
      "13\n",
      "maxabsH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1764 - val_loss: 2.1603\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1553 - val_loss: 2.1378\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0849 - val_loss: 2.0422\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0319 - val_loss: 2.0196\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0171 - val_loss: 2.0125\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0112 - val_loss: 2.0059\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0092 - val_loss: 2.0043\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0057 - val_loss: 1.9992\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0041 - val_loss: 1.9980\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0032 - val_loss: 1.9979\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0017 - val_loss: 1.9963\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0009 - val_loss: 1.9950\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0023 - val_loss: 1.9950\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9946\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9998 - val_loss: 1.9936\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9993 - val_loss: 1.9937\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 1.9942\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9921\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9924\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9971 - val_loss: 1.9917\n",
      "Top-2 accuracy = 0.448\n",
      "14\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1826 - val_loss: 2.1710\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1638 - val_loss: 2.1476\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0983 - val_loss: 2.0539\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0403 - val_loss: 2.0236\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0234 - val_loss: 2.0136\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0154 - val_loss: 2.0081\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0119 - val_loss: 2.0058\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0102 - val_loss: 2.0057\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0086 - val_loss: 2.0045\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0076 - val_loss: 2.0022\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0076 - val_loss: 2.0014\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0060 - val_loss: 2.0013\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0062 - val_loss: 2.0005\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0046 - val_loss: 2.0050\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0046 - val_loss: 1.9996\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0041 - val_loss: 2.0067\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0039 - val_loss: 1.9996\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0037 - val_loss: 2.0063\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0031 - val_loss: 1.9994\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0035 - val_loss: 1.9998\n",
      "Top-2 accuracy = 0.447\n",
      "15\n",
      "normalizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1467 - val_loss: 2.0885\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0593 - val_loss: 2.0217\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0158 - val_loss: 2.0232\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0055 - val_loss: 1.9959\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0039 - val_loss: 2.0221\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0017 - val_loss: 2.0064\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0009 - val_loss: 1.9932\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9969 - val_loss: 1.9954\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9970 - val_loss: 1.9911\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9966 - val_loss: 1.9976\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9956 - val_loss: 1.9951\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9955 - val_loss: 2.0070\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9986 - val_loss: 1.9936\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9938 - val_loss: 1.9873\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9928 - val_loss: 1.9919\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9924 - val_loss: 1.9905\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9909 - val_loss: 1.9853\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9922 - val_loss: 1.9896\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9927 - val_loss: 1.9911\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9934 - val_loss: 1.9954\n",
      "Top-2 accuracy = 0.445\n",
      "16\n",
      "normalizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1744 - val_loss: 2.1454\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1199 - val_loss: 2.0992\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0679 - val_loss: 2.0374\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0204 - val_loss: 2.0077\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0075 - val_loss: 2.0025\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0060 - val_loss: 2.0041\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0044 - val_loss: 1.9997\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 2.0027\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0034 - val_loss: 2.0017\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0039 - val_loss: 1.9984\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0038 - val_loss: 1.9999\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0020 - val_loss: 1.9983\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0025 - val_loss: 1.9984\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0024 - val_loss: 1.9977\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0013 - val_loss: 1.9970\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9973\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0005 - val_loss: 1.9974\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9976\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0000 - val_loss: 1.9960\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 2.0007\n",
      "Top-2 accuracy = 0.442\n",
      "17\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1609 - val_loss: 2.1287\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0967 - val_loss: 2.0595\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0418 - val_loss: 2.0254\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0159 - val_loss: 2.0053\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0039 - val_loss: 1.9980\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9991 - val_loss: 1.9959\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9967 - val_loss: 1.9923\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9945 - val_loss: 1.9916\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9932 - val_loss: 1.9904\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9889\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9908 - val_loss: 1.9883\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9901 - val_loss: 1.9871\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9892 - val_loss: 1.9877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9882 - val_loss: 1.9862\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9879 - val_loss: 1.9850\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9877 - val_loss: 1.9847\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9874 - val_loss: 1.9836\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9865 - val_loss: 1.9834\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9869 - val_loss: 1.9834\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9857 - val_loss: 1.9826\n",
      "Top-2 accuracy = 0.45\n",
      "18\n",
      "standardizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1530 - val_loss: 2.1001\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0643 - val_loss: 2.0358\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0300 - val_loss: 2.0203\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0186 - val_loss: 2.0123\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0123 - val_loss: 2.0075\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0083 - val_loss: 2.0038\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0046 - val_loss: 2.0006\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0022 - val_loss: 1.9979\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9963\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9945\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9962 - val_loss: 1.9933\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9942 - val_loss: 1.9921\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9934 - val_loss: 1.9909\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9893\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9909 - val_loss: 1.9886\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9896 - val_loss: 1.9877\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9888 - val_loss: 1.9871\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9882 - val_loss: 1.9864\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9872 - val_loss: 1.9865\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9870 - val_loss: 1.9854\n",
      "Top-2 accuracy = 0.449\n",
      "19\n",
      "standardizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1655 - val_loss: 2.1414\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1178 - val_loss: 2.0875\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0709 - val_loss: 2.0525\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0424 - val_loss: 2.0300\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0273 - val_loss: 2.0184\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0197 - val_loss: 2.0135\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0153 - val_loss: 2.0102\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0109 - val_loss: 2.0054\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0079 - val_loss: 2.0025\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0057 - val_loss: 2.0003\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 1.9997\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0021 - val_loss: 1.9975\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9968\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9997 - val_loss: 1.9948\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9990 - val_loss: 1.9941\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9981 - val_loss: 1.9954\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9974 - val_loss: 1.9943\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9973 - val_loss: 1.9933\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9959 - val_loss: 1.9925\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9955 - val_loss: 1.9922\n",
      "Top-2 accuracy = 0.448\n",
      "20\n",
      "maxabsj|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1893 - val_loss: 2.1818\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1771 - val_loss: 2.1721\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1696 - val_loss: 2.1660\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1649 - val_loss: 2.1624\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1622 - val_loss: 2.1603\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1606 - val_loss: 2.1592\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1598 - val_loss: 2.1587\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1594 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "21\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1259 - val_loss: 2.0368\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0144 - val_loss: 1.9976\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9989 - val_loss: 1.9941\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9943 - val_loss: 1.9923\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9933 - val_loss: 1.9911\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9917 - val_loss: 1.9879\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9913 - val_loss: 1.9905\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9891 - val_loss: 1.9883\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9891 - val_loss: 1.9894\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9882 - val_loss: 1.9882\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9874 - val_loss: 1.9842\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9863 - val_loss: 1.9851\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9867 - val_loss: 1.9841\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9860 - val_loss: 1.9884\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9866 - val_loss: 1.9845\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9872 - val_loss: 1.9839\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9849 - val_loss: 1.9839\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9848 - val_loss: 1.9839\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9853 - val_loss: 1.9829\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9845 - val_loss: 1.9823\n",
      "Top-2 accuracy = 0.447\n",
      "22\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1894 - val_loss: 2.1819\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1771 - val_loss: 2.1721\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1695 - val_loss: 2.1661\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1648 - val_loss: 2.1624\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1621 - val_loss: 2.1603\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1606 - val_loss: 2.1592\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1598 - val_loss: 2.1587\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1594 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "23\n",
      "standardizeV|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_393 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1607 - val_loss: 2.1376\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1188 - val_loss: 2.0975\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0867 - val_loss: 2.0720\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0658 - val_loss: 2.0548\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0503 - val_loss: 2.0409\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0386 - val_loss: 2.0308\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0302 - val_loss: 2.0233\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0242 - val_loss: 2.0179\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0193 - val_loss: 2.0137\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0157 - val_loss: 2.0106\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0127 - val_loss: 2.0080\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0102 - val_loss: 2.0058\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0081 - val_loss: 2.0046\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0064 - val_loss: 2.0028\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0047 - val_loss: 2.0015\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0032 - val_loss: 2.0001\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0019 - val_loss: 1.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0008 - val_loss: 1.9981\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9999 - val_loss: 1.9971\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9990 - val_loss: 1.9959\n",
      "Top-2 accuracy = 0.447\n",
      "24\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1893 - val_loss: 2.1817\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1770 - val_loss: 2.1720\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1693 - val_loss: 2.1659\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1648 - val_loss: 2.1624\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1621 - val_loss: 2.1604\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1606 - val_loss: 2.1593\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1598 - val_loss: 2.1587\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1594 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "25\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1766 - val_loss: 2.1607\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1528 - val_loss: 2.1340\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1081 - val_loss: 2.0717\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0539 - val_loss: 2.0356\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0346 - val_loss: 2.0241\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0260 - val_loss: 2.0172\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0207 - val_loss: 2.0128\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0159 - val_loss: 2.0091\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0126 - val_loss: 2.0068\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0105 - val_loss: 2.0049\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0084 - val_loss: 2.0040\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0072 - val_loss: 2.0018\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0059 - val_loss: 2.0013\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0047 - val_loss: 2.0002\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0041 - val_loss: 1.9995\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0031 - val_loss: 1.9995\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0024 - val_loss: 1.9987\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0019 - val_loss: 1.9981\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0013 - val_loss: 1.9978\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0007 - val_loss: 1.9972\n",
      "Top-2 accuracy = 0.445\n",
      "26\n",
      "standardizeP|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_407 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1892 - val_loss: 2.1365\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1091 - val_loss: 2.0740\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0615 - val_loss: 2.0418\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0372 - val_loss: 2.0254\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0259 - val_loss: 2.0176\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0193 - val_loss: 2.0125\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0144 - val_loss: 2.0085\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0105 - val_loss: 2.0052\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0077 - val_loss: 2.0029\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0053 - val_loss: 2.0006\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0029 - val_loss: 1.9986\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0009 - val_loss: 1.9976\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9996 - val_loss: 1.9961\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9977 - val_loss: 1.9946\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9963 - val_loss: 1.9936\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9950 - val_loss: 1.9930\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9938 - val_loss: 1.9915\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9924 - val_loss: 1.9908\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9914 - val_loss: 1.9896\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9905 - val_loss: 1.9888\n",
      "Top-2 accuracy = 0.446\n",
      "27\n",
      "normalizeM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1781 - val_loss: 2.1405\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0919 - val_loss: 2.0578\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0510 - val_loss: 2.0359\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0325 - val_loss: 2.0209\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0223 - val_loss: 2.0135\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0151 - val_loss: 2.0077\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0112 - val_loss: 2.0044\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0087 - val_loss: 2.0066\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0079 - val_loss: 2.0023\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0064 - val_loss: 2.0031\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0057 - val_loss: 2.0002\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 1.9988\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0037 - val_loss: 2.0047\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0037 - val_loss: 1.9990\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0024 - val_loss: 1.9983\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0023 - val_loss: 1.9990\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0018 - val_loss: 2.0018\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 1.9962\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 1.9970\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9998 - val_loss: 1.9961\n",
      "Top-2 accuracy = 0.446\n",
      "28\n",
      "maxabsr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1734 - val_loss: 2.1383\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1044 - val_loss: 2.0745\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0621 - val_loss: 2.0390\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0291 - val_loss: 2.0147\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0135 - val_loss: 2.0054\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0074 - val_loss: 2.0001\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0034 - val_loss: 1.9979\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9968\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9994 - val_loss: 1.9943\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9976 - val_loss: 1.9933\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9971 - val_loss: 1.9925\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9963 - val_loss: 1.9919\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9953 - val_loss: 1.9912\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9950 - val_loss: 1.9912\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9905\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9941 - val_loss: 1.9902\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9931 - val_loss: 1.9898\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9928 - val_loss: 1.9893\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9929 - val_loss: 1.9892\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9924 - val_loss: 1.9884\n",
      "Top-2 accuracy = 0.448\n",
      "29\n",
      "normalizeN|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_420 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1595 - val_loss: 2.1260\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0889 - val_loss: 2.0507\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0384 - val_loss: 2.0197\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0206 - val_loss: 2.0107\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0132 - val_loss: 2.0058\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0083 - val_loss: 2.0017\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0043 - val_loss: 1.9999\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0021 - val_loss: 1.9976\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0004 - val_loss: 1.9959\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9977 - val_loss: 1.9943\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9964 - val_loss: 1.9927\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9946 - val_loss: 1.9910\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9927 - val_loss: 1.9897\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9916 - val_loss: 1.9898\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9904 - val_loss: 1.9871\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9891 - val_loss: 1.9873\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9879 - val_loss: 1.9858\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9867 - val_loss: 1.9853\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9866 - val_loss: 1.9846\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9855 - val_loss: 1.9836\n",
      "Top-2 accuracy = 0.452\n",
      "0\n",
      "minmaxN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1838 - val_loss: 2.1674\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1526 - val_loss: 2.1188\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0824 - val_loss: 2.0459\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0333 - val_loss: 2.0181\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0184 - val_loss: 2.0116\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0145 - val_loss: 2.0118\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0148 - val_loss: 2.0071\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0124 - val_loss: 2.0363\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0136 - val_loss: 2.0089\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0081 - val_loss: 2.0039\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0073 - val_loss: 2.0203\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0086 - val_loss: 2.0102\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0076 - val_loss: 2.0058\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0057 - val_loss: 2.0016\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0057 - val_loss: 2.0028\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0064 - val_loss: 2.0016\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0049 - val_loss: 2.0015\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0055 - val_loss: 2.0016\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0049 - val_loss: 2.0009\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0041 - val_loss: 2.0100\n",
      "Top-2 accuracy = 0.437\n",
      "1\n",
      "minmaxy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1821 - val_loss: 2.1696\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1404 - val_loss: 2.1000\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0651 - val_loss: 2.0376\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0289 - val_loss: 2.0175\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0164 - val_loss: 2.0125\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0126 - val_loss: 2.0081\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0089 - val_loss: 2.0040\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0069 - val_loss: 2.0029\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0053 - val_loss: 2.0013\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 2.0013\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0039 - val_loss: 1.9997\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0026 - val_loss: 2.0022\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0013 - val_loss: 1.9972\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0003 - val_loss: 1.9995\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0027 - val_loss: 1.9952\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9990 - val_loss: 1.9948\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9985 - val_loss: 1.9938\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9934\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9931\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9969 - val_loss: 1.9928\n",
      "Top-2 accuracy = 0.446\n",
      "2\n",
      "maxabsY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1570 - val_loss: 2.0726\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0341 - val_loss: 2.0095\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0119 - val_loss: 2.0018\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0061 - val_loss: 1.9994\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0037 - val_loss: 1.9990\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 1.9957\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0004 - val_loss: 1.9929\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0002 - val_loss: 1.9921\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9982 - val_loss: 1.9921\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9994 - val_loss: 1.9918\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9920\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9970 - val_loss: 1.9921\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9962 - val_loss: 1.9930\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9968 - val_loss: 1.9899\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9932\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9965 - val_loss: 1.9905\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9953 - val_loss: 1.9895\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9942 - val_loss: 1.9906\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9942 - val_loss: 1.9899\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9945 - val_loss: 1.9892\n",
      "Top-2 accuracy = 0.448\n",
      "3\n",
      "maxabsE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1717 - val_loss: 2.1249\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0977 - val_loss: 2.0770\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0713 - val_loss: 2.0573\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0522 - val_loss: 2.0377\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0353 - val_loss: 2.0244\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0245 - val_loss: 2.0186\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0184 - val_loss: 2.0111\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0135 - val_loss: 2.0069\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0114 - val_loss: 2.0047\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0079 - val_loss: 2.0020\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0059 - val_loss: 2.0011\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0046 - val_loss: 1.9994\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0040 - val_loss: 1.9980\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0028 - val_loss: 1.9969\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 1.9998\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9949\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9993 - val_loss: 1.9948\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9991 - val_loss: 1.9961\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9983 - val_loss: 1.9971\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9984 - val_loss: 1.9966\n",
      "Top-2 accuracy = 0.444\n",
      "4\n",
      "minmaxK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1496 - val_loss: 2.0947\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0779 - val_loss: 2.0508\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0377 - val_loss: 2.0251\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0170 - val_loss: 2.0109\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0109 - val_loss: 2.0059\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0072 - val_loss: 2.0022\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0059 - val_loss: 2.0041\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 2.0022\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0058 - val_loss: 2.0008\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0031 - val_loss: 1.9978\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0004 - val_loss: 2.0014\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9993\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9980\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9996 - val_loss: 1.9945\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9982 - val_loss: 1.9971\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9960\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9948\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9967 - val_loss: 1.9958\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9971 - val_loss: 1.9937\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9961 - val_loss: 2.0013\n",
      "Top-2 accuracy = 0.445\n",
      "5\n",
      "maxabsg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1646 - val_loss: 2.1267\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1035 - val_loss: 2.0724\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0612 - val_loss: 2.0463\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0411 - val_loss: 2.0308\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0310 - val_loss: 2.0272\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0244 - val_loss: 2.0220\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0219 - val_loss: 2.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0188 - val_loss: 2.0155\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0171 - val_loss: 2.0149\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0171 - val_loss: 2.0119\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0155 - val_loss: 2.0119\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0135 - val_loss: 2.0098\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0129 - val_loss: 2.0097\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0140 - val_loss: 2.0079\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0121 - val_loss: 2.0076\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0117 - val_loss: 2.0098\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0109 - val_loss: 2.0064\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0124 - val_loss: 2.0154\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 2.0086\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0116 - val_loss: 2.0119\n",
      "Top-2 accuracy = 0.44\n",
      "6\n",
      "minmaxQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1861 - val_loss: 2.1735\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1671 - val_loss: 2.1604\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1601 - val_loss: 2.1557\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1550 - val_loss: 2.1508\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1490 - val_loss: 2.1403\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1321 - val_loss: 2.1126\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1006 - val_loss: 2.0850\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0814 - val_loss: 2.0736\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0724 - val_loss: 2.0657\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0615 - val_loss: 2.0486\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0433 - val_loss: 2.0307\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0301 - val_loss: 2.0200\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0222 - val_loss: 2.0264\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0193 - val_loss: 2.0126\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0145 - val_loss: 2.0119\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0123 - val_loss: 2.0073\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0106 - val_loss: 2.0057\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0110 - val_loss: 2.0066\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0089 - val_loss: 2.0049\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0086 - val_loss: 2.0066\n",
      "Top-2 accuracy = 0.444\n",
      "7\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1743 - val_loss: 2.1407\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1155 - val_loss: 2.0896\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0727 - val_loss: 2.0555\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0426 - val_loss: 2.0570\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0347 - val_loss: 2.0269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0264 - val_loss: 2.0242\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0211 - val_loss: 2.0270\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0193 - val_loss: 2.0303\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0205 - val_loss: 2.0160\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0162 - val_loss: 2.0160\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0158 - val_loss: 2.0160\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0155 - val_loss: 2.0112\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0116 - val_loss: 2.0085\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0119 - val_loss: 2.0092\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0111 - val_loss: 2.0095\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0098 - val_loss: 2.0208\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0104 - val_loss: 2.0052\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0095 - val_loss: 2.0067\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0076 - val_loss: 2.0187\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0073 - val_loss: 2.0111\n",
      "Top-2 accuracy = 0.442\n",
      "8\n",
      "standardizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1562 - val_loss: 2.0962\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0709 - val_loss: 2.0397\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0319 - val_loss: 2.0142\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0162 - val_loss: 2.0032\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0082 - val_loss: 2.0013\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0041 - val_loss: 1.9960\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0009 - val_loss: 1.9949\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9982 - val_loss: 1.9973\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9978 - val_loss: 1.9943\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9953 - val_loss: 1.9919\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9948 - val_loss: 1.9907\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9910\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9931 - val_loss: 1.9912\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9926 - val_loss: 1.9893\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9921 - val_loss: 1.9889\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9920 - val_loss: 1.9939\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9920 - val_loss: 1.9881\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9909 - val_loss: 1.9890\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9898 - val_loss: 1.9892\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9901 - val_loss: 1.9916\n",
      "Top-2 accuracy = 0.447\n",
      "9\n",
      "robustu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1432 - val_loss: 2.0664\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0275 - val_loss: 2.0091\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0019 - val_loss: 1.9984\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9974 - val_loss: 1.9953\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9949 - val_loss: 1.9923\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9929 - val_loss: 1.9908\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9919 - val_loss: 1.9914\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9908 - val_loss: 1.9905\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9910 - val_loss: 1.9885\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9905 - val_loss: 1.9884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9888 - val_loss: 1.9941\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9898 - val_loss: 1.9880\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9881 - val_loss: 1.9934\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9920 - val_loss: 1.9883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9887 - val_loss: 1.9880\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9878 - val_loss: 1.9870\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9881 - val_loss: 1.9875\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9871 - val_loss: 1.9878\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9868 - val_loss: 1.9874\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9865 - val_loss: 1.9890\n",
      "Top-2 accuracy = 0.449\n",
      "10\n",
      "robustj|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_472 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1734 - val_loss: 2.1454\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1065 - val_loss: 2.0768\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0574 - val_loss: 2.0421\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0357 - val_loss: 2.0272\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0257 - val_loss: 2.0200\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0195 - val_loss: 2.0134\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0154 - val_loss: 2.0102\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0124 - val_loss: 2.0082\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0101 - val_loss: 2.0049\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0080 - val_loss: 2.0030\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0068 - val_loss: 2.0014\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0053 - val_loss: 2.0006\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0040 - val_loss: 1.9993\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0034 - val_loss: 1.9980\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0021 - val_loss: 1.9971\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0015 - val_loss: 1.9972\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0012 - val_loss: 1.9954\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0000 - val_loss: 1.9951\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9992 - val_loss: 1.9944\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9983 - val_loss: 1.9938\n",
      "Top-2 accuracy = 0.447\n",
      "11\n",
      "standardizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1399 - val_loss: 2.0786\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0510 - val_loss: 2.0290\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0249 - val_loss: 2.0151\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0150 - val_loss: 2.0096\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0095 - val_loss: 2.0049\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0069 - val_loss: 2.0017\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0023 - val_loss: 1.9990\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 1.9974\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9997 - val_loss: 1.9961\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9996\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9983 - val_loss: 1.9953\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9946\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9970 - val_loss: 1.9940\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9926\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9953 - val_loss: 1.9927\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9955 - val_loss: 1.9919\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9946 - val_loss: 1.9923\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9939 - val_loss: 1.9911\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9905\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9932 - val_loss: 1.9927\n",
      "Top-2 accuracy = 0.446\n",
      "12\n",
      "maxabso|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1667 - val_loss: 2.1226\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0867 - val_loss: 2.0484\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0363 - val_loss: 2.0182\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0155 - val_loss: 2.0049\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0069 - val_loss: 1.9997\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0036 - val_loss: 1.9968\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9948\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9983 - val_loss: 1.9978\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9973 - val_loss: 1.9930\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9961 - val_loss: 1.9914\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9955 - val_loss: 1.9917\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9953 - val_loss: 1.9904\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9925\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9943 - val_loss: 1.9897\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9935 - val_loss: 1.9888\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9929 - val_loss: 1.9890\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9929 - val_loss: 1.9905\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9931 - val_loss: 1.9897\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9920 - val_loss: 1.9873\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9917 - val_loss: 1.9895\n",
      "Top-2 accuracy = 0.446\n",
      "13\n",
      "minmaxw|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_489 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1804 - val_loss: 2.1417\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1132 - val_loss: 2.0812\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0671 - val_loss: 2.0485\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0445 - val_loss: 2.0324\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0345 - val_loss: 2.0251\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0284 - val_loss: 2.0208\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0243 - val_loss: 2.0169\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0206 - val_loss: 2.0135\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0181 - val_loss: 2.0107\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0155 - val_loss: 2.0084\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0131 - val_loss: 2.0049\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0101 - val_loss: 2.0039\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0083 - val_loss: 2.0013\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0067 - val_loss: 1.9999\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0048 - val_loss: 1.9979\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0036 - val_loss: 1.9968\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0026 - val_loss: 1.9965\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0014 - val_loss: 1.9952\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0011 - val_loss: 1.9940\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0008 - val_loss: 1.9945\n",
      "Top-2 accuracy = 0.445\n",
      "14\n",
      "normalizea|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1812 - val_loss: 2.1497\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0928 - val_loss: 2.0399\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0313 - val_loss: 2.0193\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0189 - val_loss: 2.0109\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0129 - val_loss: 2.0070\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0104 - val_loss: 2.0121\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0092 - val_loss: 2.0052\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0080 - val_loss: 2.0031\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 2.0007\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0030 - val_loss: 1.9998\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0027 - val_loss: 1.9989\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0014 - val_loss: 2.0000\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0009 - val_loss: 1.9970\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9991\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0007 - val_loss: 1.9956\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9992 - val_loss: 1.9957\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9992 - val_loss: 1.9947\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9981 - val_loss: 1.9961\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9981 - val_loss: 1.9936\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9981 - val_loss: 1.9943\n",
      "Top-2 accuracy = 0.445\n",
      "15\n",
      "maxabsp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1614 - val_loss: 2.0958\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0740 - val_loss: 2.0527\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0491 - val_loss: 2.0369\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0346 - val_loss: 2.0236\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0249 - val_loss: 2.0164\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0192 - val_loss: 2.0124\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0174 - val_loss: 2.0122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0148 - val_loss: 2.0086\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0120 - val_loss: 2.0101\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0130 - val_loss: 2.0054\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0096 - val_loss: 2.0047\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0084 - val_loss: 2.0040\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0077 - val_loss: 2.0049\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0073 - val_loss: 2.0043\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0060 - val_loss: 2.0025\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0056 - val_loss: 2.0005\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0052 - val_loss: 2.0018\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0042 - val_loss: 2.0007\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0032 - val_loss: 1.9995\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0029 - val_loss: 1.9986\n",
      "Top-2 accuracy = 0.446\n",
      "16\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1340 - val_loss: 2.0591\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0347 - val_loss: 2.0134\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0129 - val_loss: 2.0047\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0061 - val_loss: 1.9999\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 1.9989\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9951\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9976 - val_loss: 1.9939\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9961 - val_loss: 1.9930\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9951 - val_loss: 1.9925\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9942 - val_loss: 1.9905\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9929 - val_loss: 1.9888\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9922 - val_loss: 1.9883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9908 - val_loss: 1.9884\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9898 - val_loss: 1.9879\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9895 - val_loss: 1.9862\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9883 - val_loss: 1.9856\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9872 - val_loss: 1.9863\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9872 - val_loss: 1.9855\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9863 - val_loss: 1.9826\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9857 - val_loss: 1.9834\n",
      "Top-2 accuracy = 0.45\n",
      "17\n",
      "robustX|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_507 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1242 - val_loss: 2.0762\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0542 - val_loss: 2.0316\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0276 - val_loss: 2.0172\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0185 - val_loss: 2.0105\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0133 - val_loss: 2.0062\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0096 - val_loss: 2.0031\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0064 - val_loss: 1.9999\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0041 - val_loss: 1.9984\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0018 - val_loss: 1.9959\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0000 - val_loss: 1.9943\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9984 - val_loss: 1.9926\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9967 - val_loss: 1.9918\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9954 - val_loss: 1.9902\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9946 - val_loss: 1.9895\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9934 - val_loss: 1.9880\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9926 - val_loss: 1.9876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9917 - val_loss: 1.9869\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9908 - val_loss: 1.9865\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9903 - val_loss: 1.9857\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9896 - val_loss: 1.9849\n",
      "Top-2 accuracy = 0.45\n",
      "18\n",
      "minmaxA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1491 - val_loss: 2.0764\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0414 - val_loss: 2.0171\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0178 - val_loss: 2.0079\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0097 - val_loss: 2.0088\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0029 - val_loss: 1.9989\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0008 - val_loss: 1.9993\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0000 - val_loss: 1.9950\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9979 - val_loss: 1.9938\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9983 - val_loss: 1.9939\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9964 - val_loss: 1.9961\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9977 - val_loss: 1.9944\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9945 - val_loss: 1.9909\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9982 - val_loss: 1.9929\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9960 - val_loss: 1.9896\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9933 - val_loss: 1.9891\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9917 - val_loss: 1.9898\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9922 - val_loss: 1.9871\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9929 - val_loss: 1.9920\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9929 - val_loss: 1.9912\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9932 - val_loss: 1.9905\n",
      "Top-2 accuracy = 0.447\n",
      "19\n",
      "maxabsO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1648 - val_loss: 2.1309\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1050 - val_loss: 2.0833\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0724 - val_loss: 2.0476\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0353 - val_loss: 2.0182\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0186 - val_loss: 2.0128\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0151 - val_loss: 2.0102\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0129 - val_loss: 2.0067\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0113 - val_loss: 2.0065\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0121 - val_loss: 2.0087\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0099 - val_loss: 2.0051\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0098 - val_loss: 2.0044\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0090 - val_loss: 2.0035\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0080 - val_loss: 2.0054\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0084 - val_loss: 2.0022\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0067 - val_loss: 2.0013\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0058 - val_loss: 2.0012\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 2.0009\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0057 - val_loss: 2.0015\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0044 - val_loss: 2.0009\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0041 - val_loss: 1.9989\n",
      "Top-2 accuracy = 0.443\n",
      "20\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1425 - val_loss: 2.0605\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0339 - val_loss: 2.0071\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0035 - val_loss: 2.0074\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9994 - val_loss: 1.9956\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9946 - val_loss: 1.9901\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9935 - val_loss: 1.9951\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9924 - val_loss: 1.9884\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9903 - val_loss: 1.9887\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9903 - val_loss: 1.9897\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9903 - val_loss: 1.9864\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9888 - val_loss: 2.0017\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9891 - val_loss: 1.9875\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9871 - val_loss: 1.9862\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9859 - val_loss: 1.9856\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9866 - val_loss: 1.9871\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9868 - val_loss: 1.9893\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9865 - val_loss: 1.9870\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9860 - val_loss: 1.9864\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9874 - val_loss: 1.9930\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9865 - val_loss: 1.9856\n",
      "Top-2 accuracy = 0.449\n",
      "21\n",
      "robustn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1892 - val_loss: 2.1736\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1621 - val_loss: 2.1454\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1297 - val_loss: 2.1067\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0925 - val_loss: 2.0710\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0635 - val_loss: 2.0465\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0437 - val_loss: 2.0311\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0318 - val_loss: 2.0218\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0246 - val_loss: 2.0167\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0200 - val_loss: 2.0133\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0172 - val_loss: 2.0113\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0150 - val_loss: 2.0104\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0136 - val_loss: 2.0087\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0123 - val_loss: 2.0074\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0112 - val_loss: 2.0077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0105 - val_loss: 2.0063\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0098 - val_loss: 2.0056\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0094 - val_loss: 2.0050\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0088 - val_loss: 2.0044\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0085 - val_loss: 2.0042\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0080 - val_loss: 2.0039\n",
      "Top-2 accuracy = 0.445\n",
      "22\n",
      "maxabsZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1866 - val_loss: 2.1767\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1716 - val_loss: 2.1655\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1640 - val_loss: 2.1608\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1609 - val_loss: 2.1590\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1597 - val_loss: 2.1582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1583\n",
      "Top-2 accuracy = 0.324\n",
      "23\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1883 - val_loss: 2.1787\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1737 - val_loss: 2.1670\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1542 - val_loss: 2.1298\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1058 - val_loss: 2.0819\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0708 - val_loss: 2.0598\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0539 - val_loss: 2.0472\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0450 - val_loss: 2.0401\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0387 - val_loss: 2.0327\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0318 - val_loss: 2.0273\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0287 - val_loss: 2.0252\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0267 - val_loss: 2.0237\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0255 - val_loss: 2.0223\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0240 - val_loss: 2.0215\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0228 - val_loss: 2.0201\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0212 - val_loss: 2.0190\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0196 - val_loss: 2.0173\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0183 - val_loss: 2.0157\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0172 - val_loss: 2.0141\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0164 - val_loss: 2.0131\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0154 - val_loss: 2.0121\n",
      "Top-2 accuracy = 0.442\n",
      "24\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_540 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1835 - val_loss: 2.1704\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1547 - val_loss: 2.1336\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1102 - val_loss: 2.0794\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0677 - val_loss: 2.0451\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0433 - val_loss: 2.0313\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0323 - val_loss: 2.0242\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0260 - val_loss: 2.0199\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0219 - val_loss: 2.0170\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0195 - val_loss: 2.0149\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0176 - val_loss: 2.0128\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0160 - val_loss: 2.0115\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0143 - val_loss: 2.0101\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0132 - val_loss: 2.0094\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0117 - val_loss: 2.0082\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0106 - val_loss: 2.0073\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0097 - val_loss: 2.0058\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0088 - val_loss: 2.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0076 - val_loss: 2.0046\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0068 - val_loss: 2.0039\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0063 - val_loss: 2.0027\n",
      "Top-2 accuracy = 0.443\n",
      "25\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_546 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1621 - val_loss: 2.0931\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0650 - val_loss: 2.0359\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0323 - val_loss: 2.0203\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0219 - val_loss: 2.0137\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0173 - val_loss: 2.0095\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0128 - val_loss: 2.0066\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0111 - val_loss: 2.0040\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0082 - val_loss: 2.0038\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0069 - val_loss: 2.0024\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0053 - val_loss: 1.9981\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0038 - val_loss: 1.9979\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0037 - val_loss: 1.9971\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0022 - val_loss: 2.0002\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9953\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0001 - val_loss: 1.9949\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9992 - val_loss: 1.9928\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9980 - val_loss: 1.9912\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9970 - val_loss: 1.9904\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9896\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9950 - val_loss: 1.9894\n",
      "Top-2 accuracy = 0.449\n",
      "26\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1246 - val_loss: 2.0207\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9998 - val_loss: 1.9904\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9902 - val_loss: 1.9926\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9886 - val_loss: 1.9857\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9874 - val_loss: 1.9925\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9872 - val_loss: 1.9938\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9859 - val_loss: 1.9910\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9855 - val_loss: 1.9915\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9861 - val_loss: 1.9909\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9855 - val_loss: 1.9934\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9844 - val_loss: 1.9925\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9853 - val_loss: 1.9883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9849 - val_loss: 1.9858\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9835 - val_loss: 1.9880\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9831 - val_loss: 1.9889\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9840 - val_loss: 1.9889\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9818 - val_loss: 1.9927\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9823 - val_loss: 1.9873\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9816 - val_loss: 1.9861\n",
      "Top-2 accuracy = 0.45\n",
      "27\n",
      "minmaxh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1800 - val_loss: 2.1664\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1638 - val_loss: 2.1592\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1599 - val_loss: 2.1582\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1557 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1593 - val_loss: 2.1581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1584\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "28\n",
      "minmaxm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1325 - val_loss: 2.0672\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.0381 - val_loss: 2.0086\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0092 - val_loss: 1.9982\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0033 - val_loss: 1.9969\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9983 - val_loss: 2.0182\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0044 - val_loss: 1.9918\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9946 - val_loss: 1.9913\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9937 - val_loss: 2.0005\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9975 - val_loss: 1.9938\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9917 - val_loss: 1.9888\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9930 - val_loss: 1.9979\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9948 - val_loss: 2.0010\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9916 - val_loss: 1.9902\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9913 - val_loss: 1.9927\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9923 - val_loss: 2.0062\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9910 - val_loss: 1.9876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9902 - val_loss: 1.9896\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9907 - val_loss: 1.9866\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9915 - val_loss: 1.9919\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9925 - val_loss: 1.9855\n",
      "Top-2 accuracy = 0.447\n",
      "29\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1701 - val_loss: 2.1342\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0878 - val_loss: 2.0480\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0394 - val_loss: 2.0256\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0260 - val_loss: 2.0183\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0205 - val_loss: 2.0152\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0173 - val_loss: 2.0158\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0149 - val_loss: 2.0114\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0140 - val_loss: 2.0069\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0114 - val_loss: 2.0063\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0103 - val_loss: 2.0059\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0091 - val_loss: 2.0037\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0090 - val_loss: 2.0028\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0071 - val_loss: 2.0023\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0073 - val_loss: 2.0040\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0075 - val_loss: 2.0009\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0046 - val_loss: 2.0000\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0043 - val_loss: 1.9994\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0037 - val_loss: 1.9987\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0032 - val_loss: 1.9979\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0028 - val_loss: 1.9981\n",
      "Top-2 accuracy = 0.444\n",
      "0\n",
      "minmaxR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1503 - val_loss: 2.0877\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0500 - val_loss: 2.0235\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0208 - val_loss: 2.0094\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0115 - val_loss: 2.0060\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0085 - val_loss: 2.0029\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0065 - val_loss: 2.0016\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0060 - val_loss: 1.9998\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 1.9991\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0049 - val_loss: 2.0015\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0048 - val_loss: 2.0038\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0058 - val_loss: 1.9983\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0032 - val_loss: 1.9973\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0032 - val_loss: 1.9984\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0020 - val_loss: 1.9972\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0024 - val_loss: 1.9984\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0025 - val_loss: 1.9982\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0018 - val_loss: 1.9994\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 1.9970\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0015 - val_loss: 2.0007\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0027 - val_loss: 1.9961\n",
      "Top-2 accuracy = 0.445\n",
      "1\n",
      "standardizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1859 - val_loss: 2.1744\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1635 - val_loss: 2.1496\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1272 - val_loss: 2.0920\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0739 - val_loss: 2.0517\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0454 - val_loss: 2.0338\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0307 - val_loss: 2.0223\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0222 - val_loss: 2.0174\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0173 - val_loss: 2.0117\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0143 - val_loss: 2.0086\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 2.0069\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0101 - val_loss: 2.0063\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0083 - val_loss: 2.0044\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0072 - val_loss: 2.0030\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0063 - val_loss: 2.0019\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0053 - val_loss: 2.0020\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0047 - val_loss: 2.0013\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0043 - val_loss: 2.0000\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0031 - val_loss: 1.9997\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0027 - val_loss: 1.9996\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0020 - val_loss: 1.9991\n",
      "Top-2 accuracy = 0.448\n",
      "2\n",
      "normalizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1535 - val_loss: 2.0948\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0643 - val_loss: 2.0288\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0211 - val_loss: 2.0070\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0097 - val_loss: 2.0035\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 1.9994\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0021 - val_loss: 1.9980\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0001 - val_loss: 1.9968\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9985 - val_loss: 1.9955\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9949\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9975 - val_loss: 1.9952\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9931\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9953 - val_loss: 1.9921\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9946 - val_loss: 1.9928\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9945 - val_loss: 1.9914\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9910\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9928 - val_loss: 1.9908\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9922 - val_loss: 1.9922\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9928 - val_loss: 1.9902\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9923 - val_loss: 1.9893\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9912 - val_loss: 1.9886\n",
      "Top-2 accuracy = 0.447\n",
      "3\n",
      "minmaxL|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1848 - val_loss: 2.1672\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1498 - val_loss: 2.1307\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1025 - val_loss: 2.0723\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0523 - val_loss: 2.0291\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0230 - val_loss: 2.0118\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0154 - val_loss: 2.0085\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0115 - val_loss: 2.0023\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0065 - val_loss: 1.9990\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0039 - val_loss: 2.0003\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0041 - val_loss: 1.9977\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0019 - val_loss: 1.9982\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0001 - val_loss: 2.0047\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0047 - val_loss: 1.9947\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0010 - val_loss: 1.9963\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 1.9955\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9996 - val_loss: 2.0106\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0019 - val_loss: 1.9961\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9987 - val_loss: 1.9942\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9973 - val_loss: 1.9930\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9976 - val_loss: 1.9938\n",
      "Top-2 accuracy = 0.447\n",
      "4\n",
      "standardizeG|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_597 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1688 - val_loss: 2.1304\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1198 - val_loss: 2.0986\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0966 - val_loss: 2.0809\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0762 - val_loss: 2.0595\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0597 - val_loss: 2.0458\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0489 - val_loss: 2.0365\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0415 - val_loss: 2.0308\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0364 - val_loss: 2.0254\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0322 - val_loss: 2.0221\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0289 - val_loss: 2.0181\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0259 - val_loss: 2.0166\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0239 - val_loss: 2.0131\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0209 - val_loss: 2.0113\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0187 - val_loss: 2.0089\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0168 - val_loss: 2.0075\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0148 - val_loss: 2.0066\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0133 - val_loss: 2.0048\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0115 - val_loss: 2.0028\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0099 - val_loss: 2.0019\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0087 - val_loss: 2.0006\n",
      "Top-2 accuracy = 0.445\n",
      "5\n",
      "standardizer|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1749 - val_loss: 2.1463\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1234 - val_loss: 2.1050\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0913 - val_loss: 2.0787\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0655 - val_loss: 2.0532\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0434 - val_loss: 2.0332\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0273 - val_loss: 2.0204\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0181 - val_loss: 2.0122\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0140 - val_loss: 2.0106\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0104 - val_loss: 2.0071\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0090 - val_loss: 2.0060\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0069 - val_loss: 2.0039\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0063 - val_loss: 2.0033\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0056 - val_loss: 2.0036\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0048 - val_loss: 2.0030\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0041 - val_loss: 2.0049\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0048 - val_loss: 2.0017\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0036 - val_loss: 2.0022\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0028 - val_loss: 2.0009\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0029 - val_loss: 1.9994\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0014 - val_loss: 2.0032\n",
      "Top-2 accuracy = 0.445\n",
      "6\n",
      "minmaxU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1878 - val_loss: 2.1764\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1659 - val_loss: 2.1498\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1355 - val_loss: 2.1218\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.1002\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0912 - val_loss: 2.0838\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0758 - val_loss: 2.0705\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0628 - val_loss: 2.0567\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0534 - val_loss: 2.0481\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0464 - val_loss: 2.0419\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0416 - val_loss: 2.0368\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0370 - val_loss: 2.0328\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0337 - val_loss: 2.0303\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0313 - val_loss: 2.0270\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0294 - val_loss: 2.0248\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0264 - val_loss: 2.0227\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0251 - val_loss: 2.0222\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0243 - val_loss: 2.0197\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0227 - val_loss: 2.0186\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0216 - val_loss: 2.0207\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0213 - val_loss: 2.0169\n",
      "Top-2 accuracy = 0.442\n",
      "7\n",
      "normalizeo|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1887 - val_loss: 2.1786\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1719 - val_loss: 2.1663\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1631 - val_loss: 2.1611\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1570 - val_loss: 2.1390\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0816 - val_loss: 2.0269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0249 - val_loss: 2.0162\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0091 - val_loss: 2.0038\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0029 - val_loss: 1.9966\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9991 - val_loss: 1.9965\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9992 - val_loss: 1.9902\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9957 - val_loss: 1.9903\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9950 - val_loss: 1.9903\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9943 - val_loss: 1.9893\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9894\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9952 - val_loss: 1.9899\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9946 - val_loss: 1.9902\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9935 - val_loss: 1.9892\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9937 - val_loss: 1.9891\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9928 - val_loss: 1.9888\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9931 - val_loss: 1.9891\n",
      "Top-2 accuracy = 0.448\n",
      "8\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1718 - val_loss: 2.1498\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1350 - val_loss: 2.1201\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1081 - val_loss: 2.0969\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0871 - val_loss: 2.0772\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0691 - val_loss: 2.0660\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0558 - val_loss: 2.0501\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0466 - val_loss: 2.0409\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0389 - val_loss: 2.0355\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0331 - val_loss: 2.0290\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0282 - val_loss: 2.0238\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0250 - val_loss: 2.0228\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0227 - val_loss: 2.0174\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0187 - val_loss: 2.0209\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0185 - val_loss: 2.0133\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0141 - val_loss: 2.0097\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0125 - val_loss: 2.0078\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0111 - val_loss: 2.0062\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0096 - val_loss: 2.0058\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0089 - val_loss: 2.0035\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0072 - val_loss: 2.0082\n",
      "Top-2 accuracy = 0.444\n",
      "9\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1581 - val_loss: 2.0726\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0446 - val_loss: 2.0272\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0226 - val_loss: 2.0183\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0159 - val_loss: 2.0082\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0121 - val_loss: 2.0037\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0089 - val_loss: 2.0047\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0076 - val_loss: 2.0198\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0054 - val_loss: 2.0032\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0045 - val_loss: 1.9971\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0016 - val_loss: 1.9965\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0011 - val_loss: 1.9966\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0012 - val_loss: 1.9934\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9999 - val_loss: 1.9987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9991 - val_loss: 2.0060\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0015 - val_loss: 1.9934\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9965 - val_loss: 1.9911\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9971 - val_loss: 1.9917\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9966 - val_loss: 2.0063\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9978 - val_loss: 1.9914\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9965 - val_loss: 1.9955\n",
      "Top-2 accuracy = 0.447\n",
      "10\n",
      "standardizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1475 - val_loss: 2.0693\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0472 - val_loss: 2.0225\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0152 - val_loss: 2.0049\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0038 - val_loss: 1.9949\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9998 - val_loss: 1.9930\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9970 - val_loss: 1.9916\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9962 - val_loss: 1.9888\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9943 - val_loss: 1.9879\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9935 - val_loss: 1.9870\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9922 - val_loss: 1.9863\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9913 - val_loss: 1.9867\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9905 - val_loss: 1.9841\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9899 - val_loss: 1.9846\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9876 - val_loss: 1.9819\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9870 - val_loss: 1.9827\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9864 - val_loss: 1.9785\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9852 - val_loss: 1.9789\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9842 - val_loss: 1.9774\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9836 - val_loss: 1.9794\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9826 - val_loss: 1.9781\n",
      "Top-2 accuracy = 0.453\n",
      "11\n",
      "minmaxE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1643 - val_loss: 2.1100\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0821 - val_loss: 2.0424\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0205 - val_loss: 2.0037\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0050 - val_loss: 1.9977\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0036 - val_loss: 1.9980\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 1.9960\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 1.9965\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0018 - val_loss: 1.9950\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 1.9997\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9958\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9978 - val_loss: 1.9933\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9964 - val_loss: 1.9962\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9978 - val_loss: 1.9939\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9962 - val_loss: 1.9916\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9956 - val_loss: 1.9932\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9990 - val_loss: 1.9963\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9971 - val_loss: 1.9935\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9921\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9947 - val_loss: 1.9928\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9947 - val_loss: 1.9910\n",
      "Top-2 accuracy = 0.446\n",
      "12\n",
      "normalizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1891 - val_loss: 2.1808\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1755 - val_loss: 2.1693\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1668 - val_loss: 2.1629\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1622 - val_loss: 2.1600\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1605 - val_loss: 2.1592\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1596 - val_loss: 2.1586\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1593 - val_loss: 2.1585\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1583\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "13\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1602 - val_loss: 2.1198\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0975 - val_loss: 2.0709\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0635 - val_loss: 2.0457\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0411 - val_loss: 2.0276\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0297 - val_loss: 2.0222\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0237 - val_loss: 2.0192\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0206 - val_loss: 2.0363\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0258 - val_loss: 2.0155\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0166 - val_loss: 2.0102\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0144 - val_loss: 2.0083\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0143 - val_loss: 2.0082\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0129 - val_loss: 2.0059\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0123 - val_loss: 2.0112\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0125 - val_loss: 2.0064\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0120 - val_loss: 2.0083\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0127 - val_loss: 2.0102\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0114 - val_loss: 2.0045\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0105 - val_loss: 2.0197\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0136 - val_loss: 2.0066\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0105 - val_loss: 2.0046\n",
      "Top-2 accuracy = 0.444\n",
      "14\n",
      "maxabsF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1446 - val_loss: 2.0715\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0470 - val_loss: 2.0188\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0176 - val_loss: 2.0093\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0117 - val_loss: 2.0031\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0078 - val_loss: 2.0067\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0077 - val_loss: 1.9998\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0062 - val_loss: 2.0000\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0061 - val_loss: 1.9987\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0050 - val_loss: 1.9981\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0051 - val_loss: 1.9990\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0040 - val_loss: 1.9983\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0043 - val_loss: 1.9969\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0047 - val_loss: 1.9978\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0029 - val_loss: 1.9974\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0055 - val_loss: 1.9972\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0036 - val_loss: 1.9964\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0023 - val_loss: 1.9980\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0027 - val_loss: 1.9957\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0019 - val_loss: 1.9956\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0031 - val_loss: 1.9983\n",
      "Top-2 accuracy = 0.446\n",
      "15\n",
      "normalizel|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1827 - val_loss: 2.1677\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1627 - val_loss: 2.1586\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1594 - val_loss: 2.1582\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1577\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1593 - val_loss: 2.1580\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1593 - val_loss: 2.1578\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1532 - val_loss: 2.1254\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1205 - val_loss: 2.1343\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1243 - val_loss: 2.1354\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1264 - val_loss: 2.1208\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1391 - val_loss: 2.1399\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1391 - val_loss: 2.1375\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1316 - val_loss: 2.1251\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1207 - val_loss: 2.1138\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1088 - val_loss: 2.0956\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1091 - val_loss: 2.1303\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1280 - val_loss: 2.1293\n",
      "Top-2 accuracy = 0.358\n",
      "16\n",
      "standardizeN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1573 - val_loss: 2.1176\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0925 - val_loss: 2.0562\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0481 - val_loss: 2.0286\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0276 - val_loss: 2.0168\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0182 - val_loss: 2.0150\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0130 - val_loss: 2.0058\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0088 - val_loss: 2.0040\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0058 - val_loss: 2.0062\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0044 - val_loss: 2.0022\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9995 - val_loss: 1.9997\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9981 - val_loss: 1.9969\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9970 - val_loss: 1.9957\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9957 - val_loss: 1.9990\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9966 - val_loss: 1.9965\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9966 - val_loss: 1.9955\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9946 - val_loss: 1.9916\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9931 - val_loss: 1.9920\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9925 - val_loss: 1.9928\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9928 - val_loss: 1.9968\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9962 - val_loss: 1.9900\n",
      "Top-2 accuracy = 0.448\n",
      "17\n",
      "maxabse|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1765 - val_loss: 2.1514\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1222 - val_loss: 2.0891\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0719 - val_loss: 2.0548\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0503 - val_loss: 2.0395\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0384 - val_loss: 2.0298\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0303 - val_loss: 2.0228\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0245 - val_loss: 2.0183\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0200 - val_loss: 2.0146\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0166 - val_loss: 2.0111\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0141 - val_loss: 2.0083\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0116 - val_loss: 2.0062\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0100 - val_loss: 2.0051\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0085 - val_loss: 2.0034\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0068 - val_loss: 2.0017\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0054 - val_loss: 2.0002\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0046 - val_loss: 1.9990\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0034 - val_loss: 1.9981\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0023 - val_loss: 1.9971\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 1.9961\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0011 - val_loss: 1.9949\n",
      "Top-2 accuracy = 0.444\n",
      "18\n",
      "maxabsG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1513 - val_loss: 2.0775\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0402 - val_loss: 2.0360\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0208 - val_loss: 2.0122\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0123 - val_loss: 2.0073\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0103 - val_loss: 2.0063\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0077 - val_loss: 2.0038\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0059 - val_loss: 2.0035\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 2.0008\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0039 - val_loss: 2.0003\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0019 - val_loss: 1.9987\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 2.0032\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0014 - val_loss: 1.9997\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9994 - val_loss: 1.9986\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9997 - val_loss: 1.9974\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 2.0008\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9977 - val_loss: 1.9952\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9963 - val_loss: 1.9954\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9967 - val_loss: 1.9960\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9963 - val_loss: 1.9960\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9951 - val_loss: 1.9948\n",
      "Top-2 accuracy = 0.447\n",
      "19\n",
      "robustN|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1449 - val_loss: 2.1070\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0936 - val_loss: 2.0753\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0709 - val_loss: 2.0565\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0536 - val_loss: 2.0415\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0409 - val_loss: 2.0316\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0317 - val_loss: 2.0241\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0250 - val_loss: 2.0179\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0193 - val_loss: 2.0127\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0141 - val_loss: 2.0111\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0113 - val_loss: 2.0096\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0095 - val_loss: 2.0065\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0070 - val_loss: 2.0042\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 2.0048\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0047 - val_loss: 2.0027\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0036 - val_loss: 2.0019\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0022 - val_loss: 2.0004\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 1.9999\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0010 - val_loss: 1.9991\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9985\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9990 - val_loss: 1.9980\n",
      "Top-2 accuracy = 0.447\n",
      "20\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1741 - val_loss: 2.1492\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1049 - val_loss: 2.0578\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0384 - val_loss: 2.0245\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0208 - val_loss: 2.0159\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0138 - val_loss: 2.0128\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0126 - val_loss: 2.0072\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0134 - val_loss: 2.0084\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0083 - val_loss: 2.0054\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0074 - val_loss: 2.0084\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0069 - val_loss: 2.0047\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0059 - val_loss: 2.0059\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0047 - val_loss: 2.0071\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0049 - val_loss: 2.0054\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0039 - val_loss: 2.0056\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0044 - val_loss: 2.0027\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0036 - val_loss: 2.0055\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0037 - val_loss: 2.0025\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0035 - val_loss: 2.0044\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0038 - val_loss: 2.0033\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0039 - val_loss: 2.0022\n",
      "Top-2 accuracy = 0.447\n",
      "21\n",
      "standardizeu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1606 - val_loss: 2.1114\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0727 - val_loss: 2.0303\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0144 - val_loss: 2.0014\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0021 - val_loss: 1.9972\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9988 - val_loss: 1.9979\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9974 - val_loss: 1.9928\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9957 - val_loss: 1.9922\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9952 - val_loss: 1.9911\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9944 - val_loss: 1.9910\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9935 - val_loss: 1.9913\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9941 - val_loss: 1.9902\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9922 - val_loss: 1.9896\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9914 - val_loss: 1.9897\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9920 - val_loss: 1.9892\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9906 - val_loss: 1.9891\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9905 - val_loss: 1.9881\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9899 - val_loss: 1.9895\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9903 - val_loss: 1.9896\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9897 - val_loss: 1.9891\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9896 - val_loss: 1.9886\n",
      "Top-2 accuracy = 0.452\n",
      "22\n",
      "standardizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1778 - val_loss: 2.1535\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1279 - val_loss: 2.1063\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0922 - val_loss: 2.0824\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0735 - val_loss: 2.0671\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0608 - val_loss: 2.0541\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0485 - val_loss: 2.0436\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0397 - val_loss: 2.0380\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0333 - val_loss: 2.0315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0281 - val_loss: 2.0262\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0227 - val_loss: 2.0197\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0184 - val_loss: 2.0162\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0155 - val_loss: 2.0138\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0128 - val_loss: 2.0095\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0098 - val_loss: 2.0080\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0076 - val_loss: 2.0057\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0059 - val_loss: 2.0035\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0046 - val_loss: 2.0021\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0036 - val_loss: 2.0008\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0025 - val_loss: 2.0010\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0023 - val_loss: 1.9993\n",
      "Top-2 accuracy = 0.447\n",
      "23\n",
      "maxabsu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1860 - val_loss: 2.1655\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1268 - val_loss: 2.0858\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0823 - val_loss: 2.0665\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0672 - val_loss: 2.0558\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0577 - val_loss: 2.0474\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0506 - val_loss: 2.0407\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0444 - val_loss: 2.0355\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0398 - val_loss: 2.0321\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0353 - val_loss: 2.0279\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0322 - val_loss: 2.0243\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0290 - val_loss: 2.0218\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0265 - val_loss: 2.0212\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0240 - val_loss: 2.0214\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0252 - val_loss: 2.0159\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0206 - val_loss: 2.0141\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0193 - val_loss: 2.0142\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0173 - val_loss: 2.0121\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0159 - val_loss: 2.0109\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0153 - val_loss: 2.0093\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0130 - val_loss: 2.0098\n",
      "Top-2 accuracy = 0.45\n",
      "24\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1657 - val_loss: 2.1327\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0986 - val_loss: 2.0559\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0328 - val_loss: 2.0101\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0108 - val_loss: 2.0074\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0075 - val_loss: 2.0011\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0052 - val_loss: 2.0007\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0037 - val_loss: 1.9999\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0031 - val_loss: 1.9996\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0014 - val_loss: 1.9996\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0011 - val_loss: 1.9986\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9981\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0000 - val_loss: 1.9994\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0002 - val_loss: 1.9956\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9994 - val_loss: 1.9953\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9946\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9996 - val_loss: 1.9952\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9970 - val_loss: 1.9934\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9971 - val_loss: 1.9978\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9976 - val_loss: 1.9944\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9965 - val_loss: 1.9933\n",
      "Top-2 accuracy = 0.447\n",
      "25\n",
      "maxabso|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1215 - val_loss: 2.0579\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0387 - val_loss: 2.0184\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0195 - val_loss: 2.0109\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0131 - val_loss: 2.0061\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0106 - val_loss: 2.0039\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0084 - val_loss: 2.0043\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0069 - val_loss: 1.9999\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0061 - val_loss: 2.0002\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 1.9986\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0041 - val_loss: 1.9983\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0036 - val_loss: 1.9978\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0034 - val_loss: 1.9969\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0035 - val_loss: 1.9959\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0031 - val_loss: 1.9957\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0017 - val_loss: 1.9990\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0027 - val_loss: 1.9940\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0020 - val_loss: 1.9938\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0000 - val_loss: 1.9964\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9994 - val_loss: 1.9924\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9992 - val_loss: 1.9923\n",
      "Top-2 accuracy = 0.448\n",
      "26\n",
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1292 - val_loss: 2.0744\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0386 - val_loss: 2.0108\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0058 - val_loss: 1.9980\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9998 - val_loss: 1.9942\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9968 - val_loss: 1.9914\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9954 - val_loss: 1.9911\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9932 - val_loss: 1.9893\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9888\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9913 - val_loss: 1.9893\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9900 - val_loss: 1.9873\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9899 - val_loss: 1.9865\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9889 - val_loss: 1.9861\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9883 - val_loss: 1.9864\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9884 - val_loss: 1.9884\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9882 - val_loss: 1.9898\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9876 - val_loss: 1.9869\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9868 - val_loss: 1.9846\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9864 - val_loss: 1.9846\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9858 - val_loss: 1.9845\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9852 - val_loss: 1.9848\n",
      "Top-2 accuracy = 0.447\n",
      "27\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1241 - val_loss: 2.0349\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0068 - val_loss: 2.0027\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9946 - val_loss: 1.9913\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9894 - val_loss: 1.9910\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9866 - val_loss: 1.9916\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9859 - val_loss: 1.9909\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9850 - val_loss: 1.9954\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9853 - val_loss: 1.9887\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9866 - val_loss: 1.9884\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9843 - val_loss: 1.9891\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9839 - val_loss: 1.9873\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9828 - val_loss: 1.9871\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9824 - val_loss: 1.9878\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9826 - val_loss: 1.9885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9851 - val_loss: 1.9999\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9829 - val_loss: 1.9992\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9862 - val_loss: 1.9884\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9818 - val_loss: 1.9896\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9815 - val_loss: 1.9974\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9816 - val_loss: 1.9886\n",
      "Top-2 accuracy = 0.449\n",
      "28\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1493 - val_loss: 2.1008\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0830 - val_loss: 2.0414\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0260 - val_loss: 2.0082\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0070 - val_loss: 1.9995\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0002 - val_loss: 1.9997\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9979 - val_loss: 1.9935\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9968 - val_loss: 1.9932\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9938 - val_loss: 2.0040\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9937 - val_loss: 1.9886\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9919 - val_loss: 2.0027\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9915 - val_loss: 2.0027\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9958 - val_loss: 1.9894\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9908 - val_loss: 1.9882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9903 - val_loss: 1.9866\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9886 - val_loss: 2.0001\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9902 - val_loss: 1.9874\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9883 - val_loss: 1.9931\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9886 - val_loss: 1.9863\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9882 - val_loss: 1.9867\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9871 - val_loss: 1.9889\n",
      "Top-2 accuracy = 0.449\n",
      "29\n",
      "normalizeY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1499 - val_loss: 2.1015\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0711 - val_loss: 2.0423\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0347 - val_loss: 2.0226\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0203 - val_loss: 2.0125\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0138 - val_loss: 2.0058\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0089 - val_loss: 2.0046\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0049 - val_loss: 1.9989\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0025 - val_loss: 1.9968\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0009 - val_loss: 1.9968\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0000 - val_loss: 1.9949\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9965\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9983 - val_loss: 1.9928\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9966 - val_loss: 1.9926\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9962 - val_loss: 1.9914\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9954 - val_loss: 1.9916\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9948 - val_loss: 1.9902\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9948 - val_loss: 1.9893\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9939 - val_loss: 1.9907\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9952 - val_loss: 1.9891\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9937 - val_loss: 1.9898\n",
      "Top-2 accuracy = 0.448\n",
      "0\n",
      "minmaxA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1793 - val_loss: 2.1625\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1607 - val_loss: 2.1581\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1420 - val_loss: 2.0825\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0380 - val_loss: 2.0164\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0102 - val_loss: 1.9997\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0046 - val_loss: 2.0018\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0018 - val_loss: 1.9980\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0014 - val_loss: 1.9961\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9990 - val_loss: 1.9943\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9980 - val_loss: 1.9968\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9987 - val_loss: 1.9933\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9979 - val_loss: 1.9938\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9958 - val_loss: 1.9917\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9967\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9967 - val_loss: 1.9904\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9949 - val_loss: 1.9909\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9935 - val_loss: 1.9903\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9938 - val_loss: 1.9891\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9931 - val_loss: 1.9907\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9924 - val_loss: 1.9957\n",
      "Top-2 accuracy = 0.444\n",
      "1\n",
      "minmaxq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1580 - val_loss: 2.1132\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0805 - val_loss: 2.0494\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0370 - val_loss: 2.0208\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0189 - val_loss: 2.0085\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0103 - val_loss: 2.0022\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0062 - val_loss: 2.0012\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0047 - val_loss: 1.9998\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0031 - val_loss: 1.9978\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0029 - val_loss: 1.9953\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9950\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0007 - val_loss: 1.9941\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9993 - val_loss: 1.9968\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0000 - val_loss: 1.9955\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9987 - val_loss: 1.9956\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9985 - val_loss: 1.9942\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9984 - val_loss: 1.9926\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9921\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9968 - val_loss: 1.9920\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9965 - val_loss: 1.9933\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9969 - val_loss: 1.9918\n",
      "Top-2 accuracy = 0.447\n",
      "2\n",
      "maxabsm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1723 - val_loss: 2.1226\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0726 - val_loss: 2.0276\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0177 - val_loss: 2.0051\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0071 - val_loss: 1.9985\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0034 - val_loss: 1.9960\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9991 - val_loss: 1.9973\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9988 - val_loss: 1.9946\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9962 - val_loss: 1.9922\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9962 - val_loss: 1.9906\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9950 - val_loss: 1.9909\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9964 - val_loss: 1.9914\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9947 - val_loss: 1.9963\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9942 - val_loss: 2.0012\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9968 - val_loss: 1.9944\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9982 - val_loss: 1.9918\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9951 - val_loss: 1.9890\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9927 - val_loss: 1.9895\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9921 - val_loss: 1.9917\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9932 - val_loss: 1.9880\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9918 - val_loss: 1.9913\n",
      "Top-2 accuracy = 0.446\n",
      "3\n",
      "minmaxM|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1732 - val_loss: 2.1405\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1104 - val_loss: 2.0806\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0632 - val_loss: 2.0495\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0356 - val_loss: 2.0229\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0226 - val_loss: 2.0244\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0174 - val_loss: 2.0104\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0142 - val_loss: 2.0196\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0172 - val_loss: 2.0084\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0109 - val_loss: 2.0134\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0116 - val_loss: 2.0136\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0105 - val_loss: 2.0037\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0098 - val_loss: 2.0039\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0088 - val_loss: 2.0079\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0078 - val_loss: 2.0040\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0075 - val_loss: 2.0012\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0073 - val_loss: 2.0060\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0074 - val_loss: 2.0009\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0063 - val_loss: 2.0036\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0069 - val_loss: 2.0034\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0074 - val_loss: 2.0011\n",
      "Top-2 accuracy = 0.446\n",
      "4\n",
      "normalizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1762 - val_loss: 2.1614\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1597 - val_loss: 2.1559\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1310 - val_loss: 2.0901\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0713 - val_loss: 2.0513\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0427 - val_loss: 2.0314\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0272 - val_loss: 2.0184\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0197 - val_loss: 2.0115\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0147 - val_loss: 2.0076\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0129 - val_loss: 2.0051\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0112 - val_loss: 2.0070\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0103 - val_loss: 2.0114\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0091 - val_loss: 2.0040\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0082 - val_loss: 2.0030\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0096 - val_loss: 2.0041\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0072 - val_loss: 2.0022\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0058 - val_loss: 2.0062\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0066 - val_loss: 2.0014\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0049 - val_loss: 2.0003\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0046 - val_loss: 2.0012\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0050 - val_loss: 1.9986\n",
      "Top-2 accuracy = 0.446\n",
      "5\n",
      "robustb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 2.1789 - val_loss: 2.1505\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1260 - val_loss: 2.1109\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0982 - val_loss: 2.0881\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0780 - val_loss: 2.0698\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0623 - val_loss: 2.0544\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0485 - val_loss: 2.0427\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0386 - val_loss: 2.0330\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0308 - val_loss: 2.0267\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0245 - val_loss: 2.0225\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0201 - val_loss: 2.0151\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0154 - val_loss: 2.0109\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0118 - val_loss: 2.0076\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0089 - val_loss: 2.0069\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0080 - val_loss: 2.0036\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0073 - val_loss: 2.0025\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0035 - val_loss: 1.9994\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0014 - val_loss: 1.9982\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0008 - val_loss: 1.9965\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9996 - val_loss: 1.9952\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9984 - val_loss: 1.9945\n",
      "Top-2 accuracy = 0.45\n",
      "6\n",
      "minmaxz|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1552 - val_loss: 2.0891\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0442 - val_loss: 2.0143\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0085 - val_loss: 1.9967\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0007 - val_loss: 1.9954\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9988 - val_loss: 1.9911\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9965 - val_loss: 1.9899\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9956 - val_loss: 1.9990\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9965 - val_loss: 1.9929\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9955 - val_loss: 1.9901\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9930 - val_loss: 1.9991\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9998 - val_loss: 1.9897\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9936 - val_loss: 1.9906\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9934 - val_loss: 1.9876\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9922 - val_loss: 1.9866\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9916 - val_loss: 1.9886\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9923 - val_loss: 1.9924\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9913 - val_loss: 1.9870\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9909 - val_loss: 1.9897\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9918 - val_loss: 1.9861\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9910 - val_loss: 1.9864\n",
      "Top-2 accuracy = 0.45\n",
      "7\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1700 - val_loss: 2.1294\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0928 - val_loss: 2.0508\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0341 - val_loss: 2.0188\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0186 - val_loss: 2.0100\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0129 - val_loss: 2.0055\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0090 - val_loss: 2.0015\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0063 - val_loss: 2.0012\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0055 - val_loss: 1.9992\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0032 - val_loss: 1.9982\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0015 - val_loss: 1.9962\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0017 - val_loss: 2.0034\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0015 - val_loss: 1.9960\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0003 - val_loss: 1.9951\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9993 - val_loss: 1.9936\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9990 - val_loss: 1.9948\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9989 - val_loss: 1.9939\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9980 - val_loss: 1.9941\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9991 - val_loss: 1.9944\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9975 - val_loss: 1.9932\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9967 - val_loss: 1.9948\n",
      "Top-2 accuracy = 0.446\n",
      "8\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1775 - val_loss: 2.1422\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1144 - val_loss: 2.0905\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0883 - val_loss: 2.0845\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0856 - val_loss: 2.0838\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0844 - val_loss: 2.0843\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0838 - val_loss: 2.0811\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0835 - val_loss: 2.0806\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0831 - val_loss: 2.0808\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0832 - val_loss: 2.0807\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0833 - val_loss: 2.0810\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0836 - val_loss: 2.0807\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0837 - val_loss: 2.0808\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0833 - val_loss: 2.0804\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0833 - val_loss: 2.0807\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0838 - val_loss: 2.0820\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0856 - val_loss: 2.0979\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0921 - val_loss: 2.0880\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0884 - val_loss: 2.0864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0877 - val_loss: 2.0866\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0883 - val_loss: 2.0881\n",
      "Top-2 accuracy = 0.411\n",
      "9\n",
      "robustY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1862 - val_loss: 2.1771\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1680 - val_loss: 2.1579\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1439 - val_loss: 2.1266\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1099 - val_loss: 2.0895\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0783 - val_loss: 2.0634\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0573 - val_loss: 2.0460\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0438 - val_loss: 2.0349\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0350 - val_loss: 2.0279\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0292 - val_loss: 2.0225\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0244 - val_loss: 2.0176\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0201 - val_loss: 2.0143\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0168 - val_loss: 2.0111\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0146 - val_loss: 2.0083\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0122 - val_loss: 2.0065\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0102 - val_loss: 2.0045\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0087 - val_loss: 2.0031\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0076 - val_loss: 2.0019\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0065 - val_loss: 2.0006\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 1.9998\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 1.9991\n",
      "Top-2 accuracy = 0.446\n",
      "10\n",
      "minmaxp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1479 - val_loss: 2.0904\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0674 - val_loss: 2.0433\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0328 - val_loss: 2.0192\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0183 - val_loss: 2.0079\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0109 - val_loss: 2.0035\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0061 - val_loss: 1.9997\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0044 - val_loss: 1.9975\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0031 - val_loss: 1.9979\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0011 - val_loss: 1.9959\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0017 - val_loss: 1.9947\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9995 - val_loss: 1.9950\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9994 - val_loss: 1.9951\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9989 - val_loss: 1.9927\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9983 - val_loss: 1.9965\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9984 - val_loss: 1.9934\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9975 - val_loss: 1.9932\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9972 - val_loss: 1.9921\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9966 - val_loss: 1.9917\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9959 - val_loss: 1.9949\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9965 - val_loss: 1.9912\n",
      "Top-2 accuracy = 0.448\n",
      "11\n",
      "minmaxx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1558 - val_loss: 2.1207\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0998 - val_loss: 2.0748\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0705 - val_loss: 2.0552\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0539 - val_loss: 2.0410\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0430 - val_loss: 2.0347\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0349 - val_loss: 2.0282\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0297 - val_loss: 2.0270\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0258 - val_loss: 2.0234\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0233 - val_loss: 2.0183\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0201 - val_loss: 2.0170\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0187 - val_loss: 2.0136\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0184 - val_loss: 2.0128\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0152 - val_loss: 2.0107\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0145 - val_loss: 2.0105\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0132 - val_loss: 2.0107\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0122 - val_loss: 2.0072\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0113 - val_loss: 2.0128\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0110 - val_loss: 2.0080\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0097 - val_loss: 2.0080\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0096 - val_loss: 2.0070\n",
      "Top-2 accuracy = 0.445\n",
      "12\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1625 - val_loss: 2.1217\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0882 - val_loss: 2.0530\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0292 - val_loss: 2.0074\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0052 - val_loss: 1.9964\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 1.9922\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9957 - val_loss: 1.9899\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9947 - val_loss: 1.9893\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9937 - val_loss: 1.9887\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9938 - val_loss: 1.9887\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9923 - val_loss: 1.9879\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9880\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9914 - val_loss: 1.9878\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9911 - val_loss: 1.9877\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9905 - val_loss: 1.9878\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9873\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9903 - val_loss: 1.9871\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9870\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9892 - val_loss: 1.9869\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9888 - val_loss: 1.9874\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9896 - val_loss: 1.9862\n",
      "Top-2 accuracy = 0.448\n",
      "13\n",
      "robustp|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1554 - val_loss: 2.1189\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0956 - val_loss: 2.0686\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0521 - val_loss: 2.0336\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0274 - val_loss: 2.0183\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0167 - val_loss: 2.0103\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 2.0058\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0085 - val_loss: 2.0029\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0064 - val_loss: 2.0012\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0050 - val_loss: 1.9999\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0037 - val_loss: 1.9991\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0028 - val_loss: 1.9973\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0015 - val_loss: 1.9969\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0007 - val_loss: 1.9953\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9948\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9996 - val_loss: 1.9947\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9992 - val_loss: 1.9932\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9984 - val_loss: 1.9934\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9932\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9983 - val_loss: 1.9935\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9919\n",
      "Top-2 accuracy = 0.447\n",
      "14\n",
      "robustT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1874 - val_loss: 2.1767\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1579 - val_loss: 2.1298\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1025 - val_loss: 2.0734\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0575 - val_loss: 2.0407\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0368 - val_loss: 2.0248\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0235 - val_loss: 2.0118\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0129 - val_loss: 2.0080\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0085 - val_loss: 2.0032\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0053 - val_loss: 1.9984\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0034 - val_loss: 1.9974\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0014 - val_loss: 1.9972\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0025 - val_loss: 1.9990\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9977\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0018 - val_loss: 1.9954\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9985 - val_loss: 1.9967\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9993 - val_loss: 1.9954\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9982 - val_loss: 1.9948\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9972 - val_loss: 1.9974\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9992 - val_loss: 1.9964\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9985 - val_loss: 1.9939\n",
      "Top-2 accuracy = 0.448\n",
      "15\n",
      "minmaxQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1865 - val_loss: 2.1729\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1529 - val_loss: 2.1142\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1029 - val_loss: 2.0866\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0810 - val_loss: 2.0647\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0545 - val_loss: 2.0397\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0386 - val_loss: 2.0300\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0304 - val_loss: 2.0242\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0259 - val_loss: 2.0200\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0221 - val_loss: 2.0165\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0196 - val_loss: 2.0154\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0176 - val_loss: 2.0136\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0157 - val_loss: 2.0108\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0143 - val_loss: 2.0103\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0132 - val_loss: 2.0083\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0123 - val_loss: 2.0079\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0119 - val_loss: 2.0070\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0111 - val_loss: 2.0058\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0106 - val_loss: 2.0060\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0099 - val_loss: 2.0048\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0093 - val_loss: 2.0040\n",
      "Top-2 accuracy = 0.442\n",
      "16\n",
      "maxabsv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1617 - val_loss: 2.1256\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1142 - val_loss: 2.0924\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0903 - val_loss: 2.0911\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0983 - val_loss: 2.1213\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0999 - val_loss: 2.0945\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0998 - val_loss: 2.0975\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1086 - val_loss: 2.1048\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1100 - val_loss: 2.1046\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0926 - val_loss: 2.0865\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0882 - val_loss: 2.0848\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0882 - val_loss: 2.0835\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.0872 - val_loss: 2.0832\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0874 - val_loss: 2.0834\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0876 - val_loss: 2.0833\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0875 - val_loss: 2.0833\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0875 - val_loss: 2.0841\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0876 - val_loss: 2.0838\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0876 - val_loss: 2.0833\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0876 - val_loss: 2.0832\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0875 - val_loss: 2.0833\n",
      "Top-2 accuracy = 0.41\n",
      "17\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1351 - val_loss: 2.0873\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0671 - val_loss: 2.0472\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0349 - val_loss: 2.0162\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0159 - val_loss: 2.0067\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0101 - val_loss: 2.0007\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0053 - val_loss: 2.0021\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0032 - val_loss: 1.9972\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0009 - val_loss: 1.9949\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9996 - val_loss: 2.0124\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0032 - val_loss: 1.9954\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9985 - val_loss: 1.9935\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9971 - val_loss: 1.9929\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9966 - val_loss: 1.9935\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9953 - val_loss: 1.9919\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9933\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9952 - val_loss: 1.9958\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9968 - val_loss: 1.9936\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9946 - val_loss: 1.9924\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9956 - val_loss: 1.9940\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9940 - val_loss: 1.9918\n",
      "Top-2 accuracy = 0.448\n",
      "18\n",
      "standardizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1841 - val_loss: 2.1668\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1392 - val_loss: 2.1018\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0693 - val_loss: 2.0393\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0263 - val_loss: 2.0130\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0107 - val_loss: 2.0037\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0044 - val_loss: 1.9988\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0015 - val_loss: 1.9968\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9993 - val_loss: 1.9947\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9971 - val_loss: 1.9936\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9965 - val_loss: 1.9921\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9949 - val_loss: 1.9924\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9943 - val_loss: 1.9908\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9937 - val_loss: 1.9900\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9930 - val_loss: 1.9910\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9923 - val_loss: 1.9906\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9898\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9914 - val_loss: 1.9889\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9910 - val_loss: 1.9884\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9909 - val_loss: 1.9883\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9901 - val_loss: 1.9879\n",
      "Top-2 accuracy = 0.448\n",
      "19\n",
      "robustE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1706 - val_loss: 2.1258\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0984 - val_loss: 2.0676\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0593 - val_loss: 2.0357\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0352 - val_loss: 2.0194\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0223 - val_loss: 2.0122\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0169 - val_loss: 2.0080\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0141 - val_loss: 2.0056\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0113 - val_loss: 2.0042\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0093 - val_loss: 2.0020\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0076 - val_loss: 1.9995\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0056 - val_loss: 2.0004\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 2.0002\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 1.9971\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0021 - val_loss: 1.9958\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0014 - val_loss: 1.9962\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0005 - val_loss: 1.9968\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0009 - val_loss: 1.9935\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9996 - val_loss: 2.0041\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0013 - val_loss: 1.9948\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9949\n",
      "Top-2 accuracy = 0.446\n",
      "20\n",
      "standardizeq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1854 - val_loss: 2.1737\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1654 - val_loss: 2.1608\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1599 - val_loss: 2.1587\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1583\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1580\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1580\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "21\n",
      "standardizeG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1719 - val_loss: 2.1448\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1211 - val_loss: 2.0900\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0706 - val_loss: 2.0434\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0344 - val_loss: 2.0201\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0175 - val_loss: 2.0095\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0095 - val_loss: 2.0023\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0052 - val_loss: 2.0027\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0032 - val_loss: 1.9985\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0010 - val_loss: 1.9967\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0009 - val_loss: 1.9959\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9998 - val_loss: 1.9981\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9997 - val_loss: 1.9946\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9989 - val_loss: 1.9953\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9996 - val_loss: 1.9945\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9976 - val_loss: 1.9929\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9973 - val_loss: 1.9943\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9975 - val_loss: 1.9921\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9985 - val_loss: 1.9929\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9975 - val_loss: 1.9929\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9960 - val_loss: 1.9912\n",
      "Top-2 accuracy = 0.448\n",
      "22\n",
      "normalizev|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1367 - val_loss: 2.0685\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0302 - val_loss: 2.0033\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0034 - val_loss: 1.9915\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9964 - val_loss: 1.9890\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9933 - val_loss: 1.9879\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9916 - val_loss: 1.9858\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9912 - val_loss: 1.9847\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9915\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9908 - val_loss: 1.9851\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9893 - val_loss: 1.9844\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9884 - val_loss: 1.9888\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9892 - val_loss: 1.9910\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9903 - val_loss: 1.9852\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9882 - val_loss: 2.0074\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9850\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9882 - val_loss: 1.9835\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9880 - val_loss: 1.9832\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9869 - val_loss: 1.9832\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9877 - val_loss: 1.9842\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9877 - val_loss: 1.9831\n",
      "Top-2 accuracy = 0.45\n",
      "23\n",
      "maxabst|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1428 - val_loss: 2.0892\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0831 - val_loss: 2.0677\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0646 - val_loss: 2.0522\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0478 - val_loss: 2.0354\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0331 - val_loss: 2.0227\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0218 - val_loss: 2.0216\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0175 - val_loss: 2.0144\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0130 - val_loss: 2.0073\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0091 - val_loss: 2.0059\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0070 - val_loss: 2.0084\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0062 - val_loss: 2.0048\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0048 - val_loss: 2.0125\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0050 - val_loss: 2.0145\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0039 - val_loss: 2.0007\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0032 - val_loss: 2.0040\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0019 - val_loss: 2.0008\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0015 - val_loss: 2.0007\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0015 - val_loss: 2.0013\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0016 - val_loss: 1.9999\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0001 - val_loss: 2.0030\n",
      "Top-2 accuracy = 0.448\n",
      "24\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1822 - val_loss: 2.1633\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1474 - val_loss: 2.1249\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1086 - val_loss: 2.0911\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0862 - val_loss: 2.0733\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0688 - val_loss: 2.0518\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0475 - val_loss: 2.0314\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0312 - val_loss: 2.0212\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0236 - val_loss: 2.0164\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0194 - val_loss: 2.0139\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0169 - val_loss: 2.0130\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0158 - val_loss: 2.0112\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0146 - val_loss: 2.0108\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0139 - val_loss: 2.0102\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0143 - val_loss: 2.0091\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0130 - val_loss: 2.0089\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0124 - val_loss: 2.0083\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 2.0087\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 2.0076\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0110 - val_loss: 2.0074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0108 - val_loss: 2.0074\n",
      "Top-2 accuracy = 0.446\n",
      "25\n",
      "robustJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1780 - val_loss: 2.1504\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1278 - val_loss: 2.0924\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0874 - val_loss: 2.0691\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0717 - val_loss: 2.0578\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0619 - val_loss: 2.0501\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0551 - val_loss: 2.0443\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0499 - val_loss: 2.0397\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0459 - val_loss: 2.0364\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0426 - val_loss: 2.0341\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0399 - val_loss: 2.0318\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0378 - val_loss: 2.0297\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0361 - val_loss: 2.0277\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0344 - val_loss: 2.0261\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0330 - val_loss: 2.0248\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0317 - val_loss: 2.0237\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0304 - val_loss: 2.0225\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0295 - val_loss: 2.0213\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0283 - val_loss: 2.0201\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0273 - val_loss: 2.0194\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0264 - val_loss: 2.0186\n",
      "Top-2 accuracy = 0.441\n",
      "26\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1688 - val_loss: 2.1382\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1098 - val_loss: 2.0836\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0769 - val_loss: 2.0624\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0637 - val_loss: 2.0523\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0537 - val_loss: 2.0428\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0466 - val_loss: 2.0373\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0401 - val_loss: 2.0328\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0355 - val_loss: 2.0278\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0316 - val_loss: 2.0249\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0282 - val_loss: 2.0230\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0261 - val_loss: 2.0200\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0234 - val_loss: 2.0174\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0215 - val_loss: 2.0152\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0185 - val_loss: 2.0185\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0198 - val_loss: 2.0114\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0153 - val_loss: 2.0101\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0133 - val_loss: 2.0093\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0123 - val_loss: 2.0079\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0108 - val_loss: 2.0102\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0103 - val_loss: 2.0099\n",
      "Top-2 accuracy = 0.444\n",
      "27\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1381 - val_loss: 2.0803\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0489 - val_loss: 2.0216\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0155 - val_loss: 2.0060\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0062 - val_loss: 2.0051\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0035 - val_loss: 1.9997\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0017 - val_loss: 2.0001\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0012 - val_loss: 1.9980\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9992 - val_loss: 2.0006\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9988 - val_loss: 1.9962\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9980 - val_loss: 1.9963\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9976 - val_loss: 1.9953\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9968 - val_loss: 1.9952\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9964 - val_loss: 1.9947\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9961 - val_loss: 1.9941\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9959 - val_loss: 1.9950\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9942\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9942\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9945 - val_loss: 1.9936\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9943 - val_loss: 1.9931\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9945 - val_loss: 1.9940\n",
      "Top-2 accuracy = 0.448\n",
      "28\n",
      "maxabsI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1891 - val_loss: 2.1816\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1770 - val_loss: 2.1719\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1695 - val_loss: 2.1660\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1649 - val_loss: 2.1624\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1621 - val_loss: 2.1603\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1606 - val_loss: 2.1592\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1598 - val_loss: 2.1586\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1594 - val_loss: 2.1583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1580\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "29\n",
      "robusty|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1880 - val_loss: 2.1782\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1713 - val_loss: 2.1652\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1631 - val_loss: 2.1606\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1603 - val_loss: 2.1590\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1595 - val_loss: 2.1586\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1593 - val_loss: 2.1583\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1590 - val_loss: 2.1585\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "0\n",
      "normalizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1868 - val_loss: 2.1760\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1716 - val_loss: 2.1650\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1490\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1361 - val_loss: 2.1239\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1095 - val_loss: 2.0986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0857 - val_loss: 2.0777\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0678 - val_loss: 2.0619\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0542 - val_loss: 2.0494\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0438 - val_loss: 2.0407\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0359 - val_loss: 2.0328\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0296 - val_loss: 2.0272\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0252 - val_loss: 2.0228\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0217 - val_loss: 2.0199\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0184 - val_loss: 2.0163\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0165 - val_loss: 2.0146\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0153 - val_loss: 2.0126\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0129 - val_loss: 2.0106\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0120 - val_loss: 2.0094\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0111 - val_loss: 2.0092\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0104 - val_loss: 2.0075\n",
      "Top-2 accuracy = 0.446\n",
      "1\n",
      "maxabsm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1552 - val_loss: 2.1211\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0950 - val_loss: 2.0612\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0194 - val_loss: 2.0010\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0005 - val_loss: 1.9957\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9971 - val_loss: 1.9945\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9954 - val_loss: 1.9954\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9952 - val_loss: 1.9918\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9945 - val_loss: 1.9948\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9926 - val_loss: 1.9914\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9919 - val_loss: 1.9906\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9923 - val_loss: 2.0012\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9955 - val_loss: 1.9906\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9907 - val_loss: 1.9900\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9938 - val_loss: 1.9882\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9894 - val_loss: 1.9902\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9889 - val_loss: 1.9871\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9888 - val_loss: 1.9884\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9902 - val_loss: 1.9865\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9904 - val_loss: 1.9881\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9885 - val_loss: 1.9871\n",
      "Top-2 accuracy = 0.45\n",
      "2\n",
      "minmaxu|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1813 - val_loss: 2.1557\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1227 - val_loss: 2.0890\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0830 - val_loss: 2.0664\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0693 - val_loss: 2.0522\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0514 - val_loss: 2.0312\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0332 - val_loss: 2.0182\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0217 - val_loss: 2.0123\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0157 - val_loss: 2.0057\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0100 - val_loss: 2.0022\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0080 - val_loss: 2.0041\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0059 - val_loss: 2.0049\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0057 - val_loss: 1.9978\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0043 - val_loss: 2.0087\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0035 - val_loss: 1.9960\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0022 - val_loss: 1.9956\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9948\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9986 - val_loss: 2.0004\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9993 - val_loss: 1.9934\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9975 - val_loss: 1.9933\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9976 - val_loss: 1.9928\n",
      "Top-2 accuracy = 0.448\n",
      "3\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1895 - val_loss: 2.1821\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1774 - val_loss: 2.1723\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1696 - val_loss: 2.1661\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1649 - val_loss: 2.1625\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1622 - val_loss: 2.1604\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1607 - val_loss: 2.1592\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1599 - val_loss: 2.1586\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1594 - val_loss: 2.1583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "4\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1840 - val_loss: 2.1691\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1578 - val_loss: 2.1465\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1149 - val_loss: 2.0732\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0586 - val_loss: 2.0448\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0464 - val_loss: 2.0373\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0375 - val_loss: 2.0287\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0334 - val_loss: 2.0271\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0275 - val_loss: 2.0205\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0225 - val_loss: 2.0172\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0192 - val_loss: 2.0345\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0182 - val_loss: 2.0177\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0147 - val_loss: 2.0174\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0138 - val_loss: 2.0141\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0129 - val_loss: 2.0077\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0112 - val_loss: 2.0147\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0109 - val_loss: 2.0082\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0111 - val_loss: 2.0102\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0102 - val_loss: 2.0077\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0115 - val_loss: 2.0080\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0086 - val_loss: 2.0073\n",
      "Top-2 accuracy = 0.445\n",
      "5\n",
      "robustt|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1477 - val_loss: 2.0915\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0519 - val_loss: 2.0171\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0077 - val_loss: 1.9983\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9991 - val_loss: 1.9951\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9919\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9941 - val_loss: 1.9914\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9936 - val_loss: 1.9890\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9929 - val_loss: 1.9901\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9916 - val_loss: 1.9963\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9916 - val_loss: 1.9880\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9895 - val_loss: 1.9896\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9909 - val_loss: 1.9878\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9889 - val_loss: 1.9860\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9882 - val_loss: 1.9863\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9878 - val_loss: 1.9879\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9907 - val_loss: 1.9870\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9889 - val_loss: 1.9888\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9873 - val_loss: 1.9880\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9871 - val_loss: 1.9882\n",
      "Top-2 accuracy = 0.449\n",
      "6\n",
      "standardizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1410 - val_loss: 2.0662\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0312 - val_loss: 2.0132\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0068 - val_loss: 1.9995\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0017 - val_loss: 2.0002\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0021 - val_loss: 1.9967\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9962\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9970 - val_loss: 1.9960\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9957 - val_loss: 1.9956\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9961 - val_loss: 1.9944\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9952 - val_loss: 1.9936\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9947 - val_loss: 1.9943\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9939 - val_loss: 1.9941\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9932 - val_loss: 1.9928\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9930 - val_loss: 1.9941\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9927 - val_loss: 1.9928\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9932 - val_loss: 1.9991\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9921\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9921 - val_loss: 1.9958\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9915 - val_loss: 1.9977\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9925 - val_loss: 1.9945\n",
      "Top-2 accuracy = 0.448\n",
      "7\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1494 - val_loss: 2.1124\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0876 - val_loss: 2.0583\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0446 - val_loss: 2.0275\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0232 - val_loss: 2.0144\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0136 - val_loss: 2.0076\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0093 - val_loss: 2.0038\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0063 - val_loss: 2.0007\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0039 - val_loss: 1.9996\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0029 - val_loss: 1.9998\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0024 - val_loss: 1.9969\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0008 - val_loss: 1.9962\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0001 - val_loss: 1.9963\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0000 - val_loss: 1.9952\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9994 - val_loss: 1.9943\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9989 - val_loss: 1.9950\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9987 - val_loss: 1.9939\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9985 - val_loss: 1.9935\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9981 - val_loss: 1.9927\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9976 - val_loss: 1.9934\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9976 - val_loss: 1.9923\n",
      "Top-2 accuracy = 0.447\n",
      "8\n",
      "standardizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1367 - val_loss: 2.0884\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0611 - val_loss: 2.0361\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0119 - val_loss: 2.0031\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9981 - val_loss: 1.9949\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9938 - val_loss: 1.9921\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9914 - val_loss: 2.0083\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9960 - val_loss: 1.9904\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9916 - val_loss: 1.9877\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9906 - val_loss: 1.9891\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9915 - val_loss: 2.0129\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9929 - val_loss: 1.9879\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9876 - val_loss: 1.9912\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9882 - val_loss: 1.9987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9866 - val_loss: 1.9882\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9859 - val_loss: 1.9869\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9864 - val_loss: 1.9928\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9858 - val_loss: 1.9896\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9872 - val_loss: 1.9860\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9855 - val_loss: 1.9878\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9867 - val_loss: 2.0015\n",
      "Top-2 accuracy = 0.448\n",
      "9\n",
      "normalizeb|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1044 - val_loss: 2.0237\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0114 - val_loss: 2.0008\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9970 - val_loss: 1.9934\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9942 - val_loss: 1.9943\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9939 - val_loss: 1.9898\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9919 - val_loss: 1.9883\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9895 - val_loss: 1.9882\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9894 - val_loss: 1.9857\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9888 - val_loss: 1.9871\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9875 - val_loss: 1.9884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9870 - val_loss: 1.9906\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9879 - val_loss: 1.9900\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9861 - val_loss: 1.9880\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9859 - val_loss: 1.9887\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9862 - val_loss: 1.9855\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9851 - val_loss: 1.9952\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9872 - val_loss: 1.9852\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9858 - val_loss: 1.9843\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9850 - val_loss: 1.9897\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9860 - val_loss: 1.9846\n",
      "Top-2 accuracy = 0.449\n",
      "10\n",
      "normalizek|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1596 - val_loss: 2.1154\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0737 - val_loss: 2.0347\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0241 - val_loss: 2.0111\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0104 - val_loss: 2.0087\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0091 - val_loss: 2.0105\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0065 - val_loss: 2.0016\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0052 - val_loss: 2.0034\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0041 - val_loss: 2.0013\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0029 - val_loss: 2.0054\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0029 - val_loss: 2.0020\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0035 - val_loss: 2.0041\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0036 - val_loss: 1.9997\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 2.0004\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0014 - val_loss: 2.0004\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0013 - val_loss: 2.0007\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0014 - val_loss: 1.9991\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0008 - val_loss: 1.9987\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0003 - val_loss: 1.9989\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0006 - val_loss: 1.9994\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0007 - val_loss: 1.9988\n",
      "Top-2 accuracy = 0.445\n",
      "11\n",
      "normalizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1374 - val_loss: 2.0579\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0168 - val_loss: 1.9935\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9968 - val_loss: 1.9892\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9919 - val_loss: 1.9876\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9899 - val_loss: 1.9862\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9898 - val_loss: 1.9860\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9881 - val_loss: 1.9852\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9878 - val_loss: 1.9843\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9884 - val_loss: 1.9841\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9870 - val_loss: 1.9833\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9877 - val_loss: 1.9847\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9864 - val_loss: 1.9839\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9873 - val_loss: 1.9840\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9862 - val_loss: 1.9832\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9850 - val_loss: 1.9848\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9860 - val_loss: 1.9835\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9863 - val_loss: 1.9878\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9878 - val_loss: 1.9856\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9870 - val_loss: 1.9836\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9844 - val_loss: 1.9830\n",
      "Top-2 accuracy = 0.449\n",
      "12\n",
      "maxabsx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 2.1155\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1010 - val_loss: 2.0798\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0746 - val_loss: 2.0606\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0579 - val_loss: 2.0445\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0447 - val_loss: 2.0332\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0353 - val_loss: 2.0263\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0295 - val_loss: 2.0208\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0242 - val_loss: 2.0195\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0213 - val_loss: 2.0136\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0181 - val_loss: 2.0112\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0154 - val_loss: 2.0096\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0133 - val_loss: 2.0073\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 2.0063\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0096 - val_loss: 2.0038\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0080 - val_loss: 2.0078\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0073 - val_loss: 2.0017\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 2.0023\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0043 - val_loss: 1.9991\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0020 - val_loss: 1.9975\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0021 - val_loss: 1.9974\n",
      "Top-2 accuracy = 0.447\n",
      "13\n",
      "minmaxZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1803 - val_loss: 2.1633\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1411 - val_loss: 2.1241\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1103 - val_loss: 2.0995\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0873 - val_loss: 2.0785\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0684 - val_loss: 2.0648\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0562 - val_loss: 2.0503\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0480 - val_loss: 2.0444\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0414 - val_loss: 2.0374\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0354 - val_loss: 2.0306\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0301 - val_loss: 2.0269\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0270 - val_loss: 2.0222\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0231 - val_loss: 2.0224\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0206 - val_loss: 2.0165\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0181 - val_loss: 2.0166\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0166 - val_loss: 2.0145\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0150 - val_loss: 2.0166\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0139 - val_loss: 2.0098\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0119 - val_loss: 2.0080\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0128 - val_loss: 2.0241\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0146 - val_loss: 2.0075\n",
      "Top-2 accuracy = 0.445\n",
      "14\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_923 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1874 - val_loss: 2.1701\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1583 - val_loss: 2.1413\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1343 - val_loss: 2.1200\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1137 - val_loss: 2.1004\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0948 - val_loss: 2.0849\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0801 - val_loss: 2.0708\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0681 - val_loss: 2.0617\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0596 - val_loss: 2.0546\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0538 - val_loss: 2.0481\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0491 - val_loss: 2.0450\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0462 - val_loss: 2.0414\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0437 - val_loss: 2.0390\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0415 - val_loss: 2.0371\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0401 - val_loss: 2.0354\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0390 - val_loss: 2.0350\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0378 - val_loss: 2.0335\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0367 - val_loss: 2.0340\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0360 - val_loss: 2.0311\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0353 - val_loss: 2.0306\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0347 - val_loss: 2.0300\n",
      "Top-2 accuracy = 0.433\n",
      "15\n",
      "minmaxY|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1413 - val_loss: 2.0943\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0393 - val_loss: 2.0079\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0061 - val_loss: 1.9978\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0010 - val_loss: 1.9994\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9962 - val_loss: 1.9920\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9954 - val_loss: 2.0149\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9966 - val_loss: 1.9927\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9970 - val_loss: 1.9940\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9924 - val_loss: 1.9945\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9914 - val_loss: 1.9960\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9909 - val_loss: 1.9925\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9914 - val_loss: 1.9909\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9894 - val_loss: 1.9919\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9916 - val_loss: 1.9950\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9894 - val_loss: 1.9899\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9903 - val_loss: 1.9904\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9886 - val_loss: 1.9898\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9879 - val_loss: 1.9896\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9888 - val_loss: 1.9902\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9890 - val_loss: 1.9940\n",
      "Top-2 accuracy = 0.449\n",
      "16\n",
      "normalizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1383 - val_loss: 2.0838\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0610 - val_loss: 2.0352\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0324 - val_loss: 2.0243\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0225 - val_loss: 2.0167\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0145 - val_loss: 2.0067\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0140 - val_loss: 2.0116\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0094 - val_loss: 2.0037\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0098 - val_loss: 2.0024\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0070 - val_loss: 2.0023\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0059 - val_loss: 2.0204\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0080 - val_loss: 1.9999\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0072 - val_loss: 2.0102\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0068 - val_loss: 2.0052\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0046 - val_loss: 2.0001\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0060 - val_loss: 2.0127\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0056 - val_loss: 1.9988\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0028 - val_loss: 1.9994\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0035 - val_loss: 1.9984\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0038 - val_loss: 2.0163\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0050 - val_loss: 2.0000\n",
      "Top-2 accuracy = 0.444\n",
      "17\n",
      "normalizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 2.1481 - val_loss: 2.1049\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1379 - val_loss: 2.1542\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1578 - val_loss: 2.1575\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1588 - val_loss: 2.1582\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1406 - val_loss: 2.0694\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1606 - val_loss: 2.1584\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1595 - val_loss: 2.1585\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1591 - val_loss: 2.1586\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1585\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1586\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "18\n",
      "robustC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1378 - val_loss: 2.0618\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0525 - val_loss: 2.0421\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0604 - val_loss: 2.0543\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0499 - val_loss: 2.0476\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0590 - val_loss: 2.0734\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0715 - val_loss: 2.0583\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0631 - val_loss: 2.2224\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1650 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1595 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1595 - val_loss: 2.1585\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1595 - val_loss: 2.1583\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1594 - val_loss: 2.1583\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1595 - val_loss: 2.1584\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1584\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1594 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1595\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "19\n",
      "robustZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 2.1687 - val_loss: 2.1525\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.0957 - val_loss: 2.0755\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0723 - val_loss: 2.0719\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0712 - val_loss: 2.0722\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.0715 - val_loss: 2.0713\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1024 - val_loss: 2.1290\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1310 - val_loss: 2.1334\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1334 - val_loss: 2.1333\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1336 - val_loss: 2.1333\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1334 - val_loss: 2.1334\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1334 - val_loss: 2.1337\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1343 - val_loss: 2.1336\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1336 - val_loss: 2.1336\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1335 - val_loss: 2.1331\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1333 - val_loss: 2.1331\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1333 - val_loss: 2.1330\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1333 - val_loss: 2.1334\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1332 - val_loss: 2.1331\n",
      "Top-2 accuracy = 0.343\n",
      "20\n",
      "maxabsg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1673 - val_loss: 2.1220\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0872 - val_loss: 2.0545\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0351 - val_loss: 2.0138\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0117 - val_loss: 2.0014\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0034 - val_loss: 1.9975\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9977 - val_loss: 1.9968\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9971 - val_loss: 1.9938\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9951 - val_loss: 1.9952\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9945 - val_loss: 1.9926\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9940 - val_loss: 1.9941\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9935 - val_loss: 1.9912\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9922 - val_loss: 1.9918\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9924 - val_loss: 1.9942\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9914 - val_loss: 1.9913\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9913 - val_loss: 1.9956\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9915 - val_loss: 1.9928\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9907 - val_loss: 1.9892\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9904 - val_loss: 1.9891\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9898 - val_loss: 1.9909\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9903 - val_loss: 1.9889\n",
      "Top-2 accuracy = 0.448\n",
      "21\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1457 - val_loss: 2.1018\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0759 - val_loss: 2.0440\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0379 - val_loss: 2.0204\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0214 - val_loss: 2.0118\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0127 - val_loss: 2.0094\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0096 - val_loss: 2.0042\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 1.9981\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0034 - val_loss: 1.9977\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0019 - val_loss: 2.0075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0025 - val_loss: 1.9953\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0002 - val_loss: 1.9990\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9995 - val_loss: 1.9958\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 1.9950\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9987 - val_loss: 1.9932\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9980 - val_loss: 1.9932\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9984 - val_loss: 1.9962\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9989 - val_loss: 1.9932\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9969 - val_loss: 1.9922\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9971 - val_loss: 2.0037\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9985 - val_loss: 1.9912\n",
      "Top-2 accuracy = 0.447\n",
      "22\n",
      "maxabse|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1581 - val_loss: 2.1001\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0507 - val_loss: 2.0171\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0152 - val_loss: 2.0023\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0065 - val_loss: 1.9967\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0040 - val_loss: 1.9963\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0010 - val_loss: 1.9932\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9994 - val_loss: 1.9914\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9982 - val_loss: 1.9912\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9980 - val_loss: 1.9895\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9957 - val_loss: 1.9896\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9956 - val_loss: 1.9880\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9947 - val_loss: 1.9877\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9937 - val_loss: 1.9867\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9930 - val_loss: 1.9888\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9933 - val_loss: 1.9879\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9856\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9864\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9853\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9909 - val_loss: 1.9849\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9901 - val_loss: 1.9848\n",
      "Top-2 accuracy = 0.448\n",
      "23\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_971 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1645 - val_loss: 2.1394\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1164 - val_loss: 2.0884\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0726 - val_loss: 2.0570\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0499 - val_loss: 2.0387\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0356 - val_loss: 2.0267\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0262 - val_loss: 2.0180\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0198 - val_loss: 2.0128\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0145 - val_loss: 2.0088\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0107 - val_loss: 2.0055\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0079 - val_loss: 2.0033\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0057 - val_loss: 2.0020\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0040 - val_loss: 2.0001\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0020 - val_loss: 1.9984\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0000 - val_loss: 1.9971\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9984 - val_loss: 1.9955\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9973 - val_loss: 1.9944\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9959 - val_loss: 1.9926\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9952 - val_loss: 1.9909\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9942 - val_loss: 1.9898\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 1.9932 - val_loss: 1.9898\n",
      "Top-2 accuracy = 0.449\n",
      "24\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1781 - val_loss: 2.1536\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1321 - val_loss: 2.1114\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0902 - val_loss: 2.0674\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0459 - val_loss: 2.0181\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0117 - val_loss: 1.9990\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0016 - val_loss: 2.0039\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9998 - val_loss: 1.9929\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9964 - val_loss: 1.9922\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9905\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9939 - val_loss: 1.9902\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9940 - val_loss: 1.9892\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9930 - val_loss: 1.9893\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9931 - val_loss: 1.9943\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9940 - val_loss: 1.9956\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9930 - val_loss: 1.9888\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9918 - val_loss: 1.9878\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9907\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9924 - val_loss: 1.9884\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9914 - val_loss: 1.9891\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9919 - val_loss: 1.9885\n",
      "Top-2 accuracy = 0.449\n",
      "25\n",
      "robusta|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1609 - val_loss: 2.1158\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0795 - val_loss: 2.0457\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0422 - val_loss: 2.0260\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0233 - val_loss: 2.0144\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0138 - val_loss: 2.0072\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0086 - val_loss: 2.0028\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0043 - val_loss: 1.9993\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0013 - val_loss: 1.9973\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9991 - val_loss: 1.9962\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9960\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9973 - val_loss: 1.9934\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9954 - val_loss: 1.9983\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9954 - val_loss: 1.9957\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9906\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9927 - val_loss: 1.9900\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9918\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9916 - val_loss: 1.9897\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9912 - val_loss: 1.9889\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9909 - val_loss: 1.9889\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9899 - val_loss: 1.9877\n",
      "Top-2 accuracy = 0.449\n",
      "26\n",
      "robusth|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1810 - val_loss: 2.1471\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1030 - val_loss: 2.0562\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0411 - val_loss: 2.0243\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0243 - val_loss: 2.0159\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0174 - val_loss: 2.0115\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0144 - val_loss: 2.0077\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0100 - val_loss: 2.0053\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0066 - val_loss: 2.0024\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0031 - val_loss: 1.9971\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0009 - val_loss: 1.9974\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9992 - val_loss: 1.9940\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 1.9926\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9971 - val_loss: 1.9929\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9961 - val_loss: 1.9934\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9956 - val_loss: 1.9899\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9947 - val_loss: 1.9896\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9939 - val_loss: 1.9887\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9936 - val_loss: 1.9884\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9926 - val_loss: 1.9879\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9923 - val_loss: 1.9875\n",
      "Top-2 accuracy = 0.447\n",
      "27\n",
      "maxabsD|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1746 - val_loss: 2.1609\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1585 - val_loss: 2.1532\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1446 - val_loss: 2.1194\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0936 - val_loss: 2.0648\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0562 - val_loss: 2.0395\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0386 - val_loss: 2.0281\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0302 - val_loss: 2.0221\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0246 - val_loss: 2.0182\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0208 - val_loss: 2.0149\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0180 - val_loss: 2.0124\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0154 - val_loss: 2.0095\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0137 - val_loss: 2.0094\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0125 - val_loss: 2.0064\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0100 - val_loss: 2.0067\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0100 - val_loss: 2.0047\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0082 - val_loss: 2.0033\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0074 - val_loss: 2.0030\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0069 - val_loss: 2.0032\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0061 - val_loss: 2.0010\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0050 - val_loss: 2.0017\n",
      "Top-2 accuracy = 0.446\n",
      "28\n",
      "minmaxA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1790 - val_loss: 2.1657\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1618 - val_loss: 2.1588\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1593 - val_loss: 2.1580\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1589 - val_loss: 2.1568\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1516 - val_loss: 2.1306\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1201 - val_loss: 2.0955\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0904 - val_loss: 2.0762\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0722 - val_loss: 2.0662\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0613 - val_loss: 2.0511\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0497 - val_loss: 2.0461\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0464 - val_loss: 2.0379\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0384 - val_loss: 2.0314\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0335 - val_loss: 2.0290\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0311 - val_loss: 2.0279\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0300 - val_loss: 2.0264\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0266 - val_loss: 2.0261\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0282 - val_loss: 2.0259\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0253 - val_loss: 2.0238\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0246 - val_loss: 2.0228\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0231 - val_loss: 2.0199\n",
      "Top-2 accuracy = 0.441\n",
      "29\n",
      "standardizee|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1624 - val_loss: 2.1188\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0834 - val_loss: 2.0370\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0237 - val_loss: 2.0078\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0078 - val_loss: 1.9990\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0044 - val_loss: 2.0000\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0002 - val_loss: 1.9981\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9981 - val_loss: 1.9955\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9906\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9959 - val_loss: 1.9948\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9951 - val_loss: 1.9918\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9918\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9954 - val_loss: 1.9975\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9929 - val_loss: 1.9914\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9915 - val_loss: 1.9912\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9954 - val_loss: 1.9887\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9900\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9918 - val_loss: 1.9871\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9901 - val_loss: 1.9952\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9873\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9892 - val_loss: 1.9873\n",
      "Top-2 accuracy = 0.448\n",
      "0\n",
      "normalizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1616 - val_loss: 2.1246\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1046 - val_loss: 2.0786\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0698 - val_loss: 2.0503\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0460 - val_loss: 2.0335\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0312 - val_loss: 2.0207\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0210 - val_loss: 2.0127\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0141 - val_loss: 2.0087\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0102 - val_loss: 2.0065\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0080 - val_loss: 2.0032\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0058 - val_loss: 2.0018\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0046 - val_loss: 2.0005\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0036 - val_loss: 1.9998\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0024 - val_loss: 1.9987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0020 - val_loss: 1.9983\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0013 - val_loss: 1.9984\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0013 - val_loss: 1.9972\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0002 - val_loss: 1.9978\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0000 - val_loss: 1.9967\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0007 - val_loss: 1.9958\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 1.9960\n",
      "Top-2 accuracy = 0.446\n",
      "1\n",
      "minmaxl|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1350 - val_loss: 2.0813\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0555 - val_loss: 2.0248\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0200 - val_loss: 2.0076\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0092 - val_loss: 2.0067\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0048 - val_loss: 1.9980\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0019 - val_loss: 1.9971\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0011 - val_loss: 1.9944\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9987 - val_loss: 1.9947\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0004 - val_loss: 1.9934\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9990 - val_loss: 1.9919\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9972 - val_loss: 1.9916\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9971 - val_loss: 1.9907\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9972 - val_loss: 2.0007\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9971 - val_loss: 1.9909\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9952 - val_loss: 1.9896\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9950 - val_loss: 1.9927\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9901\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9940 - val_loss: 1.9923\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9947 - val_loss: 1.9932\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9946 - val_loss: 1.9930\n",
      "Top-2 accuracy = 0.445\n",
      "2\n",
      "standardizeZ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1258 - val_loss: 2.0551\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0324 - val_loss: 2.0116\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0062 - val_loss: 1.9994\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0000 - val_loss: 1.9961\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9967 - val_loss: 1.9969\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9946 - val_loss: 1.9971\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9991 - val_loss: 1.9942\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9924 - val_loss: 1.9920\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9922 - val_loss: 1.9912\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9917 - val_loss: 1.9954\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9912 - val_loss: 1.9929\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9915 - val_loss: 1.9907\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9905 - val_loss: 1.9881\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9884 - val_loss: 1.9939\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9886 - val_loss: 1.9886\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9882 - val_loss: 1.9892\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9882 - val_loss: 1.9890\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9876 - val_loss: 1.9884\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9874 - val_loss: 1.9887\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9874 - val_loss: 2.0042\n",
      "Top-2 accuracy = 0.436\n",
      "3\n",
      "normalizeA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1329 - val_loss: 2.0512\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0255 - val_loss: 1.9991\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0006 - val_loss: 1.9912\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9982 - val_loss: 1.9976\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9976 - val_loss: 1.9916\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9934 - val_loss: 1.9877\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9941 - val_loss: 1.9874\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9930 - val_loss: 1.9855\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9911\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9915 - val_loss: 1.9919\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9907 - val_loss: 1.9880\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9914 - val_loss: 1.9879\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9975\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9953 - val_loss: 1.9894\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9896 - val_loss: 1.9864\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9892 - val_loss: 1.9863\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9891 - val_loss: 1.9871\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9890 - val_loss: 1.9852\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9902 - val_loss: 1.9877\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9885 - val_loss: 1.9919\n",
      "Top-2 accuracy = 0.447\n",
      "4\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1451 - val_loss: 2.1023\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0701 - val_loss: 2.0348\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0207 - val_loss: 2.0179\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0142 - val_loss: 2.0026\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0089 - val_loss: 2.0069\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0061 - val_loss: 1.9977\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0047 - val_loss: 1.9956\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0025 - val_loss: 2.0035\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0023 - val_loss: 1.9941\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0006 - val_loss: 1.9969\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9989 - val_loss: 1.9951\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9977 - val_loss: 1.9979\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9956 - val_loss: 1.9907\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9974 - val_loss: 1.9925\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9943 - val_loss: 1.9915\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9971 - val_loss: 1.9920\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9960 - val_loss: 1.9907\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9948 - val_loss: 1.9898\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9939 - val_loss: 1.9914\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9933 - val_loss: 1.9916\n",
      "Top-2 accuracy = 0.447\n",
      "5\n",
      "maxabsQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1893 - val_loss: 2.1819\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1772 - val_loss: 2.1722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1695 - val_loss: 2.1660\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1648 - val_loss: 2.1624\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1622 - val_loss: 2.1604\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1607 - val_loss: 2.1592\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1599 - val_loss: 2.1587\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1594 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "6\n",
      "minmaxh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1575 - val_loss: 2.0821\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0366 - val_loss: 2.0085\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0087 - val_loss: 2.0000\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0032 - val_loss: 1.9993\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0028 - val_loss: 1.9945\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9994 - val_loss: 1.9927\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9981 - val_loss: 1.9918\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9975 - val_loss: 1.9920\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9973 - val_loss: 1.9951\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9968 - val_loss: 1.9910\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9962 - val_loss: 1.9907\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9963 - val_loss: 2.0000\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9963 - val_loss: 1.9911\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9945 - val_loss: 1.9901\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9941 - val_loss: 1.9920\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9957 - val_loss: 1.9911\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9940 - val_loss: 1.9921\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9886\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9939 - val_loss: 1.9906\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9937 - val_loss: 1.9894\n",
      "Top-2 accuracy = 0.448\n",
      "7\n",
      "minmaxa|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1781 - val_loss: 2.1613\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1597 - val_loss: 2.1587\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1584\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "8\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1513 - val_loss: 2.0919\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0508 - val_loss: 2.0168\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0100 - val_loss: 1.9987\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0021 - val_loss: 1.9956\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9989 - val_loss: 1.9931\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9969 - val_loss: 1.9908\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9909\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9965 - val_loss: 1.9887\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9951 - val_loss: 1.9890\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9937 - val_loss: 1.9920\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9951 - val_loss: 1.9901\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9937 - val_loss: 1.9892\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9930 - val_loss: 1.9882\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9939 - val_loss: 1.9888\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9930 - val_loss: 1.9889\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9923 - val_loss: 1.9889\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9927 - val_loss: 1.9899\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9924 - val_loss: 1.9884\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9931 - val_loss: 1.9881\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9915 - val_loss: 1.9894\n",
      "Top-2 accuracy = 0.447\n",
      "9\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1839 - val_loss: 2.1714\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1671 - val_loss: 2.1612\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1611 - val_loss: 2.1586\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1596 - val_loss: 2.1581\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1580\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1579\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1580\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "10\n",
      "robustm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1680 - val_loss: 2.1217\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0780 - val_loss: 2.0381\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0265 - val_loss: 2.0103\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0104 - val_loss: 2.0038\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0043 - val_loss: 2.0006\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0039 - val_loss: 1.9977\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0006 - val_loss: 1.9940\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9989 - val_loss: 1.9998\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9991 - val_loss: 1.9979\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9976 - val_loss: 1.9951\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9974 - val_loss: 1.9924\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9985 - val_loss: 1.9923\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9961 - val_loss: 1.9940\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9961 - val_loss: 1.9925\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9956 - val_loss: 1.9937\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9961 - val_loss: 1.9916\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9958 - val_loss: 1.9914\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9950 - val_loss: 1.9939\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9957 - val_loss: 1.9911\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9947 - val_loss: 1.9908\n",
      "Top-2 accuracy = 0.447\n",
      "11\n",
      "normalizew|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1704 - val_loss: 2.1210\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0685 - val_loss: 2.0336\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0235 - val_loss: 2.0091\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0116 - val_loss: 2.0035\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0064 - val_loss: 1.9986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0036 - val_loss: 2.0001\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0019 - val_loss: 1.9944\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9999 - val_loss: 1.9930\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9984 - val_loss: 1.9915\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9971 - val_loss: 1.9915\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9960 - val_loss: 1.9910\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9957 - val_loss: 1.9917\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9961 - val_loss: 1.9892\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9957 - val_loss: 1.9900\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9936 - val_loss: 1.9917\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9938 - val_loss: 1.9878\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9922\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9942 - val_loss: 1.9878\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9919 - val_loss: 1.9899\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9916 - val_loss: 1.9914\n",
      "Top-2 accuracy = 0.448\n",
      "12\n",
      "standardizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1704 - val_loss: 2.1340\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1109 - val_loss: 2.0893\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0830 - val_loss: 2.0667\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0640 - val_loss: 2.0527\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0528 - val_loss: 2.0443\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0457 - val_loss: 2.0376\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0396 - val_loss: 2.0328\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0350 - val_loss: 2.0271\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0317 - val_loss: 2.0236\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0278 - val_loss: 2.0203\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0251 - val_loss: 2.0184\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0221 - val_loss: 2.0166\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0206 - val_loss: 2.0160\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0185 - val_loss: 2.0134\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0155 - val_loss: 2.0145\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0149 - val_loss: 2.0102\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0142 - val_loss: 2.0092\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0113 - val_loss: 2.0085\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0096 - val_loss: 2.0058\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0076 - val_loss: 2.0040\n",
      "Top-2 accuracy = 0.451\n",
      "13\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 16ms/step - loss: 2.1763 - val_loss: 2.1600\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1597 - val_loss: 2.1583\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1593 - val_loss: 2.1584\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1593 - val_loss: 2.1583\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1593 - val_loss: 2.1581\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1595 - val_loss: 2.1580\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1593 - val_loss: 2.1585\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1594 - val_loss: 2.1580\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1591 - val_loss: 2.1584\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1592 - val_loss: 2.1583\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1592 - val_loss: 2.1584\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1592 - val_loss: 2.1583\n",
      "Top-2 accuracy = 0.324\n",
      "14\n",
      "maxabsB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1183 - val_loss: 2.0321\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0148 - val_loss: 1.9979\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0010 - val_loss: 1.9955\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9966 - val_loss: 1.9896\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9948 - val_loss: 1.9890\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9923 - val_loss: 1.9976\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9923 - val_loss: 1.9879\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9913 - val_loss: 1.9891\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9908 - val_loss: 1.9933\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9906 - val_loss: 1.9925\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9905 - val_loss: 1.9869\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9898 - val_loss: 1.9870\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9908 - val_loss: 1.9867\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9883 - val_loss: 1.9892\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9929 - val_loss: 1.9885\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9885 - val_loss: 1.9859\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9876 - val_loss: 2.0000\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9908 - val_loss: 1.9863\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9892 - val_loss: 1.9887\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9883 - val_loss: 1.9852\n",
      "Top-2 accuracy = 0.448\n",
      "15\n",
      "minmaxc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1830 - val_loss: 2.1527\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1025 - val_loss: 2.0656\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0567 - val_loss: 2.0418\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0389 - val_loss: 2.0276\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0277 - val_loss: 2.0187\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0207 - val_loss: 2.0143\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0162 - val_loss: 2.0097\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0140 - val_loss: 2.0098\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0115 - val_loss: 2.0040\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0096 - val_loss: 2.0036\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0085 - val_loss: 2.0026\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0091 - val_loss: 2.0010\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0067 - val_loss: 2.0007\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0060 - val_loss: 1.9999\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0061 - val_loss: 1.9991\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0054 - val_loss: 1.9992\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0051 - val_loss: 1.9987\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 1.9987\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0051 - val_loss: 1.9988\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0042 - val_loss: 1.9985\n",
      "Top-2 accuracy = 0.446\n",
      "16\n",
      "standardizeV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1712 - val_loss: 2.1387\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1156 - val_loss: 2.0820\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0686 - val_loss: 2.0450\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0429 - val_loss: 2.0285\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0301 - val_loss: 2.0198\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0225 - val_loss: 2.0146\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0181 - val_loss: 2.0120\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0153 - val_loss: 2.0085\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0133 - val_loss: 2.0075\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0120 - val_loss: 2.0060\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0102 - val_loss: 2.0048\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0089 - val_loss: 2.0035\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0081 - val_loss: 2.0026\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0070 - val_loss: 2.0018\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0062 - val_loss: 2.0012\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0055 - val_loss: 2.0008\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0049 - val_loss: 1.9996\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0042 - val_loss: 1.9992\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 1.9992\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 1.9980\n",
      "Top-2 accuracy = 0.446\n",
      "17\n",
      "maxabsv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1705 - val_loss: 2.1175\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0662 - val_loss: 2.0266\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0148 - val_loss: 2.0030\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0021 - val_loss: 2.0021\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0005 - val_loss: 1.9956\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9975 - val_loss: 1.9913\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9957 - val_loss: 1.9935\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9952 - val_loss: 1.9897\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9979 - val_loss: 1.9899\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9933 - val_loss: 1.9906\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9934 - val_loss: 1.9900\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9942 - val_loss: 1.9926\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9923 - val_loss: 1.9920\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9921 - val_loss: 1.9894\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9921 - val_loss: 2.0017\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9931 - val_loss: 2.0003\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9919 - val_loss: 1.9958\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9913 - val_loss: 1.9880\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9903 - val_loss: 2.0057\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.994 - 0s 4ms/step - loss: 1.9940 - val_loss: 1.9874\n",
      "Top-2 accuracy = 0.449\n",
      "18\n",
      "maxabsX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1382 - val_loss: 2.0898\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0745 - val_loss: 2.0462\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0319 - val_loss: 2.0240\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0070 - val_loss: 1.9971\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9976 - val_loss: 1.9957\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9937 - val_loss: 1.9887\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9919 - val_loss: 1.9943\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9903 - val_loss: 1.9855\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9888 - val_loss: 1.9951\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9917 - val_loss: 1.9884\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9883 - val_loss: 1.9845\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9879 - val_loss: 1.9937\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9894 - val_loss: 1.9872\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9872 - val_loss: 1.9871\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9876 - val_loss: 1.9859\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9890 - val_loss: 1.9848\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9866 - val_loss: 1.9878\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9877 - val_loss: 1.9871\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9870 - val_loss: 1.9944\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9862 - val_loss: 1.9872\n",
      "Top-2 accuracy = 0.451\n",
      "19\n",
      "standardizeQ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1360 - val_loss: 2.0550\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.0245 - val_loss: 1.9991\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.0007 - val_loss: 1.9968\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9969 - val_loss: 1.9904\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9931 - val_loss: 1.9899\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9904 - val_loss: 1.9929\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9936 - val_loss: 1.9943\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9913 - val_loss: 1.9892\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9888 - val_loss: 1.9907\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9894 - val_loss: 1.9920\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9890 - val_loss: 1.9872\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 1.9878 - val_loss: 1.9870\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9901 - val_loss: 1.9881\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9888 - val_loss: 1.9939\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9890 - val_loss: 1.9870\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9877 - val_loss: 1.9890\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9866 - val_loss: 1.9864\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9861 - val_loss: 1.9926\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9857 - val_loss: 1.9919\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9879 - val_loss: 1.9875\n",
      "Top-2 accuracy = 0.448\n",
      "20\n",
      "robustX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 25ms/step - loss: 2.1877 - val_loss: 2.1753\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1607 - val_loss: 2.1409\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1311 - val_loss: 2.1157\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1068 - val_loss: 2.0947\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0851 - val_loss: 2.0749\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0625 - val_loss: 2.0410\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0283 - val_loss: 2.0259\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0141 - val_loss: 2.0070\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0081 - val_loss: 2.0046\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0043 - val_loss: 1.9998\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0021 - val_loss: 1.9975\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9998 - val_loss: 1.9968\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9994 - val_loss: 1.9955\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9985 - val_loss: 1.9950\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9972 - val_loss: 1.9995\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9993 - val_loss: 1.9954\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9970 - val_loss: 1.9988\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9980 - val_loss: 1.9913\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9952 - val_loss: 1.9915\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9953 - val_loss: 1.9911\n",
      "Top-2 accuracy = 0.448\n",
      "21\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1771 - val_loss: 2.1461\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1141 - val_loss: 2.0819\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0681 - val_loss: 2.0478\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0419 - val_loss: 2.0290\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0240 - val_loss: 2.0232\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0188 - val_loss: 2.0148\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0114 - val_loss: 2.0067\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0065 - val_loss: 2.0064\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0054 - val_loss: 2.0034\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0025 - val_loss: 2.0009\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0001 - val_loss: 2.0003\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9994 - val_loss: 2.0025\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0002 - val_loss: 1.9989\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9972 - val_loss: 1.9973\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9975 - val_loss: 2.0052\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9985 - val_loss: 1.9988\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9970 - val_loss: 1.9932\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9951 - val_loss: 1.9933\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9956 - val_loss: 1.9950\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9968 - val_loss: 1.9942\n",
      "Top-2 accuracy = 0.448\n",
      "22\n",
      "minmaxR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1878 - val_loss: 2.1774\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1703 - val_loss: 2.1625\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1616 - val_loss: 2.1586\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1596 - val_loss: 2.1581\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Top-2 accuracy = 0.324\n",
      "23\n",
      "maxabse|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1832 - val_loss: 2.1605\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1362 - val_loss: 2.1087\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1003 - val_loss: 2.0841\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0815 - val_loss: 2.0687\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0681 - val_loss: 2.0577\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0586 - val_loss: 2.0488\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0512 - val_loss: 2.0446\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0457 - val_loss: 2.0364\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0396 - val_loss: 2.0326\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0365 - val_loss: 2.0297\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0325 - val_loss: 2.0265\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0299 - val_loss: 2.0232\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0273 - val_loss: 2.0232\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0259 - val_loss: 2.0193\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0233 - val_loss: 2.0175\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0223 - val_loss: 2.0184\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0214 - val_loss: 2.0157\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0200 - val_loss: 2.0145\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0190 - val_loss: 2.0145\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0179 - val_loss: 2.0127\n",
      "Top-2 accuracy = 0.444\n",
      "24\n",
      "minmaxX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1714 - val_loss: 2.1325\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0893 - val_loss: 2.0496\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0411 - val_loss: 2.0194\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0214 - val_loss: 2.0159\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0122 - val_loss: 2.0006\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0067 - val_loss: 1.9963\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0029 - val_loss: 1.9936\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0009 - val_loss: 1.9918\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0014 - val_loss: 1.9990\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0003 - val_loss: 1.9913\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9994 - val_loss: 1.9895\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9971 - val_loss: 1.9893\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9976 - val_loss: 1.9898\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9985 - val_loss: 1.9892\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9970 - val_loss: 1.9882\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9960 - val_loss: 1.9884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9958 - val_loss: 1.9883\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9871\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9957 - val_loss: 1.9952\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9955 - val_loss: 1.9879\n",
      "Top-2 accuracy = 0.449\n",
      "25\n",
      "robustH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1493 - val_loss: 2.0968\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0697 - val_loss: 2.0474\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0348 - val_loss: 2.0262\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0190 - val_loss: 2.0075\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0083 - val_loss: 1.9986\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 1.9955\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9997 - val_loss: 1.9957\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9959 - val_loss: 1.9940\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9956 - val_loss: 1.9968\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9935 - val_loss: 1.9921\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9926 - val_loss: 1.9899\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9926 - val_loss: 1.9918\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9898 - val_loss: 1.9916\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9903 - val_loss: 1.9898\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9897 - val_loss: 1.9909\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9899 - val_loss: 1.9891\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9890 - val_loss: 1.9873\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9896 - val_loss: 1.9895\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9885 - val_loss: 1.9856\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9878 - val_loss: 1.9917\n",
      "Top-2 accuracy = 0.445\n",
      "26\n",
      "minmaxK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1397 - val_loss: 2.0889\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0727 - val_loss: 2.0483\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0459 - val_loss: 2.0318\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0260 - val_loss: 2.0139\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0143 - val_loss: 2.0031\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0036 - val_loss: 1.9967\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0000 - val_loss: 1.9950\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9975 - val_loss: 1.9896\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9959 - val_loss: 1.9973\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9940 - val_loss: 1.9912\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9929 - val_loss: 1.9885\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9933 - val_loss: 1.9887\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9935 - val_loss: 1.9894\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9923 - val_loss: 1.9872\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9910 - val_loss: 1.9869\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9902 - val_loss: 1.9862\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9907 - val_loss: 1.9878\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9929 - val_loss: 1.9937\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9909 - val_loss: 1.9922\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9902 - val_loss: 1.9879\n",
      "Top-2 accuracy = 0.45\n",
      "27\n",
      "robustk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1789 - val_loss: 2.1552\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1285 - val_loss: 2.0974\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0702 - val_loss: 2.0394\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0228 - val_loss: 2.0066\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0041 - val_loss: 1.9959\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9983 - val_loss: 1.9975\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9950 - val_loss: 1.9937\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9941 - val_loss: 2.0086\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9959 - val_loss: 1.9961\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9937 - val_loss: 1.9907\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9917 - val_loss: 1.9881\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9909 - val_loss: 1.9883\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9919 - val_loss: 1.9959\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9954 - val_loss: 1.9902\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9899 - val_loss: 1.9867\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9899 - val_loss: 1.9879\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9891 - val_loss: 1.9871\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9900 - val_loss: 1.9880\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9897 - val_loss: 1.9869\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9889 - val_loss: 1.9878\n",
      "Top-2 accuracy = 0.451\n",
      "28\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1682 - val_loss: 2.1581\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1584\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1593 - val_loss: 2.1583\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1593 - val_loss: 2.1581\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1592 - val_loss: 2.1584\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1594 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "29\n",
      "robustc|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1816 - val_loss: 2.1628\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1435 - val_loss: 2.1184\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0956 - val_loss: 2.0683\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0576 - val_loss: 2.0421\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0397 - val_loss: 2.0302\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0311 - val_loss: 2.0228\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0249 - val_loss: 2.0180\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0209 - val_loss: 2.0149\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0180 - val_loss: 2.0122\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0161 - val_loss: 2.0106\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0146 - val_loss: 2.0089\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0132 - val_loss: 2.0079\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0122 - val_loss: 2.0071\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0114 - val_loss: 2.0063\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0107 - val_loss: 2.0053\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0099 - val_loss: 2.0048\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0092 - val_loss: 2.0042\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0088 - val_loss: 2.0038\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0084 - val_loss: 2.0033\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0081 - val_loss: 2.0031\n",
      "Top-2 accuracy = 0.446\n",
      "0\n",
      "maxabsC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1863 - val_loss: 2.1734\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1675 - val_loss: 2.1574\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1390 - val_loss: 2.0955\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0666 - val_loss: 2.0349\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0267 - val_loss: 2.0134\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0136 - val_loss: 2.0122\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0095 - val_loss: 2.0016\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0053 - val_loss: 1.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0038 - val_loss: 2.0046\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0043 - val_loss: 1.9976\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0029 - val_loss: 1.9973\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 1.9978\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 1.9960\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0004 - val_loss: 1.9965\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9998 - val_loss: 1.9963\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9993 - val_loss: 1.9971\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9992 - val_loss: 1.9956\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9990 - val_loss: 1.9953\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9983 - val_loss: 1.9960\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9984 - val_loss: 1.9948\n",
      "Top-2 accuracy = 0.445\n",
      "1\n",
      "standardizex|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1604 - val_loss: 2.1283\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1041 - val_loss: 2.0735\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0556 - val_loss: 2.0366\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0300 - val_loss: 2.0197\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0191 - val_loss: 2.0129\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0142 - val_loss: 2.0079\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0107 - val_loss: 2.0090\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0093 - val_loss: 2.0043\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0067 - val_loss: 2.0012\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0049 - val_loss: 1.9990\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0043 - val_loss: 1.9983\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0029 - val_loss: 1.9974\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0027 - val_loss: 1.9970\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0021 - val_loss: 1.9971\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0007 - val_loss: 1.9958\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0000 - val_loss: 1.9950\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9991 - val_loss: 1.9948\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9983 - val_loss: 1.9940\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9989 - val_loss: 1.9933\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9974 - val_loss: 1.9934\n",
      "Top-2 accuracy = 0.446\n",
      "2\n",
      "robustf|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1763 - val_loss: 2.1383\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0911 - val_loss: 2.0545\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0376 - val_loss: 2.0199\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0180 - val_loss: 2.0091\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0101 - val_loss: 2.0029\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0055 - val_loss: 1.9973\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0022 - val_loss: 1.9959\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0007 - val_loss: 1.9968\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0002 - val_loss: 1.9951\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9988 - val_loss: 1.9918\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9980 - val_loss: 1.9930\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9962 - val_loss: 1.9907\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9952 - val_loss: 1.9901\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9916\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9959 - val_loss: 1.9921\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9949 - val_loss: 1.9924\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9953 - val_loss: 1.9895\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9933 - val_loss: 1.9900\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9933 - val_loss: 1.9890\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9922 - val_loss: 1.9893\n",
      "Top-2 accuracy = 0.446\n",
      "3\n",
      "standardizet|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1319 - val_loss: 2.0812\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0605 - val_loss: 2.0326\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0297 - val_loss: 2.0174\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0175 - val_loss: 2.0112\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0134 - val_loss: 2.0176\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0118 - val_loss: 2.0049\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0073 - val_loss: 2.0013\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0042 - val_loss: 1.9984\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0035 - val_loss: 2.0042\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0019 - val_loss: 1.9977\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0032 - val_loss: 1.9996\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9998 - val_loss: 1.9942\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9975 - val_loss: 1.9987\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9980 - val_loss: 1.9944\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9976 - val_loss: 1.9930\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9955 - val_loss: 1.9933\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9959 - val_loss: 1.9919\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9953 - val_loss: 1.9989\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9959 - val_loss: 1.9943\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9942 - val_loss: 1.9907\n",
      "Top-2 accuracy = 0.448\n",
      "4\n",
      "standardizeB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1895 - val_loss: 2.1820\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1774 - val_loss: 2.1722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1696 - val_loss: 2.1660\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1649 - val_loss: 2.1625\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1622 - val_loss: 2.1603\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1606 - val_loss: 2.1592\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1598 - val_loss: 2.1586\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1594 - val_loss: 2.1583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1583\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "5\n",
      "minmaxr|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1707 - val_loss: 2.1462\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1307 - val_loss: 2.1210\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1051 - val_loss: 2.0948\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0853 - val_loss: 2.0776\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0678 - val_loss: 2.0704\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0558 - val_loss: 2.0485\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0424 - val_loss: 2.0383\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0360 - val_loss: 2.0315\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0290 - val_loss: 2.0242\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0229 - val_loss: 2.0219\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0198 - val_loss: 2.0199\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0156 - val_loss: 2.0128\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0125 - val_loss: 2.0142\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0103 - val_loss: 2.0082\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0082 - val_loss: 2.0115\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0084 - val_loss: 2.0038\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0049 - val_loss: 2.0023\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0103 - val_loss: 1.9999\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0028 - val_loss: 2.0019\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0051 - val_loss: 2.0018\n",
      "Top-2 accuracy = 0.445\n",
      "6\n",
      "minmaxi|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1711 - val_loss: 2.1406\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1157 - val_loss: 2.0954\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0702 - val_loss: 2.0447\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0279 - val_loss: 2.0179\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0126 - val_loss: 2.0014\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0089 - val_loss: 2.0126\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0027 - val_loss: 1.9963\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9995 - val_loss: 1.9955\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9987 - val_loss: 2.0121\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0012 - val_loss: 1.9937\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9983 - val_loss: 1.9970\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0007 - val_loss: 1.9936\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9969 - val_loss: 1.9915\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9991 - val_loss: 1.9937\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9965 - val_loss: 1.9967\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9970 - val_loss: 1.9923\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9965 - val_loss: 1.9994\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9963 - val_loss: 1.9940\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9979 - val_loss: 1.9966\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9960 - val_loss: 1.9913\n",
      "Top-2 accuracy = 0.449\n",
      "7\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1634 - val_loss: 2.1188\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0945 - val_loss: 2.0731\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0686 - val_loss: 2.0541\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0540 - val_loss: 2.0418\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0441 - val_loss: 2.0355\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0347 - val_loss: 2.0250\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0277 - val_loss: 2.0218\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0224 - val_loss: 2.0146\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0173 - val_loss: 2.0124\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0153 - val_loss: 2.0084\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0118 - val_loss: 2.0142\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0106 - val_loss: 2.0059\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0078 - val_loss: 2.0032\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0074 - val_loss: 1.9999\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0039 - val_loss: 2.0004\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0053 - val_loss: 1.9976\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0026 - val_loss: 1.9999\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0036 - val_loss: 1.9970\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0009 - val_loss: 1.9942\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0008 - val_loss: 1.9946\n",
      "Top-2 accuracy = 0.448\n",
      "8\n",
      "maxabsP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1730 - val_loss: 2.1590\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1594 - val_loss: 2.1582\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1581\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1585\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1583\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1585\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1583\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1595 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1591 - val_loss: 2.1585\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "9\n",
      "robusti|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1419 - val_loss: 2.0894\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0787 - val_loss: 2.0557\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0507 - val_loss: 2.0378\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0333 - val_loss: 2.0220\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0221 - val_loss: 2.0144\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0135 - val_loss: 2.0183\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0133 - val_loss: 2.0074\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0065 - val_loss: 2.0003\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0025 - val_loss: 2.0120\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0016 - val_loss: 1.9983\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0037 - val_loss: 1.9989\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9993 - val_loss: 1.9960\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9974 - val_loss: 1.9945\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9971 - val_loss: 1.9942\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9959 - val_loss: 1.9948\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9956 - val_loss: 1.9932\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9961 - val_loss: 1.9970\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9965 - val_loss: 1.9965\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9956 - val_loss: 1.9919\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9950 - val_loss: 1.9925\n",
      "Top-2 accuracy = 0.449\n",
      "10\n",
      "normalizef|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1712 - val_loss: 2.1268\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0836 - val_loss: 2.0456\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0333 - val_loss: 2.0164\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0131 - val_loss: 2.0040\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0057 - val_loss: 1.9993\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0036 - val_loss: 1.9967\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0010 - val_loss: 1.9959\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9964\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9994 - val_loss: 1.9945\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9943\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9976 - val_loss: 1.9926\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9970 - val_loss: 1.9916\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9962 - val_loss: 1.9924\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9964 - val_loss: 1.9916\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9956 - val_loss: 1.9910\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9945 - val_loss: 1.9913\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9951 - val_loss: 1.9900\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9943 - val_loss: 1.9892\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9939 - val_loss: 1.9890\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9935 - val_loss: 1.9904\n",
      "Top-2 accuracy = 0.447\n",
      "11\n",
      "robustG|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1776 - val_loss: 2.1641\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1632 - val_loss: 2.1594\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1603 - val_loss: 2.1585\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1594 - val_loss: 2.1581\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "12\n",
      "maxabsy|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1896 - val_loss: 2.1821\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1775 - val_loss: 2.1724\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1698 - val_loss: 2.1663\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1652 - val_loss: 2.1627\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1623 - val_loss: 2.1605\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1608 - val_loss: 2.1594\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1599 - val_loss: 2.1587\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1595 - val_loss: 2.1585\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1583\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "13\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1895 - val_loss: 2.1820\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1773 - val_loss: 2.1722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1698 - val_loss: 2.1662\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1652 - val_loss: 2.1626\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1624 - val_loss: 2.1604\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1608 - val_loss: 2.1593\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1599 - val_loss: 2.1586\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1594 - val_loss: 2.1583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "14\n",
      "maxabsF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1575 - val_loss: 2.1007\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0622 - val_loss: 2.0288\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0235 - val_loss: 2.0107\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0095 - val_loss: 2.0028\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0040 - val_loss: 1.9991\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9991 - val_loss: 1.9955\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9959 - val_loss: 1.9975\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9967 - val_loss: 1.9922\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9935 - val_loss: 1.9926\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9924 - val_loss: 1.9906\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9915 - val_loss: 1.9895\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9918 - val_loss: 1.9886\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9903 - val_loss: 1.9895\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9897 - val_loss: 1.9876\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9891 - val_loss: 1.9883\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9889 - val_loss: 1.9936\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9905 - val_loss: 1.9887\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9882 - val_loss: 1.9880\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9876 - val_loss: 1.9876\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9882 - val_loss: 1.9857\n",
      "Top-2 accuracy = 0.45\n",
      "15\n",
      "maxabsk|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1895 - val_loss: 2.1821\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1775 - val_loss: 2.1724\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1699 - val_loss: 2.1664\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1651 - val_loss: 2.1625\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1623 - val_loss: 2.1605\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1607 - val_loss: 2.1593\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1599 - val_loss: 2.1587\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1594 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "16\n",
      "robustI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1556 - val_loss: 2.0957\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0565 - val_loss: 2.0279\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0266 - val_loss: 2.0127\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0175 - val_loss: 2.0072\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0122 - val_loss: 2.0064\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0104 - val_loss: 2.0062\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0065 - val_loss: 2.0043\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0059 - val_loss: 2.0036\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0033 - val_loss: 2.0010\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0024 - val_loss: 2.0001\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0015 - val_loss: 1.9970\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0006 - val_loss: 1.9986\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0015 - val_loss: 2.0001\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0027 - val_loss: 1.9981\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9981 - val_loss: 1.9967\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0004 - val_loss: 1.9954\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9991 - val_loss: 1.9943\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9993 - val_loss: 1.9975\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9979 - val_loss: 1.9984\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9977 - val_loss: 1.9940\n",
      "Top-2 accuracy = 0.445\n",
      "17\n",
      "minmaxY|rf\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_1240 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1858 - val_loss: 2.1733\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1631 - val_loss: 2.1446\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1351 - val_loss: 2.1176\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.1083 - val_loss: 2.0925\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0873 - val_loss: 2.0776\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0720 - val_loss: 2.0626\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0595 - val_loss: 2.0547\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0506 - val_loss: 2.0448\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0433 - val_loss: 2.0374\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0375 - val_loss: 2.0335\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0346 - val_loss: 2.0315\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0320 - val_loss: 2.0284\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0297 - val_loss: 2.0263\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0279 - val_loss: 2.0249\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0265 - val_loss: 2.0242\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0253 - val_loss: 2.0245\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0245 - val_loss: 2.0206\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0226 - val_loss: 2.0193\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0217 - val_loss: 2.0182\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 2.0206 - val_loss: 2.0169\n",
      "Top-2 accuracy = 0.434\n",
      "18\n",
      "robustP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1700 - val_loss: 2.1398\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0990 - val_loss: 2.0537\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0354 - val_loss: 2.0118\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0104 - val_loss: 1.9983\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0017 - val_loss: 1.9946\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9980 - val_loss: 1.9925\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9977 - val_loss: 1.9908\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9907\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9947 - val_loss: 1.9936\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9953 - val_loss: 1.9879\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9936 - val_loss: 1.9884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9928 - val_loss: 1.9881\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9935 - val_loss: 1.9870\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9919 - val_loss: 1.9862\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9915 - val_loss: 1.9868\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9915 - val_loss: 1.9867\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9914 - val_loss: 1.9909\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9918 - val_loss: 1.9854\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9905 - val_loss: 1.9852\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9909 - val_loss: 1.9860\n",
      "Top-2 accuracy = 0.448\n",
      "19\n",
      "maxabsJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1769 - val_loss: 2.1363\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0973 - val_loss: 2.0595\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0393 - val_loss: 2.0156\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0089 - val_loss: 2.0021\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0024 - val_loss: 1.9937\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9965 - val_loss: 1.9973\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9943 - val_loss: 2.0004\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9939 - val_loss: 1.9891\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9926 - val_loss: 1.9881\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9916 - val_loss: 1.9880\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9906 - val_loss: 1.9871\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9918 - val_loss: 1.9875\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9908 - val_loss: 1.9870\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9901 - val_loss: 1.9899\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9934 - val_loss: 1.9873\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9895 - val_loss: 1.9890\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9891 - val_loss: 1.9880\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9896 - val_loss: 1.9907\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9890 - val_loss: 1.9860\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9884 - val_loss: 1.9852\n",
      "Top-2 accuracy = 0.449\n",
      "20\n",
      "normalizeS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1893 - val_loss: 2.1818\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1773 - val_loss: 2.1722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1697 - val_loss: 2.1661\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1651 - val_loss: 2.1625\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1622 - val_loss: 2.1604\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1608 - val_loss: 2.1593\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1599 - val_loss: 2.1588\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1594 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1593 - val_loss: 2.1583\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "21\n",
      "maxabsd|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 18ms/step - loss: 2.1703 - val_loss: 2.1586\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1593 - val_loss: 2.1580\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1594 - val_loss: 2.1578\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1585 - val_loss: 2.1544\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1431 - val_loss: 2.1173\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1020 - val_loss: 2.0965\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1019 - val_loss: 2.1028\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1047 - val_loss: 2.1036\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1049 - val_loss: 2.1031\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1047 - val_loss: 2.1031\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1045 - val_loss: 2.1027\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1044 - val_loss: 2.1029\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1044 - val_loss: 2.1027\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1048 - val_loss: 2.1028\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1044 - val_loss: 2.1027\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1044 - val_loss: 2.1027\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1043 - val_loss: 2.1022\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1044 - val_loss: 2.1024\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1044 - val_loss: 2.1022\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1045 - val_loss: 2.1026\n",
      "Top-2 accuracy = 0.359\n",
      "22\n",
      "normalizeH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1892 - val_loss: 2.1817\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1771 - val_loss: 2.1722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1695 - val_loss: 2.1661\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1650 - val_loss: 2.1626\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1623 - val_loss: 2.1605\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1607 - val_loss: 2.1593\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1598 - val_loss: 2.1587\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1593 - val_loss: 2.1583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "23\n",
      "standardizej|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1284 - val_loss: 2.0724\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0566 - val_loss: 2.0354\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0290 - val_loss: 2.0173\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0181 - val_loss: 2.0100\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0114 - val_loss: 2.0043\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0078 - val_loss: 2.0020\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0053 - val_loss: 1.9991\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0029 - val_loss: 1.9982\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0015 - val_loss: 1.9959\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9998 - val_loss: 1.9934\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9979 - val_loss: 1.9942\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9971 - val_loss: 1.9920\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9966 - val_loss: 1.9916\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9965 - val_loss: 1.9907\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9948 - val_loss: 1.9902\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9938 - val_loss: 1.9900\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9939 - val_loss: 1.9906\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9933 - val_loss: 1.9898\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9936 - val_loss: 1.9883\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9933 - val_loss: 1.9883\n",
      "Top-2 accuracy = 0.447\n",
      "24\n",
      "normalizeJ|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1866 - val_loss: 2.1764\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1706 - val_loss: 2.1651\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1634 - val_loss: 2.1608\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1608 - val_loss: 2.1591\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1597 - val_loss: 2.1585\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1592 - val_loss: 2.1583\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "25\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1564 - val_loss: 2.1127\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0766 - val_loss: 2.0421\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0248 - val_loss: 2.0110\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0071 - val_loss: 2.0027\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0012 - val_loss: 1.9988\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 1.9976 - val_loss: 1.9941\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 1.9942 - val_loss: 1.9919\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9927 - val_loss: 1.9922\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9920 - val_loss: 1.9930\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9905 - val_loss: 1.9909\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9917 - val_loss: 1.9911\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9929 - val_loss: 1.9978\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9904 - val_loss: 1.9892\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9892 - val_loss: 1.9914\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9893 - val_loss: 1.9896\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9884 - val_loss: 1.9930\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9887 - val_loss: 1.9911\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9878 - val_loss: 1.9899\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9877 - val_loss: 1.9892\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9877 - val_loss: 1.9982\n",
      "Top-2 accuracy = 0.444\n",
      "26\n",
      "robustv|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1439 - val_loss: 2.0716\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0405 - val_loss: 2.0102\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0068 - val_loss: 2.0097\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0008 - val_loss: 1.9933\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9948 - val_loss: 1.9911\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9934 - val_loss: 1.9914\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9929 - val_loss: 1.9919\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9916 - val_loss: 1.9912\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9911 - val_loss: 1.9889\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9904 - val_loss: 1.9930\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 1.9919 - val_loss: 1.9884\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9885 - val_loss: 1.9879\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9905 - val_loss: 1.9888\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9872 - val_loss: 1.9861\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9873 - val_loss: 1.9879\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9860 - val_loss: 1.9884\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9872 - val_loss: 1.9928\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9918 - val_loss: 1.9867\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9861 - val_loss: 1.9868\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9867 - val_loss: 1.9880\n",
      "Top-2 accuracy = 0.447\n",
      "27\n",
      "minmaxH|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1480 - val_loss: 2.0733\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0422 - val_loss: 2.0112\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0080 - val_loss: 1.9977\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0024 - val_loss: 2.0004\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9987 - val_loss: 2.0031\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9957 - val_loss: 1.9901\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9935 - val_loss: 1.9895\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9973 - val_loss: 1.9910\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9939 - val_loss: 1.9943\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9929 - val_loss: 1.9890\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9917 - val_loss: 2.0162\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9975 - val_loss: 1.9948\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9923 - val_loss: 1.9880\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9917 - val_loss: 1.9883\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9908 - val_loss: 1.9927\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9897 - val_loss: 1.9870\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9917 - val_loss: 1.9897\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9905 - val_loss: 1.9863\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9898 - val_loss: 1.9872\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9901 - val_loss: 1.9864\n",
      "Top-2 accuracy = 0.45\n",
      "28\n",
      "robustU|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1650 - val_loss: 2.1390\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1189 - val_loss: 2.1057\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0933 - val_loss: 2.0860\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0764 - val_loss: 2.0709\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0633 - val_loss: 2.0591\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0523 - val_loss: 2.0487\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0439 - val_loss: 2.0418\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0366 - val_loss: 2.0346\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0306 - val_loss: 2.0300\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0269 - val_loss: 2.0245\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0227 - val_loss: 2.0206\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0200 - val_loss: 2.0182\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0172 - val_loss: 2.0151\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0151 - val_loss: 2.0125\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0135 - val_loss: 2.0110\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0117 - val_loss: 2.0089\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0101 - val_loss: 2.0078\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0091 - val_loss: 2.0065\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0086 - val_loss: 2.0074\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0080 - val_loss: 2.0046\n",
      "Top-2 accuracy = 0.446\n",
      "29\n",
      "maxabss|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1645 - val_loss: 2.1223\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0757 - val_loss: 2.0263\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0149 - val_loss: 2.0010\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0028 - val_loss: 1.9974\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9988 - val_loss: 1.9928\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9972 - val_loss: 1.9930\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9959 - val_loss: 1.9907\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9949 - val_loss: 1.9922\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9937 - val_loss: 1.9890\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9930 - val_loss: 1.9957\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9932 - val_loss: 1.9908\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9921 - val_loss: 1.9889\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9912 - val_loss: 1.9883\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9914 - val_loss: 1.9900\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9907 - val_loss: 1.9886\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9915 - val_loss: 1.9881\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9904 - val_loss: 1.9894\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9903 - val_loss: 1.9875\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9904 - val_loss: 1.9887\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9869\n",
      "Top-2 accuracy = 0.448\n",
      "0\n",
      "minmaxX|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 2.1897 - val_loss: 2.1821\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1773 - val_loss: 2.1722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1692 - val_loss: 2.1656\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1641 - val_loss: 2.1616\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1613 - val_loss: 2.1598\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1600 - val_loss: 2.1588\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1594 - val_loss: 2.1584\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "1\n",
      "maxabsO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 2.1438 - val_loss: 2.0792\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0619 - val_loss: 2.0392\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0404 - val_loss: 2.0243\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0264 - val_loss: 2.0201\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0223 - val_loss: 2.0413\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0233 - val_loss: 2.0094\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0126 - val_loss: 2.0132\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0115 - val_loss: 2.0053\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0088 - val_loss: 2.0094\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0069 - val_loss: 2.0044\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0064 - val_loss: 1.9995\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0066 - val_loss: 1.9992\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0027 - val_loss: 1.9982\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0031 - val_loss: 1.9986\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0043 - val_loss: 1.9971\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0033 - val_loss: 1.9963\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9996 - val_loss: 1.9954\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0003 - val_loss: 1.9979\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9984 - val_loss: 1.9984\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9996 - val_loss: 1.9963\n",
      "Top-2 accuracy = 0.451\n",
      "2\n",
      "minmaxA|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1815 - val_loss: 2.1709\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1653 - val_loss: 2.1604\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1602 - val_loss: 2.1583\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1593 - val_loss: 2.1580\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1584\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "3\n",
      "standardizeh|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 2s 19ms/step - loss: 2.1656 - val_loss: 2.1197\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 2.1060 - val_loss: 2.0943\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 2.0917 - val_loss: 2.0861\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0886 - val_loss: 2.0851\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0879 - val_loss: 2.0847\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0877 - val_loss: 2.0852\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0877 - val_loss: 2.0852\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0873 - val_loss: 2.0857\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0876 - val_loss: 2.0854\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0875 - val_loss: 2.0850\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0875 - val_loss: 2.0850\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0872 - val_loss: 2.0854\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0872 - val_loss: 2.0860\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0872 - val_loss: 2.0847\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0875 - val_loss: 2.0851\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0874 - val_loss: 2.0846\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.0871 - val_loss: 2.0849\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.0872 - val_loss: 2.0846\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.0871 - val_loss: 2.0846\n",
      "Top-2 accuracy = 0.387\n",
      "4\n",
      "normalizeP|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1611 - val_loss: 2.0928\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0524 - val_loss: 2.0219\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0212 - val_loss: 2.0161\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0124 - val_loss: 2.0029\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0068 - val_loss: 1.9996\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0040 - val_loss: 1.9971\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0012 - val_loss: 1.9951\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9985 - val_loss: 1.9963\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9981 - val_loss: 1.9933\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9968 - val_loss: 1.9916\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9940 - val_loss: 1.9919\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9935 - val_loss: 1.9912\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9930 - val_loss: 1.9891\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9915 - val_loss: 1.9889\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9917 - val_loss: 1.9880\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9912 - val_loss: 1.9879\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9904 - val_loss: 1.9876\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9893 - val_loss: 1.9913\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9896 - val_loss: 1.9887\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9908\n",
      "Top-2 accuracy = 0.448\n",
      "5\n",
      "minmaxB|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1822 - val_loss: 2.1520\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1063 - val_loss: 2.0680\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0381 - val_loss: 2.0124\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0154 - val_loss: 2.0019\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0037 - val_loss: 2.0003\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0017 - val_loss: 2.0356\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0050 - val_loss: 1.9938\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0004 - val_loss: 1.9933\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9978 - val_loss: 1.9997\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9984 - val_loss: 1.9981\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9977 - val_loss: 1.9913\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9987 - val_loss: 1.9925\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9976 - val_loss: 2.0011\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9975 - val_loss: 1.9913\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9966 - val_loss: 1.9974\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9962 - val_loss: 1.9904\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9958 - val_loss: 1.9900\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9957 - val_loss: 1.9894\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9961 - val_loss: 1.9906\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9966 - val_loss: 1.9887\n",
      "Top-2 accuracy = 0.448\n",
      "6\n",
      "minmaxI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1808 - val_loss: 2.1696\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1651 - val_loss: 2.1611\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1607 - val_loss: 2.1590\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1595 - val_loss: 2.1583\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1593 - val_loss: 2.1581\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1581\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1585\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "7\n",
      "standardizeE|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1746 - val_loss: 2.1502\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1271 - val_loss: 2.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0867 - val_loss: 2.0681\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0602 - val_loss: 2.0483\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0443 - val_loss: 2.0365\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0348 - val_loss: 2.0281\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0285 - val_loss: 2.0231\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0240 - val_loss: 2.0198\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0212 - val_loss: 2.0163\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0186 - val_loss: 2.0145\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0169 - val_loss: 2.0121\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0158 - val_loss: 2.0107\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0147 - val_loss: 2.0098\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0138 - val_loss: 2.0090\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0134 - val_loss: 2.0085\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0126 - val_loss: 2.0084\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0124 - val_loss: 2.0068\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0112 - val_loss: 2.0068\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0113 - val_loss: 2.0067\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0102 - val_loss: 2.0049\n",
      "Top-2 accuracy = 0.445\n",
      "8\n",
      "normalizeT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1761 - val_loss: 2.1391\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1161 - val_loss: 2.0885\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0820 - val_loss: 2.0629\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0618 - val_loss: 2.0472\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0476 - val_loss: 2.0350\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0370 - val_loss: 2.0247\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0291 - val_loss: 2.0180\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0221 - val_loss: 2.0146\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0182 - val_loss: 2.0105\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0151 - val_loss: 2.0086\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0130 - val_loss: 2.0070\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0112 - val_loss: 2.0063\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0101 - val_loss: 2.0031\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0082 - val_loss: 2.0017\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0072 - val_loss: 2.0009\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0067 - val_loss: 2.0015\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0059 - val_loss: 1.9990\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0053 - val_loss: 1.9986\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0043 - val_loss: 1.9991\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0040 - val_loss: 1.9971\n",
      "Top-2 accuracy = 0.446\n",
      "9\n",
      "maxabsK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1565 - val_loss: 2.1314\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1129 - val_loss: 2.0964\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0805 - val_loss: 2.0669\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0544 - val_loss: 2.0433\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0340 - val_loss: 2.0233\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0190 - val_loss: 2.0095\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0095 - val_loss: 2.0028\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0046 - val_loss: 1.9988\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0013 - val_loss: 2.0023\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0011 - val_loss: 1.9953\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9997 - val_loss: 1.9942\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9990 - val_loss: 1.9953\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9979 - val_loss: 1.9968\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9986 - val_loss: 1.9933\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9971 - val_loss: 1.9916\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9965 - val_loss: 1.9919\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9963 - val_loss: 1.9909\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9959 - val_loss: 1.9903\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9950 - val_loss: 1.9906\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9949 - val_loss: 1.9934\n",
      "Top-2 accuracy = 0.446\n",
      "10\n",
      "normalizeK|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1879 - val_loss: 2.1785\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1734 - val_loss: 2.1676\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1658 - val_loss: 2.1625\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1619 - val_loss: 2.1598\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1603 - val_loss: 2.1587\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1595 - val_loss: 2.1583\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1580\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "11\n",
      "standardizem|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1780 - val_loss: 2.1555\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1348 - val_loss: 2.1089\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0947 - val_loss: 2.0734\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0666 - val_loss: 2.0501\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0459 - val_loss: 2.0334\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0309 - val_loss: 2.0209\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0213 - val_loss: 2.0141\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0162 - val_loss: 2.0104\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0127 - val_loss: 2.0072\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0108 - val_loss: 2.0063\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0084 - val_loss: 2.0054\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0073 - val_loss: 2.0027\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0057 - val_loss: 2.0023\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0051 - val_loss: 2.0003\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0038 - val_loss: 1.9994\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0030 - val_loss: 2.0011\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0026 - val_loss: 1.9983\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0016 - val_loss: 1.9977\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0013 - val_loss: 1.9980\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0012 - val_loss: 1.9971\n",
      "Top-2 accuracy = 0.447\n",
      "12\n",
      "normalizeC|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1697 - val_loss: 2.1415\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1248 - val_loss: 2.1064\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0884 - val_loss: 2.0686\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0564 - val_loss: 2.0445\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0343 - val_loss: 2.0269\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0250 - val_loss: 2.0196\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0192 - val_loss: 2.0139\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0168 - val_loss: 2.0165\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0149 - val_loss: 2.0097\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0152 - val_loss: 2.0067\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0106 - val_loss: 2.0051\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0109 - val_loss: 2.0039\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0078 - val_loss: 2.0041\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0065 - val_loss: 2.0006\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0063 - val_loss: 2.0023\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0070 - val_loss: 1.9997\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0065 - val_loss: 2.0047\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0053 - val_loss: 1.9992\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0054 - val_loss: 2.0078\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0066 - val_loss: 2.0060\n",
      "Top-2 accuracy = 0.443\n",
      "13\n",
      "standardizeI|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1672 - val_loss: 2.1307\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1054 - val_loss: 2.0779\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0582 - val_loss: 2.0356\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0283 - val_loss: 2.0222\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0147 - val_loss: 2.0059\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0077 - val_loss: 2.0043\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0045 - val_loss: 1.9990\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0017 - val_loss: 1.9975\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0002 - val_loss: 2.0036\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0002 - val_loss: 1.9940\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9984 - val_loss: 1.9998\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9976 - val_loss: 1.9924\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9968 - val_loss: 1.9906\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9898\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9961 - val_loss: 1.9909\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9951 - val_loss: 1.9902\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9949 - val_loss: 1.9897\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9945 - val_loss: 1.9931\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9956 - val_loss: 1.9889\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9954 - val_loss: 1.9892\n",
      "Top-2 accuracy = 0.449\n",
      "14\n",
      "minmaxF|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1894 - val_loss: 2.1819\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1773 - val_loss: 2.1722\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1696 - val_loss: 2.1660\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1649 - val_loss: 2.1624\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1622 - val_loss: 2.1603\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1607 - val_loss: 2.1592\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1598 - val_loss: 2.1586\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1594 - val_loss: 2.1583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "15\n",
      "maxabsn|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1899 - val_loss: 2.1820\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1774 - val_loss: 2.1723\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1697 - val_loss: 2.1662\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1651 - val_loss: 2.1627\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1623 - val_loss: 2.1605\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1607 - val_loss: 2.1593\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1599 - val_loss: 2.1588\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1594 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "16\n",
      "standardizeW|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1552 - val_loss: 2.0929\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0779 - val_loss: 2.0522\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0462 - val_loss: 2.0273\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0242 - val_loss: 2.0210\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0113 - val_loss: 2.0195\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0036 - val_loss: 2.0126\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9994 - val_loss: 2.0024\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9972 - val_loss: 2.0434\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0017 - val_loss: 1.9937\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9978 - val_loss: 1.9939\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9962 - val_loss: 2.0210\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0022 - val_loss: 1.9978\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9960 - val_loss: 1.9944\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9962 - val_loss: 2.0012\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9962 - val_loss: 1.9911\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9942 - val_loss: 2.0063\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9951 - val_loss: 1.9916\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9935 - val_loss: 1.9903\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9932 - val_loss: 1.9972\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9943 - val_loss: 1.9922\n",
      "Top-2 accuracy = 0.448\n",
      "17\n",
      "robustm|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1525 - val_loss: 2.0986\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0545 - val_loss: 2.0167\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0111 - val_loss: 1.9991\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0008 - val_loss: 1.9965\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9987 - val_loss: 1.9952\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9958 - val_loss: 1.9935\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9957 - val_loss: 1.9902\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9938 - val_loss: 1.9894\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9928 - val_loss: 1.9895\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9923 - val_loss: 1.9890\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9917 - val_loss: 1.9911\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9916 - val_loss: 1.9884\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9908 - val_loss: 1.9880\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9899 - val_loss: 1.9885\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9897 - val_loss: 1.9953\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9920 - val_loss: 1.9876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9888 - val_loss: 1.9883\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9893 - val_loss: 1.9875\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9892 - val_loss: 1.9897\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9906 - val_loss: 1.9871\n",
      "Top-2 accuracy = 0.45\n",
      "18\n",
      "robuste|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 14ms/step - loss: 2.1721 - val_loss: 2.1585\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1597 - val_loss: 2.1590\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1595 - val_loss: 2.1586\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1594 - val_loss: 2.1589\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1593 - val_loss: 2.1584\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1594 - val_loss: 2.1586\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1596 - val_loss: 2.1588\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1597 - val_loss: 2.1584\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1593 - val_loss: 2.1583\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1594 - val_loss: 2.1582\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1594 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1594 - val_loss: 2.1583\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1596 - val_loss: 2.1584\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1593 - val_loss: 2.1583\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1596 - val_loss: 2.1584\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1593 - val_loss: 2.1585\n",
      "Top-2 accuracy = 0.324\n",
      "19\n",
      "maxabsT|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1857 - val_loss: 2.1734\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1673 - val_loss: 2.1624\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1611 - val_loss: 2.1590\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1595 - val_loss: 2.1583\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1583\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1580\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1591 - val_loss: 2.1580\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "20\n",
      "minmaxs|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1870 - val_loss: 2.1746\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1592 - val_loss: 2.1309\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1121 - val_loss: 2.0987\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0864 - val_loss: 2.0787\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0692 - val_loss: 2.0683\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0574 - val_loss: 2.0549\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0472 - val_loss: 2.0426\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0388 - val_loss: 2.0354\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0322 - val_loss: 2.0288\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0263 - val_loss: 2.0231\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0220 - val_loss: 2.0203\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0195 - val_loss: 2.0154\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0164 - val_loss: 2.0120\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0137 - val_loss: 2.0126\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0125 - val_loss: 2.0078\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0105 - val_loss: 2.0074\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0095 - val_loss: 2.0087\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0088 - val_loss: 2.0061\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0073 - val_loss: 2.0031\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0065 - val_loss: 2.0053\n",
      "Top-2 accuracy = 0.448\n",
      "21\n",
      "standardizeR|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1425 - val_loss: 2.0642\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0353 - val_loss: 2.0070\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0012 - val_loss: 1.9940\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9974 - val_loss: 1.9897\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9936 - val_loss: 1.9897\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9927 - val_loss: 1.9873\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9907 - val_loss: 1.9934\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9908 - val_loss: 1.9905\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9894 - val_loss: 1.9868\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9897 - val_loss: 1.9918\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9909 - val_loss: 1.9867\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9873 - val_loss: 1.9865\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9864 - val_loss: 1.9870\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9862 - val_loss: 1.9852\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9868 - val_loss: 1.9913\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9878 - val_loss: 1.9855\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9852 - val_loss: 1.9839\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9874 - val_loss: 1.9863\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9842 - val_loss: 1.9857\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9849 - val_loss: 1.9888\n",
      "Top-2 accuracy = 0.444\n",
      "22\n",
      "standardizez|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 2.1643 - val_loss: 2.1013\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0477 - val_loss: 2.0172\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0094 - val_loss: 1.9971\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9985 - val_loss: 2.0048\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9981 - val_loss: 2.0056\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0017 - val_loss: 1.9927\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9935 - val_loss: 1.9893\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9923 - val_loss: 1.9952\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 1.9946 - val_loss: 1.9875\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9900 - val_loss: 1.9904\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9906 - val_loss: 1.9876\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9894 - val_loss: 1.9873\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9912 - val_loss: 1.9880\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9889 - val_loss: 1.9894\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9895 - val_loss: 1.9880\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9891 - val_loss: 1.9865\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9886 - val_loss: 1.9889\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9895 - val_loss: 1.9875\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9878 - val_loss: 1.9854\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 1.9873 - val_loss: 1.9864\n",
      "Top-2 accuracy = 0.448\n",
      "23\n",
      "normalizey|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1723 - val_loss: 2.1583\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1372 - val_loss: 2.1030\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0751 - val_loss: 2.0563\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0360 - val_loss: 2.0238\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0171 - val_loss: 2.0064\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0076 - val_loss: 2.0071\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0045 - val_loss: 1.9998\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0016 - val_loss: 1.9953\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9996 - val_loss: 1.9949\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9980 - val_loss: 1.9967\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9973 - val_loss: 1.9930\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9965 - val_loss: 1.9906\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9955 - val_loss: 1.9923\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9948 - val_loss: 1.9891\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9938 - val_loss: 1.9924\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9938 - val_loss: 1.9876\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9923 - val_loss: 1.9874\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9950 - val_loss: 1.9886\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9922 - val_loss: 1.9864\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9917 - val_loss: 1.9942\n",
      "Top-2 accuracy = 0.444\n",
      "24\n",
      "robustS|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 2.1732 - val_loss: 2.1593\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1597 - val_loss: 2.1581\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1594 - val_loss: 2.1583\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1592 - val_loss: 2.1583\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1594 - val_loss: 2.1586\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1580\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1594 - val_loss: 2.1581\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1584\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1581\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1583\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1593 - val_loss: 2.1582\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1592 - val_loss: 2.1582\n",
      "Top-2 accuracy = 0.324\n",
      "25\n",
      "robustx|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 2.1894 - val_loss: 2.1819\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1773 - val_loss: 2.1721\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1696 - val_loss: 2.1660\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1648 - val_loss: 2.1624\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1620 - val_loss: 2.1603\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1605 - val_loss: 2.1592\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1597 - val_loss: 2.1586\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1593 - val_loss: 2.1583\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1582\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1582\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1590 - val_loss: 2.1581\n",
      "Top-2 accuracy = 0.324\n",
      "26\n",
      "standardizeO|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.1630 - val_loss: 2.1335\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.1122 - val_loss: 2.1000\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0866 - val_loss: 2.0792\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0691 - val_loss: 2.0626\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0524 - val_loss: 2.0451\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0356 - val_loss: 2.0265\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0199 - val_loss: 2.0105\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0093 - val_loss: 2.0049\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0045 - val_loss: 2.0020\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0028 - val_loss: 1.9999\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0015 - val_loss: 1.9976\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0013 - val_loss: 1.9967\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0005 - val_loss: 1.9963\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 2.0002 - val_loss: 1.9995\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9995 - val_loss: 1.9967\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9992 - val_loss: 1.9972\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9990 - val_loss: 1.9956\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9952\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9952\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 1.9986 - val_loss: 1.9973\n",
      "Top-2 accuracy = 0.445\n",
      "27\n",
      "minmaxV|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 2.1503 - val_loss: 2.1136\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1101 - val_loss: 2.1001\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1000 - val_loss: 2.0923\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0922 - val_loss: 2.0872\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0898 - val_loss: 2.0868\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0927 - val_loss: 2.0950\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0975 - val_loss: 2.0945\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0976 - val_loss: 2.0934\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0973 - val_loss: 2.0939\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0971 - val_loss: 2.0934\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0971 - val_loss: 2.0935\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0970 - val_loss: 2.0933\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0970 - val_loss: 2.0934\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0970 - val_loss: 2.0944\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0971 - val_loss: 2.0934\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0972 - val_loss: 2.0935\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0969 - val_loss: 2.0936\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 2.0970 - val_loss: 2.0935\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0970 - val_loss: 2.0936\n",
      "Top-2 accuracy = 0.402\n",
      "28\n",
      "normalizeg|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1795 - val_loss: 2.1664\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1624 - val_loss: 2.1598\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1596 - val_loss: 2.1585\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1591 - val_loss: 2.1581\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1558 - val_loss: 2.1403\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1069 - val_loss: 2.0672\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0618 - val_loss: 2.0581\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0451 - val_loss: 2.0486\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0375 - val_loss: 2.0377\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0332 - val_loss: 2.0293\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0281 - val_loss: 2.0305\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0289 - val_loss: 2.0494\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0354 - val_loss: 2.0238\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0243 - val_loss: 2.0358\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0234 - val_loss: 2.0201\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0234 - val_loss: 2.0296\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0214 - val_loss: 2.0191\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0207 - val_loss: 2.0195\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0207 - val_loss: 2.0169\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.0190 - val_loss: 2.0156\n",
      "Top-2 accuracy = 0.443\n",
      "29\n",
      "robustq|rf\n",
      "Epoch 1/20\n",
      "83/83 [==============================] - 1s 11ms/step - loss: 2.1710 - val_loss: 2.1444\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.1221 - val_loss: 2.0970\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0939 - val_loss: 2.0909\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0932 - val_loss: 2.0911\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0925 - val_loss: 2.0909\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0923 - val_loss: 2.0911\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0927 - val_loss: 2.0916\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0924 - val_loss: 2.0910\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0923 - val_loss: 2.0918\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0924 - val_loss: 2.0911\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0923 - val_loss: 2.0912\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0924 - val_loss: 2.0912\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0923 - val_loss: 2.0911\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0924 - val_loss: 2.0916\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0926 - val_loss: 2.0910\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0924 - val_loss: 2.0914\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0924 - val_loss: 2.0910\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 0s 5ms/step - loss: 2.0924 - val_loss: 2.0915\n",
      "Top-2 accuracy = 0.406\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"accuracy\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [MulticlassDL(n_classes=9, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20)],\n",
    "    \"post_train_hooks\": [top2_hook],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"chromium-9class\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        MulticlassDL(n_classes=9, random={'n_layers': (2, 6), 'n_units': (3, 20)}, n_epochs=20))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 1873.0264370441437 seconds.\n",
      "Top-1 Accuracy: 0.2798125821381635\n",
      "Top-2 Accuracy: 0.45074567167590424\n"
     ]
    }
   ],
   "source": [
    "print('Completed in', end - start, 'seconds.')\n",
    "interp = DODGEInterpreter(files=['./chromium-9class.txt'], max_by=0, \n",
    "                          metrics=['accuracy'])\n",
    "results = interp.interpret()['chromium-9class.txt']\n",
    "print('Top-1 Accuracy:', np.median(results['accuracy']))\n",
    "print('Top-2 Accuracy:', np.median(np.amax(np.array(top2).reshape(10,30), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
