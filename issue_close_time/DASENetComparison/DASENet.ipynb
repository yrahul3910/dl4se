{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from raise_utils.data import Data\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-c86471ff691a>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['s70'] = df['s7'].apply(lambda x: eval(x)[0])\n",
      "<ipython-input-3-c86471ff691a>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['s71'] = df['s7'].apply(lambda x: eval(x)[1])\n",
      "<ipython-input-3-c86471ff691a>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['s72'] = df['s7'].apply(lambda x: eval(x)[2])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Bug-Related-Activity-Logs/firefox.csv')\n",
    "df.drop(['Unnamed: 0', 'bugID'], axis=1, inplace=True)\n",
    "\n",
    "_df = df[['s1', 's2', 's3', 's4', 's5', 's6', 's8', 'y']]\n",
    "_df['s70'] = df['s7'].apply(lambda x: eval(x)[0])\n",
    "_df['s71'] = df['s7'].apply(lambda x: eval(x)[1])\n",
    "_df['s72'] = df['s7'].apply(lambda x: eval(x)[2])\n",
    "\n",
    "_df['s90'] = df['s9'].apply(lambda x: eval(x)[0])\n",
    "_df['s91'] = df['s9'].apply(lambda x: eval(x)[1])\n",
    "_df['s92'] = df['s9'].apply(lambda x: eval(x)[2])\n",
    "\n",
    "x = _df.drop('y', axis=1)\n",
    "y = _df['y']\n",
    "\n",
    "data = Data(*train_test_split(x, y))\n",
    "data.y_train = data.y_train < 4\n",
    "data.y_test = data.y_test < 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_comments</th>\n",
       "      <th>system_records</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['eyedropper', 'style', 'editor', 'use', 'shar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['258347', 'assignee', 'comment1', 'createdatt...</td>\n",
       "      <td>['assignee', 'nobody', 'archaeopteryx', 'statu...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['75935', 'comment7']</td>\n",
       "      <td>['keywords', 'checkin-needed', 'whiteboard', '...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['keyboard', 'long', 'word', 'suggestions', 'c...</td>\n",
       "      <td>['see', 'also', 'bug', 'blocking-b2g', '2.0', ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['465859', 'comment2', 'ni', 'william', 'regre...</td>\n",
       "      <td>['cc', 'bhuang', 'whsu', 'flags', 'needinfo', ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       user_comments  \\\n",
       "0  ['eyedropper', 'style', 'editor', 'use', 'shar...   \n",
       "1  ['258347', 'assignee', 'comment1', 'createdatt...   \n",
       "2                              ['75935', 'comment7']   \n",
       "3  ['keyboard', 'long', 'word', 'suggestions', 'c...   \n",
       "4  ['465859', 'comment2', 'ni', 'william', 'regre...   \n",
       "\n",
       "                                      system_records  s1  s2  s3   s4  s5  s6  \\\n",
       "0                                                 []   1   1   0   32   1   0   \n",
       "1  ['assignee', 'nobody', 'archaeopteryx', 'statu...  13   6   7  260   2   2   \n",
       "2  ['keywords', 'checkin-needed', 'whiteboard', '...   2   1   1   10   3   3   \n",
       "3  ['see', 'also', 'bug', 'blocking-b2g', '2.0', ...   5   2   3   81   1   0   \n",
       "4  ['cc', 'bhuang', 'whsu', 'flags', 'needinfo', ...   2   1   1   27   2   3   \n",
       "\n",
       "          s7  s8         s9  y  \n",
       "0  [0, 0, 0]   1  [0, 1, 0]  3  \n",
       "1  [0, 1, 0]   3  [0, 1, 1]  1  \n",
       "2  [1, 0, 1]   1  [0, 0, 1]  0  \n",
       "3  [0, 0, 0]   2  [1, 0, 1]  9  \n",
       "4  [1, 0, 0]   1  [0, 0, 1]  6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_user_raw = [eval(x) for x in df['user_comments']]\n",
    "x_user_raw_train, x_user_raw_test = train_test_split(x_user_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = FastText(sentences=x_user_raw_train, sg=1, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sys_raw = [eval(x) for x in df['system_records']]\n",
    "x_sys_raw_train, x_sys_raw_test = train_test_split(x_sys_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_model = FastText(sentences=x_sys_raw_train, sg=1, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-77f8e53d42cb>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  user_model['boooooo'].shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_model['boooooo'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity log stream encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, LSTM, Dense, BatchNormalization, merge, Input, LeakyReLU, Flatten, Reshape\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 50\n",
    "x_user_train = [t[:50] if len(t) >= 50 else t.extend(['end'] * (50 - len(t))) for t in x_user_raw_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_user_train = [t for t in x_user_train if t is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20193, 50)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_user_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sys_train = [t[:50] if len(t) >= 50 else t.extend(['end'] * (50 - len(t))) for t in x_sys_raw_train]\n",
    "x_sys_train = [t for t in x_sys_train if t is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-105-ad4210106d98>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  x_user_train = [[user_model[word] for word in arr] for arr in x_user_train]\n"
     ]
    }
   ],
   "source": [
    "x_user_train = [[user_model[word] for word in arr] for arr in x_user_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_user_train = np.array(x_user_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-108-09af2f8763fd>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  x_sys_train = np.array([[system_model[word] for word in arr] for arr in x_sys_train])\n"
     ]
    }
   ],
   "source": [
    "x_sys_train = np.array([[system_model[word] for word in arr] for arr in x_sys_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20193, 50, 200), (769, 50, 200))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_user_train.shape, x_sys_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_user_test = [t[:50] if len(t) >= 50 else t.extend(['end'] * (50 - len(t))) for t in x_user_raw_test]\n",
    "x_user_test = [t for t in x_user_test if t is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sys_test = [t[:50] if len(t) >= 50 else t.extend(['end'] * (50 - len(t))) for t in x_sys_raw_test]\n",
    "x_sys_test = [t for t in x_sys_test if t is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10620"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_sys_raw_train, x_sys_raw_test, x_user_raw_train, x_user_raw_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_input = Input(shape=x_user_train.shape[1:])\n",
    "\n",
    "user_activity_stream_hidden_layer = Bidirectional(\n",
    "    LSTM(128, return_sequences=True, input_shape=(x_user_train.shape[1], x_user_train.shape[2]))\n",
    ")(user_activity_input)\n",
    "\n",
    "user_activity_stream = Bidirectional(\n",
    "    LSTM(256, return_sequences=True, input_shape=(x_user_train.shape[1], 256))\n",
    ")(user_activity_stream_hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_activity_input = Input(shape=x_sys_train.shape[1:])\n",
    "\n",
    "sys_activity_stream_hidden_layer = Bidirectional(\n",
    "    LSTM(128, return_sequences=True, input_shape=x_sys_train.shape[1:])\n",
    ")(sys_activity_input)\n",
    "\n",
    "sys_activity_stream = Bidirectional(\n",
    "    LSTM(32, return_sequences=True, input_shape=(x_sys_train.shape[1], 256))\n",
    ")(sys_activity_stream_hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_input = Input(shape=data.x_train.shape[1:])\n",
    "\n",
    "meta_hidden_layer = Dense(50)(meta_input)\n",
    "meta_hidden_activation = LeakyReLU()(meta_hidden_layer)\n",
    "\n",
    "meta = Dense(30)(meta_hidden_activation)\n",
    "meta = LeakyReLU()(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten1 = Flatten()(user_activity_stream)\n",
    "flatten2 = Flatten()(sys_activity_stream)\n",
    "\n",
    "concat_layer = merge.Concatenate(axis=-1)([flatten1, flatten2, meta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging MLP layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_layer1 = Dense(380, input_shape=())(concat_layer)\n",
    "mlp_activ1 = LeakyReLU()(mlp_layer1)\n",
    "\n",
    "mlp_layer2 = Dense(450)(mlp_activ1)\n",
    "mlp_activ2 = LeakyReLU()(mlp_layer2)\n",
    "\n",
    "mlp_layer3 = Dense(260)(mlp_activ2)\n",
    "mlp_activ3 = LeakyReLU()(mlp_layer3)\n",
    "\n",
    "mlp_layer4 = Dense(200)(mlp_activ3)\n",
    "mlp_activ4 = LeakyReLU()(mlp_layer4)\n",
    "\n",
    "mlp_out = Dense(200)(mlp_activ4)\n",
    "mlp_out = LeakyReLU()(mlp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin-sequence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://gist.github.com/skeeet/b639eea7e3fc51dd03e9b69c06b2fdf1\n",
    "def make_residual_lstm_layers(input, rnn_width, rnn_depth):\n",
    "    \"\"\"\n",
    "    The intermediate LSTM layers return sequences, while the last returns a single element.\n",
    "    The input is also a sequence. In order to match the shape of input and output of the LSTM\n",
    "    to sum them we can do it only for all layers but the last.\n",
    "    \"\"\"\n",
    "    x = input\n",
    "    for i in range(rnn_depth):\n",
    "        return_sequences = i < rnn_depth - 1\n",
    "        x_rnn = LSTM(rnn_width, return_sequences=return_sequences)(input)\n",
    "        x_rnn = BatchNormalization()(x_rnn)\n",
    "        if return_sequences:\n",
    "            # residual block\n",
    "            x = merge.Add()([x, x_rnn])\n",
    "        else:\n",
    "            # last layer does not return sequences and cannot be residual\n",
    "            x = x_rnn\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape = Reshape((1, 200))(mlp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dasenet = make_residual_lstm_layers(reshape, 200, rnn_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 200])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dasenet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "final_layer = Dense(n_classes, activation='softmax')(dasenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[user_activity_input, sys_activity_input, meta_input], outputs=[final_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 50, 200)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 50, 200)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           700         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 50, 256)      336896      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 50, 256)      336896      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 50)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 50, 512)      1050624     bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 50, 64)       73984       bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           1530        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 25600)        0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3200)         0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 30)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 28830)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 380)          10955780    concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 380)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 450)          171450      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 450)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 260)          117260      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 260)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 200)          52200       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 200)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 200)          40200       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 200)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 200)       0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_22 (LSTM)                  (None, 200)          320800      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 200)          800         lstm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            402         batch_normalization_8[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 13,459,522\n",
      "Trainable params: 13,459,122\n",
      "Non-trainable params: 400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
