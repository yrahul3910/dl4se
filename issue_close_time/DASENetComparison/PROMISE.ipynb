{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/Downloads/Bug-Fix Dataset (PROMISE\\'19)/dataset/snapshot/buildr-full-bug-fix-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Category</th>\n",
       "      <th>Key</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>Reporter</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Components</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUILDR</td>\n",
       "      <td>ASF</td>\n",
       "      <td>Apache Buildr Committee</td>\n",
       "      <td>build-management</td>\n",
       "      <td>BUILDR-235</td>\n",
       "      <td>Trivial</td>\n",
       "      <td>Closed</td>\n",
       "      <td>alexismidon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JRuby Site/documentation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUILDR</td>\n",
       "      <td>ASF</td>\n",
       "      <td>Apache Buildr Committee</td>\n",
       "      <td>build-management</td>\n",
       "      <td>BUILDR-236</td>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>alexismidon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUILDR</td>\n",
       "      <td>ASF</td>\n",
       "      <td>Apache Buildr Committee</td>\n",
       "      <td>build-management</td>\n",
       "      <td>BUILDR-239</td>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>jmuzz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Core features</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUILDR</td>\n",
       "      <td>ASF</td>\n",
       "      <td>Apache Buildr Committee</td>\n",
       "      <td>build-management</td>\n",
       "      <td>BUILDR-241</td>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>rsutphin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDE</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUILDR</td>\n",
       "      <td>ASF</td>\n",
       "      <td>Apache Buildr Committee</td>\n",
       "      <td>build-management</td>\n",
       "      <td>BUILDR-243</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Closed</td>\n",
       "      <td>digitalsanctum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Compilers</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Project Owner                  Manager          Category         Key  \\\n",
       "0  BUILDR   ASF  Apache Buildr Committee  build-management  BUILDR-235   \n",
       "1  BUILDR   ASF  Apache Buildr Committee  build-management  BUILDR-236   \n",
       "2  BUILDR   ASF  Apache Buildr Committee  build-management  BUILDR-239   \n",
       "3  BUILDR   ASF  Apache Buildr Committee  build-management  BUILDR-241   \n",
       "4  BUILDR   ASF  Apache Buildr Committee  build-management  BUILDR-243   \n",
       "\n",
       "  Priority  Status        Reporter Assignee                Components  ...  \\\n",
       "0  Trivial  Closed     alexismidon      NaN  JRuby Site/documentation  ...   \n",
       "1    Major  Closed     alexismidon      NaN                       NaN  ...   \n",
       "2    Major  Closed           jmuzz      NaN             Core features  ...   \n",
       "3    Major  Closed        rsutphin      NaN                       IDE  ...   \n",
       "4    Minor  Closed  digitalsanctum      NaN                 Compilers  ...   \n",
       "\n",
       "  SrcAddFiles SrcDelFiles SrcModFiles SrcAddLines SrcDelLines TestAddFiles  \\\n",
       "0           0           0           0           0           0            0   \n",
       "1           0           0           0           0           0            0   \n",
       "2           0           0           2          27           1            0   \n",
       "3           2           0           1         153           2            0   \n",
       "4           0           0           0           0           0            0   \n",
       "\n",
       "  TestDelFiles  TestModFiles TestAddLines TestDelLines  \n",
       "0            0             0            0            0  \n",
       "1            0             0            0            0  \n",
       "2            0             0            0            0  \n",
       "3            0             0            0            0  \n",
       "4            0             0            0            0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Project', 'Owner', 'Manager', 'Category', 'Key', 'Priority', 'Status',\n",
       "       'Reporter', 'Assignee', 'Components', 'SummaryTopWords',\n",
       "       'DescriptionTopWords', 'CommentsTopWords', 'CreationDate',\n",
       "       'ResolutionDate', 'AffectsVersions', 'FixVersions', 'NoComments',\n",
       "       'FirstCommentDate', 'LastCommentDate', 'NoWatchers', 'NoAttachments',\n",
       "       'FirstAttachmentDate', 'LastAttachmentDate', 'NoAttachedPatches',\n",
       "       'FirstAttachedPatchDate', 'LastAttachedPatchDate', 'InwardIssueLinks',\n",
       "       'OutwardIssueLinks', 'HasMergeCommit', 'CommitsMessagesTopWords',\n",
       "       'NoCommits', 'NoAuthors', 'NoCommitters', 'AuthorsFirstCommitDate',\n",
       "       'AuthorsLastCommitDate', 'CommittersFirstCommitDate',\n",
       "       'CommittersLastCommitDate', 'NonSrcAddFiles', 'NonSrcDelFiles',\n",
       "       'NonSrcModFiles', 'NonSrcAddLines', 'NonSrcDelLines', 'SrcAddFiles',\n",
       "       'SrcDelFiles', 'SrcModFiles', 'SrcAddLines', 'SrcDelLines',\n",
       "       'TestAddFiles', 'TestDelFiles', 'TestModFiles', 'TestAddLines',\n",
       "       'TestDelLines'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Project', 'Owner', 'Manager', 'Category', \n",
    "         'Key', 'Reporter', 'Assignee', 'Components',\n",
    "         'SummaryTopWords', 'DescriptionTopWords',\n",
    "         'CommentsTopWords', 'AffectsVersions',\n",
    "         'FixVersions', 'FirstCommentDate', 'LastCommentDate',\n",
    "         'FirstAttachmentDate', 'LastAttachmentDate',\n",
    "         'FirstAttachedPatchDate', 'LastAttachedPatchDate',\n",
    "         'InwardIssueLinks', 'OutwardIssueLinks',\n",
    "         'CommitsMessagesTopWords', 'AuthorsFirstCommitDate',\n",
    "         'AuthorsLastCommitDate', 'CommittersFirstCommitDate',\n",
    "         'CommittersLastCommitDate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ResolutionDate</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trivial</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-07 20:26:20+00:00</td>\n",
       "      <td>2009-03-12 22:52:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-14 00:35:08+00:00</td>\n",
       "      <td>2010-02-28 15:45:40+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-29 00:44:50+00:00</td>\n",
       "      <td>2009-03-12 23:20:28+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-04 17:19:01+00:00</td>\n",
       "      <td>2009-03-12 23:29:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Minor</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-06 21:40:44+00:00</td>\n",
       "      <td>2009-02-15 01:43:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Priority  Status               CreationDate             ResolutionDate  \\\n",
       "0  Trivial  Closed  2009-01-07 20:26:20+00:00  2009-03-12 22:52:51+00:00   \n",
       "1    Major  Closed  2009-01-14 00:35:08+00:00  2010-02-28 15:45:40+00:00   \n",
       "2    Major  Closed  2009-01-29 00:44:50+00:00  2009-03-12 23:20:28+00:00   \n",
       "3    Major  Closed  2009-02-04 17:19:01+00:00  2009-03-12 23:29:19+00:00   \n",
       "4    Minor  Closed  2009-02-06 21:40:44+00:00  2009-02-15 01:43:54+00:00   \n",
       "\n",
       "   NoComments  NoWatchers  NoAttachments  NoAttachedPatches  HasMergeCommit  \\\n",
       "0           0           0              1                  1               0   \n",
       "1           3           0              1                  0               0   \n",
       "2           2           0              2                  2               0   \n",
       "3           1           0              1                  1               0   \n",
       "4           1           0              0                  0               0   \n",
       "\n",
       "   NoCommits  ...  SrcAddFiles  SrcDelFiles  SrcModFiles  SrcAddLines  \\\n",
       "0          1  ...            0            0            0            0   \n",
       "1          0  ...            0            0            0            0   \n",
       "2          1  ...            0            0            2           27   \n",
       "3          2  ...            2            0            1          153   \n",
       "4          0  ...            0            0            0            0   \n",
       "\n",
       "   SrcDelLines  TestAddFiles  TestDelFiles  TestModFiles  TestAddLines  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            1             0             0             0             0   \n",
       "3            2             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   TestDelLines  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Priority'] = df['Priority'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ResolutionDate</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trivial</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-07 20:26:20+00:00</td>\n",
       "      <td>2009-03-12 22:52:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-14 00:35:08+00:00</td>\n",
       "      <td>2010-02-28 15:45:40+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-29 00:44:50+00:00</td>\n",
       "      <td>2009-03-12 23:20:28+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-04 17:19:01+00:00</td>\n",
       "      <td>2009-03-12 23:29:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Minor</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-06 21:40:44+00:00</td>\n",
       "      <td>2009-02-15 01:43:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Priority  Status               CreationDate             ResolutionDate  \\\n",
       "0  Trivial  Closed  2009-01-07 20:26:20+00:00  2009-03-12 22:52:51+00:00   \n",
       "1    Major  Closed  2009-01-14 00:35:08+00:00  2010-02-28 15:45:40+00:00   \n",
       "2    Major  Closed  2009-01-29 00:44:50+00:00  2009-03-12 23:20:28+00:00   \n",
       "3    Major  Closed  2009-02-04 17:19:01+00:00  2009-03-12 23:29:19+00:00   \n",
       "4    Minor  Closed  2009-02-06 21:40:44+00:00  2009-02-15 01:43:54+00:00   \n",
       "\n",
       "   NoComments  NoWatchers  NoAttachments  NoAttachedPatches  HasMergeCommit  \\\n",
       "0           0           0              1                  1               0   \n",
       "1           3           0              1                  0               0   \n",
       "2           2           0              2                  2               0   \n",
       "3           1           0              1                  1               0   \n",
       "4           1           0              0                  0               0   \n",
       "\n",
       "   NoCommits  ...  SrcAddFiles  SrcDelFiles  SrcModFiles  SrcAddLines  \\\n",
       "0          1  ...            0            0            0            0   \n",
       "1          0  ...            0            0            0            0   \n",
       "2          1  ...            0            0            2           27   \n",
       "3          2  ...            2            0            1          153   \n",
       "4          0  ...            0            0            0            0   \n",
       "\n",
       "   SrcDelLines  TestAddFiles  TestDelFiles  TestModFiles  TestAddLines  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            1             0             0             0             0   \n",
       "3            2             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   TestDelLines  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Priority'] = df['Priority'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ResolutionDate</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-07 20:26:20+00:00</td>\n",
       "      <td>2009-03-12 22:52:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-14 00:35:08+00:00</td>\n",
       "      <td>2010-02-28 15:45:40+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-29 00:44:50+00:00</td>\n",
       "      <td>2009-03-12 23:20:28+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-04 17:19:01+00:00</td>\n",
       "      <td>2009-03-12 23:29:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-06 21:40:44+00:00</td>\n",
       "      <td>2009-02-15 01:43:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Status               CreationDate             ResolutionDate  \\\n",
       "0         4  Closed  2009-01-07 20:26:20+00:00  2009-03-12 22:52:51+00:00   \n",
       "1         2  Closed  2009-01-14 00:35:08+00:00  2010-02-28 15:45:40+00:00   \n",
       "2         2  Closed  2009-01-29 00:44:50+00:00  2009-03-12 23:20:28+00:00   \n",
       "3         2  Closed  2009-02-04 17:19:01+00:00  2009-03-12 23:29:19+00:00   \n",
       "4         3  Closed  2009-02-06 21:40:44+00:00  2009-02-15 01:43:54+00:00   \n",
       "\n",
       "   NoComments  NoWatchers  NoAttachments  NoAttachedPatches  HasMergeCommit  \\\n",
       "0           0           0              1                  1               0   \n",
       "1           3           0              1                  0               0   \n",
       "2           2           0              2                  2               0   \n",
       "3           1           0              1                  1               0   \n",
       "4           1           0              0                  0               0   \n",
       "\n",
       "   NoCommits  ...  SrcAddFiles  SrcDelFiles  SrcModFiles  SrcAddLines  \\\n",
       "0          1  ...            0            0            0            0   \n",
       "1          0  ...            0            0            0            0   \n",
       "2          1  ...            0            0            2           27   \n",
       "3          2  ...            2            0            1          153   \n",
       "4          0  ...            0            0            0            0   \n",
       "\n",
       "   SrcDelLines  TestAddFiles  TestDelFiles  TestModFiles  TestAddLines  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            1             0             0             0             0   \n",
       "3            2             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   TestDelLines  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Status'] = df['Status'].astype('category')\n",
    "df['Status'] = df['Status'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ResolutionDate</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-07 20:26:20+00:00</td>\n",
       "      <td>2009-03-12 22:52:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-14 00:35:08+00:00</td>\n",
       "      <td>2010-02-28 15:45:40+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-29 00:44:50+00:00</td>\n",
       "      <td>2009-03-12 23:20:28+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-02-04 17:19:01+00:00</td>\n",
       "      <td>2009-03-12 23:29:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-02-06 21:40:44+00:00</td>\n",
       "      <td>2009-02-15 01:43:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Status               CreationDate             ResolutionDate  \\\n",
       "0         4       0  2009-01-07 20:26:20+00:00  2009-03-12 22:52:51+00:00   \n",
       "1         2       0  2009-01-14 00:35:08+00:00  2010-02-28 15:45:40+00:00   \n",
       "2         2       0  2009-01-29 00:44:50+00:00  2009-03-12 23:20:28+00:00   \n",
       "3         2       0  2009-02-04 17:19:01+00:00  2009-03-12 23:29:19+00:00   \n",
       "4         3       0  2009-02-06 21:40:44+00:00  2009-02-15 01:43:54+00:00   \n",
       "\n",
       "   NoComments  NoWatchers  NoAttachments  NoAttachedPatches  HasMergeCommit  \\\n",
       "0           0           0              1                  1               0   \n",
       "1           3           0              1                  0               0   \n",
       "2           2           0              2                  2               0   \n",
       "3           1           0              1                  1               0   \n",
       "4           1           0              0                  0               0   \n",
       "\n",
       "   NoCommits  ...  SrcAddFiles  SrcDelFiles  SrcModFiles  SrcAddLines  \\\n",
       "0          1  ...            0            0            0            0   \n",
       "1          0  ...            0            0            0            0   \n",
       "2          1  ...            0            0            2           27   \n",
       "3          2  ...            2            0            1          153   \n",
       "4          0  ...            0            0            0            0   \n",
       "\n",
       "   SrcDelLines  TestAddFiles  TestDelFiles  TestModFiles  TestAddLines  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            1             0             0             0             0   \n",
       "3            2             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   TestDelLines  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 227 entries, 0 to 226\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Priority           227 non-null    int8  \n",
      " 1   Status             227 non-null    int8  \n",
      " 2   CreationDate       227 non-null    object\n",
      " 3   ResolutionDate     227 non-null    object\n",
      " 4   NoComments         227 non-null    int64 \n",
      " 5   NoWatchers         227 non-null    int64 \n",
      " 6   NoAttachments      227 non-null    int64 \n",
      " 7   NoAttachedPatches  227 non-null    int64 \n",
      " 8   HasMergeCommit     227 non-null    int64 \n",
      " 9   NoCommits          227 non-null    int64 \n",
      " 10  NoAuthors          227 non-null    int64 \n",
      " 11  NoCommitters       227 non-null    int64 \n",
      " 12  NonSrcAddFiles     227 non-null    int64 \n",
      " 13  NonSrcDelFiles     227 non-null    int64 \n",
      " 14  NonSrcModFiles     227 non-null    int64 \n",
      " 15  NonSrcAddLines     227 non-null    int64 \n",
      " 16  NonSrcDelLines     227 non-null    int64 \n",
      " 17  SrcAddFiles        227 non-null    int64 \n",
      " 18  SrcDelFiles        227 non-null    int64 \n",
      " 19  SrcModFiles        227 non-null    int64 \n",
      " 20  SrcAddLines        227 non-null    int64 \n",
      " 21  SrcDelLines        227 non-null    int64 \n",
      " 22  TestAddFiles       227 non-null    int64 \n",
      " 23  TestDelFiles       227 non-null    int64 \n",
      " 24  TestModFiles       227 non-null    int64 \n",
      " 25  TestAddLines       227 non-null    int64 \n",
      " 26  TestDelLines       227 non-null    int64 \n",
      "dtypes: int64(23), int8(2), object(2)\n",
      "memory usage: 44.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CreationDate'] = pd.to_datetime(df['CreationDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ResolutionDate'] = pd.to_datetime(df['ResolutionDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ResolutionDate</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-07 20:26:20+00:00</td>\n",
       "      <td>2009-03-12 22:52:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-14 00:35:08+00:00</td>\n",
       "      <td>2010-02-28 15:45:40+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-29 00:44:50+00:00</td>\n",
       "      <td>2009-03-12 23:20:28+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-02-04 17:19:01+00:00</td>\n",
       "      <td>2009-03-12 23:29:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-02-06 21:40:44+00:00</td>\n",
       "      <td>2009-02-15 01:43:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Status              CreationDate            ResolutionDate  \\\n",
       "0         4       0 2009-01-07 20:26:20+00:00 2009-03-12 22:52:51+00:00   \n",
       "1         2       0 2009-01-14 00:35:08+00:00 2010-02-28 15:45:40+00:00   \n",
       "2         2       0 2009-01-29 00:44:50+00:00 2009-03-12 23:20:28+00:00   \n",
       "3         2       0 2009-02-04 17:19:01+00:00 2009-03-12 23:29:19+00:00   \n",
       "4         3       0 2009-02-06 21:40:44+00:00 2009-02-15 01:43:54+00:00   \n",
       "\n",
       "   NoComments  NoWatchers  NoAttachments  NoAttachedPatches  HasMergeCommit  \\\n",
       "0           0           0              1                  1               0   \n",
       "1           3           0              1                  0               0   \n",
       "2           2           0              2                  2               0   \n",
       "3           1           0              1                  1               0   \n",
       "4           1           0              0                  0               0   \n",
       "\n",
       "   NoCommits  ...  SrcAddFiles  SrcDelFiles  SrcModFiles  SrcAddLines  \\\n",
       "0          1  ...            0            0            0            0   \n",
       "1          0  ...            0            0            0            0   \n",
       "2          1  ...            0            0            2           27   \n",
       "3          2  ...            2            0            1          153   \n",
       "4          0  ...            0            0            0            0   \n",
       "\n",
       "   SrcDelLines  TestAddFiles  TestDelFiles  TestModFiles  TestAddLines  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            1             0             0             0             0   \n",
       "3            2             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   TestDelLines  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 227 entries, 0 to 226\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count  Dtype              \n",
      "---  ------             --------------  -----              \n",
      " 0   Priority           227 non-null    int8               \n",
      " 1   Status             227 non-null    int8               \n",
      " 2   CreationDate       227 non-null    datetime64[ns, UTC]\n",
      " 3   ResolutionDate     227 non-null    datetime64[ns, UTC]\n",
      " 4   NoComments         227 non-null    int64              \n",
      " 5   NoWatchers         227 non-null    int64              \n",
      " 6   NoAttachments      227 non-null    int64              \n",
      " 7   NoAttachedPatches  227 non-null    int64              \n",
      " 8   HasMergeCommit     227 non-null    int64              \n",
      " 9   NoCommits          227 non-null    int64              \n",
      " 10  NoAuthors          227 non-null    int64              \n",
      " 11  NoCommitters       227 non-null    int64              \n",
      " 12  NonSrcAddFiles     227 non-null    int64              \n",
      " 13  NonSrcDelFiles     227 non-null    int64              \n",
      " 14  NonSrcModFiles     227 non-null    int64              \n",
      " 15  NonSrcAddLines     227 non-null    int64              \n",
      " 16  NonSrcDelLines     227 non-null    int64              \n",
      " 17  SrcAddFiles        227 non-null    int64              \n",
      " 18  SrcDelFiles        227 non-null    int64              \n",
      " 19  SrcModFiles        227 non-null    int64              \n",
      " 20  SrcAddLines        227 non-null    int64              \n",
      " 21  SrcDelLines        227 non-null    int64              \n",
      " 22  TestAddFiles       227 non-null    int64              \n",
      " 23  TestDelFiles       227 non-null    int64              \n",
      " 24  TestModFiles       227 non-null    int64              \n",
      " 25  TestAddLines       227 non-null    int64              \n",
      " 26  TestDelLines       227 non-null    int64              \n",
      "dtypes: datetime64[ns, UTC](2), int64(23), int8(2)\n",
      "memory usage: 44.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ResolutionTime'] = (df['ResolutionDate'] - df['CreationDate']).astype('timedelta64[D]').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CreationDate', 'ResolutionDate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>NoAuthors</th>\n",
       "      <th>NoCommitters</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "      <th>ResolutionTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Status  NoComments  NoWatchers  NoAttachments  NoAttachedPatches  \\\n",
       "0         4       0           0           0              1                  1   \n",
       "1         2       0           3           0              1                  0   \n",
       "2         2       0           2           0              2                  2   \n",
       "3         2       0           1           0              1                  1   \n",
       "4         3       0           1           0              0                  0   \n",
       "\n",
       "   HasMergeCommit  NoCommits  NoAuthors  NoCommitters  ...  SrcDelFiles  \\\n",
       "0               0          1          1             1  ...            0   \n",
       "1               0          0          0             0  ...            0   \n",
       "2               0          1          1             1  ...            0   \n",
       "3               0          2          1             1  ...            0   \n",
       "4               0          0          0             0  ...            0   \n",
       "\n",
       "   SrcModFiles  SrcAddLines  SrcDelLines  TestAddFiles  TestDelFiles  \\\n",
       "0            0            0            0             0             0   \n",
       "1            0            0            0             0             0   \n",
       "2            2           27            1             0             0   \n",
       "3            1          153            2             0             0   \n",
       "4            0            0            0             0             0   \n",
       "\n",
       "   TestModFiles  TestAddLines  TestDelLines  ResolutionTime  \n",
       "0             0             0             0              64  \n",
       "1             0             0             0             410  \n",
       "2             0             0             0              42  \n",
       "3             0             0             0              36  \n",
       "4             0             0             0               8  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'ResolutionTime'}>]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist('ResolutionTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['ResolutionTime'] < 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 7) & (df['ResolutionTime'] >= 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 14) & (df['ResolutionTime'] >= 7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 30) & (df['ResolutionTime'] >= 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 90) & (df['ResolutionTime'] >= 30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 180) & (df['ResolutionTime'] >= 90)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 365) & (df['ResolutionTime'] >= 180)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['ResolutionTime'] >= 365])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ResolutionTime'] < 1,'ResolutionTime'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 7) & (df['ResolutionTime'] >= 1),'ResolutionTime'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 14) & (df['ResolutionTime'] >= 7),'ResolutionTime'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 30) & (df['ResolutionTime'] >= 14),'ResolutionTime'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 90) & (df['ResolutionTime'] >= 30),'ResolutionTime'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 180) & (df['ResolutionTime'] >= 90),'ResolutionTime'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 365) & (df['ResolutionTime'] >= 180),'ResolutionTime'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ResolutionTime'] >= 365,'ResolutionTime'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['ResolutionTime'].hist(bins=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.learners import MulticlassDL\n",
    "from raise_utils.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = MulticlassDL(n_classes=8, n_layers=5, n_units=len(df.columns), n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('ResolutionTime', axis=1)\n",
    "y = df['ResolutionTime']\n",
    "\n",
    "y = to_categorical(y, num_classes=8)\n",
    "\n",
    "learner.set_data(*Data(*train_test_split(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 4.0194 - val_loss: 4.3536\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6138 - val_loss: 3.8695\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.2879 - val_loss: 3.4814\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0174 - val_loss: 3.1732\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.8149 - val_loss: 2.9414\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.6427 - val_loss: 2.7753\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4967 - val_loss: 2.6576\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3822 - val_loss: 2.5821\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2971 - val_loss: 2.5326\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2325 - val_loss: 2.4937\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1830 - val_loss: 2.4578\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1430 - val_loss: 2.4268\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1080 - val_loss: 2.3919\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0765 - val_loss: 2.3534\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0503 - val_loss: 2.3101\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0274 - val_loss: 2.2660\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.0092 - val_loss: 2.2290\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9946 - val_loss: 2.2027\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9837 - val_loss: 2.1959\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9784 - val_loss: 2.2000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9797 - val_loss: 2.2008\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9795 - val_loss: 2.1937\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9699 - val_loss: 2.1819\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9547 - val_loss: 2.1704\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9408 - val_loss: 2.1632\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9307 - val_loss: 2.1598\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9226 - val_loss: 2.1591\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9167 - val_loss: 2.1602\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9121 - val_loss: 2.1624\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9082 - val_loss: 2.1643\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9045 - val_loss: 2.1653\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9004 - val_loss: 2.1649\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8959 - val_loss: 2.1619\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8907 - val_loss: 2.1574\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8851 - val_loss: 2.1522\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8787 - val_loss: 2.1455\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8718 - val_loss: 2.1387\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8650 - val_loss: 2.1326\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8584 - val_loss: 2.1273\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8527 - val_loss: 2.1228\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8475 - val_loss: 2.1191\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8429 - val_loss: 2.1150\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8384 - val_loss: 2.1109\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8336 - val_loss: 2.1056\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8290 - val_loss: 2.0998\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8250 - val_loss: 2.0939\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8212 - val_loss: 2.0883\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8173 - val_loss: 2.0838\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8133 - val_loss: 2.0806\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8092 - val_loss: 2.0779\n"
     ]
    }
   ],
   "source": [
    "learner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/raise_utils/learners/multiclassdl.py:84: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "preds = learner.predict(learner.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 5, 7, 7, 0, 0, 7, 1, 0, 0, 7, 0, 1, 0, 7, 0, 0, 0, 0, 0, 0, 7,\n",
       "       7, 4, 0, 0, 0, 0, 7, 7, 0, 0, 7, 1, 1, 0, 1, 1, 0, 0, 7, 0, 7, 7,\n",
       "       0, 7, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 7])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.metrics import ClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ClassificationMetrics(np.argmax(learner.y_test, axis=-1), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_metrics(['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2982456140350877]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.3384 - val_loss: 1.9640\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.0903 - val_loss: 2.0076\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9955 - val_loss: 2.0809\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.9439 - val_loss: 2.1479\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.8830 - val_loss: 2.2279\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8223 - val_loss: 2.3313\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7588 - val_loss: 2.4979\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.7026 - val_loss: 2.6473\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6510 - val_loss: 2.8050\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6051 - val_loss: 2.9489\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5622 - val_loss: 3.0709\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5189 - val_loss: 3.1863\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.4822 - val_loss: 3.2946\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4368 - val_loss: 3.3696\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3942 - val_loss: 3.5157\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3542 - val_loss: 3.5498\n"
     ]
    }
   ],
   "source": [
    "learner = MulticlassDL(n_classes=8, wfo=True, n_layers=5, n_units=len(df.columns), n_epochs=50)\n",
    "\n",
    "x = df.drop('ResolutionTime', axis=1)\n",
    "y = df['ResolutionTime']\n",
    "\n",
    "y = to_categorical(y, num_classes=8)\n",
    "\n",
    "learner.set_data(*Data(*train_test_split(x, y)))\n",
    "learner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('promise-buildr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.learners import FeedforwardDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('ResolutionTime', axis=1)\n",
    "y = (df['ResolutionTime'] == 1)\n",
    "\n",
    "data = Data(*train_test_split(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20588235294117646"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.y_train) / len(data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.hyperparams import DODGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602db3a0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 25, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.5, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602db250>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 23, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14c583c10>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 22, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14c5838b0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602c2310>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602c25b0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x14c5832b0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160013b20>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 24, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x15ffe69d0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601aca30>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601ac580>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601aca90>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601acb50>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 26, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601ac130>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601acd00>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601ac610>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160201a90>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602015b0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160201d30>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 26, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160201880>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 25, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160201e20>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160201fa0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160201370>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x16022d1c0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 26, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x16022dd00>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x16022d2b0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x16022d040>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x16022d640>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x16022deb0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 13, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x16022d850>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602248e0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602242b0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160224580>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 21, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160224c10>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160224610>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160224af0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160224a00>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160256a90>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602569d0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 23, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602562b0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 25, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602568e0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 25, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160256d90>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 25, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160256100>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602567c0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 23, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601c3c40>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601aaaf0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 26, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601aae20>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601aa9a0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 24, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1602501c0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 25, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x160250820>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 10, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1601bc310>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.1, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxabsM|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1883 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5120 - val_loss: 0.5345\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5099 - val_loss: 0.5405\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5079 - val_loss: 0.5465\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5061 - val_loss: 0.5528\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5042 - val_loss: 0.5592\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5025 - val_loss: 0.5659\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5008 - val_loss: 0.5730\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4991 - val_loss: 0.5803\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4972 - val_loss: 0.5875\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4957 - val_loss: 0.5952\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4938 - val_loss: 0.6030\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4920 - val_loss: 0.6112\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4903 - val_loss: 0.6197\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4887 - val_loss: 0.6284\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4868 - val_loss: 0.6372\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4852 - val_loss: 0.6464\n",
      "1\n",
      "maxabsJ|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1888 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5345 - val_loss: 0.4817\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5291 - val_loss: 0.4926\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5239 - val_loss: 0.5034\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5195 - val_loss: 0.5140\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5157 - val_loss: 0.5245\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5119 - val_loss: 0.5346\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5088 - val_loss: 0.5447\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5060 - val_loss: 0.5546\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5036 - val_loss: 0.5642\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5014 - val_loss: 0.5731\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4996 - val_loss: 0.5815\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4979 - val_loss: 0.5895\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4963 - val_loss: 0.5970\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4948 - val_loss: 0.6041\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4934 - val_loss: 0.6111\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4919 - val_loss: 0.6177\n",
      "2\n",
      "maxabsm|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1892 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5114 - val_loss: 0.5485\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5089 - val_loss: 0.5562\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5063 - val_loss: 0.5640\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5039 - val_loss: 0.5723\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5017 - val_loss: 0.5809\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4994 - val_loss: 0.5893\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4973 - val_loss: 0.5976\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4951 - val_loss: 0.6060\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4933 - val_loss: 0.6146\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4911 - val_loss: 0.6232\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4892 - val_loss: 0.6323\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4874 - val_loss: 0.6413\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4857 - val_loss: 0.6506\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4842 - val_loss: 0.6602\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4829 - val_loss: 0.6701\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4811 - val_loss: 0.6783\n",
      "3\n",
      "minmaxa|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1896 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5017 - val_loss: 0.6193\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4994 - val_loss: 0.6359\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4975 - val_loss: 0.6521\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4964 - val_loss: 0.6686\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4951 - val_loss: 0.6835\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4939 - val_loss: 0.6953\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4933 - val_loss: 0.7069\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4926 - val_loss: 0.7156\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4918 - val_loss: 0.7199\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4910 - val_loss: 0.7221\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4904 - val_loss: 0.7221\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4897 - val_loss: 0.7204\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4889 - val_loss: 0.7200\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4882 - val_loss: 0.7193\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4875 - val_loss: 0.7171\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4867 - val_loss: 0.7150\n",
      "4\n",
      "minmaxT|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1900 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5189 - val_loss: 0.5077\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5160 - val_loss: 0.5141\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5138 - val_loss: 0.5201\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5125 - val_loss: 0.5255\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5114 - val_loss: 0.5303\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5104 - val_loss: 0.5347\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5095 - val_loss: 0.5386\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5087 - val_loss: 0.5425\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5079 - val_loss: 0.5465\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5069 - val_loss: 0.5507\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5061 - val_loss: 0.5554\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5051 - val_loss: 0.5605\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5040 - val_loss: 0.5661\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5027 - val_loss: 0.5723\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5016 - val_loss: 0.5795\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5003 - val_loss: 0.5878\n",
      "5\n",
      "minmaxB|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1907 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5115 - val_loss: 0.5328\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5103 - val_loss: 0.5377\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5090 - val_loss: 0.5425\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5078 - val_loss: 0.5477\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5064 - val_loss: 0.5534\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5050 - val_loss: 0.5594\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5036 - val_loss: 0.5662\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5023 - val_loss: 0.5737\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5009 - val_loss: 0.5818\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4993 - val_loss: 0.5906\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4979 - val_loss: 0.6000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4967 - val_loss: 0.6096\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4955 - val_loss: 0.6193\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4945 - val_loss: 0.6292\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4935 - val_loss: 0.6391\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4927 - val_loss: 0.6491\n",
      "6\n",
      "minmaxS|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1913 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5102 - val_loss: 0.5596\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5063 - val_loss: 0.5806\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5023 - val_loss: 0.5999\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4995 - val_loss: 0.6195\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4969 - val_loss: 0.6380\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4953 - val_loss: 0.6558\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4935 - val_loss: 0.6713\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4921 - val_loss: 0.6849\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4908 - val_loss: 0.6970\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4893 - val_loss: 0.7056\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4883 - val_loss: 0.7140\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4872 - val_loss: 0.7177\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4862 - val_loss: 0.7201\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4855 - val_loss: 0.7222\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4846 - val_loss: 0.7206\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4837 - val_loss: 0.7179\n",
      "7\n",
      "standardizeA|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1917 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5061 - val_loss: 0.5529\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5012 - val_loss: 0.5674\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4973 - val_loss: 0.5848\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4934 - val_loss: 0.6037\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4888 - val_loss: 0.6242\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4850 - val_loss: 0.6468\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4811 - val_loss: 0.6708\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4776 - val_loss: 0.6954\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4743 - val_loss: 0.7185\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4712 - val_loss: 0.7379\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4682 - val_loss: 0.7510\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4654 - val_loss: 0.7590\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4623 - val_loss: 0.7605\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4595 - val_loss: 0.7600\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4562 - val_loss: 0.7542\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4529 - val_loss: 0.7481\n",
      "8\n",
      "normalizeB|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1924 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5235 - val_loss: 0.4891\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5227 - val_loss: 0.4913\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5221 - val_loss: 0.4936\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5213 - val_loss: 0.4958\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5207 - val_loss: 0.4980\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5200 - val_loss: 0.5001\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5194 - val_loss: 0.5022\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5188 - val_loss: 0.5042\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5181 - val_loss: 0.5062\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5176 - val_loss: 0.5082\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5170 - val_loss: 0.5101\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5165 - val_loss: 0.5119\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5159 - val_loss: 0.5138\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5153 - val_loss: 0.5156\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5148 - val_loss: 0.5173\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5143 - val_loss: 0.5190\n",
      "9\n",
      "standardizey|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1927 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4959 - val_loss: 0.6286\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4909 - val_loss: 0.6548\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4859 - val_loss: 0.6793\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4826 - val_loss: 0.7047\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4799 - val_loss: 0.7242\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4774 - val_loss: 0.7353\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4754 - val_loss: 0.7442\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4730 - val_loss: 0.7441\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4707 - val_loss: 0.7397\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4683 - val_loss: 0.7311\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4660 - val_loss: 0.7240\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4634 - val_loss: 0.7187\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4609 - val_loss: 0.7171\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4581 - val_loss: 0.7205\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4554 - val_loss: 0.7257\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4525 - val_loss: 0.7259\n",
      "10\n",
      "robustk|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1934 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.2294 - val_loss: 0.1371\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.1122 - val_loss: 0.1623\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0037 - val_loss: 0.1915\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.9027 - val_loss: 0.2251\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.8135 - val_loss: 0.2637\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7363 - val_loss: 0.3078\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6719 - val_loss: 0.3567\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6160 - val_loss: 0.4089\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5750 - val_loss: 0.4635\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5400 - val_loss: 0.5176\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5147 - val_loss: 0.5704\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4964 - val_loss: 0.6196\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4821 - val_loss: 0.6631\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4732 - val_loss: 0.7000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4663 - val_loss: 0.7294\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4618 - val_loss: 0.7510\n",
      "11\n",
      "maxabsG|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1937 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5329 - val_loss: 0.4573\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5291 - val_loss: 0.4660\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5257 - val_loss: 0.4740\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5229 - val_loss: 0.4814\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5206 - val_loss: 0.4881\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5186 - val_loss: 0.4940\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5170 - val_loss: 0.4994\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5156 - val_loss: 0.5043\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5144 - val_loss: 0.5087\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5135 - val_loss: 0.5128\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5124 - val_loss: 0.5164\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5116 - val_loss: 0.5196\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5108 - val_loss: 0.5224\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5101 - val_loss: 0.5250\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5096 - val_loss: 0.5274\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5090 - val_loss: 0.5297\n",
      "12\n",
      "robustS|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5141 - val_loss: 0.5222\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5129 - val_loss: 0.5275\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5115 - val_loss: 0.5332\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5104 - val_loss: 0.5390\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5090 - val_loss: 0.5449\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5079 - val_loss: 0.5512\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5066 - val_loss: 0.5579\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5053 - val_loss: 0.5647\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5041 - val_loss: 0.5717\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5028 - val_loss: 0.5789\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5017 - val_loss: 0.5863\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5005 - val_loss: 0.5938\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4994 - val_loss: 0.6016\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4984 - val_loss: 0.6096\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4975 - val_loss: 0.6177\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4965 - val_loss: 0.6258\n",
      "13\n",
      "minmaxp|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5112 - val_loss: 0.5365\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5095 - val_loss: 0.5436\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5081 - val_loss: 0.5502\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5066 - val_loss: 0.5580\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5052 - val_loss: 0.5667\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5036 - val_loss: 0.5755\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5019 - val_loss: 0.5852\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5007 - val_loss: 0.5955\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4991 - val_loss: 0.6063\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4977 - val_loss: 0.6174\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4967 - val_loss: 0.6291\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4954 - val_loss: 0.6411\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4943 - val_loss: 0.6533\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4933 - val_loss: 0.6654\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4926 - val_loss: 0.6772\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4921 - val_loss: 0.6890\n",
      "14\n",
      "standardizes|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1952 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5067 - val_loss: 0.8884\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4957 - val_loss: 0.8288\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4877 - val_loss: 0.7835\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4829 - val_loss: 0.7495\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4795 - val_loss: 0.7260\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4770 - val_loss: 0.7107\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4742 - val_loss: 0.7027\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4718 - val_loss: 0.6971\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4691 - val_loss: 0.6952\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4662 - val_loss: 0.6970\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4634 - val_loss: 0.7004\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4605 - val_loss: 0.7040\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4579 - val_loss: 0.7075\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4555 - val_loss: 0.7104\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4530 - val_loss: 0.7127\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4507 - val_loss: 0.7140\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4485 - val_loss: 0.7146\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4462 - val_loss: 0.7133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4438 - val_loss: 0.7110\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4414 - val_loss: 0.7063\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4388 - val_loss: 0.6988\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4363 - val_loss: 0.6922\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4336 - val_loss: 0.6878\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4310 - val_loss: 0.6838\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4281 - val_loss: 0.6823\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4253 - val_loss: 0.6806\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4224 - val_loss: 0.6777\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4195 - val_loss: 0.6755\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4163 - val_loss: 0.6695\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4132 - val_loss: 0.6653\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4102 - val_loss: 0.6652\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4071 - val_loss: 0.6688\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4039 - val_loss: 0.6697\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4008 - val_loss: 0.6652\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3972 - val_loss: 0.6529\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3937 - val_loss: 0.6416\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3898 - val_loss: 0.6377\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3860 - val_loss: 0.6349\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3819 - val_loss: 0.6360\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3777 - val_loss: 0.6338\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3739 - val_loss: 0.6312\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3694 - val_loss: 0.6187\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3649 - val_loss: 0.6098\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3602 - val_loss: 0.6019\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3556 - val_loss: 0.5931\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3506 - val_loss: 0.5831\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3458 - val_loss: 0.5757\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3405 - val_loss: 0.5678\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3351 - val_loss: 0.5598\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3297 - val_loss: 0.5572\n",
      "15\n",
      "minmaxE|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.5079 - val_loss: 0.5555\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5056 - val_loss: 0.5680\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5034 - val_loss: 0.5815\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5013 - val_loss: 0.5945\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4994 - val_loss: 0.6057\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4982 - val_loss: 0.6162\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4969 - val_loss: 0.6268\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4959 - val_loss: 0.6377\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4949 - val_loss: 0.6486\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4940 - val_loss: 0.6598\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4934 - val_loss: 0.6708\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4928 - val_loss: 0.6815\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4924 - val_loss: 0.6919\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4919 - val_loss: 0.7013\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4918 - val_loss: 0.7105\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4915 - val_loss: 0.7185\n",
      "16\n",
      "standardizeN|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5100 - val_loss: 0.5456\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5073 - val_loss: 0.5568\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5048 - val_loss: 0.5679\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5027 - val_loss: 0.5794\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5007 - val_loss: 0.5906\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4988 - val_loss: 0.6017\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4971 - val_loss: 0.6133\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4954 - val_loss: 0.6251\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4937 - val_loss: 0.6370\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4922 - val_loss: 0.6488\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4909 - val_loss: 0.6604\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4894 - val_loss: 0.6712\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4883 - val_loss: 0.6820\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4871 - val_loss: 0.6920\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4861 - val_loss: 0.7015\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4852 - val_loss: 0.7105\n",
      "17\n",
      "robustb|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5146 - val_loss: 0.5250\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5120 - val_loss: 0.5360\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5096 - val_loss: 0.5459\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5074 - val_loss: 0.5560\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5056 - val_loss: 0.5666\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5037 - val_loss: 0.5769\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5020 - val_loss: 0.5869\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5006 - val_loss: 0.5961\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4993 - val_loss: 0.6056\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4981 - val_loss: 0.6155\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4968 - val_loss: 0.6255\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4957 - val_loss: 0.6359\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4948 - val_loss: 0.6465\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4938 - val_loss: 0.6571\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4930 - val_loss: 0.6678\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4923 - val_loss: 0.6784\n",
      "18\n",
      "robustE|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5095 - val_loss: 0.5475\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5067 - val_loss: 0.5602\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5040 - val_loss: 0.5730\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5017 - val_loss: 0.5858\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4993 - val_loss: 0.5974\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4978 - val_loss: 0.6100\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4959 - val_loss: 0.6232\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4942 - val_loss: 0.6371\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4926 - val_loss: 0.6511\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4911 - val_loss: 0.6645\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4897 - val_loss: 0.6776\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4887 - val_loss: 0.6909\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4879 - val_loss: 0.7040\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4872 - val_loss: 0.7155\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4862 - val_loss: 0.7250\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4856 - val_loss: 0.7332\n",
      "19\n",
      "minmaxH|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5108 - val_loss: 0.5381\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5092 - val_loss: 0.5464\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5074 - val_loss: 0.5537\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5061 - val_loss: 0.5604\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5049 - val_loss: 0.5676\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5036 - val_loss: 0.5752\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5023 - val_loss: 0.5832\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5010 - val_loss: 0.5917\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5000 - val_loss: 0.6005\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4986 - val_loss: 0.6093\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4977 - val_loss: 0.6172\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4968 - val_loss: 0.6252\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4958 - val_loss: 0.6330\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4951 - val_loss: 0.6415\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4943 - val_loss: 0.6502\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4937 - val_loss: 0.6592\n",
      "20\n",
      "standardizeH|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5157 - val_loss: 0.5212\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5129 - val_loss: 0.5301\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5106 - val_loss: 0.5381\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5086 - val_loss: 0.5480\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5062 - val_loss: 0.5593\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5038 - val_loss: 0.5721\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5011 - val_loss: 0.5868\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4986 - val_loss: 0.6041\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4957 - val_loss: 0.6236\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4933 - val_loss: 0.6455\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4908 - val_loss: 0.6687\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4886 - val_loss: 0.6934\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4872 - val_loss: 0.7174\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4853 - val_loss: 0.7374\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4843 - val_loss: 0.7552\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4834 - val_loss: 0.7691\n",
      "21\n",
      "normalizeX|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1988 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5175 - val_loss: 0.5229\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5140 - val_loss: 0.5330\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5110 - val_loss: 0.5434\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5083 - val_loss: 0.5537\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5058 - val_loss: 0.5636\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5034 - val_loss: 0.5734\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5012 - val_loss: 0.5833\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4991 - val_loss: 0.5933\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4970 - val_loss: 0.6033\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4951 - val_loss: 0.6134\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4934 - val_loss: 0.6238\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4916 - val_loss: 0.6339\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4901 - val_loss: 0.6440\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4885 - val_loss: 0.6539\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4869 - val_loss: 0.6632\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4852 - val_loss: 0.6720\n",
      "22\n",
      "robustu|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_1992 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 18.2717 - val_loss: 0.0498\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 13.0626 - val_loss: 0.5915\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 8.6295 - val_loss: 2.6027\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 5.8817 - val_loss: 5.6144\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 5.1008 - val_loss: 9.0726\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 5.4749 - val_loss: 11.2480\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 5.7046 - val_loss: 12.0094\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 5.6541 - val_loss: 11.6181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 5.2803 - val_loss: 10.1778\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 4.5627 - val_loss: 7.9832\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.7262 - val_loss: 5.5597\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.0926 - val_loss: 3.8468\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.9735 - val_loss: 2.7487\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.9252 - val_loss: 2.0847\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.6395 - val_loss: 1.8873\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1525 - val_loss: 2.2423\n",
      "23\n",
      "robustr|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5179 - val_loss: 0.5157\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5141 - val_loss: 0.5294\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5106 - val_loss: 0.5446\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5074 - val_loss: 0.5598\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5046 - val_loss: 0.5754\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5021 - val_loss: 0.5914\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4996 - val_loss: 0.6078\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4976 - val_loss: 0.6246\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4957 - val_loss: 0.6415\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4941 - val_loss: 0.6583\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4926 - val_loss: 0.6749\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4916 - val_loss: 0.6911\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4907 - val_loss: 0.7059\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4904 - val_loss: 0.7194\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4897 - val_loss: 0.7302\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4894 - val_loss: 0.7391\n",
      "24\n",
      "minmaxe|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5148 - val_loss: 0.5195\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5136 - val_loss: 0.5234\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5127 - val_loss: 0.5274\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5118 - val_loss: 0.5310\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5109 - val_loss: 0.5348\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5101 - val_loss: 0.5387\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5093 - val_loss: 0.5426\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5084 - val_loss: 0.5468\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5076 - val_loss: 0.5510\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5067 - val_loss: 0.5555\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5060 - val_loss: 0.5602\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5050 - val_loss: 0.5648\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5042 - val_loss: 0.5698\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5034 - val_loss: 0.5744\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5026 - val_loss: 0.5791\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5019 - val_loss: 0.5842\n",
      "25\n",
      "standardizeG|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_2003 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5062 - val_loss: 0.5841\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5035 - val_loss: 0.5927\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5007 - val_loss: 0.6023\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4975 - val_loss: 0.6137\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4946 - val_loss: 0.6252\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4918 - val_loss: 0.6365\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4896 - val_loss: 0.6476\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4877 - val_loss: 0.6579\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4858 - val_loss: 0.6666\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4841 - val_loss: 0.6743\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4827 - val_loss: 0.6817\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4814 - val_loss: 0.6884\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4802 - val_loss: 0.6942\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4787 - val_loss: 0.6989\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4769 - val_loss: 0.7036\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4752 - val_loss: 0.7080\n",
      "26\n",
      "robustt|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_2009 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4920 - val_loss: 0.7056\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4869 - val_loss: 0.6942\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4823 - val_loss: 0.6852\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4791 - val_loss: 0.6768\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4754 - val_loss: 0.6712\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4721 - val_loss: 0.6666\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4692 - val_loss: 0.6620\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4669 - val_loss: 0.6576\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4646 - val_loss: 0.6547\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4624 - val_loss: 0.6528\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4603 - val_loss: 0.6516\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4584 - val_loss: 0.6510\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4564 - val_loss: 0.6526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4545 - val_loss: 0.6541\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4527 - val_loss: 0.6558\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4509 - val_loss: 0.6574\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4492 - val_loss: 0.6589\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4476 - val_loss: 0.6604\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4460 - val_loss: 0.6610\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4444 - val_loss: 0.6616\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4428 - val_loss: 0.6615\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4411 - val_loss: 0.6608\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4395 - val_loss: 0.6596\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4379 - val_loss: 0.6584\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4363 - val_loss: 0.6575\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4349 - val_loss: 0.6567\n",
      "27\n",
      "standardizeW|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_2012 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5324 - val_loss: 0.5104\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.5228 - val_loss: 0.5276\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5149 - val_loss: 0.5440\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5077 - val_loss: 0.5588\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5022 - val_loss: 0.5725\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4973 - val_loss: 0.5855\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4929 - val_loss: 0.5976\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4890 - val_loss: 0.6088\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4853 - val_loss: 0.6194\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4816 - val_loss: 0.6289\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4780 - val_loss: 0.6371\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4749 - val_loss: 0.6446\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4722 - val_loss: 0.6517\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4694 - val_loss: 0.6569\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4665 - val_loss: 0.6605\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4639 - val_loss: 0.6632\n",
      "28\n",
      "robustc|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5104 - val_loss: 0.5398\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5084 - val_loss: 0.5469\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5069 - val_loss: 0.5535\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5055 - val_loss: 0.5603\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5040 - val_loss: 0.5674\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5027 - val_loss: 0.5745\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5014 - val_loss: 0.5815\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5001 - val_loss: 0.5887\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4989 - val_loss: 0.5963\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4978 - val_loss: 0.6042\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4966 - val_loss: 0.6124\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4955 - val_loss: 0.6209\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4945 - val_loss: 0.6297\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4934 - val_loss: 0.6385\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4925 - val_loss: 0.6474\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4916 - val_loss: 0.6563\n",
      "29\n",
      "normalizeR|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_2021 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5126 - val_loss: 0.5207\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5099 - val_loss: 0.5278\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5071 - val_loss: 0.5344\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5046 - val_loss: 0.5413\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5022 - val_loss: 0.5486\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4999 - val_loss: 0.5558\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4977 - val_loss: 0.5627\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4955 - val_loss: 0.5694\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4935 - val_loss: 0.5761\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4914 - val_loss: 0.5829\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4895 - val_loss: 0.5896\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4878 - val_loss: 0.5964\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4860 - val_loss: 0.6030\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4844 - val_loss: 0.6094\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4828 - val_loss: 0.6156\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4813 - val_loss: 0.6216\n",
      "0\n",
      "minmaxq|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_2024 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-5d1f630b7909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdodge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDODGE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdodge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/raise_utils/hyperparams/dodge.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m                     model.set_data(data.x_train, data.y_train,\n\u001b[1;32m     74\u001b[0m                                    data.x_test, data.y_test)\n\u001b[0;32m---> 75\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0;31m# Run post-training hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/raise_utils/learners/feedforward.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         self.model.fit(np.array(self.x_train), np.array(self.y_train), batch_size=512, epochs=self.n_epochs,\n\u001b[0m\u001b[1;32m     90\u001b[0m                        validation_split=0.2, verbose=self.verbose, callbacks=[\n\u001b[1;32m     91\u001b[0m             \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"n_runs\": 10,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"d2h\", \"accuracy\", \"pd\", \"pf\", \"prec\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [FeedforwardDL(random={'n_layers': (2, 6), 'n_units': (3, 26)}, n_epochs=50, weighted=.3, wfo=True)],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"buildr\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        FeedforwardDL(random={'n_layers': (2, 6), 'n_units': (3, 26)}, n_epochs=50, weighted=.3, wfo=True))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
