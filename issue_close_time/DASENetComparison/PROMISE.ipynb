{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/Downloads/Bug-Fix Dataset (PROMISE\\'19)/dataset/snapshot/buildr-full-bug-fix-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Category</th>\n",
       "      <th>Key</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>Reporter</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Components</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUILDR</td>\n",
       "      <td>ASF</td>\n",
       "      <td>Apache Buildr Committee</td>\n",
       "      <td>build-management</td>\n",
       "      <td>BUILDR-235</td>\n",
       "      <td>Trivial</td>\n",
       "      <td>Closed</td>\n",
       "      <td>alexismidon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JRuby Site/documentation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUILDR</td>\n",
       "      <td>ASF</td>\n",
       "      <td>Apache Buildr Committee</td>\n",
       "      <td>build-management</td>\n",
       "      <td>BUILDR-236</td>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>alexismidon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUILDR</td>\n",
       "      <td>ASF</td>\n",
       "      <td>Apache Buildr Committee</td>\n",
       "      <td>build-management</td>\n",
       "      <td>BUILDR-239</td>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>jmuzz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Core features</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUILDR</td>\n",
       "      <td>ASF</td>\n",
       "      <td>Apache Buildr Committee</td>\n",
       "      <td>build-management</td>\n",
       "      <td>BUILDR-241</td>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>rsutphin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDE</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUILDR</td>\n",
       "      <td>ASF</td>\n",
       "      <td>Apache Buildr Committee</td>\n",
       "      <td>build-management</td>\n",
       "      <td>BUILDR-243</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Closed</td>\n",
       "      <td>digitalsanctum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Compilers</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Project Owner                  Manager          Category         Key  \\\n",
       "0  BUILDR   ASF  Apache Buildr Committee  build-management  BUILDR-235   \n",
       "1  BUILDR   ASF  Apache Buildr Committee  build-management  BUILDR-236   \n",
       "2  BUILDR   ASF  Apache Buildr Committee  build-management  BUILDR-239   \n",
       "3  BUILDR   ASF  Apache Buildr Committee  build-management  BUILDR-241   \n",
       "4  BUILDR   ASF  Apache Buildr Committee  build-management  BUILDR-243   \n",
       "\n",
       "  Priority  Status        Reporter Assignee                Components  ...  \\\n",
       "0  Trivial  Closed     alexismidon      NaN  JRuby Site/documentation  ...   \n",
       "1    Major  Closed     alexismidon      NaN                       NaN  ...   \n",
       "2    Major  Closed           jmuzz      NaN             Core features  ...   \n",
       "3    Major  Closed        rsutphin      NaN                       IDE  ...   \n",
       "4    Minor  Closed  digitalsanctum      NaN                 Compilers  ...   \n",
       "\n",
       "  SrcAddFiles SrcDelFiles SrcModFiles SrcAddLines SrcDelLines TestAddFiles  \\\n",
       "0           0           0           0           0           0            0   \n",
       "1           0           0           0           0           0            0   \n",
       "2           0           0           2          27           1            0   \n",
       "3           2           0           1         153           2            0   \n",
       "4           0           0           0           0           0            0   \n",
       "\n",
       "  TestDelFiles  TestModFiles TestAddLines TestDelLines  \n",
       "0            0             0            0            0  \n",
       "1            0             0            0            0  \n",
       "2            0             0            0            0  \n",
       "3            0             0            0            0  \n",
       "4            0             0            0            0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Project', 'Owner', 'Manager', 'Category', 'Key', 'Priority', 'Status',\n",
       "       'Reporter', 'Assignee', 'Components', 'SummaryTopWords',\n",
       "       'DescriptionTopWords', 'CommentsTopWords', 'CreationDate',\n",
       "       'ResolutionDate', 'AffectsVersions', 'FixVersions', 'NoComments',\n",
       "       'FirstCommentDate', 'LastCommentDate', 'NoWatchers', 'NoAttachments',\n",
       "       'FirstAttachmentDate', 'LastAttachmentDate', 'NoAttachedPatches',\n",
       "       'FirstAttachedPatchDate', 'LastAttachedPatchDate', 'InwardIssueLinks',\n",
       "       'OutwardIssueLinks', 'HasMergeCommit', 'CommitsMessagesTopWords',\n",
       "       'NoCommits', 'NoAuthors', 'NoCommitters', 'AuthorsFirstCommitDate',\n",
       "       'AuthorsLastCommitDate', 'CommittersFirstCommitDate',\n",
       "       'CommittersLastCommitDate', 'NonSrcAddFiles', 'NonSrcDelFiles',\n",
       "       'NonSrcModFiles', 'NonSrcAddLines', 'NonSrcDelLines', 'SrcAddFiles',\n",
       "       'SrcDelFiles', 'SrcModFiles', 'SrcAddLines', 'SrcDelLines',\n",
       "       'TestAddFiles', 'TestDelFiles', 'TestModFiles', 'TestAddLines',\n",
       "       'TestDelLines'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Project', 'Owner', 'Manager', 'Category', \n",
    "         'Key', 'Reporter', 'Assignee', 'Components',\n",
    "         'SummaryTopWords', 'DescriptionTopWords',\n",
    "         'CommentsTopWords', 'AffectsVersions',\n",
    "         'FixVersions', 'FirstCommentDate', 'LastCommentDate',\n",
    "         'FirstAttachmentDate', 'LastAttachmentDate',\n",
    "         'FirstAttachedPatchDate', 'LastAttachedPatchDate',\n",
    "         'InwardIssueLinks', 'OutwardIssueLinks',\n",
    "         'CommitsMessagesTopWords', 'AuthorsFirstCommitDate',\n",
    "         'AuthorsLastCommitDate', 'CommittersFirstCommitDate',\n",
    "         'CommittersLastCommitDate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ResolutionDate</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trivial</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-07 20:26:20+00:00</td>\n",
       "      <td>2009-03-12 22:52:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-14 00:35:08+00:00</td>\n",
       "      <td>2010-02-28 15:45:40+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-29 00:44:50+00:00</td>\n",
       "      <td>2009-03-12 23:20:28+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-04 17:19:01+00:00</td>\n",
       "      <td>2009-03-12 23:29:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Minor</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-06 21:40:44+00:00</td>\n",
       "      <td>2009-02-15 01:43:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Priority  Status               CreationDate             ResolutionDate  \\\n",
       "0  Trivial  Closed  2009-01-07 20:26:20+00:00  2009-03-12 22:52:51+00:00   \n",
       "1    Major  Closed  2009-01-14 00:35:08+00:00  2010-02-28 15:45:40+00:00   \n",
       "2    Major  Closed  2009-01-29 00:44:50+00:00  2009-03-12 23:20:28+00:00   \n",
       "3    Major  Closed  2009-02-04 17:19:01+00:00  2009-03-12 23:29:19+00:00   \n",
       "4    Minor  Closed  2009-02-06 21:40:44+00:00  2009-02-15 01:43:54+00:00   \n",
       "\n",
       "   NoComments  NoWatchers  NoAttachments  NoAttachedPatches  HasMergeCommit  \\\n",
       "0           0           0              1                  1               0   \n",
       "1           3           0              1                  0               0   \n",
       "2           2           0              2                  2               0   \n",
       "3           1           0              1                  1               0   \n",
       "4           1           0              0                  0               0   \n",
       "\n",
       "   NoCommits  ...  SrcAddFiles  SrcDelFiles  SrcModFiles  SrcAddLines  \\\n",
       "0          1  ...            0            0            0            0   \n",
       "1          0  ...            0            0            0            0   \n",
       "2          1  ...            0            0            2           27   \n",
       "3          2  ...            2            0            1          153   \n",
       "4          0  ...            0            0            0            0   \n",
       "\n",
       "   SrcDelLines  TestAddFiles  TestDelFiles  TestModFiles  TestAddLines  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            1             0             0             0             0   \n",
       "3            2             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   TestDelLines  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Priority'] = df['Priority'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ResolutionDate</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trivial</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-07 20:26:20+00:00</td>\n",
       "      <td>2009-03-12 22:52:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-14 00:35:08+00:00</td>\n",
       "      <td>2010-02-28 15:45:40+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-29 00:44:50+00:00</td>\n",
       "      <td>2009-03-12 23:20:28+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Major</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-04 17:19:01+00:00</td>\n",
       "      <td>2009-03-12 23:29:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Minor</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-06 21:40:44+00:00</td>\n",
       "      <td>2009-02-15 01:43:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Priority  Status               CreationDate             ResolutionDate  \\\n",
       "0  Trivial  Closed  2009-01-07 20:26:20+00:00  2009-03-12 22:52:51+00:00   \n",
       "1    Major  Closed  2009-01-14 00:35:08+00:00  2010-02-28 15:45:40+00:00   \n",
       "2    Major  Closed  2009-01-29 00:44:50+00:00  2009-03-12 23:20:28+00:00   \n",
       "3    Major  Closed  2009-02-04 17:19:01+00:00  2009-03-12 23:29:19+00:00   \n",
       "4    Minor  Closed  2009-02-06 21:40:44+00:00  2009-02-15 01:43:54+00:00   \n",
       "\n",
       "   NoComments  NoWatchers  NoAttachments  NoAttachedPatches  HasMergeCommit  \\\n",
       "0           0           0              1                  1               0   \n",
       "1           3           0              1                  0               0   \n",
       "2           2           0              2                  2               0   \n",
       "3           1           0              1                  1               0   \n",
       "4           1           0              0                  0               0   \n",
       "\n",
       "   NoCommits  ...  SrcAddFiles  SrcDelFiles  SrcModFiles  SrcAddLines  \\\n",
       "0          1  ...            0            0            0            0   \n",
       "1          0  ...            0            0            0            0   \n",
       "2          1  ...            0            0            2           27   \n",
       "3          2  ...            2            0            1          153   \n",
       "4          0  ...            0            0            0            0   \n",
       "\n",
       "   SrcDelLines  TestAddFiles  TestDelFiles  TestModFiles  TestAddLines  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            1             0             0             0             0   \n",
       "3            2             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   TestDelLines  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Priority'] = df['Priority'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ResolutionDate</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-07 20:26:20+00:00</td>\n",
       "      <td>2009-03-12 22:52:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-14 00:35:08+00:00</td>\n",
       "      <td>2010-02-28 15:45:40+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-01-29 00:44:50+00:00</td>\n",
       "      <td>2009-03-12 23:20:28+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-04 17:19:01+00:00</td>\n",
       "      <td>2009-03-12 23:29:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2009-02-06 21:40:44+00:00</td>\n",
       "      <td>2009-02-15 01:43:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Status               CreationDate             ResolutionDate  \\\n",
       "0         4  Closed  2009-01-07 20:26:20+00:00  2009-03-12 22:52:51+00:00   \n",
       "1         2  Closed  2009-01-14 00:35:08+00:00  2010-02-28 15:45:40+00:00   \n",
       "2         2  Closed  2009-01-29 00:44:50+00:00  2009-03-12 23:20:28+00:00   \n",
       "3         2  Closed  2009-02-04 17:19:01+00:00  2009-03-12 23:29:19+00:00   \n",
       "4         3  Closed  2009-02-06 21:40:44+00:00  2009-02-15 01:43:54+00:00   \n",
       "\n",
       "   NoComments  NoWatchers  NoAttachments  NoAttachedPatches  HasMergeCommit  \\\n",
       "0           0           0              1                  1               0   \n",
       "1           3           0              1                  0               0   \n",
       "2           2           0              2                  2               0   \n",
       "3           1           0              1                  1               0   \n",
       "4           1           0              0                  0               0   \n",
       "\n",
       "   NoCommits  ...  SrcAddFiles  SrcDelFiles  SrcModFiles  SrcAddLines  \\\n",
       "0          1  ...            0            0            0            0   \n",
       "1          0  ...            0            0            0            0   \n",
       "2          1  ...            0            0            2           27   \n",
       "3          2  ...            2            0            1          153   \n",
       "4          0  ...            0            0            0            0   \n",
       "\n",
       "   SrcDelLines  TestAddFiles  TestDelFiles  TestModFiles  TestAddLines  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            1             0             0             0             0   \n",
       "3            2             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   TestDelLines  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Status'] = df['Status'].astype('category')\n",
    "df['Status'] = df['Status'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ResolutionDate</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-07 20:26:20+00:00</td>\n",
       "      <td>2009-03-12 22:52:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-14 00:35:08+00:00</td>\n",
       "      <td>2010-02-28 15:45:40+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-29 00:44:50+00:00</td>\n",
       "      <td>2009-03-12 23:20:28+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-02-04 17:19:01+00:00</td>\n",
       "      <td>2009-03-12 23:29:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-02-06 21:40:44+00:00</td>\n",
       "      <td>2009-02-15 01:43:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Status               CreationDate             ResolutionDate  \\\n",
       "0         4       0  2009-01-07 20:26:20+00:00  2009-03-12 22:52:51+00:00   \n",
       "1         2       0  2009-01-14 00:35:08+00:00  2010-02-28 15:45:40+00:00   \n",
       "2         2       0  2009-01-29 00:44:50+00:00  2009-03-12 23:20:28+00:00   \n",
       "3         2       0  2009-02-04 17:19:01+00:00  2009-03-12 23:29:19+00:00   \n",
       "4         3       0  2009-02-06 21:40:44+00:00  2009-02-15 01:43:54+00:00   \n",
       "\n",
       "   NoComments  NoWatchers  NoAttachments  NoAttachedPatches  HasMergeCommit  \\\n",
       "0           0           0              1                  1               0   \n",
       "1           3           0              1                  0               0   \n",
       "2           2           0              2                  2               0   \n",
       "3           1           0              1                  1               0   \n",
       "4           1           0              0                  0               0   \n",
       "\n",
       "   NoCommits  ...  SrcAddFiles  SrcDelFiles  SrcModFiles  SrcAddLines  \\\n",
       "0          1  ...            0            0            0            0   \n",
       "1          0  ...            0            0            0            0   \n",
       "2          1  ...            0            0            2           27   \n",
       "3          2  ...            2            0            1          153   \n",
       "4          0  ...            0            0            0            0   \n",
       "\n",
       "   SrcDelLines  TestAddFiles  TestDelFiles  TestModFiles  TestAddLines  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            1             0             0             0             0   \n",
       "3            2             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   TestDelLines  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 227 entries, 0 to 226\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Priority           227 non-null    int8  \n",
      " 1   Status             227 non-null    int8  \n",
      " 2   CreationDate       227 non-null    object\n",
      " 3   ResolutionDate     227 non-null    object\n",
      " 4   NoComments         227 non-null    int64 \n",
      " 5   NoWatchers         227 non-null    int64 \n",
      " 6   NoAttachments      227 non-null    int64 \n",
      " 7   NoAttachedPatches  227 non-null    int64 \n",
      " 8   HasMergeCommit     227 non-null    int64 \n",
      " 9   NoCommits          227 non-null    int64 \n",
      " 10  NoAuthors          227 non-null    int64 \n",
      " 11  NoCommitters       227 non-null    int64 \n",
      " 12  NonSrcAddFiles     227 non-null    int64 \n",
      " 13  NonSrcDelFiles     227 non-null    int64 \n",
      " 14  NonSrcModFiles     227 non-null    int64 \n",
      " 15  NonSrcAddLines     227 non-null    int64 \n",
      " 16  NonSrcDelLines     227 non-null    int64 \n",
      " 17  SrcAddFiles        227 non-null    int64 \n",
      " 18  SrcDelFiles        227 non-null    int64 \n",
      " 19  SrcModFiles        227 non-null    int64 \n",
      " 20  SrcAddLines        227 non-null    int64 \n",
      " 21  SrcDelLines        227 non-null    int64 \n",
      " 22  TestAddFiles       227 non-null    int64 \n",
      " 23  TestDelFiles       227 non-null    int64 \n",
      " 24  TestModFiles       227 non-null    int64 \n",
      " 25  TestAddLines       227 non-null    int64 \n",
      " 26  TestDelLines       227 non-null    int64 \n",
      "dtypes: int64(23), int8(2), object(2)\n",
      "memory usage: 44.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CreationDate'] = pd.to_datetime(df['CreationDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ResolutionDate'] = pd.to_datetime(df['ResolutionDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ResolutionDate</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcAddFiles</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-07 20:26:20+00:00</td>\n",
       "      <td>2009-03-12 22:52:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-14 00:35:08+00:00</td>\n",
       "      <td>2010-02-28 15:45:40+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-29 00:44:50+00:00</td>\n",
       "      <td>2009-03-12 23:20:28+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-02-04 17:19:01+00:00</td>\n",
       "      <td>2009-03-12 23:29:19+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-02-06 21:40:44+00:00</td>\n",
       "      <td>2009-02-15 01:43:54+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Status              CreationDate            ResolutionDate  \\\n",
       "0         4       0 2009-01-07 20:26:20+00:00 2009-03-12 22:52:51+00:00   \n",
       "1         2       0 2009-01-14 00:35:08+00:00 2010-02-28 15:45:40+00:00   \n",
       "2         2       0 2009-01-29 00:44:50+00:00 2009-03-12 23:20:28+00:00   \n",
       "3         2       0 2009-02-04 17:19:01+00:00 2009-03-12 23:29:19+00:00   \n",
       "4         3       0 2009-02-06 21:40:44+00:00 2009-02-15 01:43:54+00:00   \n",
       "\n",
       "   NoComments  NoWatchers  NoAttachments  NoAttachedPatches  HasMergeCommit  \\\n",
       "0           0           0              1                  1               0   \n",
       "1           3           0              1                  0               0   \n",
       "2           2           0              2                  2               0   \n",
       "3           1           0              1                  1               0   \n",
       "4           1           0              0                  0               0   \n",
       "\n",
       "   NoCommits  ...  SrcAddFiles  SrcDelFiles  SrcModFiles  SrcAddLines  \\\n",
       "0          1  ...            0            0            0            0   \n",
       "1          0  ...            0            0            0            0   \n",
       "2          1  ...            0            0            2           27   \n",
       "3          2  ...            2            0            1          153   \n",
       "4          0  ...            0            0            0            0   \n",
       "\n",
       "   SrcDelLines  TestAddFiles  TestDelFiles  TestModFiles  TestAddLines  \\\n",
       "0            0             0             0             0             0   \n",
       "1            0             0             0             0             0   \n",
       "2            1             0             0             0             0   \n",
       "3            2             0             0             0             0   \n",
       "4            0             0             0             0             0   \n",
       "\n",
       "   TestDelLines  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 227 entries, 0 to 226\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count  Dtype              \n",
      "---  ------             --------------  -----              \n",
      " 0   Priority           227 non-null    int8               \n",
      " 1   Status             227 non-null    int8               \n",
      " 2   CreationDate       227 non-null    datetime64[ns, UTC]\n",
      " 3   ResolutionDate     227 non-null    datetime64[ns, UTC]\n",
      " 4   NoComments         227 non-null    int64              \n",
      " 5   NoWatchers         227 non-null    int64              \n",
      " 6   NoAttachments      227 non-null    int64              \n",
      " 7   NoAttachedPatches  227 non-null    int64              \n",
      " 8   HasMergeCommit     227 non-null    int64              \n",
      " 9   NoCommits          227 non-null    int64              \n",
      " 10  NoAuthors          227 non-null    int64              \n",
      " 11  NoCommitters       227 non-null    int64              \n",
      " 12  NonSrcAddFiles     227 non-null    int64              \n",
      " 13  NonSrcDelFiles     227 non-null    int64              \n",
      " 14  NonSrcModFiles     227 non-null    int64              \n",
      " 15  NonSrcAddLines     227 non-null    int64              \n",
      " 16  NonSrcDelLines     227 non-null    int64              \n",
      " 17  SrcAddFiles        227 non-null    int64              \n",
      " 18  SrcDelFiles        227 non-null    int64              \n",
      " 19  SrcModFiles        227 non-null    int64              \n",
      " 20  SrcAddLines        227 non-null    int64              \n",
      " 21  SrcDelLines        227 non-null    int64              \n",
      " 22  TestAddFiles       227 non-null    int64              \n",
      " 23  TestDelFiles       227 non-null    int64              \n",
      " 24  TestModFiles       227 non-null    int64              \n",
      " 25  TestAddLines       227 non-null    int64              \n",
      " 26  TestDelLines       227 non-null    int64              \n",
      "dtypes: datetime64[ns, UTC](2), int64(23), int8(2)\n",
      "memory usage: 44.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ResolutionTime'] = (df['ResolutionDate'] - df['CreationDate']).astype('timedelta64[D]').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CreationDate', 'ResolutionDate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>NoComments</th>\n",
       "      <th>NoWatchers</th>\n",
       "      <th>NoAttachments</th>\n",
       "      <th>NoAttachedPatches</th>\n",
       "      <th>HasMergeCommit</th>\n",
       "      <th>NoCommits</th>\n",
       "      <th>NoAuthors</th>\n",
       "      <th>NoCommitters</th>\n",
       "      <th>...</th>\n",
       "      <th>SrcDelFiles</th>\n",
       "      <th>SrcModFiles</th>\n",
       "      <th>SrcAddLines</th>\n",
       "      <th>SrcDelLines</th>\n",
       "      <th>TestAddFiles</th>\n",
       "      <th>TestDelFiles</th>\n",
       "      <th>TestModFiles</th>\n",
       "      <th>TestAddLines</th>\n",
       "      <th>TestDelLines</th>\n",
       "      <th>ResolutionTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Status  NoComments  NoWatchers  NoAttachments  NoAttachedPatches  \\\n",
       "0         4       0           0           0              1                  1   \n",
       "1         2       0           3           0              1                  0   \n",
       "2         2       0           2           0              2                  2   \n",
       "3         2       0           1           0              1                  1   \n",
       "4         3       0           1           0              0                  0   \n",
       "\n",
       "   HasMergeCommit  NoCommits  NoAuthors  NoCommitters  ...  SrcDelFiles  \\\n",
       "0               0          1          1             1  ...            0   \n",
       "1               0          0          0             0  ...            0   \n",
       "2               0          1          1             1  ...            0   \n",
       "3               0          2          1             1  ...            0   \n",
       "4               0          0          0             0  ...            0   \n",
       "\n",
       "   SrcModFiles  SrcAddLines  SrcDelLines  TestAddFiles  TestDelFiles  \\\n",
       "0            0            0            0             0             0   \n",
       "1            0            0            0             0             0   \n",
       "2            2           27            1             0             0   \n",
       "3            1          153            2             0             0   \n",
       "4            0            0            0             0             0   \n",
       "\n",
       "   TestModFiles  TestAddLines  TestDelLines  ResolutionTime  \n",
       "0             0             0             0              64  \n",
       "1             0             0             0             410  \n",
       "2             0             0             0              42  \n",
       "3             0             0             0              36  \n",
       "4             0             0             0               8  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'ResolutionTime'}>]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist('ResolutionTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['ResolutionTime'] < 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 7) & (df['ResolutionTime'] >= 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 14) & (df['ResolutionTime'] >= 7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 30) & (df['ResolutionTime'] >= 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 90) & (df['ResolutionTime'] >= 30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 180) & (df['ResolutionTime'] >= 90)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['ResolutionTime'] < 365) & (df['ResolutionTime'] >= 180)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['ResolutionTime'] >= 365])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ResolutionTime'] < 1,'ResolutionTime'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 7) & (df['ResolutionTime'] >= 1),'ResolutionTime'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 14) & (df['ResolutionTime'] >= 7),'ResolutionTime'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 30) & (df['ResolutionTime'] >= 14),'ResolutionTime'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 90) & (df['ResolutionTime'] >= 30),'ResolutionTime'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 180) & (df['ResolutionTime'] >= 90),'ResolutionTime'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ResolutionTime'] < 365) & (df['ResolutionTime'] >= 180),'ResolutionTime'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ResolutionTime'] >= 365,'ResolutionTime'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAR7ElEQVR4nO3db4xldX3H8ffXBSLdwV0QOtkspEsiwVg2gntDazBmBsRgMbIPDJFQsxia6YNqMNLU1SeNSZuuadAaappugLJNV0aKkiVYtWTdqTUp6A5iV1goSJe4W9yp7rI4lNSs/fbBnG23w525d+7cO3e+9P1KJvee3z3nzGf+5DNnfveceyMzkSTV84ZhB5Ak9cYCl6SiLHBJKsoCl6SiLHBJKuqMlfxk559/fm7atKmnbV955RXWrl3b30ADVCmvWQenUt5KWaFW3uVmnZ6e/mlmXvCaBzJzxT62bNmSvdq3b1/P2w5DpbxmHZxKeStlzayVd7lZgf3ZplOdQpGkoixwSSrKApekoixwSSrKApekoixwSSqqY4FHxKUR8cRpHy9HxMcj4ryIeCQinm1uz12JwJKkOR0LPDOfyczLM/NyYAvwH8CDwHZgb2ZeAuxtliVJK2SpUyjXAD/KzBeAG4BdzfguYGsfc0mSOohcwhs6RMQ9wOOZ+ecR8VJmrm/GAzh+anneNhPABMDo6OiWycnJnoLOHDvB0Vd72nSgNm9c13Z8dnaWkZGRFU7TG7MOTqW8lbJCrbzLzTo+Pj6dma35410XeEScBfwb8OuZefT0Am8eP56Zi86Dt1qt3L9//9KSN+7cvYc7DqzoS7d05dCO69uOT01NMTY2trJhemTWwamUt1JWqJV3uVkjom2BL2UK5X3MHX0fbZaPRsSGZucbgJme00mSlmwpBX4TcN9pyw8B25r724A9/QolSeqsqwKPiLXAtcBXTxveAVwbEc8C72mWJUkrpKtJ5cx8BXjzvLGfMXdWiiRpCLwSU5KKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqahu35V+fUQ8EBFPR8TBiHhnRJwXEY9ExLPN7bmDDitJ+l/dHoF/AfhGZr4VeDtwENgO7M3MS4C9zbIkaYV0LPCIWAe8G7gbIDN/kZkvATcAu5rVdgFbBxNRktROZObiK0RcDuwEnmLu6HsauA04kpnrm3UCOH5qed72E8AEwOjo6JbJycmegs4cO8HRV3vadKA2b1zXdnx2dpaRkZEVTtMbsw5OpbyVskKtvMvNOj4+Pp2Zrfnj3RR4C3gUuCozH4uILwAvAx87vbAj4nhmLjoP3mq1cv/+/b3k587de7jjwBk9bTtIh3Zc33Z8amqKsbGxlQ3TI7MOTqW8lbJCrbzLzRoRbQu8mznww8DhzHysWX4AeAdwNCI2NDvfAMz0nE6StGQdCzwzfwL8OCIubYauYW465SFgWzO2DdgzkISSpLa6nZP4GLA7Is4Cngc+wlz53x8RtwIvADcOJqIkqZ2uCjwznwBeM//C3NG4JGkIvBJTkoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckorq6l3pI+IQ8HPgl8DJzGxFxHnAl4FNwCHgxsw8PpiYkqT5lnIEPp6Zl2dmq1neDuzNzEuAvc2yJGmFLGcK5QZgV3N/F7B12WkkSV2LzOy8UsS/AseBBP4yM3dGxEuZub55PIDjp5bnbTsBTACMjo5umZyc7CnozLETHH21p00HavPGdW3HZ2dnGRkZWeE0vTHr4FTKWykr1Mq73Kzj4+PTp81+/I+u5sCBd2XmkYj4VeCRiHj69AczMyOi7V+CzNwJ7ARotVo5Nja2tOSNO3fv4Y4D3cZdOYduHms7PjU1Ra9f60oz6+BUylspK9TKO6isXU2hZOaR5nYGeBC4EjgaERsAmtuZvqeTJC2oY4FHxNqIOOfUfeC9wA+Bh4BtzWrbgD2DCilJeq1u5iRGgQfnprk5A/hSZn4jIr4H3B8RtwIvADcOLqYkab6OBZ6ZzwNvbzP+M+CaQYSSJHXmlZiSVJQFLklFWeCSVJQFLklFWeCSVJQFLklFWeCSVJQFLklFWeCSVJQFLklFWeCSVJQFLklFrb53SChm0/avtR2/ffNJblngsZVwaMf1Q/vcklaGR+CSVJQFLklFWeCSVJQFLklFWeCSVJQFLklFWeCSVFTXBR4RayLi+xHxcLN8cUQ8FhHPRcSXI+KswcWUJM23lCPw24CDpy1/Fvh8Zr4FOA7c2s9gkqTFdVXgEXEhcD1wV7McwNXAA80qu4CtA8gnSVpAZGbnlSIeAP4EOAf4feAW4NHm6JuIuAj4emZe1mbbCWACYHR0dMvk5GRPQWeOneDoqz1tOhSjZzPUvJs3rut63dnZWUZGRgaYpn8qZYVaeStlhVp5l5t1fHx8OjNb88c7vhZKRLwfmMnM6YgYW+onzsydwE6AVquVY2NL3gUAd+7ewx0H6rx0y+2bTw4176Gbx7ped2pqil5/LiutUlaolbdSVqiVd1BZu2mYq4APRMRvAW8E3gR8AVgfEWdk5kngQuBI39NJkhbUcQ48Mz+VmRdm5ibgQ8C3MvNmYB/wwWa1bcCegaWUJL3Gcs4D/yTwiYh4DngzcHd/IkmSurGkSdrMnAKmmvvPA1f2P5IkqRteiSlJRVngklSUBS5JRVngklSUBS5JRVngklSUBS5JRVngklSUBS5JRVngklSUBS5JRVngklSUBS5JRVngklSUBS5JRVngklSUBS5JRVngklTUkt5STZJWs03bvzbsCG3de93agezXI3BJKsoCl6SiOhZ4RLwxIr4bET+IiCcj4jPN+MUR8VhEPBcRX46IswYfV5J0SjdH4P8JXJ2ZbwcuB66LiN8EPgt8PjPfAhwHbh1YSknSa3Qs8Jwz2yye2XwkcDXwQDO+C9g6iICSpPYiMzuvFLEGmAbeAnwR+FPg0ebom4i4CPh6Zl7WZtsJYAJgdHR0y+TkZE9BZ46d4OirPW06FKNnM9S8mzeu63rd2dlZRkZGBpimfyplhVp5K2WF9nkPHDkxpDSLu3jdmmV9b8fHx6czszV/vKvTCDPzl8DlEbEeeBB4a7efODN3AjsBWq1Wjo2Ndbvp/3Hn7j3ccaDOWY+3bz451LyHbh7ret2pqSl6/bmstEpZoVbeSlmhfd5bVvFphIP43i7pLJTMfAnYB7wTWB8RpxrqQuBIf6NJkhbTzVkoFzRH3kTE2cC1wEHmivyDzWrbgD0DyihJaqOb//E3ALuaefA3APdn5sMR8RQwGRF/BHwfuHuAOSVJ83Qs8Mz8Z+CKNuPPA1cOIpQkqTOvxJSkoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSqqY4FHxEURsS8inoqIJyPitmb8vIh4JCKebW7PHXxcSdIpHd+VHjgJ3J6Zj0fEOcB0RDwC3ALszcwdEbEd2A58cnBRpcHZtP1rA9nv7ZtPcssy9n1ox/V9TKPXm45H4Jn5YmY+3tz/OXAQ2AjcAOxqVtsFbB1QRklSG0uaA4+ITcAVwGPAaGa+2Dz0E2C0v9EkSYuJzOxuxYgR4B+AP87Mr0bES5m5/rTHj2fma+bBI2ICmAAYHR3dMjk52VPQmWMnOPpqT5sOxejZDDXv5o3rul53dnaWkZGRAabpn0FlPXDkRN/3Ccv/PVjKz3G5Kv0eQPu8g/o5LtfF69Ys63s7Pj4+nZmt+eNdFXhEnAk8DHwzMz/XjD0DjGXmixGxAZjKzEsX20+r1cr9+/f39AXcuXsPdxzoZsp+dbh988mh5l3K3OnU1BRjY2ODC9NHg8o6yDnw5fwerOQceKXfA2ifd1A/x+W697q1y/reRkTbAu/mLJQA7gYOnirvxkPAtub+NmBPz+kkSUvWzaHBVcCHgQMR8UQz9mlgB3B/RNwKvADcOJCEkqS2OhZ4Zn4HiAUevqa/cSRJ3fJKTEkqqs6zgtL/Qyv5pNxSLjryAqPVwSNwSSrKApekopxC0Ypa7pTAcl9bRHo98QhckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpKC+ll7Rkq+Gty3xZBY/AJaksC1ySinIK5XVqKf/i+q+oVJNH4JJUlAUuSUV1LPCIuCciZiLih6eNnRcRj0TEs83tuYONKUmar5sj8HuB6+aNbQf2ZuYlwN5mWZK0gjoWeGZ+Gzg2b/gGYFdzfxewtb+xJEmdRGZ2XiliE/BwZl7WLL+Umeub+wEcP7XcZtsJYAJgdHR0y+TkZE9BZ46d4OirPW06FKNnUyavWQenUt5KWaFW3ovXrWFkZKTn7cfHx6czszV/fNmnEWZmRsSCfwUycyewE6DVauXY2FhPn+fO3Xu440Cdsx5v33yyTF6zDk6lvJWyQq289163ll67bzG9noVyNCI2ADS3M/2LJEnqRq8F/hCwrbm/DdjTnziSpG51cxrhfcA/AZdGxOGIuBXYAVwbEc8C72mWJUkrqOMEUmbetMBD1/Q5iyRpCbwSU5KKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKssAlqSgLXJKKWlaBR8R1EfFMRDwXEdv7FUqS1FnPBR4Ra4AvAu8D3gbcFBFv61cwSdLilnMEfiXwXGY+n5m/ACaBG/oTS5LUSWRmbxtGfBC4LjN/p1n+MPAbmfnReetNABPN4qXAMz1mPR/4aY/bDkOlvGYdnEp5K2WFWnmXm/XXMvOC+YNnLGOHXcnMncDO5e4nIvZnZqsPkVZEpbxmHZxKeStlhVp5B5V1OVMoR4CLTlu+sBmTJK2A5RT494BLIuLiiDgL+BDwUH9iSZI66XkKJTNPRsRHgW8Ca4B7MvPJviV7rWVPw6ywSnnNOjiV8lbKCrXyDiRrz09iSpKGyysxJakoC1ySiipR4FUu2Y+IeyJiJiJ+OOws3YiIiyJiX0Q8FRFPRsRtw860kIh4Y0R8NyJ+0GT9zLAzdRIRayLi+xHx8LCzdBIRhyLiQEQ8ERH7h51nMRGxPiIeiIinI+JgRLxz2JkWEhGXNt/TUx8vR8TH+7b/1T4H3lyy/y/AtcBh5s5+uSkznxpqsDYi4t3ALPDXmXnZsPN0EhEbgA2Z+XhEnANMA1tX6fc2gLWZORsRZwLfAW7LzEeHHG1BEfEJoAW8KTPfP+w8i4mIQ0ArM1f9hTERsQv4x8y8qzkD7lcy86Uhx+qo6bIjzF3w+EI/9lnhCLzMJfuZ+W3g2LBzdCszX8zMx5v7PwcOAhuHm6q9nDPbLJ7ZfKzao4+IuBC4Hrhr2FleTyJiHfBu4G6AzPxFhfJuXAP8qF/lDTUKfCPw49OWD7NKS6ayiNgEXAE8NuQoC2qmJJ4AZoBHMnPVZgX+DPgD4L+GnKNbCfx9REw3L3+xWl0M/DvwV8301F0RsXbYobr0IeC+fu6wQoFrwCJiBPgK8PHMfHnYeRaSmb/MzMuZu+r3yohYldNUEfF+YCYzp4edZQnelZnvYO7VRX+vmQ5cjc4A3gH8RWZeAbwCrNrnxU5ppno+APxtP/dbocC9ZH+AmvnkrwC7M/Orw87TjeZf5n3AdUOOspCrgA8088qTwNUR8TfDjbS4zDzS3M4ADzI3dbkaHQYOn/bf1wPMFfpq9z7g8cw82s+dVihwL9kfkOaJwbuBg5n5uWHnWUxEXBAR65v7ZzP3pPbTQw21gMz8VGZemJmbmPt9/VZm/vaQYy0oItY2T2LTTEe8F1iVZ1Jl5k+AH0fEpc3QNcCqe9K9jZvo8/QJrMCrES7XEC7Z71lE3AeMAedHxGHgDzPz7uGmWtRVwIeBA83cMsCnM/PvhhdpQRuAXc0z+W8A7s/MVX96XhGjwINzf885A/hSZn5juJEW9TFgd3NA9zzwkSHnWVTzR/Fa4Hf7vu/VfhqhJKm9ClMokqQ2LHBJKsoCl6SiLHBJKsoCl6SiLHBJKsoCl6Si/hvJPi477pT7ggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['ResolutionTime'].hist(bins=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.learners import MulticlassDL\n",
    "from raise_utils.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = MulticlassDL(n_classes=8, n_layers=5, n_units=len(df.columns), n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('ResolutionTime', axis=1)\n",
    "y = df['ResolutionTime']\n",
    "\n",
    "y = to_categorical(y, num_classes=8)\n",
    "\n",
    "learner.set_data(*Data(*train_test_split(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 4.0194 - val_loss: 4.3536\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6138 - val_loss: 3.8695\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.2879 - val_loss: 3.4814\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.0174 - val_loss: 3.1732\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.8149 - val_loss: 2.9414\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.6427 - val_loss: 2.7753\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4967 - val_loss: 2.6576\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3822 - val_loss: 2.5821\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2971 - val_loss: 2.5326\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2325 - val_loss: 2.4937\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1830 - val_loss: 2.4578\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1430 - val_loss: 2.4268\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1080 - val_loss: 2.3919\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0765 - val_loss: 2.3534\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0503 - val_loss: 2.3101\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0274 - val_loss: 2.2660\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.0092 - val_loss: 2.2290\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9946 - val_loss: 2.2027\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9837 - val_loss: 2.1959\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9784 - val_loss: 2.2000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9797 - val_loss: 2.2008\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9795 - val_loss: 2.1937\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9699 - val_loss: 2.1819\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9547 - val_loss: 2.1704\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9408 - val_loss: 2.1632\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9307 - val_loss: 2.1598\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9226 - val_loss: 2.1591\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9167 - val_loss: 2.1602\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9121 - val_loss: 2.1624\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9082 - val_loss: 2.1643\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9045 - val_loss: 2.1653\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9004 - val_loss: 2.1649\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8959 - val_loss: 2.1619\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8907 - val_loss: 2.1574\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8851 - val_loss: 2.1522\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.8787 - val_loss: 2.1455\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8718 - val_loss: 2.1387\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8650 - val_loss: 2.1326\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8584 - val_loss: 2.1273\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8527 - val_loss: 2.1228\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8475 - val_loss: 2.1191\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8429 - val_loss: 2.1150\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8384 - val_loss: 2.1109\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8336 - val_loss: 2.1056\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8290 - val_loss: 2.0998\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8250 - val_loss: 2.0939\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8212 - val_loss: 2.0883\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8173 - val_loss: 2.0838\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8133 - val_loss: 2.0806\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8092 - val_loss: 2.0779\n"
     ]
    }
   ],
   "source": [
    "learner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/raise_utils/learners/multiclassdl.py:84: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "preds = learner.predict(learner.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 5, 7, 7, 0, 0, 7, 1, 0, 0, 7, 0, 1, 0, 7, 0, 0, 0, 0, 0, 0, 7,\n",
       "       7, 4, 0, 0, 0, 0, 7, 7, 0, 0, 7, 1, 1, 0, 1, 1, 0, 0, 7, 0, 7, 7,\n",
       "       0, 7, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 7])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.metrics import ClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ClassificationMetrics(np.argmax(learner.y_test, axis=-1), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_metrics(['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2982456140350877]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.3384 - val_loss: 1.9640\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.0903 - val_loss: 2.0076\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9955 - val_loss: 2.0809\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.9439 - val_loss: 2.1479\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.8830 - val_loss: 2.2279\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.8223 - val_loss: 2.3313\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7588 - val_loss: 2.4979\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.7026 - val_loss: 2.6473\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6510 - val_loss: 2.8050\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6051 - val_loss: 2.9489\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5622 - val_loss: 3.0709\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5189 - val_loss: 3.1863\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.4822 - val_loss: 3.2946\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4368 - val_loss: 3.3696\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3942 - val_loss: 3.5157\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3542 - val_loss: 3.5498\n"
     ]
    }
   ],
   "source": [
    "learner = MulticlassDL(n_classes=8, wfo=True, n_layers=5, n_units=len(df.columns), n_epochs=50)\n",
    "\n",
    "x = df.drop('ResolutionTime', axis=1)\n",
    "y = df['ResolutionTime']\n",
    "\n",
    "y = to_categorical(y, num_classes=8)\n",
    "\n",
    "learner.set_data(*Data(*train_test_split(x, y)))\n",
    "learner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('promise-buildr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.learners import FeedforwardDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('ResolutionTime', axis=1)\n",
    "y = (df['ResolutionTime'] == 1)\n",
    "\n",
    "data = Data(*train_test_split(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19411764705882353"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.y_train) / len(data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.hyperparams import DODGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x154021fd0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 26, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': 0.3, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1540211f0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x153ab6970>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x153ab6340>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x152e598b0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155f088e0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 22, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x153ab6940>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x152bf68e0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 6, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x153735550>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x152c08fd0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1536b96a0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1535e7c70>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x15024c520>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x15316b9d0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x15316bbe0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x15316b820>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x15316bac0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155f79730>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155f792e0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155f79eb0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 18, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155f79bb0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 24, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155f79670>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 11, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1563c3280>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1563c3b80>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 24, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x152f49c10>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x152f49940>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 21, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x152f493d0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 26, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155de2b80>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 7, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155de21c0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x156d87940>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 12, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x156d87c10>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x156d87d30>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 5, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x156d87040>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 24, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x156d87430>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 24, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x156f6dd30>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x156f6d340>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 26, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x156f6d730>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 3, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x156f6d970>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 19, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x156f6de80>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x153ec92e0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 23, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155d356a0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 4, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155d351f0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 9, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155d350d0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 8, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155d35ca0>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 4, 'n_units': 21, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1568db940>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 22, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1528f3f40>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 20, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x154f31a60>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 14, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x153550c40>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 3, 'n_units': 17, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1552b1790>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 6, 'n_units': 16, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x1552b1d90>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 2, 'n_units': 24, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "{'activation': 'relu', 'hooks': None, 'learner': <raise_utils.learners.feedforward.FeedforwardDL object at 0x155153910>, 'loss': 'binary_crossentropy', 'n_epochs': 50, 'n_layers': 5, 'n_units': 15, 'name': 'rf', 'optimizer': 'adam', 'random': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'random_map': {'n_layers': (2, 6), 'n_units': (3, 26)}, 'verbose': 1, 'weighted': True, 'wfo': True, 'x_test': None, 'x_train': None, 'y_test': None, 'y_train': None}\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robustB|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_682 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 467227413315584.0000 - val_loss: 1077935859564544.0000\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 391955796197376.0000 - val_loss: 725880477319168.0000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 250740777943040.0000 - val_loss: 445979035697152.0000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 144103618641920.0000 - val_loss: 202822314360832.0000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 48226598125568.0000 - val_loss: 40460680691712.0000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 29453382057984.0000 - val_loss: 37249378942976.0000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 18706514051072.0000 - val_loss: 69279777030144.0000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 32810901438464.0000 - val_loss: 68467839467520.0000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 30358970040320.0000 - val_loss: 45417089728512.0000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 15540533854208.0000 - val_loss: 24314214612992.0000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 11244922732544.0000 - val_loss: 23773430415360.0000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 8309002731520.0000 - val_loss: 15792909320192.0000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 13885507633152.0000 - val_loss: 12935029063680.0000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 7638924918784.0000 - val_loss: 10439388823552.0000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 5791918063616.0000 - val_loss: 0.2318\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4352046268416.0000 - val_loss: 11465658466304.0000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 8405196472320.0000 - val_loss: 2123057463296.0000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 6750123065344.0000 - val_loss: 0.2303\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 9917833412608.0000 - val_loss: 11152404774912.0000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 8938827284480.0000 - val_loss: 24352523288576.0000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 13958722355200.0000 - val_loss: 18085996134400.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 6322012553216.0000 - val_loss: 449319272448.0000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 13055228379136.0000 - val_loss: 0.2292\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 7910194151424.0000 - val_loss: 18590180835328.0000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 11934829117440.0000 - val_loss: 36639476809728.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 20446642700288.0000 - val_loss: 31482351452160.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 15818087727104.0000 - val_loss: 0.2281\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2160454795264.0000 - val_loss: 8700219621376.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 5058972352512.0000 - val_loss: 6677367619584.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2142642896896.0000 - val_loss: 323382411264.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 4331844665344.0000 - val_loss: 20863285985280.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 11947757010944.0000 - val_loss: 13018861666304.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3905695252480.0000 - val_loss: 786423349248.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 22564418093056.0000 - val_loss: 609723940864.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 11262310219776.0000 - val_loss: 0.2286\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 5671917977600.0000 - val_loss: 1991665909760.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 7511732125696.0000 - val_loss: 233477865472.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 5309036756992.0000 - val_loss: 23128507940864.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 13191376535552.0000 - val_loss: 16398229176320.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 5450551525376.0000 - val_loss: 0.2299\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 23456512999424.0000 - val_loss: 390484656128.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 10631723876352.0000 - val_loss: 19828182089728.0000\n",
      "1\n",
      "maxabst|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_687 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 2.1339 - val_loss: 2.1348\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1275 - val_loss: 2.1573\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1215 - val_loss: 2.1792\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1165 - val_loss: 2.2019\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1111 - val_loss: 2.2258\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1056 - val_loss: 2.2501\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0996 - val_loss: 2.2740\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0934 - val_loss: 2.2976\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0873 - val_loss: 2.3219\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0806 - val_loss: 2.3464\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0735 - val_loss: 2.3728\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0669 - val_loss: 2.4039\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0589 - val_loss: 2.4359\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0498 - val_loss: 2.4664\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0406 - val_loss: 2.4972\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0305 - val_loss: 2.5301\n",
      "2\n",
      "standardizen|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_694 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 65ms/step - loss: 2.1585 - val_loss: 2.0763\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1434 - val_loss: 2.1040\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1321 - val_loss: 2.1262\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1233 - val_loss: 2.1458\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1155 - val_loss: 2.1630\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1080 - val_loss: 2.1784\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1016 - val_loss: 2.1943\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0950 - val_loss: 2.2112\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0888 - val_loss: 2.2303\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0814 - val_loss: 2.2502\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0745 - val_loss: 2.2730\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0663 - val_loss: 2.2971\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0574 - val_loss: 2.3223\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0480 - val_loss: 2.3502\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0380 - val_loss: 2.3825\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0265 - val_loss: 2.4178\n",
      "3\n",
      "minmaxV|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_701 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.1540 - val_loss: 2.1998\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1209 - val_loss: 2.3183\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0946 - val_loss: 2.4357\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0703 - val_loss: 2.5519\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0546 - val_loss: 2.6637\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0428 - val_loss: 2.7716\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0342 - val_loss: 2.8728\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0276 - val_loss: 2.9627\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.0235 - val_loss: 3.0368\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 2.0228 - val_loss: 3.0965\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.0220 - val_loss: 3.1351\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0222 - val_loss: 3.1589\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0212 - val_loss: 3.1606\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0200 - val_loss: 3.1493\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0185 - val_loss: 3.1289\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0168 - val_loss: 3.0971\n",
      "4\n",
      "normalizeu|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_705 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.1708 - val_loss: 2.0287\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1632 - val_loss: 2.0518\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1557 - val_loss: 2.0747\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1483 - val_loss: 2.0975\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1419 - val_loss: 2.1203\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1357 - val_loss: 2.1428\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1298 - val_loss: 2.1644\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1238 - val_loss: 2.1854\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1182 - val_loss: 2.2053\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1130 - val_loss: 2.2244\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1085 - val_loss: 2.2435\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1040 - val_loss: 2.2623\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0998 - val_loss: 2.2811\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0957 - val_loss: 2.2992\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0917 - val_loss: 2.3165\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0882 - val_loss: 2.3326\n",
      "5\n",
      "normalizeT|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_708 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 2.1309 - val_loss: 2.1540\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1261 - val_loss: 2.1702\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1211 - val_loss: 2.1866\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1166 - val_loss: 2.2039\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1128 - val_loss: 2.2222\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1086 - val_loss: 2.2411\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1044 - val_loss: 2.2607\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1001 - val_loss: 2.2810\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0957 - val_loss: 2.3022\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0913 - val_loss: 2.3247\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0868 - val_loss: 2.3484\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0824 - val_loss: 2.3733\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0778 - val_loss: 2.3991\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0739 - val_loss: 2.4261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0689 - val_loss: 2.4534\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0648 - val_loss: 2.4822\n",
      "6\n",
      "robustu|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_712 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 2.7046 - val_loss: 4.9829\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.6682 - val_loss: 4.8739\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.6321 - val_loss: 4.7709\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.6021 - val_loss: 4.6702\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.5706 - val_loss: 4.5733\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.5408 - val_loss: 4.4758\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.5118 - val_loss: 4.3801\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.4818 - val_loss: 4.2857\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.4546 - val_loss: 4.1940\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.4254 - val_loss: 4.1070\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.4040 - val_loss: 4.0212\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.3800 - val_loss: 3.9376\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.3580 - val_loss: 3.8563\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.3355 - val_loss: 3.7797\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.3147 - val_loss: 3.7069\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.2961 - val_loss: 3.6378\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2785 - val_loss: 3.5728\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.2619 - val_loss: 3.5113\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.2456 - val_loss: 3.4544\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.2310 - val_loss: 3.4015\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2190 - val_loss: 3.3521\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.2053 - val_loss: 3.3072\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1923 - val_loss: 3.2646\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1823 - val_loss: 3.2253\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1724 - val_loss: 3.1874\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1624 - val_loss: 3.1534\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1537 - val_loss: 3.1231\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1454 - val_loss: 3.0952\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1384 - val_loss: 3.0688\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1310 - val_loss: 3.0461\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1236 - val_loss: 3.0265\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1187 - val_loss: 3.0068\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1124 - val_loss: 2.9895\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1068 - val_loss: 2.9754\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1020 - val_loss: 2.9610\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0970 - val_loss: 2.9474\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0926 - val_loss: 2.9354\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0875 - val_loss: 2.9230\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0834 - val_loss: 2.9104\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0788 - val_loss: 2.8984\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0748 - val_loss: 2.8876\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0709 - val_loss: 2.8767\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0671 - val_loss: 2.8641\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0629 - val_loss: 2.8526\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0589 - val_loss: 2.8406\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0550 - val_loss: 2.8291\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.0516 - val_loss: 2.8160\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0479 - val_loss: 2.7988\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0434 - val_loss: 2.7783\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0398 - val_loss: 2.7541\n",
      "7\n",
      "robustL|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_715 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.1379 - val_loss: 2.1288\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1338 - val_loss: 2.1419\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1295 - val_loss: 2.1547\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1253 - val_loss: 2.1672\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1219 - val_loss: 2.1793\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1186 - val_loss: 2.1911\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1159 - val_loss: 2.2028\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1133 - val_loss: 2.2144\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1108 - val_loss: 2.2261\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1079 - val_loss: 2.2378\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1055 - val_loss: 2.2500\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1026 - val_loss: 2.2624\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1000 - val_loss: 2.2751\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0973 - val_loss: 2.2880\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0945 - val_loss: 2.3011\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0916 - val_loss: 2.3146\n",
      "8\n",
      "maxabsa|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_722 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 50ms/step - loss: 2.1302 - val_loss: 2.1513\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1249 - val_loss: 2.1704\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1197 - val_loss: 2.1904\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1144 - val_loss: 2.2110\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1099 - val_loss: 2.2328\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1048 - val_loss: 2.2556\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0992 - val_loss: 2.2789\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0931 - val_loss: 2.3029\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0869 - val_loss: 2.3277\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0807 - val_loss: 2.3538\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0745 - val_loss: 2.3816\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0686 - val_loss: 2.4112\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0624 - val_loss: 2.4421\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0563 - val_loss: 2.4741\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0506 - val_loss: 2.5071\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0450 - val_loss: 2.5410\n",
      "9\n",
      "standardizeW|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2.1091 - val_loss: 2.2549\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1011 - val_loss: 2.2905\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0934 - val_loss: 2.3279\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0856 - val_loss: 2.3678\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0780 - val_loss: 2.4101\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0716 - val_loss: 2.4580\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0640 - val_loss: 2.5104\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0563 - val_loss: 2.5661\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0491 - val_loss: 2.6250\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0422 - val_loss: 2.6870\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0356 - val_loss: 2.7510\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0313 - val_loss: 2.8167\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0256 - val_loss: 2.8791\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0212 - val_loss: 2.9390\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0176 - val_loss: 2.9955\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0152 - val_loss: 3.0481\n",
      "10\n",
      "robustr|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_733 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.2756 - val_loss: 3.1549\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.2532 - val_loss: 3.0936\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.2330 - val_loss: 3.0340\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.2129 - val_loss: 2.9754\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1939 - val_loss: 2.9165\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1745 - val_loss: 2.8586\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1562 - val_loss: 2.8026\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 1s 437ms/step - loss: 2.1371 - val_loss: 2.7492\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1204 - val_loss: 2.6987\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1044 - val_loss: 2.6504\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0903 - val_loss: 2.6029\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0763 - val_loss: 2.5591\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0638 - val_loss: 2.5208\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0502 - val_loss: 2.4906\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0404 - val_loss: 2.4638\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0325 - val_loss: 2.4410\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0232 - val_loss: 2.4263\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0169 - val_loss: 2.4162\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0105 - val_loss: 2.4124\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0055 - val_loss: 2.4134\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9997 - val_loss: 2.4210\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9945 - val_loss: 2.4330\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9897 - val_loss: 2.4487\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9839 - val_loss: 2.4642\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9790 - val_loss: 2.4820\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9741 - val_loss: 2.5012\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.9693 - val_loss: 2.5197\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9652 - val_loss: 2.5398\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9612 - val_loss: 2.5587\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9577 - val_loss: 2.5754\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9541 - val_loss: 2.5885\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9508 - val_loss: 2.5994\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9479 - val_loss: 2.6095\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9448 - val_loss: 2.6171\n",
      "11\n",
      "normalizeO|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_737 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.1283 - val_loss: 2.1603\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1242 - val_loss: 2.1757\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1203 - val_loss: 2.1907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1165 - val_loss: 2.2058\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1130 - val_loss: 2.2215\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1092 - val_loss: 2.2378\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1053 - val_loss: 2.2548\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1013 - val_loss: 2.2727\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0974 - val_loss: 2.2918\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0929 - val_loss: 2.3121\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0888 - val_loss: 2.3337\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0842 - val_loss: 2.3562\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0798 - val_loss: 2.3797\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0755 - val_loss: 2.4045\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0713 - val_loss: 2.4305\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0670 - val_loss: 2.4579\n",
      "12\n",
      "maxabsl|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_743 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.1165 - val_loss: 2.2232\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1117 - val_loss: 2.2420\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1069 - val_loss: 2.2608\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1027 - val_loss: 2.2804\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0981 - val_loss: 2.3000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0938 - val_loss: 2.3200\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0900 - val_loss: 2.3409\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0859 - val_loss: 2.3626\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0817 - val_loss: 2.3850\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0775 - val_loss: 2.4082\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0737 - val_loss: 2.4325\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0693 - val_loss: 2.4573\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0655 - val_loss: 2.4828\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0611 - val_loss: 2.5088\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0575 - val_loss: 2.5362\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0535 - val_loss: 2.5642\n",
      "13\n",
      "minmaxN|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.1293 - val_loss: 2.1498\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1270 - val_loss: 2.1594\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1247 - val_loss: 2.1690\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1224 - val_loss: 2.1781\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1204 - val_loss: 2.1874\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1182 - val_loss: 2.1969\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1160 - val_loss: 2.2065\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1139 - val_loss: 2.2164\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1117 - val_loss: 2.2264\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1096 - val_loss: 2.2367\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1075 - val_loss: 2.2470\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1053 - val_loss: 2.2573\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1030 - val_loss: 2.2681\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1009 - val_loss: 2.2789\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0989 - val_loss: 2.2900\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0967 - val_loss: 2.3014\n",
      "14\n",
      "standardizeD|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_757 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 2.2389 - val_loss: 1.9074\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.2033 - val_loss: 1.9678\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.1782 - val_loss: 2.0204\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1604 - val_loss: 2.0644\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1450 - val_loss: 2.1023\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1317 - val_loss: 2.1343\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1224 - val_loss: 2.1648\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1138 - val_loss: 2.1919\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1070 - val_loss: 2.2183\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.1016 - val_loss: 2.2452\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0955 - val_loss: 2.2697\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0909 - val_loss: 2.2917\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0861 - val_loss: 2.3118\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0810 - val_loss: 2.3310\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0764 - val_loss: 2.3492\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0716 - val_loss: 2.3657\n",
      "15\n",
      "robustK|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_764 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 44ms/step - loss: 779714536931328.0000 - val_loss: 481256890433536.0000\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 686802314723328.0000 - val_loss: 413259370856448.0000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 570378300686336.0000 - val_loss: 347668274479104.0000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 485634804285440.0000 - val_loss: 280730521305088.0000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 397729171767296.0000 - val_loss: 214419950796800.0000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 288289915404288.0000 - val_loss: 149261069058048.0000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 195089829724160.0000 - val_loss: 83109638832128.0000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 100767625117696.0000 - val_loss: 16197989957632.0000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 47693476921344.0000 - val_loss: 2.2878\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 133410056044544.0000 - val_loss: 2.3210\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 63021195984896.0000 - val_loss: 17094166970368.0000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 30414731214848.0000 - val_loss: 42719065931776.0000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 71911946059776.0000 - val_loss: 57166140538880.0000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 84477694967808.0000 - val_loss: 59804038987776.0000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 85591525949440.0000 - val_loss: 53816732942336.0000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 75197612818432.0000 - val_loss: 41124139892736.0000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 53593285591040.0000 - val_loss: 23199771262976.0000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 27058189107200.0000 - val_loss: 2.4800\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 5494384623616.0000 - val_loss: 852653244416.0000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2971866759168.0000 - val_loss: 1673097248768.0000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 4386392375296.0000 - val_loss: 488412348416.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 514195685376.0000 - val_loss: 2.5194\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 6930393202688.0000 - val_loss: 7493237342208.0000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 11819558109184.0000 - val_loss: 8301398458368.0000\n",
      "16\n",
      "normalizex|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.1393 - val_loss: 2.1230\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1331 - val_loss: 2.1461\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1275 - val_loss: 2.1669\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1225 - val_loss: 2.1847\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1186 - val_loss: 2.1988\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1154 - val_loss: 2.2133\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1120 - val_loss: 2.2287\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1087 - val_loss: 2.2452\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1052 - val_loss: 2.2650\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1010 - val_loss: 2.2876\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0965 - val_loss: 2.3120\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0920 - val_loss: 2.3374\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0873 - val_loss: 2.3658\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0820 - val_loss: 2.3964\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0769 - val_loss: 2.4302\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0724 - val_loss: 2.4687\n",
      "17\n",
      "robusti|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.2082 - val_loss: 1.9229\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1919 - val_loss: 1.9697\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1753 - val_loss: 2.0152\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1622 - val_loss: 2.0560\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1509 - val_loss: 2.0952\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1396 - val_loss: 2.1254\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1326 - val_loss: 2.1436\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1283 - val_loss: 2.1603\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1242 - val_loss: 2.1748\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1212 - val_loss: 2.1806\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1200 - val_loss: 2.1868\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1185 - val_loss: 2.1925\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1172 - val_loss: 2.1979\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1160 - val_loss: 2.2037\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1148 - val_loss: 2.2094\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1134 - val_loss: 2.2157\n",
      "18\n",
      "standardizeP|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 2.1380 - val_loss: 2.1399\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1290 - val_loss: 2.1702\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1214 - val_loss: 2.1902\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1169 - val_loss: 2.2056\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1133 - val_loss: 2.2217\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1099 - val_loss: 2.2371\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1062 - val_loss: 2.2527\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1031 - val_loss: 2.2690\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0998 - val_loss: 2.2859\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0961 - val_loss: 2.3034\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0929 - val_loss: 2.3218\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0891 - val_loss: 2.3407\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0856 - val_loss: 2.3605\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0820 - val_loss: 2.3811\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0784 - val_loss: 2.4027\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0746 - val_loss: 2.4250\n",
      "19\n",
      "minmaxc|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 2.1198 - val_loss: 2.2083\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1125 - val_loss: 2.2425\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1053 - val_loss: 2.2777\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0975 - val_loss: 2.3136\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0915 - val_loss: 2.3511\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0847 - val_loss: 2.3898\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0785 - val_loss: 2.4270\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0726 - val_loss: 2.4648\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0676 - val_loss: 2.5043\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0625 - val_loss: 2.5450\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0580 - val_loss: 2.5872\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0540 - val_loss: 2.6305\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0499 - val_loss: 2.6741\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0457 - val_loss: 2.7176\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0435 - val_loss: 2.7625\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0406 - val_loss: 2.8065\n",
      "20\n",
      "standardizeu|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 2.1113 - val_loss: 2.2310\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1071 - val_loss: 2.2492\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1031 - val_loss: 2.2680\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0991 - val_loss: 2.2872\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.0948 - val_loss: 2.3069\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0906 - val_loss: 2.3261\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.0866 - val_loss: 2.3457\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0831 - val_loss: 2.3659\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0791 - val_loss: 2.3866\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0756 - val_loss: 2.4082\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0720 - val_loss: 2.4303\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0682 - val_loss: 2.4529\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0648 - val_loss: 2.4761\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0611 - val_loss: 2.4998\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.0579 - val_loss: 2.5241\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0544 - val_loss: 2.5487\n",
      "21\n",
      "maxabsZ|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_798 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 2.0352 - val_loss: 2.5853\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0224 - val_loss: 2.6647\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0113 - val_loss: 2.7470\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0009 - val_loss: 2.8288\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9932 - val_loss: 2.9076\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.9867 - val_loss: 2.9786\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.9816 - val_loss: 3.0303\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9774 - val_loss: 3.0666\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9733 - val_loss: 3.0861\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9687 - val_loss: 3.0938\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9636 - val_loss: 3.0845\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9588 - val_loss: 3.0690\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9536 - val_loss: 3.0501\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.9489 - val_loss: 3.0250\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9436 - val_loss: 3.0051\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9389 - val_loss: 2.9864\n",
      "22\n",
      "robustf|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_804 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.1017 - val_loss: 2.3124\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0986 - val_loss: 2.3245\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0957 - val_loss: 2.3365\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0930 - val_loss: 2.3485\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0904 - val_loss: 2.3603\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0881 - val_loss: 2.3721\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0858 - val_loss: 2.3835\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0835 - val_loss: 2.3946\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0812 - val_loss: 2.4054\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0793 - val_loss: 2.4164\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0771 - val_loss: 2.4277\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0749 - val_loss: 2.4389\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0728 - val_loss: 2.4499\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0708 - val_loss: 2.4608\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0689 - val_loss: 2.4719\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0671 - val_loss: 2.4830\n",
      "23\n",
      "minmaxR|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_807 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 2.1213 - val_loss: 2.2269\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1113 - val_loss: 2.2671\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1013 - val_loss: 2.3129\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0917 - val_loss: 2.3643\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0819 - val_loss: 2.4206\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0732 - val_loss: 2.4813\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0636 - val_loss: 2.5482\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0540 - val_loss: 2.6187\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0468 - val_loss: 2.6932\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0393 - val_loss: 2.7727\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0353 - val_loss: 2.8559\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0286 - val_loss: 2.9297\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0253 - val_loss: 3.0010\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0219 - val_loss: 3.0572\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0195 - val_loss: 3.0994\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0180 - val_loss: 3.1216\n",
      "24\n",
      "standardizeS|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 2.1229 - val_loss: 2.1858\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1170 - val_loss: 2.2124\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1105 - val_loss: 2.2413\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1037 - val_loss: 2.2718\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0972 - val_loss: 2.3058\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0901 - val_loss: 2.3442\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0830 - val_loss: 2.3863\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0743 - val_loss: 2.4318\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0671 - val_loss: 2.4821\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0587 - val_loss: 2.5361\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0514 - val_loss: 2.5958\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0438 - val_loss: 2.6600\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0374 - val_loss: 2.7280\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0298 - val_loss: 2.7925\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0248 - val_loss: 2.8597\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0202 - val_loss: 2.9254\n",
      "25\n",
      "minmaxQ|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.1318 - val_loss: 2.1350\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1310 - val_loss: 2.1380\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1303 - val_loss: 2.1411\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1295 - val_loss: 2.1441\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1288 - val_loss: 2.1472\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1280 - val_loss: 2.1502\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1273 - val_loss: 2.1533\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1265 - val_loss: 2.1564\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1258 - val_loss: 2.1594\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1250 - val_loss: 2.1625\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1243 - val_loss: 2.1655\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1236 - val_loss: 2.1686\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1229 - val_loss: 2.1717\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1222 - val_loss: 2.1747\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1215 - val_loss: 2.1778\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1207 - val_loss: 2.1808\n",
      "26\n",
      "standardizeG|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 2.1045 - val_loss: 2.2748\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0980 - val_loss: 2.3089\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0909 - val_loss: 2.3433\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0848 - val_loss: 2.3784\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0789 - val_loss: 2.4140\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0732 - val_loss: 2.4499\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0678 - val_loss: 2.4861\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.0623 - val_loss: 2.5220\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0575 - val_loss: 2.5576\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0532 - val_loss: 2.5917\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0500 - val_loss: 2.6231\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0461 - val_loss: 2.6518\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0431 - val_loss: 2.6795\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0405 - val_loss: 2.7068\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0382 - val_loss: 2.7337\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0353 - val_loss: 2.7591\n",
      "27\n",
      "standardizew|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_827 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 2.1419 - val_loss: 2.1972\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1139 - val_loss: 2.2584\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0895 - val_loss: 2.3185\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0675 - val_loss: 2.3785\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0479 - val_loss: 2.4362\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0281 - val_loss: 2.4901\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0125 - val_loss: 2.5411\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.9985 - val_loss: 2.5895\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9860 - val_loss: 2.6358\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9735 - val_loss: 2.6791\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9630 - val_loss: 2.7209\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.9526 - val_loss: 2.7633\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9428 - val_loss: 2.8029\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.9341 - val_loss: 2.8423\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9256 - val_loss: 2.8766\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9177 - val_loss: 2.9030\n",
      "28\n",
      "minmaxr|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 2.1195 - val_loss: 2.2163\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1095 - val_loss: 2.2614\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1005 - val_loss: 2.3118\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0904 - val_loss: 2.3631\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0812 - val_loss: 2.4188\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0726 - val_loss: 2.4798\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0650 - val_loss: 2.5457\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0556 - val_loss: 2.6150\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0489 - val_loss: 2.6899\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0437 - val_loss: 2.7666\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0381 - val_loss: 2.8433\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0350 - val_loss: 2.9197\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0324 - val_loss: 2.9884\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0316 - val_loss: 3.0509\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0322 - val_loss: 3.1022\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0315 - val_loss: 3.1310\n",
      "29\n",
      "minmaxe|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 2.1328 - val_loss: 2.1535\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1255 - val_loss: 2.1734\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1211 - val_loss: 2.1885\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1176 - val_loss: 2.2057\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1136 - val_loss: 2.2225\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1101 - val_loss: 2.2403\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1063 - val_loss: 2.2599\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1020 - val_loss: 2.2809\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0978 - val_loss: 2.3037\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0936 - val_loss: 2.3269\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0890 - val_loss: 2.3536\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0845 - val_loss: 2.3813\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0795 - val_loss: 2.4110\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0749 - val_loss: 2.4438\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0704 - val_loss: 2.4802\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0657 - val_loss: 2.5182\n",
      "0\n",
      "standardizej|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_844 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.0677 - val_loss: 3.2060\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0479 - val_loss: 3.1448\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0316 - val_loss: 3.1052\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0155 - val_loss: 3.0815\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0020 - val_loss: 3.0560\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9888 - val_loss: 3.0336\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.9774 - val_loss: 3.0058\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 1.9656 - val_loss: 2.9837\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9553 - val_loss: 2.9697\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9444 - val_loss: 2.9578\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9345 - val_loss: 2.9440\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9251 - val_loss: 2.9344\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9152 - val_loss: 2.9290\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9065 - val_loss: 2.9232\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8977 - val_loss: 2.9200\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8896 - val_loss: 2.9205\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.8817 - val_loss: 2.9191\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8738 - val_loss: 2.9118\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8658 - val_loss: 2.9024\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.8580 - val_loss: 2.8909\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8501 - val_loss: 2.8807\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.8417 - val_loss: 2.8657\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8337 - val_loss: 2.8503\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8254 - val_loss: 2.8347\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8173 - val_loss: 2.8208\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8092 - val_loss: 2.8061\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.8010 - val_loss: 2.7913\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7925 - val_loss: 2.7750\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7846 - val_loss: 2.7585\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7751 - val_loss: 2.7617\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7670 - val_loss: 2.7661\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7581 - val_loss: 2.7631\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.7490 - val_loss: 2.7563\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7403 - val_loss: 2.7466\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.7311 - val_loss: 2.7311\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.7223 - val_loss: 2.7191\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7129 - val_loss: 2.7045\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.7033 - val_loss: 2.6870\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6934 - val_loss: 2.6552\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6832 - val_loss: 2.6342\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6737 - val_loss: 2.6179\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6636 - val_loss: 2.5899\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6539 - val_loss: 2.5650\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6430 - val_loss: 2.5600\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6320 - val_loss: 2.5573\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.6215 - val_loss: 2.5502\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6102 - val_loss: 2.5410\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5993 - val_loss: 2.5191\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5882 - val_loss: 2.4969\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5766 - val_loss: 2.4744\n",
      "1\n",
      "minmaxg|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_848 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.1128 - val_loss: 2.2332\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1004 - val_loss: 2.2864\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0879 - val_loss: 2.3434\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0781 - val_loss: 2.4057\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0659 - val_loss: 2.4720\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0562 - val_loss: 2.5446\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0471 - val_loss: 2.6222\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0378 - val_loss: 2.7030\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0292 - val_loss: 2.7859\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0237 - val_loss: 2.8724\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0202 - val_loss: 2.9586\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0179 - val_loss: 3.0357\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0149 - val_loss: 3.0904\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0150 - val_loss: 3.1349\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0136 - val_loss: 3.1537\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0127 - val_loss: 3.1570\n",
      "2\n",
      "minmaxn|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 2.1365 - val_loss: 2.1489\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1267 - val_loss: 2.1678\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1227 - val_loss: 2.1781\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1203 - val_loss: 2.1902\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1172 - val_loss: 2.2041\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1141 - val_loss: 2.2201\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1105 - val_loss: 2.2373\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1069 - val_loss: 2.2551\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1029 - val_loss: 2.2748\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0991 - val_loss: 2.2969\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0948 - val_loss: 2.3209\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0898 - val_loss: 2.3469\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0853 - val_loss: 2.3764\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0802 - val_loss: 2.4093\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0749 - val_loss: 2.4467\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0693 - val_loss: 2.4890\n",
      "3\n",
      "standardizeL|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.0964 - val_loss: 2.3439\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0853 - val_loss: 2.4078\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0742 - val_loss: 2.4778\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0651 - val_loss: 2.5541\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0562 - val_loss: 2.6363\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0481 - val_loss: 2.7219\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0430 - val_loss: 2.8117\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0383 - val_loss: 2.9016\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0342 - val_loss: 2.9854\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0348 - val_loss: 3.0652\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0338 - val_loss: 3.1217\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0340 - val_loss: 3.1539\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0347 - val_loss: 3.1652\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0349 - val_loss: 3.1711\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0349 - val_loss: 3.1644\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0345 - val_loss: 3.1455\n",
      "4\n",
      "maxabst|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 2.1295 - val_loss: 2.1639\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1228 - val_loss: 2.1886\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1172 - val_loss: 2.2131\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1117 - val_loss: 2.2368\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1064 - val_loss: 2.2630\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1013 - val_loss: 2.2912\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0954 - val_loss: 2.3213\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0896 - val_loss: 2.3548\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0836 - val_loss: 2.3922\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0773 - val_loss: 2.4334\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0718 - val_loss: 2.4791\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0656 - val_loss: 2.5288\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0585 - val_loss: 2.5824\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0533 - val_loss: 2.6425\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0468 - val_loss: 2.7066\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0431 - val_loss: 2.7772\n",
      "5\n",
      "normalizeL|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_875 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 41ms/step - loss: 2.1493 - val_loss: 2.1006\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1296 - val_loss: 2.1550\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1141 - val_loss: 2.2105\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0985 - val_loss: 2.2649\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0854 - val_loss: 2.3187\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0732 - val_loss: 2.3708\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0625 - val_loss: 2.4201\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0528 - val_loss: 2.4682\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0431 - val_loss: 2.5126\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0341 - val_loss: 2.5521\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0260 - val_loss: 2.5874\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0190 - val_loss: 2.6198\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0119 - val_loss: 2.6472\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0057 - val_loss: 2.6705\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9985 - val_loss: 2.6881\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9925 - val_loss: 2.7019\n",
      "6\n",
      "standardizet|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 2.1019 - val_loss: 2.2969\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0870 - val_loss: 2.3616\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0743 - val_loss: 2.4188\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0649 - val_loss: 2.4718\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0551 - val_loss: 2.5262\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0472 - val_loss: 2.5861\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0389 - val_loss: 2.6459\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0318 - val_loss: 2.7086\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0249 - val_loss: 2.7722\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0196 - val_loss: 2.8340\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0143 - val_loss: 2.8955\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0097 - val_loss: 2.9554\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0068 - val_loss: 3.0111\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0037 - val_loss: 3.0608\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0018 - val_loss: 3.1045\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9991 - val_loss: 3.1364\n",
      "7\n",
      "standardizer|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_883 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.0671 - val_loss: 2.6767\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0399 - val_loss: 2.7256\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0172 - val_loss: 2.7675\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9985 - val_loss: 2.8099\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9820 - val_loss: 2.8446\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9681 - val_loss: 2.8651\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9548 - val_loss: 2.8729\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9431 - val_loss: 2.8746\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9330 - val_loss: 2.8646\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.9231 - val_loss: 2.8537\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9134 - val_loss: 2.8344\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9039 - val_loss: 2.8161\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8949 - val_loss: 2.7976\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.8868 - val_loss: 2.7784\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.8778 - val_loss: 2.7636\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.8695 - val_loss: 2.7575\n",
      "8\n",
      "normalizeN|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_886 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.1367 - val_loss: 2.1376\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1267 - val_loss: 2.1680\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1177 - val_loss: 2.1985\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1084 - val_loss: 2.2298\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0999 - val_loss: 2.2624\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0919 - val_loss: 2.2978\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0838 - val_loss: 2.3351\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0755 - val_loss: 2.3741\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0682 - val_loss: 2.4147\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0608 - val_loss: 2.4570\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0529 - val_loss: 2.5008\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0454 - val_loss: 2.5460\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0380 - val_loss: 2.5920\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0308 - val_loss: 2.6393\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0232 - val_loss: 2.6847\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0163 - val_loss: 2.7293\n",
      "9\n",
      "normalizeG|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.1191 - val_loss: 2.1954\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1163 - val_loss: 2.2080\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1135 - val_loss: 2.2209\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1106 - val_loss: 2.2341\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1078 - val_loss: 2.2477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1047 - val_loss: 2.2617\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1022 - val_loss: 2.2762\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0993 - val_loss: 2.2911\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0963 - val_loss: 2.3065\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0934 - val_loss: 2.3223\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0905 - val_loss: 2.3387\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0877 - val_loss: 2.3557\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0846 - val_loss: 2.3730\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0819 - val_loss: 2.3910\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0789 - val_loss: 2.4095\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0762 - val_loss: 2.4286\n",
      "10\n",
      "normalizeY|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 2.1106 - val_loss: 2.2274\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1027 - val_loss: 2.2611\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0944 - val_loss: 2.2987\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0859 - val_loss: 2.3391\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0770 - val_loss: 2.3822\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0689 - val_loss: 2.4281\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0608 - val_loss: 2.4761\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0523 - val_loss: 2.5257\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0443 - val_loss: 2.5761\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0364 - val_loss: 2.6272\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0297 - val_loss: 2.6795\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0235 - val_loss: 2.7302\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0170 - val_loss: 2.7785\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0127 - val_loss: 2.8285\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0080 - val_loss: 2.8770\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0034 - val_loss: 2.9228\n",
      "11\n",
      "standardizeu|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 2.0772 - val_loss: 2.4134\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0759 - val_loss: 2.4234\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0743 - val_loss: 2.4335\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0728 - val_loss: 2.4437\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0713 - val_loss: 2.4541\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.0699 - val_loss: 2.4646\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.0686 - val_loss: 2.4753\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.0672 - val_loss: 2.4859\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0657 - val_loss: 2.4966\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0643 - val_loss: 2.5073\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0631 - val_loss: 2.5182\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0618 - val_loss: 2.5292\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.0604 - val_loss: 2.5402\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0593 - val_loss: 2.5514\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0581 - val_loss: 2.5625\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0567 - val_loss: 2.5735\n",
      "12\n",
      "maxabsx|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 2.1288 - val_loss: 2.1505\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1270 - val_loss: 2.1585\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1250 - val_loss: 2.1666\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1232 - val_loss: 2.1750\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1211 - val_loss: 2.1836\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1192 - val_loss: 2.1924\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1171 - val_loss: 2.2015\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1151 - val_loss: 2.2110\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1129 - val_loss: 2.2207\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1109 - val_loss: 2.2308\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1087 - val_loss: 2.2413\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1064 - val_loss: 2.2521\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1041 - val_loss: 2.2635\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1018 - val_loss: 2.2753\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0996 - val_loss: 2.2876\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0970 - val_loss: 2.3004\n",
      "13\n",
      "robustk|rf\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense_912 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 2.1997 - val_loss: 2.0146\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1884 - val_loss: 2.0322\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1797 - val_loss: 2.0472\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1705 - val_loss: 2.0623\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.1622 - val_loss: 2.0765\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.1562 - val_loss: 2.0899\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1492 - val_loss: 2.1034\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1426 - val_loss: 2.1162\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1382 - val_loss: 2.1260\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.1358 - val_loss: 2.1346\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1339 - val_loss: 2.1427\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1320 - val_loss: 2.1509\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1297 - val_loss: 2.1587\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1278 - val_loss: 2.1662\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1257 - val_loss: 2.1734\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1238 - val_loss: 2.1803\n",
      "14\n",
      "minmaxK|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.1327 - val_loss: 2.1325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1315 - val_loss: 2.1399\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1297 - val_loss: 2.1443\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1287 - val_loss: 2.1478\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1278 - val_loss: 2.1517\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1269 - val_loss: 2.1557\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1260 - val_loss: 2.1599\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1249 - val_loss: 2.1641\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1239 - val_loss: 2.1685\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1229 - val_loss: 2.1729\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1218 - val_loss: 2.1774\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1208 - val_loss: 2.1809\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1200 - val_loss: 2.1857\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1188 - val_loss: 2.1899\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1179 - val_loss: 2.1941\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.1169 - val_loss: 2.1984\n",
      "15\n",
      "robustX|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 2.1146 - val_loss: 2.2342\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.1057 - val_loss: 2.2704\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0980 - val_loss: 2.3086\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0905 - val_loss: 2.3484\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0828 - val_loss: 2.3896\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0755 - val_loss: 2.4283\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0688 - val_loss: 2.4673\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0628 - val_loss: 2.5082\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0570 - val_loss: 2.5509\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0512 - val_loss: 2.5947\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0455 - val_loss: 2.6388\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0407 - val_loss: 2.6850\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0358 - val_loss: 2.7325\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0309 - val_loss: 2.7793\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0271 - val_loss: 2.8260\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0241 - val_loss: 2.8739\n",
      "16\n",
      "robustc|rf\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 2.1318 - val_loss: 2.1490\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1266 - val_loss: 2.1701\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1217 - val_loss: 2.1913\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1165 - val_loss: 2.2125\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1120 - val_loss: 2.2339\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1072 - val_loss: 2.2554\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1029 - val_loss: 2.2733\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0999 - val_loss: 2.2899\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0963 - val_loss: 2.3074\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0930 - val_loss: 2.3258\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0899 - val_loss: 2.3450\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0864 - val_loss: 2.3647\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0833 - val_loss: 2.3850\n",
      "Epoch 14/50\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0693"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-386607b70b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdodge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDODGE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdodge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/raise_utils/hyperparams/dodge.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m                     model.set_data(data.x_train, data.y_train,\n\u001b[1;32m     74\u001b[0m                                    data.x_test, data.y_test)\n\u001b[0;32m---> 75\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0;31m# Run post-training hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/raise_utils/learners/feedforward.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m                     \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         self.model.fit(np.array(self.x_train), np.array(self.y_train), batch_size=512, epochs=self.n_epochs,\n\u001b[0m\u001b[1;32m     96\u001b[0m                        validation_split=0.2, verbose=self.verbose, callbacks=[\n\u001b[1;32m     97\u001b[0m             \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    860\u001b[0m           val_x, val_y, val_sample_weight = (\n\u001b[1;32m    861\u001b[0m               data_adapter.unpack_x_y_sample_weight(validation_data))\n\u001b[0;32m--> 862\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    863\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1047\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func)\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \"\"\"\n\u001b[0;32m-> 1652\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m   def interleave(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4069\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4070\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4071\u001b[0m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[1;32m   4072\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[0;32m-> 2531\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   2532\u001b[0m         *args, **kwargs)\n\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         if x is not None)\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    383\u001b[0m           \u001b[0mlast_write_to_resource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m       if (op_is_stateful(op) and not resource_inputs\n\u001b[0m\u001b[1;32m    386\u001b[0m           and op._control_flow_context is None):  # pylint: disable=protected-access\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlast_write_to_resource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36mop_is_stateful\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   return (op._is_stateful and op.type not in _ALL_BLACKLISTED_OPS) or (\n\u001b[0;32m--> 124\u001b[0;31m       op.type in _WHITELIST_STATELESS_OPS)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2219\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m     \u001b[0;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationOpType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2223\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"n_runs\": 3,\n",
    "    \"transforms\": [\"normalize\", \"standardize\", \"robust\", \"maxabs\", \"minmax\"] * 30,\n",
    "    \"metrics\": [\"f1\", \"accuracy\", \"pd\", \"pf\", \"prec\"],\n",
    "    \"random\": True,\n",
    "    \"learners\": [FeedforwardDL(random={'n_layers': (2, 6), 'n_units': (3, 26)}, n_epochs=50, weighted=.3, wfo=True)],\n",
    "    \"log_path\": \"./\",\n",
    "    \"data\": [data],\n",
    "    \"name\": \"buildr\"\n",
    "}\n",
    "for _ in range(50):\n",
    "    config[\"learners\"].append(\n",
    "        FeedforwardDL(random={'n_layers': (2, 6), 'n_units': (3, 26)}, n_epochs=50, weighted=True, wfo=True))\n",
    "\n",
    "dodge = DODGE(config)\n",
    "dodge.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
