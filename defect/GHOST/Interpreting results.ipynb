{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.interpret import DODGEInterpreter\n",
    "from typing import Union, Callable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order matters!\n",
    "files = [\"ivy\", \"lucene\", \"poi\", \"synapse\", \"velocity\", \"camel\", \"jedit\", \"log4j\", \"xalan\", \"xerces\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DODGEInterpreter:\n",
    "    \"\"\"Interprets the results of DODGE-generated files\"\"\"\n",
    "\n",
    "    def __init__(self, files=None, n_datasets=1, max_by: Union[None, int, Callable[..., str]] = None,\n",
    "                 exclude_cols=None, metrics=None) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the interpreter.\n",
    "        :param files - A list of files to be interpreted.\n",
    "        :param max_by - Either a None, int, or Callable. If None, defaults to\n",
    "                        maximizing the first entry, the metric maximized by DODGE.\n",
    "                        If int, maximizes by the index specified.\n",
    "                        If callable, maximizes by the function passed.\n",
    "        :param exclude_cols - List of column indices to exclude\n",
    "        :param metrics - List of metrics passed to DODGE. If excluding columns,\n",
    "                        do NOT include these in this list.\n",
    "        :return DODGEInterpreter object\n",
    "        \"\"\"\n",
    "        if files is None:\n",
    "            files = []\n",
    "        if exclude_cols is None:\n",
    "            exclude_cols = []\n",
    "        if metrics is None:\n",
    "            metrics = []\n",
    "        self.files = files\n",
    "        self.n_datasets = n_datasets\n",
    "        if max_by is None:\n",
    "            self.max_by = 0\n",
    "        else:\n",
    "            self.max_by = max_by\n",
    "        self.exclude_cols = exclude_cols\n",
    "        self.metrics = metrics\n",
    "\n",
    "    def interpret(self) -> dict:\n",
    "        DODGE_ITER = 30\n",
    "        medians = {}\n",
    "\n",
    "        for file in self.files:\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            popt_lines = lines.copy()\n",
    "            popt_lines = [float(x.split(':')[1]) for x in popt_lines if x.startswith('popt20')]\n",
    "            popt_lines = np.array(popt_lines).reshape((self.n_datasets, 20, DODGE_ITER))\n",
    "\n",
    "            settings = [line.split(':')[1]\n",
    "                        for line in lines if line.startswith('setting')]\n",
    "\n",
    "            lines = [eval(line.split(':')[1])\n",
    "                     for line in lines if line.startswith('iter')]\n",
    "\n",
    "            n_runs = int(len(lines) // (DODGE_ITER * self.n_datasets))\n",
    "            n_metrics = len(lines[0]) - len(self.exclude_cols)\n",
    "\n",
    "            if len(self.metrics) == 0:\n",
    "                self.metrics = list(range(n_metrics))\n",
    "            elif len(self.metrics) != n_metrics:\n",
    "                raise ValueError(\"Passed list of metrics has size\", len(self.metrics),\n",
    "                                 \"but file metrics (excluding exclude_cols) has size\",\n",
    "                                 n_metrics)\n",
    "\n",
    "            lines = np.array(lines)\n",
    "            lines = np.delete(lines, self.exclude_cols, -1)\n",
    "\n",
    "            settings = np.array(settings)\n",
    "\n",
    "            assert lines.shape == (n_runs * self.n_datasets * DODGE_ITER, n_metrics)\n",
    "            \n",
    "            run_splits = lines.reshape(\n",
    "                (self.n_datasets, n_runs, DODGE_ITER, n_metrics))\n",
    "            settings = settings.reshape((self.n_datasets, n_runs, DODGE_ITER))\n",
    "\n",
    "            if isinstance(self.max_by, int):\n",
    "                mapped_vals = np.apply_along_axis(\n",
    "                    lambda x: x[self.max_by], axis=-1, arr=run_splits).reshape(self.n_datasets, n_runs, DODGE_ITER)\n",
    "            elif callable(self.max_by):\n",
    "                mapped_vals = np.apply_along_axis(\n",
    "                    self.max_by, axis=-1, arr=run_splits).reshape(self.n_datasets, n_runs, DODGE_ITER)\n",
    "\n",
    "            assert mapped_vals.shape == (self.n_datasets, n_runs, DODGE_ITER)\n",
    "\n",
    "            max_idx = np.argmax(mapped_vals, axis=-1)\n",
    "            \n",
    "            medians[file.split('/')[-1]] = {metric: max_idx.choose(np.rollaxis(np.apply_along_axis(lambda p: p[i], -1, run_splits), -1, 0))\n",
    "                                            for i, metric in enumerate(self.metrics)}\n",
    "            medians[file.split('/')[-1]]['setting'] = max_idx.choose(np.rollaxis(settings, -1, 0))\n",
    "            medians[file.split('/')[-1]]['popt20'] = max_idx.choose(np.rollaxis(popt_lines, -1, 0))\n",
    "\n",
    "        return medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = DODGEInterpreter(files=['dodge.txt'], metrics=[\"d2h\", \"auc\", \"pd\", \"pf\", \"prec\", \"f1\"], n_datasets=10)\n",
    "res = interp.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dodge.txt'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['d2h', 'auc', 'pd', 'pf', 'prec', 'f1', 'setting', 'popt20'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"dodge.txt\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"dodge.txt\"][\"d2h\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72980769, 0.5981626 , 0.71326894, 0.57623119, 0.5914629 ,\n",
       "       0.56491826, 0.69060669, 0.63144841, 0.66703786, 0.54252353])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"dodge.txt\"][\"auc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[' maxabsV|rf\\n', ' standardizeJ|rf\\n', ' normalizee|rf\\n',\n",
       "        ' minmaxr|rf\\n', ' minmaxt|rf\\n', ' maxabsS|rf\\n',\n",
       "        ' maxabsW|rf\\n', ' standardizef|rf\\n', ' minmaxB|rf\\n',\n",
       "        ' normalizex|rf\\n', ' minmaxD|rf\\n', ' minmaxU|rf\\n',\n",
       "        ' minmaxB|rf\\n', ' normalizep|rf\\n', ' minmaxH|rf\\n',\n",
       "        ' maxabsC|rf\\n', ' minmaxK|rf\\n', ' standardizen|rf\\n',\n",
       "        ' normalizez|rf\\n', ' minmaxF|rf\\n'],\n",
       "       [' standardizeO|rf\\n', ' minmaxP|rf\\n', ' normalizee|rf\\n',\n",
       "        ' minmaxD|rf\\n', ' standardizef|rf\\n', ' normalizeJ|rf\\n',\n",
       "        ' maxabst|rf\\n', ' standardizeP|rf\\n', ' maxabsR|rf\\n',\n",
       "        ' minmaxb|rf\\n', ' standardized|rf\\n', ' normalizeq|rf\\n',\n",
       "        ' minmaxJ|rf\\n', ' minmaxS|rf\\n', ' normalizeC|rf\\n',\n",
       "        ' normalizey|rf\\n', ' minmaxJ|rf\\n', ' minmaxf|rf\\n',\n",
       "        ' maxabsx|rf\\n', ' normalizeZ|rf\\n'],\n",
       "       [' maxabsP|rf\\n', ' normalizex|rf\\n', ' normalizeQ|rf\\n',\n",
       "        ' minmaxq|rf\\n', ' normalizej|rf\\n', ' minmaxN|rf\\n',\n",
       "        ' standardizeZ|rf\\n', ' standardizen|rf\\n', ' normalizee|rf\\n',\n",
       "        ' standardizea|rf\\n', ' normalizek|rf\\n', ' maxabsx|rf\\n',\n",
       "        ' standardizeD|rf\\n', ' normalizeZ|rf\\n', ' standardizeb|rf\\n',\n",
       "        ' maxabsF|rf\\n', ' normalizeH|rf\\n', ' normalizeK|rf\\n',\n",
       "        ' normalizeK|rf\\n', ' normalizec|rf\\n'],\n",
       "       [' maxabsb|rf\\n', ' minmaxF|rf\\n', ' standardizeZ|rf\\n',\n",
       "        ' minmaxF|rf\\n', ' normalized|rf\\n', ' maxabsW|rf\\n',\n",
       "        ' standardizeU|rf\\n', ' maxabsw|rf\\n', ' minmaxF|rf\\n',\n",
       "        ' minmaxy|rf\\n', ' normalizeS|rf\\n', ' maxabse|rf\\n',\n",
       "        ' standardizeb|rf\\n', ' standardizeA|rf\\n', ' standardizex|rf\\n',\n",
       "        ' standardizeC|rf\\n', ' maxabsI|rf\\n', ' maxabsr|rf\\n',\n",
       "        ' normalizeR|rf\\n', ' standardizev|rf\\n'],\n",
       "       [' minmaxG|rf\\n', ' standardizeB|rf\\n', ' standardizeU|rf\\n',\n",
       "        ' minmaxG|rf\\n', ' minmaxy|rf\\n', ' standardizeN|rf\\n',\n",
       "        ' normalizet|rf\\n', ' maxabsR|rf\\n', ' minmaxG|rf\\n',\n",
       "        ' maxabsd|rf\\n', ' maxabsT|rf\\n', ' normalizeN|rf\\n',\n",
       "        ' standardizea|rf\\n', ' standardizeJ|rf\\n', ' maxabse|rf\\n',\n",
       "        ' minmaxd|rf\\n', ' normalizeJ|rf\\n', ' standardizeO|rf\\n',\n",
       "        ' standardizec|rf\\n', ' normalizeT|rf\\n'],\n",
       "       [' normalizeX|rf\\n', ' maxabsY|rf\\n', ' maxabsL|rf\\n',\n",
       "        ' standardizeK|rf\\n', ' minmaxh|rf\\n', ' normalizej|rf\\n',\n",
       "        ' normalizeP|rf\\n', ' maxabst|rf\\n', ' maxabsE|rf\\n',\n",
       "        ' minmaxG|rf\\n', ' minmaxn|rf\\n', ' maxabsv|rf\\n',\n",
       "        ' standardizew|rf\\n', ' standardizec|rf\\n', ' normalizeS|rf\\n',\n",
       "        ' standardizeW|rf\\n', ' normalizeq|rf\\n', ' minmaxC|rf\\n',\n",
       "        ' maxabsl|rf\\n', ' standardizek|rf\\n'],\n",
       "       [' normalizeo|rf\\n', ' minmaxF|rf\\n', ' normalizeA|rf\\n',\n",
       "        ' minmaxl|rf\\n', ' standardizeI|rf\\n', ' normalizeg|rf\\n',\n",
       "        ' normalizee|rf\\n', ' normalizeC|rf\\n', ' normalizeQ|rf\\n',\n",
       "        ' normalizej|rf\\n', ' normalizeU|rf\\n', ' normalizeO|rf\\n',\n",
       "        ' minmaxG|rf\\n', ' minmaxl|rf\\n', ' maxabsL|rf\\n',\n",
       "        ' minmaxT|rf\\n', ' maxabsd|rf\\n', ' normalizeJ|rf\\n',\n",
       "        ' minmaxA|rf\\n', ' minmaxS|rf\\n'],\n",
       "       [' maxabsd|rf\\n', ' normalizej|rf\\n', ' maxabsM|rf\\n',\n",
       "        ' standardizeX|rf\\n', ' normalizeN|rf\\n', ' standardizeX|rf\\n',\n",
       "        ' normalizeq|rf\\n', ' minmaxg|rf\\n', ' minmaxT|rf\\n',\n",
       "        ' maxabsm|rf\\n', ' standardizer|rf\\n', ' normalizea|rf\\n',\n",
       "        ' maxabsL|rf\\n', ' minmaxm|rf\\n', ' normalizeF|rf\\n',\n",
       "        ' normalizep|rf\\n', ' normalizeB|rf\\n', ' minmaxD|rf\\n',\n",
       "        ' standardizek|rf\\n', ' standardizeh|rf\\n'],\n",
       "       [' minmaxi|rf\\n', ' minmaxF|rf\\n', ' normalizee|rf\\n',\n",
       "        ' normalizez|rf\\n', ' minmaxO|rf\\n', ' standardizeJ|rf\\n',\n",
       "        ' standardizer|rf\\n', ' minmaxa|rf\\n', ' standardizeN|rf\\n',\n",
       "        ' maxabsz|rf\\n', ' maxabsD|rf\\n', ' normalizeV|rf\\n',\n",
       "        ' standardizef|rf\\n', ' standardizef|rf\\n', ' normalizeL|rf\\n',\n",
       "        ' minmaxK|rf\\n', ' normalizen|rf\\n', ' standardizes|rf\\n',\n",
       "        ' normalizeD|rf\\n', ' maxabsk|rf\\n'],\n",
       "       [' normalizea|rf\\n', ' normalizex|rf\\n', ' normalizei|rf\\n',\n",
       "        ' normalizeF|rf\\n', ' standardizen|rf\\n', ' maxabsM|rf\\n',\n",
       "        ' normalizeX|rf\\n', ' standardizeE|rf\\n', ' standardizeo|rf\\n',\n",
       "        ' standardizey|rf\\n', ' minmaxH|rf\\n', ' maxabsr|rf\\n',\n",
       "        ' minmaxN|rf\\n', ' maxabsP|rf\\n', ' standardizeF|rf\\n',\n",
       "        ' standardizeJ|rf\\n', ' maxabsy|rf\\n', ' standardizex|rf\\n',\n",
       "        ' minmaxU|rf\\n', ' maxabse|rf\\n']], dtype='<U17')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"dodge.txt\"][\"setting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivy:\n",
      "====\n",
      "d2h - 0.42063608708350025\n",
      "auc - 0.7298076923076923\n",
      "pd - 0.825\n",
      "pf - 0.36538461538461536\n",
      "prec - 0.22448979591836735\n",
      "f1 - 0.35294117647058826\n",
      "\n",
      "lucene:\n",
      "=======\n",
      "d2h - 0.3025384247038405\n",
      "auc - 0.59816259753335\n",
      "pd - 0.6379310344827587\n",
      "pf - 0.43795620437956206\n",
      "prec - 0.6818103818103818\n",
      "f1 - 0.6590631626293131\n",
      "\n",
      "poi:\n",
      "====\n",
      "d2h - 0.3888260540678474\n",
      "auc - 0.7132689374682257\n",
      "pd - 0.5765124555160143\n",
      "pf - 0.14596273291925466\n",
      "prec - 0.872983870967742\n",
      "f1 - 0.6932154212668131\n",
      "\n",
      "synapse:\n",
      "========\n",
      "d2h - 0.1923082282900893\n",
      "auc - 0.5762311901504789\n",
      "pd - 0.28488372093023256\n",
      "pf - 0.13529411764705881\n",
      "prec - 0.529457065845206\n",
      "f1 - 0.3670971364402021\n",
      "\n",
      "velocity:\n",
      "=========\n",
      "d2h - 0.26291807925268096\n",
      "auc - 0.5914628969264731\n",
      "pd - 0.75\n",
      "pf - 0.5695364238410596\n",
      "prec - 0.40687883545026404\n",
      "f1 - 0.5251162499739349\n",
      "\n",
      "camel:\n",
      "======\n",
      "d2h - 0.17432390906452683\n",
      "auc - 0.5649182617267724\n",
      "pd - 0.2579787234042553\n",
      "pf - 0.12612612612612611\n",
      "prec - 0.3277921961696796\n",
      "f1 - 0.2882927728613569\n",
      "\n",
      "jedit:\n",
      "======\n",
      "d2h - 0.36535354170430934\n",
      "auc - 0.6906066906066906\n",
      "pd - 0.6363636363636364\n",
      "pf - 0.21621621621621623\n",
      "prec - 0.05955188679245283\n",
      "f1 - 0.1090245450698265\n",
      "\n",
      "log4j:\n",
      "======\n",
      "d2h - 0.2373600326825831\n",
      "auc - 0.6314484126984127\n",
      "pd - 0.3412698412698413\n",
      "pf - 0.0625\n",
      "prec - 0.9839989759344598\n",
      "f1 - 0.5058747539370079\n",
      "\n",
      "xalan:\n",
      "======\n",
      "d2h - 0.24226333254825527\n",
      "auc - 0.6670378619153675\n",
      "pd - 0.3474387527839644\n",
      "pf - 0.0\n",
      "prec - 1.0\n",
      "f1 - 0.5150633766927477\n",
      "\n",
      "xerces:\n",
      "=======\n",
      "d2h - 0.10789302801146872\n",
      "auc - 0.5425235273614499\n",
      "pd - 0.15560640732265446\n",
      "pf - 0.0728476821192053\n",
      "prec - 0.8589743589743589\n",
      "f1 - 0.2633169144493676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(files):\n",
    "    print(name + \":\")\n",
    "    print(\"=\" * len(name + \":\"))\n",
    "    \n",
    "    for key in res[\"dodge.txt\"].keys():\n",
    "        if key == \"setting\":\n",
    "            continue\n",
    "        \n",
    "        print(key, \"-\", res[\"dodge.txt\"][key][i])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = DODGEInterpreter(files=['ghost.txt'], metrics=[\"d2h\", \"auc\", \"pd\", \"pf\", \"prec\", \"f1\"], n_datasets=10)\n",
    "res = interp.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivy:\n",
      "====\n",
      "d2h - 0.4125309223626752\n",
      "auc - 0.7301282051282051\n",
      "pd - 0.825\n",
      "pf - 0.35416666666666663\n",
      "prec - 0.22327844311377246\n",
      "f1 - 0.35616331619136665\n",
      "\n",
      "lucene:\n",
      "=======\n",
      "d2h - 0.2994001961807583\n",
      "auc - 0.5985671137319766\n",
      "pd - 0.6551724137931034\n",
      "pf - 0.4635036496350365\n",
      "prec - 0.6779352226720647\n",
      "f1 - 0.6658228799859648\n",
      "\n",
      "poi:\n",
      "====\n",
      "d2h - 0.332934330491189\n",
      "auc - 0.6299374461218805\n",
      "pd - 0.6192170818505338\n",
      "pf - 0.34782608695652173\n",
      "prec - 0.754860101744186\n",
      "f1 - 0.6821657677688806\n",
      "\n",
      "synapse:\n",
      "========\n",
      "d2h - 0.3698852826288851\n",
      "auc - 0.6850205198358413\n",
      "pd - 0.5755813953488372\n",
      "pf - 0.20294117647058824\n",
      "prec - 0.5913194444444445\n",
      "f1 - 0.5806818181818182\n",
      "\n",
      "velocity:\n",
      "=========\n",
      "d2h - 0.2521430031533113\n",
      "auc - 0.5605790456783835\n",
      "pd - 0.6538461538461539\n",
      "pf - 0.543046357615894\n",
      "prec - 0.3854030501089325\n",
      "f1 - 0.4879125499264242\n",
      "\n",
      "camel:\n",
      "======\n",
      "d2h - 0.2657219639667243\n",
      "auc - 0.5733402475423752\n",
      "pd - 0.5132978723404256\n",
      "pf - 0.3384813384813385\n",
      "prec - 0.25636831913973646\n",
      "f1 - 0.3319334304364245\n",
      "\n",
      "jedit:\n",
      "======\n",
      "d2h - 0.32906236665304056\n",
      "auc - 0.6242676242676243\n",
      "pd - 0.6363636363636364\n",
      "pf - 0.3918918918918919\n",
      "prec - 0.037175234936428964\n",
      "f1 - 0.06916483954554514\n",
      "\n",
      "log4j:\n",
      "======\n",
      "d2h - 0.25602519661311074\n",
      "auc - 0.5895337301587301\n",
      "pd - 0.41534391534391535\n",
      "pf - 0.25\n",
      "prec - 0.9532147742818058\n",
      "f1 - 0.5797979797979798\n",
      "\n",
      "xalan:\n",
      "======\n",
      "d2h - 0.37908370113893297\n",
      "auc - 0.7270955659040292\n",
      "pd - 0.5462138084632516\n",
      "pf - 0.09090909090909091\n",
      "prec - 0.9979612618978344\n",
      "f1 - 0.7060091883296818\n",
      "\n",
      "xerces:\n",
      "=======\n",
      "d2h - 0.27359087415266814\n",
      "auc - 0.5772500644066255\n",
      "pd - 0.4839816933638444\n",
      "pf - 0.3410596026490066\n",
      "prec - 0.8041424315505745\n",
      "f1 - 0.6022856589428827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(files):\n",
    "    print(name + \":\")\n",
    "    print(\"=\" * len(name + \":\"))\n",
    "    \n",
    "    for key in res[\"ghost.txt\"].keys():\n",
    "        if key == \"setting\":\n",
    "            continue\n",
    "        \n",
    "        print(key, \"-\", res[\"ghost.txt\"][key][i])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_latex(dl_results, dodge_results, ghost_results):\n",
    "    def get_dodge_cell(m, i):\n",
    "        return f\"{round(dodge_results['dodge.txt'][m][i], 2)}\"\n",
    "    \n",
    "    def get_ghost_cell(m, i):\n",
    "        return f\"{round(ghost_results['ghost.txt'][m][i], 2)}\"\n",
    "    \n",
    "    def get_dl_cell(m, i):\n",
    "        return f\"{round(dl_results[m][i], 2)}\"\n",
    "    \n",
    "    print(r\"&       & AUC  & popt20 & recall & pf  \\\\ \\midrule\")\n",
    "    for i, name in enumerate(files):\n",
    "        print(f\"\\multirow{{3}}{{*}}{'{' + name + '}'}\\t& DL & {get_dl_cell('auc', i)} & & {get_dl_cell('pd', i)} & {get_dl_cell('pf', i)} \\\\\\\\\")\n",
    "        print(f\"\\t& DODGE & {get_dodge_cell('auc', i)} & & {get_dodge_cell('pd', i)} & {get_dodge_cell('pf', i)} \\\\\\\\\")\n",
    "        print(f\"\\t& GHOST & {get_ghost_cell('auc', i)} & & {get_ghost_cell('pd', i)} & {get_ghost_cell('pf', i)} \\\\\\\\\", end=\" \")\n",
    "        \n",
    "        if i == len(files) - 1:\n",
    "            print()\n",
    "        else:\n",
    "            print(r\"\\midrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dl_results(metrics, n_datasets=10, n_runs=20):\n",
    "    with open('dl.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    #lines_metr = [eval(x.split(':')[1]) for x in lines if x.startswith('metr')]\n",
    "    #print(lines_metr)\n",
    "    #lines_metr = np.array(lines_metr).reshape(n_datasets, n_runs, len(metrics))\n",
    "    \n",
    "    #res = {metrics[i]: np.apply_along_axis(lambda p: p[i], -1, lines_metr) for i in range(len(metrics))}\n",
    "    res = {}\n",
    "    lines_popt = [float(x.split(':')[1]) for x in lines if x.startswith('popt20')]\n",
    "    lines_popt = np.array(lines_popt).reshape(n_datasets, n_runs, 30)\n",
    "    res['popt20'] = np.median(lines_popt, axis=-1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_res = parse_dl_results(metrics=[\"d2h\", \"auc\", \"pd\", \"pf\", \"prec\", \"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_res['d2h'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = DODGEInterpreter(files=['dodge.txt'], metrics=[\"d2h\", \"auc\", \"pd\", \"pf\", \"prec\", \"f1\"], n_datasets=10)\n",
    "dodge_res = interp.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = DODGEInterpreter(files=['ghost.txt'], metrics=[\"d2h\", \"auc\", \"pd\", \"pf\", \"prec\", \"f1\"], n_datasets=10)\n",
    "ghost_res = interp.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dodge_res['dodge.txt']['d2h'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_latex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-471b1144bc61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_latex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdodge_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mghost_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_latex' is not defined"
     ]
    }
   ],
   "source": [
    "print_latex(dl_res, dodge_res, ghost_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing to old results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.interpret.sk import Rx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_result(file, metric, algorithm):\n",
    "    if metric == \"pd\":\n",
    "        metric = \"recall\"\n",
    "    \n",
    "    filename = f'./unencoded-results/{file}_{metric}'\n",
    "    \n",
    "    if file == 'xalan' and metric == 'popt20':\n",
    "        filename += '.txt'\n",
    "    else:\n",
    "        filename += '_new.txt'\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    line = [eval(f'[{x.split(algorithm + \",\")[1]}]') for x in lines if x.startswith(algorithm)][0]\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_result(i, metric, algorithm):\n",
    "    if algorithm == 'DL':\n",
    "        return dl_res[metric][i]\n",
    "    if algorithm == 'DODGE':\n",
    "        return dodge_res['dodge.txt'][metric][i]\n",
    "    return ghost_res['ghost.txt'][metric][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivy\n",
      "===\n",
      "\tauc\tpd\tpf\n",
      "DL\tLOSS\tLOSS\tWIN\t\n",
      "DODGE\tWIN\tLOSS\tTIE\t\n",
      "GHOST\tWIN\tLOSS\tWIN\t\n",
      "\n",
      "lucene\n",
      "======\n",
      "\tauc\tpd\tpf\n",
      "DL\tWIN\tLOSS\tWIN\t\n",
      "DODGE\tTIE\tLOSS\tLOSS\t\n",
      "GHOST\tWIN\tLOSS\tLOSS\t\n",
      "\n",
      "poi\n",
      "===\n",
      "\tauc\tpd\tpf\n",
      "DL\tLOSS\tLOSS\tWIN\t\n",
      "DODGE\tLOSS\tLOSS\tWIN\t\n",
      "GHOST\tLOSS\tLOSS\tTIE\t\n",
      "\n",
      "synapse\n",
      "=======\n",
      "\tauc\tpd\tpf\n",
      "DL\tLOSS\tLOSS\tWIN\t\n",
      "DODGE\tLOSS\tLOSS\tWIN\t\n",
      "GHOST\tWIN\tLOSS\tWIN\t\n",
      "\n",
      "velocity\n",
      "========\n",
      "\tauc\tpd\tpf\n",
      "DL\tLOSS\tWIN\tLOSS\t\n",
      "DODGE\tLOSS\tTIE\tLOSS\t\n",
      "GHOST\tLOSS\tLOSS\tLOSS\t\n",
      "\n",
      "camel\n",
      "=====\n",
      "\tauc\tpd\tpf\n",
      "DL\tTIE\tTIE\tWIN\t\n",
      "DODGE\tLOSS\tLOSS\tWIN\t\n",
      "GHOST\tLOSS\tLOSS\tWIN\t\n",
      "\n",
      "jedit\n",
      "=====\n",
      "\tauc\tpd\tpf\n",
      "DL\tWIN\tTIE\tTIE\t\n",
      "DODGE\tWIN\tWIN\tWIN\t\n",
      "GHOST\tLOSS\tTIE\tTIE\t\n",
      "\n",
      "log4j\n",
      "=====\n",
      "\tauc\tpd\tpf\n",
      "DL\tLOSS\tLOSS\tTIE\t\n",
      "DODGE\tWIN\tLOSS\tWIN\t\n",
      "GHOST\tLOSS\tLOSS\tLOSS\t\n",
      "\n",
      "xalan\n",
      "=====\n",
      "\tauc\tpd\tpf\n",
      "DL\tTIE\tTIE\tWIN\t\n",
      "DODGE\tLOSS\tLOSS\tWIN\t\n",
      "GHOST\tLOSS\tLOSS\tWIN\t\n",
      "\n",
      "xerces\n",
      "======\n",
      "\tauc\tpd\tpf\n",
      "DL\tTIE\tTIE\tTIE\t\n",
      "DODGE\tLOSS\tLOSS\tWIN\t\n",
      "GHOST\tLOSS\tLOSS\tWIN\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "possible_results = [\"WIN\", \"TIE\", \"LOSS\"]\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    print(file)\n",
    "    print('=' * len(file))\n",
    "    \n",
    "    for metric in [\"auc\", \"pd\", \"pf\", \"popt20\"]:\n",
    "        print('\\t' + metric, end='')\n",
    "    \n",
    "    print()\n",
    "    for alg in ['DL', 'DODGE', 'GHOST']:\n",
    "        print(alg, end='\\t')\n",
    "        \n",
    "        for metric in [\"auc\", \"pd\", \"pf\", \"popt20\"]:\n",
    "            old = get_old_result(file, metric, alg)\n",
    "            new = get_new_result(i, metric, alg)\n",
    "            \n",
    "            data = {'old': old, 'new': new}\n",
    "            results = Rx.sk(Rx.data(**data))\n",
    "            \n",
    "            result = \"\"\n",
    "            # if results[0].rx == 'old':\n",
    "            if results[1].rank > results[0].rank:\n",
    "                if metric == 'pf':\n",
    "                    # Old pf < new pf: loss\n",
    "                    result = \"LOSS\"\n",
    "                else:\n",
    "                    result = \"WIN\"\n",
    "            elif results[1].rank == results[0].rank:\n",
    "                result = \"TIE\"\n",
    "            else:\n",
    "                if metric == 'pf':\n",
    "                    result = \"WIN\"\n",
    "                else:\n",
    "                    result = \"LOSS\"\n",
    "            \n",
    "            if results[0].rx == 'new':\n",
    "                # Flip the result\n",
    "                idx = possible_results.index(result)\n",
    "                result = possible_results[2 - idx]\n",
    "            \n",
    "            print(result, end='\\t')\n",
    "        print()\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "??Rx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting results with popt20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivy\n",
      "===\n",
      "\tpopt20\n",
      "GHOST\tWIN (0.6)\t\n",
      "\n",
      "lucene\n",
      "======\n",
      "\tpopt20\n",
      "GHOST\tLOSS (0.68)\t\n",
      "\n",
      "poi\n",
      "===\n",
      "\tpopt20\n",
      "GHOST\tTIE (0.72)\t\n",
      "\n",
      "synapse\n",
      "=======\n",
      "\tpopt20\n",
      "GHOST\tWIN (0.63)\t\n",
      "\n",
      "velocity\n",
      "========\n",
      "\tpopt20\n",
      "GHOST\tLOSS (0.58)\t\n",
      "\n",
      "camel\n",
      "=====\n",
      "\tpopt20\n",
      "GHOST\tLOSS (0.43)\t\n",
      "\n",
      "jedit\n",
      "=====\n",
      "\tpopt20\n",
      "GHOST\tWIN (0.54)\t\n",
      "\n",
      "log4j\n",
      "=====\n",
      "\tpopt20\n",
      "GHOST\tLOSS (0.66)\t\n",
      "\n",
      "xalan\n",
      "=====\n",
      "\tpopt20\n",
      "GHOST\tLOSS (0.61)\t\n",
      "\n",
      "xerces\n",
      "======\n",
      "\tpopt20\n",
      "GHOST\tLOSS (0.61)\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "possible_results = [\"WIN\", \"TIE\", \"LOSS\"]\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    print(file)\n",
    "    print('=' * len(file))\n",
    "    \n",
    "    for metric in [\"popt20\"]:\n",
    "        print('\\t' + metric, end='')\n",
    "    \n",
    "    print()\n",
    "    for alg in ['GHOST']:\n",
    "        print(alg, end='\\t')\n",
    "        \n",
    "        for metric in [\"popt20\"]:\n",
    "            old = get_old_result(file, metric, alg)\n",
    "            new = get_new_result(i, metric, alg)\n",
    "            \n",
    "            data = {'old': old, 'new': new}\n",
    "            results = Rx.sk(Rx.data(**data))\n",
    "            \n",
    "            result = \"\"\n",
    "            # if results[0].rx == 'old':\n",
    "            if results[1].rank > results[0].rank:\n",
    "                if metric == 'pf':\n",
    "                    # Old pf < new pf: loss\n",
    "                    result = \"LOSS\"\n",
    "                else:\n",
    "                    result = \"WIN\"\n",
    "            elif results[1].rank == results[0].rank:\n",
    "                result = \"TIE\"\n",
    "            else:\n",
    "                if metric == 'pf':\n",
    "                    result = \"WIN\"\n",
    "                else:\n",
    "                    result = \"LOSS\"\n",
    "            \n",
    "            if results[0].rx == 'new':\n",
    "                # Flip the result\n",
    "                idx = possible_results.index(result)\n",
    "                result = possible_results[2 - idx]\n",
    "\n",
    "            print(result, f'({round(np.median(new), 2)})', end='\\t')\n",
    "        print()\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
